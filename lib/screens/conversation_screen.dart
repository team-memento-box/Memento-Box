// 0603 ê³ ê¶Œì•„ ì‘ì—…
// ì‚¬ìš©ì ì±—ë´‡ í™”ë©´

import '../utils/audio_service.dart';
import 'dart:convert';
import 'dart:io';
import 'dart:async';
import 'package:http/http.dart' as http;
import 'package:flutter_dotenv/flutter_dotenv.dart';
import 'package:flutter/material.dart';
import 'package:provider/provider.dart';
import 'package:record/record.dart';
import 'package:path_provider/path_provider.dart';
import 'package:permission_handler/permission_handler.dart';
import '../widgets/assistant_bubble.dart'; // ì±—ë´‡ ë§í’ì„  ìœ„ì ¯
import '../widgets/photo_box.dart'; // ê³ ì •ëœ ì‚¬ì§„ ì˜ì—­ ìœ„ì ¯
import '../widgets/user_speech_bubble.dart'; // ì‚¬ìš©ì ìŒì„± ë§í’ì„  ìœ„ì ¯
import '../data/user_data.dart'; // ì§ˆë¬¸/ì‘ë‹µ/ì‚¬ì§„ ì •ë³´ê°€ ë‹´ê¸´ ë°ì´í„° íŒŒì¼
import '../user_provider.dart';
import '../utils/routes.dart';
import '../utils/styles.dart';
import '../models/photo.dart';
import '../models/question.dart';

class PhotoConversationScreen extends StatefulWidget {
  final String photoId;
  final String photoUrl;

  const PhotoConversationScreen({
    Key? key,
    required this.photoId,
    required this.photoUrl,
  }) : super(key: key);

  @override
  State<PhotoConversationScreen> createState() =>
      _PhotoConversationScreenState();
}

class _PhotoConversationScreenState extends State<PhotoConversationScreen> {
  late String photoId;
  late String photoUrl;

  String apiResult = 'Loading...';
  // String assistantText = 'ì´ˆê¸° í…ìŠ¤íŠ¸';
  String photoPath = 'ì´ˆê¸° url';
  // String userSpeechText = 'ì´ˆê¸° ëŒ€ë‹µ';
  String? _conversationId;
  bool shouldEnd = false;

  // TTS, STT ê¸°ëŠ¥ì´ ë™ì‘ ì¤‘ì¸ì§€ ì—¬ë¶€ë¥¼ ì €ì¥í•˜ëŠ” ìƒíƒœ ë³€ìˆ˜
  bool isTTSActive = false;
  bool isSTTActive = false;

  // ì¢…ë£Œ í”Œë˜ê·¸
  bool _isConversationActive = true;

  // ìŒì„± ì¸ì‹ ê´€ë ¨ ë³€ìˆ˜ë“¤
  late AudioRecorder _audioRecorder;
  bool _isRecording = false;
  String _recognizedText = '...';
  String? _recordingPath;
  Timer? _silenceTimer;
  StreamSubscription<Amplitude>? _amplitudeSubscription;
  // ë¬´ìŒ ê°ì§€ ì„¤ì •
  final double _silenceThreshold = -15.0; // dB ë‹¨ìœ„
  final int _silenceDuration = 7000; // ë°€ë¦¬ì´ˆ ë‹¨ìœ„ (7ì´ˆ)

  // === ìë™ ìŒì„± ì¬ìƒì„ ìœ„í•œ AudioService ì¸ìŠ¤í„´ìŠ¤ ===
  late AudioService _audioService;

  // API í˜¸ì¶œ ìƒíƒœ ì¶”ì ì„ ìœ„í•œ ë³€ìˆ˜ ì¶”ê°€
  bool _isApiCallInProgress = false;
  Timer? _apiTimeoutTimer;

  @override
  void initState() {
    super.initState();
    photoId = widget.photoId;
    photoUrl = widget.photoUrl;
    _audioService = AudioService(); // AudioService ì´ˆê¸°í™”
    _isConversationActive = true;
    shouldEnd = false;
    _audioRecorder = AudioRecorder(); // AudioRecorder ì´ˆê¸°í™”
    print('photoId: $photoId');
    print('photoUrl: $photoUrl');

    WidgetsBinding.instance.addPostFrameCallback((_) async {
      while (true) {
        await _startConversation();
        await _startRecording();
        if (shouldEnd == true || !_isConversationActive) break;
      }
      await _audioService.stop(); // ë§Œì•½ ë£¨í”„ íƒˆì¶œ í›„ ì˜¤ë””ì˜¤ ë‚¨ì•„ ìˆìœ¼ë©´ ë©ˆì¶¤
    });
  }

  @override
  void dispose() {
    _amplitudeSubscription?.cancel();
    _audioService.dispose();
    super.dispose();
  }

  Future<void> _startConversation() async {
    try {
      final jsonData = await startConversation(photoId);
      final conversation = ConversationResponse.fromJson(jsonData);

      apiResult = conversation.question;
      photoPath = conversation.photoInfo.url;
      _conversationId = conversation.conversationId;

      setState(() {
        apiResult = conversation.question;
      });

      // === ì´ˆê¸° ì§ˆë¬¸/ìŒì„±íŒŒì¼ë§Œ ì¬ìƒ ===
      if (conversation.audioUrl != null && conversation.audioUrl.isNotEmpty) {
        await _audioService.loadAudio(conversation.audioUrl);
        isTTSActive = true;
        await _audioService.play();
        // ì´ˆê¸° ìŒì„± ì¬ìƒì´ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
        await Future.delayed(const Duration(milliseconds: 500));
      }
    } catch (e) {
      print('âŒ API error: $e');
      setState(() {
        apiResult = 'API failed: $e';
      });
    }
    isTTSActive = false;
  }

  Future<Map<String, dynamic>> startConversation(String imageId) async {
    final baseUrl = dotenv.env['BASE_URL']!;
    print("**********");
    print(imageId);
    print("**********");
    final url = Uri.parse('$baseUrl/api/chat/start?image_id=$imageId');

    final response = await http.post(url);

    if (response.statusCode == 200) {
      // ì—¬ê¸°ì„œ ì‘ë‹µ ë°”ë””ë¥¼ UTF8ë¡œ ë””ì½”ë”©
      final decoded = utf8.decode(response.bodyBytes);
      final Map<String, dynamic> jsonData = jsonDecode(decoded);
      return jsonData;
    } else {
      throw Exception('ëŒ€í™” ì‹œì‘ ì‹¤íŒ¨: ${response.statusCode}, ${response.body}');
    }
  }

  Future<bool> _requestPermissions() async {
    // í˜„ì¬ ê¶Œí•œ ìƒíƒœ í™•ì¸
    final micStatus = await Permission.microphone.status;

    if (micStatus.isGranted) {
      return true;
    }

    // ê¶Œí•œì´ ì—†ëŠ” ê²½ìš° ìš”ì²­
    final result = await Permission.microphone.request();

    if (result.isGranted) {
      return true;
    }

    if (result.isPermanentlyDenied) {
      // ì˜êµ¬ì ìœ¼ë¡œ ê±°ë¶€ëœ ê²½ìš° ì„¤ì •ìœ¼ë¡œ ì´ë™
      await openAppSettings();
    }

    return false;
  }

  Future<void> _startRecording() async {
    try {
      // ê¸°ì¡´ ë…¹ìŒ ì¤‘ì§€ ë° ë¦¬ì†ŒìŠ¤ ì •ë¦¬
      if (_isRecording) {
        await _audioRecorder.stop();
      }
      await _amplitudeSubscription?.cancel();
      _amplitudeSubscription = null;
      _silenceTimer?.cancel();
      _silenceTimer = null;
      _audioRecorder.dispose();
      _audioRecorder = AudioRecorder();

      final hasPermission = await _requestPermissions();

      if (hasPermission) {
        final directory = await getTemporaryDirectory();
        _recordingPath =
            '${directory.path}/audio_${DateTime.now().millisecondsSinceEpoch}.wav';

        // ìƒˆë¡œìš´ ë…¹ìŒ ì‹œì‘
        await _audioRecorder.start(
          RecordConfig(
            encoder: AudioEncoder.wav, // WAV í¬ë§·
            sampleRate: 16000, // 16kHz
            numChannels: 1, // Mono
            bitRate: 256000, // ì‹¤ì œ STTì—ëŠ” ì˜í–¥ ì ì§€ë§Œ ê³ ì •ê°’ ê°€ëŠ¥
          ),
          path: _recordingPath!,
        );

        setState(() {
          _isRecording = true;
          isSTTActive = true;
          _recognizedText = '';
        });

        // ìƒˆë¡œìš´ amplitude ëª¨ë‹ˆí„°ë§ ì‹œì‘
        _amplitudeSubscription = _audioRecorder
            .onAmplitudeChanged(const Duration(milliseconds: 300))
            .listen((amplitude) {
              if (amplitude.current < _silenceThreshold) {
                if (_silenceTimer == null || !_silenceTimer!.isActive) {
                  _silenceTimer = Timer(
                    Duration(milliseconds: _silenceDuration),
                    () {
                      if (_isRecording) {
                        _stopRecording();
                      }
                    },
                  );
                }
              } else {
                _silenceTimer?.cancel();
                _silenceTimer = null;
              }
            });
      } else {
        if (mounted) {
          ScaffoldMessenger.of(context).showSnackBar(
            const SnackBar(
              content: Text('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ì„¤ì •ì—ì„œ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.'),
              duration: Duration(seconds: 2),
            ),
          );
        }
      }
    } catch (e) {
      print('ë…¹ìŒ ì‹œì‘ ì˜¤ë¥˜: $e');
      if (mounted) {
        ScaffoldMessenger.of(context).showSnackBar(
          SnackBar(
            content: Text('ë…¹ìŒ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: $e'),
            duration: const Duration(seconds: 2),
          ),
        );
      }
    }
  }

  Future<void> _stopRecording() async {
    try {
      print('ë…¹ìŒ ì¤‘ì§€ ì‹œë„');
      _silenceTimer?.cancel();
      await _amplitudeSubscription?.cancel();

      await _audioRecorder.stop();
      setState(() {
        _isRecording = false;
        isSTTActive = false;
      });

      if (_recordingPath != null) {
        print('ë…¹ìŒ íŒŒì¼ ê²½ë¡œ: $_recordingPath');
        await _sendAudioToBackend();
      }
    } catch (e) {
      print('ë…¹ìŒ ì¤‘ì§€ ì˜¤ë¥˜: $e');
    }
  }

  // ëª¨ë“  ì‘ì—… ì·¨ì†Œë¥¼ ìœ„í•œ í•¨ìˆ˜
  Future<void> _cancelAllOperations() async {
    // 1. ë…¹ìŒ ì¤‘ì§€ ë° ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    if (_isRecording) {
      await _audioRecorder.stop();
    }
    await _amplitudeSubscription?.cancel();
    _amplitudeSubscription = null;
    _silenceTimer?.cancel();
    _silenceTimer = null;
    _audioRecorder.dispose();

    // 2. TTS ì¤‘ì§€
    await _audioService.pause();

    // 3. API íƒ€ì„ì•„ì›ƒ íƒ€ì´ë¨¸ ì·¨ì†Œ
    _apiTimeoutTimer?.cancel();
    _apiTimeoutTimer = null;

    // 4. API í˜¸ì¶œ ìƒíƒœ ì´ˆê¸°í™”
    _isApiCallInProgress = false;
  }

  Future<void> _sendAudioToBackend() async {
    if (_isApiCallInProgress) return; // ì´ë¯¸ API í˜¸ì¶œ ì¤‘ì´ë©´ ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€

    try {
      _isApiCallInProgress = true;
      print('[ë””ë²„ê·¸] _sendAudioToBackend ì§„ì…');
      final baseUrl = dotenv.env['BASE_URL']!;
      final file = File(_recordingPath!);
      print('[ë””ë²„ê·¸] ë…¹ìŒ íŒŒì¼ ê²½ë¡œ: \\${file.path}');
      print('[ë””ë²„ê·¸] _conversationId: \\${_conversationId}');

      var request = http.MultipartRequest(
        'POST',
        Uri.parse('$baseUrl/api/chat/user_answer'),
      );
      request.files.add(await http.MultipartFile.fromPath('audio', file.path));
      if (_conversationId != null) {
        request.fields['conversation_id'] = _conversationId!;
      } else {
        print('[ê²½ê³ ] _conversationIdê°€ nullì…ë‹ˆë‹¤!');
      }

      var response = await request.send();
      if (!mounted) return; // ìœ„ì ¯ì´ disposeëœ ê²½ìš° ì¤‘ë‹¨

      print('[ë””ë²„ê·¸] ì„œë²„ ì‘ë‹µ ì½”ë“œ: \\${response.statusCode}');
      var responseBody = await response.stream.bytesToString();
      print('[ë””ë²„ê·¸] ì„œë²„ ì‘ë‹µ ë°”ë””: \\${responseBody}');

      if (response.statusCode == 200) {
        final data = jsonDecode(responseBody);
        print('[ë””ë²„ê·¸] ë°›ì€ ì‚¬ìš©ì ë°œí™” í…ìŠ¤íŠ¸: ${data['answer']}');

        if (!mounted) return;
        setState(() {
          _recognizedText = data['answer'] ?? '';
          print('[ë””ë²„ê·¸] _recognizedText ì—…ë°ì´íŠ¸: $_recognizedText');
        });

        // AI ì‘ë‹µ ìŒì„± ì¬ìƒ (ìˆëŠ” ê²½ìš°ì—ë§Œ)
        if (data['audio_url'] != null && data['audio_url'].isNotEmpty) {
          await _audioService.loadAudio(data['audio_url']);

          // TTS ì¬ìƒ ì™„ë£Œ í›„ ë…¹ìŒ ì‹œì‘ì„ ìœ„í•œ ì½œë°± ì„¤ì •
          _audioService.onCompleted = () async {
            if (!mounted) return;

            // ê¸°ì¡´ ë…¹ìŒ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ë° ìƒˆë¡œ ìƒì„±
            if (_isRecording) {
              await _audioRecorder.stop();
            }
            await _amplitudeSubscription?.cancel();
            _amplitudeSubscription = null;
            _silenceTimer?.cancel();
            _silenceTimer = null;
            _audioRecorder.dispose();
            _audioRecorder = AudioRecorder();

            // ëŒ€í™”ê°€ ëë‚˜ì§€ ì•Šì•˜ë‹¤ë©´ AIì˜ ìƒˆë¡œìš´ ì§ˆë¬¸ì„ ë°›ì•„ì˜´
            if (data['should_end'] != true) {
              final nextQuestion = await startConversation(photoId);
              if (!mounted) return;

              final conversation = ConversationResponse.fromJson(nextQuestion);
              setState(() {
                apiResult = conversation.question;
              });

              // AIì˜ ìƒˆë¡œìš´ ì§ˆë¬¸ ìŒì„± ì¬ìƒ
              if (conversation.audioUrl != null &&
                  conversation.audioUrl.isNotEmpty) {
                await _audioService.loadAudio(conversation.audioUrl);
                await _audioService.play();
                // TTS ì¬ìƒ ì™„ë£Œ í›„ ë…¹ìŒ ì‹œì‘ì„ ìœ„í•œ ì½œë°± ì„¤ì •
                _audioService.onCompleted = () {
                  if (mounted) _startRecording();
                };
              } else {
                if (mounted) _startRecording();
              }
            }
          };

          await _audioService.play();
        } else {
          // ìŒì„±ì´ ì—†ëŠ” ê²½ìš° ë°”ë¡œ ë‹¤ìŒ ë‹¨ê³„ ì§„í–‰
          if (data['should_end'] != true) {
            final nextQuestion = await startConversation(photoId);
            if (!mounted) return;

            final conversation = ConversationResponse.fromJson(nextQuestion);
            setState(() {
              apiResult = conversation.question;
            });

            if (conversation.audioUrl != null &&
                conversation.audioUrl.isNotEmpty) {
              await _audioService.loadAudio(conversation.audioUrl);
              await _audioService.play();
              // TTS ì¬ìƒ ì™„ë£Œ í›„ ë…¹ìŒ ì‹œì‘ì„ ìœ„í•œ ì½œë°± ì„¤ì •
              _audioService.onCompleted = () {
                if (mounted) _startRecording();
              };
            } else {
              if (mounted) _startRecording();
            }
          }
        }
      } else {
        print('ì„œë²„ ì˜¤ë¥˜: $responseBody');
      }

      // await file.delete();
    } catch (e, st) {
      print('[ì—ëŸ¬] ì˜¤ë””ì˜¤ ì „ì†¡ ì˜¤ë¥˜: \\${e}');
      print('[ì—ëŸ¬] ìŠ¤íƒíŠ¸ë ˆì´ìŠ¤: \\${st}');
    } finally {
      _isApiCallInProgress = false;
    }
  }

  // Fish-Speech API í˜¸ì¶œ í•¨ìˆ˜
  Future<void> _convertVoice(String aVoiceUrl, String summaryText) async {
    try {
      final baseUrl = dotenv.env['BASE_URL']!;
      final url = Uri.parse('$baseUrl/api/chat/convert');

      var request = http.MultipartRequest('POST', url);
      request.fields['conversation_id'] = _conversationId!;
      request.fields['a_voice_url'] = aVoiceUrl;
      request.fields['summary_text'] = summaryText;

      var response = await request.send();
      var responseBody = await response.stream.bytesToString();

      if (response.statusCode == 200) {
        final data = jsonDecode(responseBody);
        print('ìŒì„± ë³€í™˜ ì„±ê³µ: ${data['url']}');

        // ë³€í™˜ëœ ìŒì„± URLì„ ì €ì¥í•˜ê³  ì¬ìƒ
        if (data['url'] != null) {
          await _audioService.loadAudio(data['url']);
          await _audioService.play();
        }
      } else {
        print('ìŒì„± ë³€í™˜ ì‹¤íŒ¨: ${response.statusCode}');
        if (mounted) {
          ScaffoldMessenger.of(context).showSnackBar(
            const SnackBar(
              content: Text('ìŒì„± ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'),
              duration: Duration(seconds: 2),
            ),
          );
        }
      }
    } catch (e) {
      print('ìŒì„± ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: $e');
      if (mounted) {
        ScaffoldMessenger.of(context).showSnackBar(
          const SnackBar(
            content: Text('ìŒì„± ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'),
            duration: Duration(seconds: 2),
          ),
        );
      }
    }
  }

  Future<void> forceEndConversation() async {
    try {
      final baseUrl = dotenv.env['BASE_URL']!;
      final uri = Uri.parse('$baseUrl/api/chat/force-end');

      var request = http.MultipartRequest('POST', uri);
      request.fields['conversation_id'] = _conversationId ?? '';
      if (apiResult != "Loading...") {
        request.fields['current_question'] = apiResult;
      }

      final response = await request.send();
      final responseBody = await response.stream.bytesToString();

      if (response.statusCode == 200) {
        print('âœ… ëŒ€í™” ê°•ì œ ì¢…ë£Œ ì„±ê³µ');
      } else {
        print('âŒ ì„œë²„ ì˜¤ë¥˜: $responseBody');
      }
    } catch (e) {
      print('ğŸ”¥ ê°•ì œ ì¢…ë£Œ API í˜¸ì¶œ ì‹¤íŒ¨: $e');
    }
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      backgroundColor: const Color(0xFFF7F7F7),

      // ê¸°ì¡´ AppBar ëŒ€ì‹  ì»¤ìŠ¤í…€ ì•±ë°” ì ìš©
      appBar: PreferredSize(
        preferredSize: const Size.fromHeight(114),
        child: _buildCustomAppBar(context),
      ),

      body: SingleChildScrollView(
        child: Padding(
          padding: const EdgeInsets.symmetric(horizontal: 20),
          child: Column(
            crossAxisAlignment: CrossAxisAlignment.start,
            children: [
              const SizedBox(height: 20),

              // ì±—ë´‡ ì§ˆë¬¸ ë§í’ì„  (ê¸°ì¡´ ë””ìì¸ ë°˜ì˜)
              AssistantBubble(text: apiResult, isActive: isTTSActive),

              // const SizedBox(height: 10),

              // ì‚¬ì§„ ì˜ì—­ (375x375) - ê¸°ì¡´ PhotoBox ì‚¬ìš©
              Center(
                child: Padding(
                  padding: const EdgeInsets.symmetric(vertical: 40),
                  child: PhotoBox(photoPath: photoPath, isNetwork: true),
                ),
              ),

              // const SizedBox(height: 20),

              // ì‚¬ìš©ì ìŒì„± ì‘ë‹µ ë§í’ì„ 
              UserSpeechBubble(text: _recognizedText, isActive: isSTTActive),
            ],
          ),
        ),
      ),
    );
  }

  /// ì‚¬ìš©ì ì •ì˜ ìƒë‹¨ íƒ€ì´í‹€ ë°”
  Widget _buildCustomAppBar(BuildContext context) {
    final statusBarHeight = MediaQuery.of(context).padding.top;

    return Container(
      padding: EdgeInsets.only(top: statusBarHeight),
      height: 80 + statusBarHeight,
      color: Colors.white,
      child: Padding(
        padding: const EdgeInsets.symmetric(horizontal: 20),
        child: Row(
          mainAxisAlignment: MainAxisAlignment.spaceBetween,
          children: [
            const SizedBox(width: 30), // ì™¼ìª½ ê³µë°±
            Row(
              mainAxisSize: MainAxisSize.min,
              children: [
                Text(
                  'ì‚¬ì§„ íšŒìƒ ëŒ€í™” ì¤‘',
                  style: TextStyle(
                    color: Color(0xFF333333),
                    fontSize: 24,
                    fontWeight: FontWeight.w700,
                    fontFamily: 'Pretendard',
                  ),
                ),
                SizedBox(width: 8),
                Image.asset('assets/icons/Chat.png', color: Color(0xFF333333)),
              ],
            ),
            IconButton(
              icon: const Icon(Icons.close, color: Color(0xFF333333), size: 30),
              onPressed: () {
                showExitModal();
              },
            ),
          ],
        ),
      ),
    );
  }

  /// TTS ìƒíƒœ í† ê¸€ í•¨ìˆ˜ (ì±—ë´‡ ë§í’ì„  ê°•ì¡°ìš©)
  void toggleTTS() {
    setState(() {
      isTTSActive = !isTTSActive;
    });
  }

  /// STT ìƒíƒœ í† ê¸€ í•¨ìˆ˜ (ë§ˆì´í¬ ì•„ì´ì½˜ ê°•ì¡°ìš©)
  void toggleSTT() {
    setState(() {
      isSTTActive = !isSTTActive;
    });
  }

  void showExitModal() async {
    // ëª¨ë“  ì‘ì—… ì·¨ì†Œ
    await _cancelAllOperations();

    if (!mounted) return;

    showModalBottomSheet(
      isScrollControlled: true,
      context: context,
      backgroundColor: const Color.fromARGB(230, 255, 255, 255),
      shape: const RoundedRectangleBorder(
        borderRadius: BorderRadius.vertical(top: Radius.circular(25)),
      ),
      builder: (BuildContext context) {
        return Padding(
          padding: const EdgeInsets.symmetric(horizontal: 40, vertical: 10),
          child: Column(
            mainAxisSize: MainAxisSize.min,
            children: [
              Container(
                width: 60,
                height: 5,
                margin: const EdgeInsets.only(bottom: 16),
                decoration: BoxDecoration(
                  color: Colors.grey[400],
                  borderRadius: BorderRadius.circular(10),
                ),
              ),
              const SizedBox(height: 20),
              const Text(
                'ì •ë§ë¡œ ì§€ê¸ˆ ëŒ€í™”ë¥¼ ì¢…ë£Œí•˜ì‹œê² ì–´ìš”?',
                style: TextStyle(
                  color: Color(0xFF333333),
                  fontSize: 20,
                  fontFamily: 'Pretendard',
                  fontWeight: FontWeight.w700,
                ),
                textAlign: TextAlign.center,
              ),
              const SizedBox(height: 25),
              SizedBox(
                width: double.infinity,
                child: ElevatedButton(
                  onPressed: () {
                    Navigator.pop(context);
                    _startRecording(); // ëŒ€í™” ê³„ì†í•˜ê¸° ì„ íƒ ì‹œ ë…¹ìŒ ë‹¤ì‹œ ì‹œì‘
                  },
                  style: ElevatedButton.styleFrom(
                    backgroundColor: const Color(0xFF00C8B8),
                    padding: const EdgeInsets.symmetric(vertical: 12),
                    shape: RoundedRectangleBorder(
                      borderRadius: BorderRadius.circular(20),
                    ),
                  ),
                  child: const Text(
                    'ëŒ€í™” ê³„ì†í•˜ê¸°',
                    style: TextStyle(
                      color: Colors.white,
                      fontSize: 22,
                      fontFamily: 'Pretendard',
                      fontWeight: FontWeight.w800,
                    ),
                  ),
                ),
              ),
              const SizedBox(height: 12),
              SizedBox(
                width: double.infinity,
                child: OutlinedButton(
                  onPressed: () async {
                    try {
                      if (_conversationId != null) {
                        final baseUrl = dotenv.env['BASE_URL']!;
                        final url = Uri.parse('$baseUrl/api/chat/force-end');

                        var request = http.MultipartRequest('POST', url);
                        request.fields['conversation_id'] = _conversationId!;
                        if (apiResult.isNotEmpty) {
                          request.fields['current_question'] = apiResult;
                        }

                        // 5ì´ˆ íƒ€ì„ì•„ì›ƒ ì„¤ì •
                        var response = await request.send().timeout(
                          const Duration(seconds: 5),
                          onTimeout: () {
                            print('force-end API íƒ€ì„ì•„ì›ƒ');
                            Navigator.pushReplacementNamed(
                              context,
                              Routes.gallery,
                            );
                            throw TimeoutException('force-end API íƒ€ì„ì•„ì›ƒ');
                          },
                        );

                        if (response.statusCode == 200) {
                          print('ëŒ€í™” ê°•ì œ ì¢…ë£Œ ì„±ê³µ');
                          // ëŒ€í™” ì¢…ë£Œ í›„ ìŒì„± ë³€í™˜ ìš”ì²­
                          await _convertVoice(photoUrl, apiResult);
                        } else {
                          print('ëŒ€í™” ê°•ì œ ì¢…ë£Œ ì‹¤íŒ¨: ${response.statusCode}');
                        }
                      }
                    } catch (e) {
                      print('ëŒ€í™” ê°•ì œ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: $e');
                    }

                    // ì–´ë–¤ ê²½ìš°ë“  ê°¤ëŸ¬ë¦¬ë¡œ ì´ë™
                    Navigator.pushReplacementNamed(context, Routes.gallery);
                  },
                  style: OutlinedButton.styleFrom(
                    side: const BorderSide(color: Color(0xFF00C8B8), width: 2),
                    padding: const EdgeInsets.symmetric(vertical: 12),
                    shape: RoundedRectangleBorder(
                      borderRadius: BorderRadius.circular(20),
                    ),
                  ),
                  child: const Text(
                    'ëŒ€í™” ëë‚´ê¸°',
                    style: TextStyle(
                      color: Color(0xFF00C8B8),
                      fontSize: 22,
                      fontFamily: 'Pretendard',
                      fontWeight: FontWeight.w800,
                    ),
                  ),
                ),
              ),
              const SizedBox(height: 20),
            ],
          ),
        );
      },
    );
  }
}
