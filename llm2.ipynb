{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ebe0481",
   "metadata": {},
   "source": [
    "# 1. 데이터 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ac3b483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 설정 및 데이터 클래스가 로드되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 1. 설정 및 데이터 클래스 (config.ipynb)\n",
    "\n",
    "# 필요한 라이브러리 import\n",
    "import json\n",
    "import base64\n",
    "import os\n",
    "import tiktoken\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "@dataclass\n",
    "class StrangeResponse:\n",
    "    \"\"\"이상한 답변을 저장하는 데이터 클래스\"\"\"\n",
    "    question: str\n",
    "    answer: str\n",
    "    timestamp: str\n",
    "    severity: str  # \"mild\", \"moderate\", \"severe\"\n",
    "    question_type: str = \"normal\"  # \"keyword\", \"cognitive\", \"normal\"\n",
    "\n",
    "@dataclass\n",
    "class ConversationTurn:\n",
    "    \"\"\"대화 턴을 저장하는 데이터 클래스\"\"\"\n",
    "    question: str\n",
    "    answer: str\n",
    "    timestamp: str\n",
    "    question_type: str = \"normal\"  # \"keyword\", \"cognitive\", \"normal\"\n",
    "\n",
    "# 설정 상수\n",
    "class Config:\n",
    "    \"\"\"시스템 설정 상수\"\"\"\n",
    "    # Azure OpenAI 설정\n",
    "    ENDPOINT = os.getenv(\"gpt-endpoint\")\n",
    "    DEPLOYMENT = \"gpt-4o\"\n",
    "    SUBSCRIPTION_KEY = os.getenv(\"gpt-key\")\n",
    "    API_VERSION = \"2024-12-01-preview\"\n",
    "    \n",
    "    # 토큰 제한\n",
    "    MAX_TOKENS = 4000\n",
    "    \n",
    "    # 키워드 기반 질문\n",
    "    KEYWORD_QUESTIONS = {\n",
    "        \"남편\": \"남편에게 전하고 싶은 말이 있나요?\",\n",
    "        \"아내\": \"아내분과의 좋은 추억이 또 있나요?\",\n",
    "        \"손자\": \"요즘 손자는 학교 잘 다니나요?\",\n",
    "        \"손녀\": \"손녀는 요즘 뭘 하며 지내나요?\",\n",
    "        \"아들\": \"아들은 요즘 어떻게 지내나요?\",\n",
    "        \"딸\": \"딸과의 추억 중에 특별한 게 있나요?\",\n",
    "        \"엄마\": \"어머님은 어떤 분이셨어요?\",\n",
    "        \"아버지\": \"아버님은 어떤 분이셨나요?\",\n",
    "        \"친구\": \"그 친구분과는 자주 만나셨나요?\",\n",
    "        \"여행\": \"그때 여행이 즐거우셨나요?\",\n",
    "        \"집\": \"그 집에서 살 때가 그리우시나요?\",\n",
    "    }\n",
    "    \n",
    "    # 기본 인지 능력 검사 질문\n",
    "    BASE_COGNITIVE_QUESTIONS = [\n",
    "        \"이 사진에는 몇 명이 있는지 기억나세요?\",\n",
    "        \"사진이 낮에 찍힌 것 같나요, 밤인가요?\",\n",
    "        \"이 사진에서 가장 눈에 띄는 것이 무엇인가요?\",\n",
    "    ]\n",
    "\n",
    "print(\"✅ 설정 및 데이터 클래스가 로드되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11205c56",
   "metadata": {},
   "source": [
    "# 2 이미지 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ebaf6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 이미지 분석기 모듈이 로드되었습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ImageAnalysisGPT:\n",
    "    \"\"\"GPT-4o를 사용한 이미지 분석 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Azure OpenAI 관련 설정\n",
    "        self.endpoint = Config.ENDPOINT\n",
    "        self.deployment = Config.DEPLOYMENT\n",
    "        self.subscription_key = Config.SUBSCRIPTION_KEY\n",
    "        self.api_version = Config.API_VERSION\n",
    "        \n",
    "        if not self.endpoint or not self.subscription_key:\n",
    "            raise ValueError(\"Please set the gpt-endpoint and gpt-key in the environment variables.\")\n",
    "        \n",
    "        # LLM 클라이언트 초기화\n",
    "        self.client = AzureOpenAI(\n",
    "            api_version=self.api_version,\n",
    "            azure_endpoint=self.endpoint,\n",
    "            api_key=self.subscription_key,\n",
    "        )\n",
    "    \n",
    "    def encode_image_to_base64(self, image_path):\n",
    "        \"\"\"이미지를 base64로 인코딩\"\"\"\n",
    "        try:\n",
    "            with open(image_path, \"rb\") as image_file:\n",
    "                return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: 이미지 파일을 찾을 수 없습니다: {image_path}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"이미지 인코딩 오류: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def analyze_image_with_gpt(self, image_path):\n",
    "        \"\"\"GPT-4o를 사용하여 이미지 분석\"\"\"\n",
    "        # 이미지를 base64로 인코딩\n",
    "        base64_image = self.encode_image_to_base64(image_path)\n",
    "        if not base64_image:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.deployment,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": \"\"\"이 이미지를 자세히 분석해서 다음 정보를 JSON 형식으로 제공해주세요:\n",
    "\n",
    "1. caption: 이미지의 전체적인 설명 (구체적으로 그리고 한편의 이야기처럼)\n",
    "2. dense_captions: 이미지의 세부적인 요소들을 여러 문장으로 설명 (배열 형태)\n",
    "3. mood: 이미지에서 느껴지는 분위기나 감정\n",
    "4. time_period: 추정되는 시대나 시기\n",
    "5. key_objects: 주요 객체들 (배열 형태)\n",
    "6. people_description: 사람이 있다면 그들에 대한 설명\n",
    "7. people_count: 사진 속 사람 수 (숫자로)\n",
    "8. time_of_day: 촬영 시간대 (낮/밤/저녁 등)\n",
    "\n",
    "다음과 같은 JSON 형식으로 답해주세요:\n",
    "{\n",
    "    \"caption\": \"전체 이미지 설명\",\n",
    "    \"dense_captions\": [\"세부사항1\", \"세부사항2\", \"세부사항3\"],\n",
    "    \"mood\": \"분위기 설명\",\n",
    "    \"time_period\": \"추정 시대\",\n",
    "    \"key_objects\": [\"객체1\", \"객체2\", \"객체3\"],\n",
    "    \"people_description\": \"사람들에 대한 설명\",\n",
    "    \"people_count\": 2,\n",
    "    \"time_of_day\": \"낮\"\n",
    "}\"\"\"\n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"image_url\",\n",
    "                                \"image_url\": {\n",
    "                                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                                }\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "                max_tokens=1000,\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            # 응답에서 JSON 추출\n",
    "            response_text = response.choices[0].message.content\n",
    "            \n",
    "            # JSON 부분만 추출 (```json으로 감싸져 있을 수 있음)\n",
    "            if \"```json\" in response_text:\n",
    "                json_start = response_text.find(\"```json\") + 7\n",
    "                json_end = response_text.find(\"```\", json_start)\n",
    "                response_text = response_text[json_start:json_end].strip()\n",
    "            elif \"{\" in response_text:\n",
    "                json_start = response_text.find(\"{\")\n",
    "                json_end = response_text.rfind(\"}\") + 1\n",
    "                response_text = response_text[json_start:json_end]\n",
    "            \n",
    "            analysis_result = json.loads(response_text)\n",
    "            \n",
    "            # 결과 출력\n",
    "            print(f\"\\nCaption: {analysis_result.get('caption', 'N/A')}\")\n",
    "            print(f\"Mood: {analysis_result.get('mood', 'N/A')}\")\n",
    "            print(f\"Time Period: {analysis_result.get('time_period', 'N/A')}\")\n",
    "            print(f\"People Count: {analysis_result.get('people_count', 'N/A')}\")\n",
    "            print(f\"Time of Day: {analysis_result.get('time_of_day', 'N/A')}\")\n",
    "            print(\"\\nDense Captions:\")\n",
    "            for caption in analysis_result.get('dense_captions', []):\n",
    "                print(f\"- {caption}\")\n",
    "            \n",
    "            return analysis_result\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON 파싱 오류: {e}\")\n",
    "            print(f\"원본 응답: {response_text}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"이미지 분석 오류: {e}\")\n",
    "            return None\n",
    "\n",
    "# 테스트 함수\n",
    "def test_image_analyzer():\n",
    "    \"\"\"이미지 분석기 테스트\"\"\"\n",
    "    # 테스트용 이미지 경로 (실제 사용시 변경 필요)\n",
    "    test_image_path = \"test_image.jpg\"\n",
    "    \n",
    "    if os.path.exists(test_image_path):\n",
    "        analyzer = ImageAnalysisGPT()\n",
    "        result = analyzer.analyze_image_with_gpt(test_image_path)\n",
    "        return result\n",
    "    else:\n",
    "        print(f\"테스트 이미지 파일이 없습니다: {test_image_path}\")\n",
    "        return None\n",
    "\n",
    "print(\"✅ 이미지 분석기 모듈이 로드되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41573b1",
   "metadata": {},
   "source": [
    "# 3. 대화 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e30f9309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 대화 관리자 모듈이 로드되었습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ConversationManager:\n",
    "    \"\"\"대화 관리 및 평가 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Azure OpenAI 관련 설정\n",
    "        self.endpoint = Config.ENDPOINT\n",
    "        self.deployment = Config.DEPLOYMENT\n",
    "        self.subscription_key = Config.SUBSCRIPTION_KEY\n",
    "        self.api_version = Config.API_VERSION\n",
    "        \n",
    "        if not self.endpoint or not self.subscription_key:\n",
    "            raise ValueError(\"Please set the gpt-endpoint and gpt-key in the environment variables.\")\n",
    "        \n",
    "        # LLM 클라이언트 초기화\n",
    "        self.client = AzureOpenAI(\n",
    "            api_version=self.api_version,\n",
    "            azure_endpoint=self.endpoint,\n",
    "            api_key=self.subscription_key,\n",
    "        )\n",
    "        \n",
    "        # 대화 기록 초기화\n",
    "        self.conversation_history = []\n",
    "        \n",
    "        # 토큰 카운터 초기화\n",
    "        self.tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        self.token_count = 0\n",
    "        self.MAX_TOKENS = Config.MAX_TOKENS\n",
    "        \n",
    "        # 이상한 답변 추적\n",
    "        self.strange_responses = []\n",
    "        self.strange_response_count = 0\n",
    "        self.last_question = \"\"\n",
    "        self.last_question_type = \"normal\"\n",
    "        \n",
    "        # 대화 기록 추적\n",
    "        self.conversation_turns = []\n",
    "        \n",
    "        # 실시간 대화 시스템 관련 변수\n",
    "        self.turn_count = 0\n",
    "        self.image_analysis_result = None\n",
    "        \n",
    "    def _count_tokens(self, text: str) -> int:\n",
    "        \"\"\"문자열의 토큰 수 계산\"\"\"\n",
    "        return len(self.tokenizer.encode(text))\n",
    "    \n",
    "    def _count_message_tokens(self, messages: List[Dict[str, Any]]) -> int:\n",
    "        \"\"\"대화 메시지 목록의 총 토큰 수 계산\"\"\"\n",
    "        total = 0\n",
    "        for message in messages:\n",
    "            total += self._count_tokens(message.get(\"content\", \"\"))\n",
    "        return total\n",
    "    \n",
    "    def _evaluate_response_relevance(self, question: str, answer: str, question_type: str = \"normal\") -> Dict[str, Any]:\n",
    "        \"\"\"답변이 질문과 얼마나 관련성이 있는지 LLM으로 평가\"\"\"\n",
    "        \n",
    "        # 질문 타입에 따른 평가 기준 조정\n",
    "        if question_type == \"cognitive\":\n",
    "            evaluation_criteria = \"\"\"\n",
    "특별히 이 질문은 인지 능력을 테스트하는 질문입니다. 다음을 중점적으로 평가해주세요:\n",
    "- 질문에서 요구하는 구체적인 정보를 제공했는지 (예: 숫자, 시간대 등)\n",
    "- 현실 인식 능력이 적절한지\n",
    "- 시공간 지남력이 유지되고 있는지\n",
    "\"\"\"\n",
    "        elif question_type == \"keyword\":\n",
    "            evaluation_criteria = \"\"\"\n",
    "이 질문은 특정 키워드를 기반으로 한 감정적 연결 질문입니다. 다음을 평가해주세요:\n",
    "- 질문의 대상(사람이나 상황)에 대한 적절한 반응인지\n",
    "- 감정적 연결성이 있는지\n",
    "- 기억과 관련된 적절한 내용인지\n",
    "\"\"\"\n",
    "        else:\n",
    "            evaluation_criteria = \"\"\"\n",
    "일반적인 대화 질문입니다. 다음을 평가해주세요:\n",
    "- 질문과 답변의 일반적인 관련성\n",
    "- 대화의 자연스러운 흐름\n",
    "\"\"\"\n",
    "        \n",
    "        evaluation_prompt = f\"\"\"\n",
    "다음 질문과 답변을 분석해서 답변이 얼마나 적절한지 평가해주세요.\n",
    "\n",
    "질문: {question}\n",
    "답변: {answer}\n",
    "질문 타입: {question_type}\n",
    "\n",
    "{evaluation_criteria}\n",
    "\n",
    "평가 기준:\n",
    "1. 질문과 답변의 관련성\n",
    "2. 답변의 일관성\n",
    "3. 맥락적 적절성\n",
    "\n",
    "다음 JSON 형식으로만 답해주세요:\n",
    "{{\n",
    "    \"is_strange\": true/false,\n",
    "    \"severity\": \"normal/mild/moderate/severe\",\n",
    "    \"reason\": \"평가 이유를 간단히 설명\"\n",
    "}}\n",
    "\n",
    "severity 기준:\n",
    "- normal: 완전히 적절한 답변\n",
    "- mild: 약간 벗어났지만 이해 가능\n",
    "- moderate: 상당히 엉뚱하지만 완전히 무관하지는 않음\n",
    "- severe: 완전히 무관하거나 비논리적인 답변\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.deployment,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"당신은 치매 환자의 답변을 평가하는 의료 전문가입니다. 객관적이고 정확하게 평가해주세요.\"},\n",
    "                    {\"role\": \"user\", \"content\": evaluation_prompt}\n",
    "                ],\n",
    "                max_tokens=256,\n",
    "                temperature=0.1,\n",
    "                top_p=1.0,\n",
    "            )\n",
    "            \n",
    "            evaluation_text = response.choices[0].message.content\n",
    "            \n",
    "            # JSON 부분만 추출\n",
    "            if \"```json\" in evaluation_text:\n",
    "                json_start = evaluation_text.find(\"```json\") + 7\n",
    "                json_end = evaluation_text.find(\"```\", json_start)\n",
    "                evaluation_text = evaluation_text[json_start:json_end].strip()\n",
    "            elif \"{\" in evaluation_text:\n",
    "                json_start = evaluation_text.find(\"{\")\n",
    "                json_end = evaluation_text.rfind(\"}\") + 1\n",
    "                evaluation_text = evaluation_text[json_start:json_end]\n",
    "            \n",
    "            evaluation_json = json.loads(evaluation_text)\n",
    "            return evaluation_json\n",
    "            \n",
    "        except (json.JSONDecodeError, Exception) as e:\n",
    "            print(f\"답변 평가 중 오류 발생: {e}\")\n",
    "            # 기본값 반환\n",
    "            return {\n",
    "                \"is_strange\": False,\n",
    "                \"severity\": \"normal\",\n",
    "                \"reason\": \"평가 실패\"\n",
    "            }\n",
    "    \n",
    "    def _store_strange_response(self, question: str, answer: str, severity: str, reason: str, question_type: str = \"normal\"):\n",
    "        \"\"\"이상한 답변을 저장\"\"\"\n",
    "        strange_response = StrangeResponse(\n",
    "            question=question,\n",
    "            answer=answer,\n",
    "            timestamp=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            severity=severity,\n",
    "            question_type=question_type\n",
    "        )\n",
    "        \n",
    "        self.strange_responses.append(strange_response)\n",
    "        self.strange_response_count += 1\n",
    "    \n",
    "    def _generate_dynamic_cognitive_questions(self):\n",
    "        \"\"\"이미지 분석 결과를 바탕으로 동적 인지 질문 생성\"\"\"\n",
    "        if not self.image_analysis_result:\n",
    "            return Config.BASE_COGNITIVE_QUESTIONS\n",
    "        \n",
    "        dynamic_questions = []\n",
    "        \n",
    "        # 사람 수 관련 질문\n",
    "        people_count = self.image_analysis_result.get('people_count', 0)\n",
    "        if people_count > 0:\n",
    "            dynamic_questions.append(f\"이 사진에는 몇 명이 있는지 기억나세요?\")\n",
    "        \n",
    "        # 시간대 관련 질문\n",
    "        time_of_day = self.image_analysis_result.get('time_of_day', '')\n",
    "        if time_of_day:\n",
    "            dynamic_questions.append(f\"사진이 낮에 찍힌 것 같나요, 밤인가요?\")\n",
    "        \n",
    "        # 주요 객체 관련 질문\n",
    "        key_objects = self.image_analysis_result.get('key_objects', [])\n",
    "        if key_objects:\n",
    "            obj = random.choice(key_objects)\n",
    "            dynamic_questions.append(f\"이 사진에서 {obj}이(가) 보이시나요?\")\n",
    "        \n",
    "        # 기본 질문과 합쳐서 반환\n",
    "        all_questions = Config.BASE_COGNITIVE_QUESTIONS + dynamic_questions\n",
    "        return all_questions\n",
    "    \n",
    "    def _get_next_question_type_and_content(self, user_input):\n",
    "        \"\"\"다음 질문의 타입과 내용을 결정하는 통합 로직\"\"\"\n",
    "        self.turn_count += 1\n",
    "        \n",
    "        # 1. 키워드 기반 질문 체크 (우선순위 1)\n",
    "        for keyword, question in Config.KEYWORD_QUESTIONS.items():\n",
    "            if keyword in user_input:\n",
    "                return \"keyword\", question\n",
    "        \n",
    "        # 2. 인지 능력 검사 질문 (3턴마다, 우선순위 2)\n",
    "        if self.turn_count > 0 and self.turn_count % 3 == 0:\n",
    "            cognitive_questions = self._generate_dynamic_cognitive_questions()\n",
    "            question = random.choice(cognitive_questions)\n",
    "            return \"cognitive\", question\n",
    "        \n",
    "        # 3. 일반 대화 계속 (우선순위 3)\n",
    "        return \"normal\", None\n",
    "\n",
    "print(\"✅ 대화 관리자 모듈이 로드되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2332180e",
   "metadata": {},
   "source": [
    "# 4. 채팅 시스템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82e24316",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ChatSystem(ConversationManager):\n",
    "    \"\"\"실시간 채팅 시스템 클래스\"\"\"\n",
    "    \n",
    "    def setup_conversation_context(self, analysis_result, user_description=\"\", user_description_date=\"\"):\n",
    "        \"\"\"대화 컨텍스트 설정\"\"\"\n",
    "        self.image_analysis_result = analysis_result  # 이미지 분석 결과 저장\n",
    "        \n",
    "        caption = analysis_result.get(\"caption\", \"\")\n",
    "        dense_captions = analysis_result.get(\"dense_captions\", [])\n",
    "        mood = analysis_result.get(\"mood\", \"\")\n",
    "        time_period = analysis_result.get(\"time_period\", \"\")\n",
    "        key_objects = analysis_result.get(\"key_objects\", [])\n",
    "        people_description = analysis_result.get(\"people_description\", \"\")\n",
    "        \n",
    "        # 상세 캡션 텍스트 포맷팅\n",
    "        dense_captions_text = \"\\n\".join([f\"- {dc}\" for dc in dense_captions])\n",
    "        key_objects_text = \", \".join(key_objects)\n",
    "        \n",
    "        # 통합된 시스템 메시지 설정\n",
    "        system_message = f\"\"\"너는 노인과 대화하는 요양보호사야. 노인과 특정 이미지에 대해서 질의응답을 주고받아. \n",
    "노인은 치매 증상이 갑자기 나타날 수도 있어. 반복되는 말에도 똑같이 대답해줘야 해. \n",
    "친절하고 어른을 공경하는 말투여야 해. 그리고 공감을 잘 해야 해. 예의도 지켜. \n",
    "너는 주로 질문을 하는 쪽이고, 노인은 대답을 해줄거야. 대답에 대한 리액션과 함께 적절히 대화를 이어 가.\n",
    "노인의 발언이 끝나면 그와 관련된 공감 문장을 먼저 말한 후, 자연스럽게 그 기억에 대해 더 물어보는 꼬리 질문을 덧붙여.\n",
    "그리고 질문을 줄 때 한문장으로 간단 명료하게 해줘.\n",
    "\n",
    "=== 이미지 분석 결과 ===\n",
    "주요 설명(Caption): {caption}\n",
    "분위기/감정: {mood}\n",
    "추정 시대: {time_period}\n",
    "주요 객체들: {key_objects_text}\n",
    "인물 설명: {people_description}\n",
    "\n",
    "세부 요소들:\n",
    "{dense_captions_text}\n",
    "\n",
    "=== 대화 가이드라인 ===\n",
    "1. 어르신들(특히 치매 환자)과 대화한다고 가정하고 친근하고 따뜻하게 대화하세요.\n",
    "2. 이미지에 대한 흥미로운 질문을 먼저 던져 대화를 시작하세요.\n",
    "3. 사용자가 엉뚱한 답변을 해도 자연스럽게 이어가며 친절하게 이끌어주세요.\n",
    "4. 그때 당시의 감정이나 경험에 대해 물어보며 추억을 되살려주세요.\n",
    "5. 그리고 긴 질문은 피하고, 한문장으로 간단하고 감성적으로 질문해줘.\n",
    "=== 대화 전략 ===\n",
    "문제 상황별 해결 방법:\n",
    "\n",
    "▪ 질문을 이해하지 못할 경우:\n",
    "  - 질문을 단순화하여 재구성\n",
    "  - 선택지를 제공하여 답하기 쉽게 만들기\n",
    "  - 예시나 맥락을 함께 제공\n",
    "\n",
    "▪ 엉뚱한 대답을 할 경우:\n",
    "  - 대답을 수용하면서 자연스럽게 주제로 유도\n",
    "  - 대답의 일부분이라도 연결점을 찾아 이어가기\n",
    "\n",
    "▪ 대답을 못할 경우:\n",
    "  - 심리적 부담 없이 넘어가기\n",
    "  - \"기억이 안 나셔도 괜찮다\"고 안심시키기\n",
    "\n",
    "이미지의 시각적 요소들을 생생하게 묘사하며, 그때의 감정과 상황에 대해 궁금해하는 손자/손녀의 마음으로 대화하세요.\"\"\"\n",
    "        \n",
    "        # 대화 기록 초기화 및 토큰 수 계산\n",
    "        self.conversation_history = [{\"role\": \"system\", \"content\": system_message}]\n",
    "        self.token_count = self._count_tokens(system_message)\n",
    "        \n",
    "        return system_message\n",
    "    \n",
    "    def generate_initial_question(self):\n",
    "        \"\"\"첫 질문 생성 함수\"\"\"\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.deployment,\n",
    "            messages=self.conversation_history + [\n",
    "                {\"role\": \"user\", \"content\": \"이 옛날 사진에 대해 어르신에게 물어볼 첫 질문을 만들어주세요. 간단하고 기억하기 쉬우며, 감정적으로 연결될 수 있는 질문이어야 합니다.\"}\n",
    "            ],\n",
    "            max_tokens=512,\n",
    "            temperature=0.8,\n",
    "            top_p=1.0,\n",
    "        )\n",
    "        \n",
    "        initial_question = response.choices[0].message.content\n",
    "        \n",
    "        # 질문 추가 및 토큰 수 업데이트\n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": initial_question})\n",
    "        self.token_count += self._count_tokens(initial_question)\n",
    "        \n",
    "        # 마지막 질문 저장\n",
    "        self.last_question = initial_question\n",
    "        self.last_question_type = \"normal\"\n",
    "        \n",
    "        return initial_question\n",
    "    \n",
    "    def chat_about_image(self, user_query):\n",
    "        \"\"\"사용자 질문에 대한 응답 생성\"\"\"\n",
    "        # 토큰 제한 확인\n",
    "        user_tokens = self._count_tokens(user_query)\n",
    "        \n",
    "        # 사용자 답변의 적절성 평가 (이전 질문이 있는 경우)\n",
    "        if self.last_question:\n",
    "            evaluation = self._evaluate_response_relevance(\n",
    "                self.last_question, \n",
    "                user_query, \n",
    "                self.last_question_type\n",
    "            )\n",
    "            \n",
    "            if evaluation.get(\"is_strange\", False):\n",
    "                severity = evaluation.get(\"severity\", \"mild\")\n",
    "                reason = evaluation.get(\"reason\", \"관련성 부족\")\n",
    "                \n",
    "                # 이상한 답변 저장\n",
    "                self._store_strange_response(\n",
    "                    question=self.last_question,\n",
    "                    answer=user_query,\n",
    "                    severity=severity,\n",
    "                    reason=reason,\n",
    "                    question_type=self.last_question_type\n",
    "                )\n",
    "        \n",
    "        # 대화 턴 저장 (질문-답변 쌍)\n",
    "        if self.last_question:\n",
    "            conversation_turn = ConversationTurn(\n",
    "                question=self.last_question,\n",
    "                answer=user_query,\n",
    "                timestamp=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                question_type=self.last_question_type\n",
    "            )\n",
    "            self.conversation_turns.append(conversation_turn)\n",
    "        \n",
    "        # 사용자 입력 추가\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": user_query})\n",
    "        self.token_count += user_tokens\n",
    "        \n",
    "        # 토큰 제한 초과 확인\n",
    "        if self.token_count > self.MAX_TOKENS:\n",
    "            answer = \"죄송합니다, 나중에 다시 얘기해요. 지금은 잠시 쉬어야 할 것 같아요. 만약 더 많은 대화를 원한다면 MEMENTO BOX Premium을 사용해보세요.\"\n",
    "            self.conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "            return answer, True, \"normal\"  # True는 대화 종료 신호\n",
    "        \n",
    "        # 다음 질문 타입과 내용 결정\n",
    "        next_question_type, special_question = self._get_next_question_type_and_content(user_query)\n",
    "        \n",
    "        if special_question:\n",
    "            # 특별 질문 (키워드 기반 또는 인지 검사)\n",
    "            answer = special_question\n",
    "            question_type = next_question_type\n",
    "        else:\n",
    "            # 일반 LLM 응답 생성\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.deployment,\n",
    "                messages=self.conversation_history,\n",
    "                max_tokens=1024,\n",
    "                temperature=0.7,\n",
    "                top_p=1.0,\n",
    "            )\n",
    "            answer = response.choices[0].message.content\n",
    "            question_type = \"normal\"\n",
    "        \n",
    "        # 응답 추가 및 토큰 수 업데이트\n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "        self.token_count += self._count_tokens(answer)\n",
    "        \n",
    "        # 다음 평가를 위해 현재 AI 응답을 질문으로 저장\n",
    "        self.last_question = answer\n",
    "        self.last_question_type = question_type\n",
    "        \n",
    "        # 토큰 제한 초과 확인 (응답 후)\n",
    "        if self.token_count > self.MAX_TOKENS:\n",
    "            return answer, True, question_type  # 대화 종료 신호\n",
    "        \n",
    "        return answer, False, question_type  # 대화 계속\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1bd3a9",
   "metadata": {},
   "source": [
    "# 5. 리포트 생성기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b24ee02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 리포트 생성기 모듈이 로드되었습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ReportGenerator:\n",
    "    \"\"\"리포트 생성 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, chat_system):\n",
    "        self.chat_system = chat_system\n",
    "        \n",
    "    def setup_korean_font(self):\n",
    "        \"\"\"한글 폰트 설정\"\"\"\n",
    "        try:\n",
    "            # Windows\n",
    "            font_path = \"C:/Windows/Fonts/malgun.ttf\"\n",
    "            if not os.path.exists(font_path):\n",
    "                # macOS\n",
    "                font_path = \"/System/Library/Fonts/AppleGothic.ttf\"\n",
    "                if not os.path.exists(font_path):\n",
    "                    # Linux (Ubuntu)\n",
    "                    font_path = \"/usr/share/fonts/truetype/nanum/NanumGothic.ttf\"\n",
    "            \n",
    "            if os.path.exists(font_path):\n",
    "                font_prop = fm.FontProperties(fname=font_path)\n",
    "                plt.rcParams['font.family'] = font_prop.get_name()\n",
    "            else:\n",
    "                # 기본 폰트 사용\n",
    "                plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "        except:\n",
    "            plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "        \n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "    \n",
    "    def generate_mobile_report(self, image_path, output_dir=\"reports\"):\n",
    "        \"\"\"모바일 화면에 최적화된 리포트 생성\"\"\"\n",
    "        \n",
    "        # 한글 폰트 설정\n",
    "        self.setup_korean_font()\n",
    "        \n",
    "        # 리포트 디렉토리 생성\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # 전체 답변 횟수 계산\n",
    "        total_responses = len(self.chat_system.conversation_turns)\n",
    "        \n",
    "        if total_responses == 0:\n",
    "            print(\"대화가 진행되지 않았습니다.\")\n",
    "            return None\n",
    "        \n",
    "        # 심각도별 분류\n",
    "        severity_counts = {\"mild\": 0, \"moderate\": 0, \"severe\": 0}\n",
    "        question_type_counts = {\"normal\": 0, \"keyword\": 0, \"cognitive\": 0}\n",
    "        \n",
    "        for response in self.chat_system.strange_responses:\n",
    "            severity_counts[response.severity] += 1\n",
    "        \n",
    "        for turn in self.chat_system.conversation_turns:\n",
    "            question_type_counts[turn.question_type] += 1\n",
    "        \n",
    "        # 위험도 점수 계산\n",
    "        risk_score = (severity_counts['mild'] * 1 + \n",
    "                     severity_counts['moderate'] * 3 + \n",
    "                     severity_counts['severe'] * 5)\n",
    "        max_risk_score = self.chat_system.strange_response_count * 5 if self.chat_system.strange_response_count > 0 else 1\n",
    "        risk_percentage = (risk_score / max_risk_score * 100) if max_risk_score > 0 else 0\n",
    "        \n",
    "        # 모바일 화면에 최적화된 세로형 레이아웃 생성\n",
    "        fig = plt.figure(figsize=(9, 16), facecolor='#f8f9fa')\n",
    "        \n",
    "        # 전체 타이틀 추가\n",
    "        fig.suptitle('통합 치매 진단 대화 분석 리포트', fontsize=18, fontweight='bold', y=0.98, color='#2c3e50')\n",
    "        \n",
    "        # 1. 상단: 원본 이미지 표시\n",
    "        ax1 = plt.subplot2grid((8, 2), (0, 0), colspan=2, rowspan=1)\n",
    "        try:\n",
    "            img = Image.open(image_path)\n",
    "            img.thumbnail((500, 300), Image.Resampling.LANCZOS)\n",
    "            ax1.imshow(img)\n",
    "            ax1.axis('off')\n",
    "            for spine in ax1.spines.values():\n",
    "                spine.set_visible(True)\n",
    "                spine.set_linewidth(2)\n",
    "                spine.set_color('#34495e')\n",
    "        except Exception as e:\n",
    "            ax1.text(0.5, 0.5, f'이미지 로드 실패\\n{os.path.basename(image_path)}', \n",
    "                    ha='center', va='center', fontsize=12, \n",
    "                    bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"#e74c3c\", alpha=0.8, edgecolor='none'))\n",
    "            ax1.set_xlim(0, 1)\n",
    "            ax1.set_ylim(0, 1)\n",
    "            ax1.axis('off')\n",
    "        \n",
    "        # 2. 왼쪽: 주요 수치 표시\n",
    "        ax2 = plt.subplot2grid((8, 2), (1, 0), rowspan=2)\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        stats_text = f\"\"\"[통합 대화 분석 결과]\n",
    "\n",
    "▪ 전체 답변: {total_responses}회\n",
    "▪ 이상 답변: {self.chat_system.strange_response_count}회 ({(self.chat_system.strange_response_count/total_responses*100):.1f}%)\n",
    "▪ 위험도: {risk_percentage:.1f}% ({risk_score}/{max_risk_score}점)\n",
    "\n",
    "대화 타입별 분류:\n",
    "  ● 일반: {question_type_counts['normal']}회\n",
    "  ● 키워드: {question_type_counts['keyword']}회\n",
    "  ● 인지검사: {question_type_counts['cognitive']}회\n",
    "\n",
    "심각도별 분류:\n",
    "  ● 경미: {severity_counts['mild']}회\n",
    "  ● 보통: {severity_counts['moderate']}회  \n",
    "  ● 심각: {severity_counts['severe']}회\"\"\"\n",
    "        \n",
    "        ax2.text(0.05, 0.95, stats_text, fontsize=11, va='top', \n",
    "                bbox=dict(boxstyle=\"round,pad=0.8\", facecolor=\"#ecf0f1\", alpha=0.9, \n",
    "                         edgecolor='#bdc3c7', linewidth=1.5))\n",
    "        \n",
    "        # 3. 오른쪽: 상세 기록 예시\n",
    "        ax3 = plt.subplot2grid((8, 2), (1, 1), rowspan=2)\n",
    "        ax3.axis('off')\n",
    "        \n",
    "        detail_examples = \"[상세 기록 예시]\\n\\n\"\n",
    "        \n",
    "        if self.chat_system.strange_response_count > 0:\n",
    "            examples_to_show = min(3, len(self.chat_system.strange_responses))\n",
    "            for i, response in enumerate(self.chat_system.strange_responses[:examples_to_show]):\n",
    "                severity_symbol = {\"mild\": \"●\", \"moderate\": \"●\", \"severe\": \"●\"}\n",
    "                severity_name = {\"mild\": \"경미\", \"moderate\": \"보통\", \"severe\": \"심각\"}\n",
    "                type_name = {\"normal\": \"일반\", \"keyword\": \"키워드\", \"cognitive\": \"인지\"}\n",
    "                \n",
    "                detail_examples += f\"{severity_symbol[response.severity]} [{severity_name[response.severity]}][{type_name[response.question_type]}]\\n\"\n",
    "                detail_examples += f\"Q: {response.question[:20]}...\\n\"\n",
    "                detail_examples += f\"A: {response.answer[:20]}...\\n\\n\"\n",
    "            \n",
    "            if len(self.chat_system.strange_responses) > 3:\n",
    "                detail_examples += f\"... 외 {len(self.chat_system.strange_responses) - 3}건 더\"\n",
    "        else:\n",
    "            detail_examples += \"✓ 이상 답변이 감지되지\\n    않았습니다.\\n\\n정상적인 대화가\\n진행되었습니다.\"\n",
    "        \n",
    "        ax3.text(0.05, 0.95, detail_examples, fontsize=10, va='top',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.8\", \n",
    "                         facecolor=\"#fff3cd\" if self.chat_system.strange_response_count > 0 else \"#d4edda\", \n",
    "                         alpha=0.9, \n",
    "                         edgecolor='#ffeaa7' if self.chat_system.strange_response_count > 0 else '#c3e6cb', \n",
    "                         linewidth=1.5))\n",
    "        \n",
    "        # 4-7. 차트들 (간소화)\n",
    "        self._add_charts(fig, severity_counts, question_type_counts, total_responses)\n",
    "        \n",
    "        # 8. 하단: 권장사항\n",
    "        self._add_recommendation(fig, severity_counts, risk_percentage, question_type_counts)\n",
    "        \n",
    "        # 전체 레이아웃 조정\n",
    "        plt.tight_layout(rect=[0, 0.08, 1, 0.95], pad=2.0)\n",
    "        \n",
    "        # 파일명 생성 및 저장\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        image_basename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        report_filename = os.path.join(output_dir, f\"{image_basename}_report_{timestamp}.png\")\n",
    "        \n",
    "        plt.savefig(report_filename, dpi=200, bbox_inches='tight', \n",
    "                    facecolor='#f8f9fa', edgecolor='none', format='png')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"📱 모바일 리포트가 생성되었습니다: {report_filename}\")\n",
    "        return report_filename\n",
    "    \n",
    "    def _add_charts(self, fig, severity_counts, question_type_counts, total_responses):\n",
    "        \"\"\"차트 추가 (간소화된 버전)\"\"\"\n",
    "        # 4. 대화 분석 바 그래프\n",
    "        ax4 = plt.subplot2grid((8, 2), (3, 0), rowspan=2)\n",
    "        \n",
    "        categories = ['정상\\n답변', '이상\\n답변']\n",
    "        counts = [total_responses - self.chat_system.strange_response_count, self.chat_system.strange_response_count]\n",
    "        colors = ['#27ae60', '#e74c3c']\n",
    "        \n",
    "        bars1 = ax4.bar(categories, counts, color=colors, alpha=0.8, width=0.6, edgecolor='white', linewidth=2)\n",
    "        ax4.set_title('대화 분석', fontsize=13, fontweight='bold', pad=15, color='#2c3e50')\n",
    "        ax4.set_ylabel('답변 횟수', fontsize=11, color='#34495e')\n",
    "        \n",
    "        for bar, count in zip(bars1, counts):\n",
    "            height = bar.get_height()\n",
    "            ax4.text(bar.get_x() + bar.get_width()/2., height + 0.2,\n",
    "                    f'{count}회', ha='center', va='bottom', fontsize=11, fontweight='bold', color='#2c3e50')\n",
    "        \n",
    "        ax4.set_ylim(0, max(counts) * 1.3)\n",
    "        ax4.grid(axis='y', alpha=0.2, linestyle='--')\n",
    "        ax4.spines['top'].set_visible(False)\n",
    "        ax4.spines['right'].set_visible(False)\n",
    "        ax4.tick_params(colors='#34495e')\n",
    "        \n",
    "        # 5. 심각도별 이상 답변 바 그래프\n",
    "        ax5 = plt.subplot2grid((8, 2), (3, 1), rowspan=2)\n",
    "        \n",
    "        if self.chat_system.strange_response_count > 0:\n",
    "            severity_labels = ['경미', '보통', '심각']\n",
    "            severity_values = [severity_counts['mild'], severity_counts['moderate'], severity_counts['severe']]\n",
    "            severity_colors = ['#f39c12', '#e67e22', '#e74c3c']\n",
    "            \n",
    "            bars2 = ax5.bar(severity_labels, severity_values, color=severity_colors, alpha=0.8, \n",
    "                           width=0.6, edgecolor='white', linewidth=2)\n",
    "            ax5.set_title('이상 답변 심각도', fontsize=13, fontweight='bold', pad=15, color='#2c3e50')\n",
    "            ax5.set_ylabel('답변 횟수', fontsize=11, color='#34495e')\n",
    "            \n",
    "            for bar, count in zip(bars2, severity_values):\n",
    "                height = bar.get_height()\n",
    "                if height > 0:\n",
    "                    ax5.text(bar.get_x() + bar.get_width()/2., height + 0.05,\n",
    "                            f'{count}회', ha='center', va='bottom', fontsize=11, fontweight='bold', color='#2c3e50')\n",
    "            \n",
    "            ax5.set_ylim(0, max(severity_values) * 1.4 if max(severity_values) > 0 else 1)\n",
    "            ax5.grid(axis='y', alpha=0.2, linestyle='--')\n",
    "            ax5.spines['top'].set_visible(False)\n",
    "            ax5.spines['right'].set_visible(False)\n",
    "            ax5.tick_params(colors='#34495e')\n",
    "        else:\n",
    "            ax5.text(0.5, 0.5, '이상 답변 없음', ha='center', va='center', \n",
    "                    fontsize=13, fontweight='bold', color='#27ae60', transform=ax5.transAxes,\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"#d4edda\", alpha=0.8, edgecolor='#c3e6cb'))\n",
    "            ax5.set_xlim(0, 1)\n",
    "            ax5.set_ylim(0, 1)\n",
    "            ax5.axis('off')\n",
    "    \n",
    "    def _add_recommendation(self, fig, severity_counts, risk_percentage, question_type_counts):\n",
    "        \"\"\"권장사항 추가\"\"\"\n",
    "        cognitive_strange = [r for r in self.chat_system.strange_responses if r.question_type == \"cognitive\"]\n",
    "        cognitive_risk = len(cognitive_strange) / question_type_counts['cognitive'] * 100 if question_type_counts['cognitive'] > 0 else 0\n",
    "        \n",
    "        if severity_counts['severe'] >= 2 or risk_percentage > 80 or cognitive_risk > 60:\n",
    "            recommendation = \"[긴급] 전문의 상담 시급\"\n",
    "            rec_color = '#e74c3c'\n",
    "            bg_color = '#fadbd8'\n",
    "        elif severity_counts['severe'] >= 1 or risk_percentage > 60 or cognitive_risk > 40:\n",
    "            recommendation = \"[주의] 관찰 필요\"\n",
    "            rec_color = '#e67e22'\n",
    "            bg_color = '#fdeaa7'\n",
    "        elif risk_percentage > 40 or cognitive_risk > 30:\n",
    "            recommendation = \"[안내] 정기적 관찰 권장\"\n",
    "            rec_color = '#f39c12'\n",
    "            bg_color = '#fcf3cf'\n",
    "        else:\n",
    "            recommendation = \"[정상] 양호한 상태\"\n",
    "            rec_color = '#27ae60'\n",
    "            bg_color = '#d5f4e6'\n",
    "        \n",
    "        fig.text(0.5, 0.04, recommendation, ha='center', va='center', \n",
    "                fontsize=16, fontweight='bold', color=rec_color,\n",
    "                bbox=dict(boxstyle=\"round,pad=1.0\", facecolor=bg_color, alpha=0.9, \n",
    "                         edgecolor=rec_color, linewidth=2))\n",
    "\n",
    "print(\"✅ 리포트 생성기 모듈이 로드되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8caa205",
   "metadata": {},
   "source": [
    "# 6. 스토리 생성기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67e26855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 스토리 생성기 모듈이 로드되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 6. 스토리 생성기 (story_generator.ipynb)\n",
    "\n",
    "# 이전 모듈들 import (실제 사용시에는 %run 또는 import 사용)\n",
    "# %run config.ipynb\n",
    "\n",
    "class StoryGenerator:\n",
    "    \"\"\"추억 스토리 생성 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, chat_system):\n",
    "        self.chat_system = chat_system\n",
    "        \n",
    "        # Azure OpenAI 클라이언트 사용\n",
    "        self.client = self.chat_system.client\n",
    "        self.deployment = self.chat_system.deployment\n",
    "    \n",
    "    def generate_story_from_conversation(self, image_path):\n",
    "        \"\"\"대화 내용을 바탕으로 노인분의 관점에서 스토리 생성\"\"\"\n",
    "        # 대화 내용 정리\n",
    "        conversation_text = \"\"\n",
    "        for turn in self.chat_system.conversation_turns:\n",
    "            type_name = {\"normal\": \"일반\", \"keyword\": \"키워드\", \"cognitive\": \"인지검사\"}\n",
    "            conversation_text += f\"[{type_name[turn.question_type]}] 질문: {turn.question}\\n답변: {turn.answer}\\n\\n\"\n",
    "        \n",
    "        # 스토리 생성을 위한 프롬프트\n",
    "        story_prompt = f\"\"\"\n",
    "다음은 한 어르신이 옛날 사진을 보며 나눈 대화입니다:\n",
    "\n",
    "{conversation_text}\n",
    "\n",
    "이 대화 내용을 바탕으로, 사진 속 순간에 대한 어르신의 추억을 1인칭 시점으로 15줄 정도의 이야기로 작성해주세요.\n",
    "\n",
    "작성 지침:\n",
    "1. 어르신의 감정과 당시의 느낌을 생생하게 표현\n",
    "2. 구체적인 감각적 묘사 포함 (소리, 냄새, 촉감 등)\n",
    "3. 따뜻하고 향수를 불러일으키는 톤\n",
    "4. 대화에서 언급된 내용을 자연스럽게 포함\n",
    "5. 마치 손자/손녀에게 들려주는 것처럼 친근한 어투\n",
    "6. 키워드 기반 대화와 인지검사 내용도 자연스럽게 반영\n",
    "\n",
    "스토리만 작성하고 다른 설명은 하지 마세요.\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.deployment,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"당신은 노인의 추억을 아름답게 재구성하는 스토리텔러입니다.\"},\n",
    "                    {\"role\": \"user\", \"content\": story_prompt}\n",
    "                ],\n",
    "                max_tokens=1024,\n",
    "                temperature=0.8,\n",
    "                top_p=1.0,\n",
    "            )\n",
    "            \n",
    "            story = response.choices[0].message.content\n",
    "            \n",
    "            # story_telling 폴더 생성\n",
    "            story_dir = \"story_telling\"\n",
    "            os.makedirs(story_dir, exist_ok=True)\n",
    "            \n",
    "            # 이미지 파일명에서 확장자 제거하여 스토리 파일명 생성\n",
    "            image_basename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "            story_filename = os.path.join(story_dir, f\"{image_basename}_story.txt\")\n",
    "            \n",
    "            # 스토리 파일 저장\n",
    "            with open(story_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(story)\n",
    "            \n",
    "            print(f\"📖 추억 이야기가 '{story_filename}' 파일로 저장되었습니다.\")\n",
    "            \n",
    "            return story, story_filename\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"스토리 생성 중 오류 발생: {e}\")\n",
    "            return None, None\n",
    "    \n",
    "    def save_conversation_summary(self, image_path=None):\n",
    "        \"\"\"대화 종료 후 요약 제공\"\"\"\n",
    "        # 전체 답변 횟수 계산\n",
    "        total_responses = len(self.chat_system.conversation_turns)\n",
    "        \n",
    "        if total_responses == 0:\n",
    "            return \"대화가 진행되지 않았습니다.\"\n",
    "        \n",
    "        if self.chat_system.strange_response_count == 0:\n",
    "            return f\"🎉 대화 중 특별히 이상한 답변은 없었습니다. 좋은 대화였어요!\\n전체 답변 횟수: {total_responses}회\"\n",
    "        \n",
    "        summary = f\"\\n{'='*60}\\n\"\n",
    "        summary += f\"📊 대화 종료 - 분석 결과\\n\"\n",
    "        summary += f\"{'='*60}\\n\"\n",
    "        summary += f\"📌 전체 답변 횟수: {total_responses}회\\n\"\n",
    "        summary += f\"🔍 이상한 답변 횟수: {self.chat_system.strange_response_count}회 ({(self.chat_system.strange_response_count/total_responses*100):.1f}%)\\n\\n\"\n",
    "        \n",
    "        # 질문 타입별 분류\n",
    "        question_type_counts = {\"normal\": 0, \"keyword\": 0, \"cognitive\": 0}\n",
    "        for turn in self.chat_system.conversation_turns:\n",
    "            question_type_counts[turn.question_type] += 1\n",
    "        \n",
    "        summary += f\"질문 타입별 대화 분석:\\n\"\n",
    "        summary += f\"  • 일반 대화: {question_type_counts['normal']}회\\n\"\n",
    "        summary += f\"  • 키워드 기반: {question_type_counts['keyword']}회\\n\"\n",
    "        summary += f\"  • 인지 검사: {question_type_counts['cognitive']}회\\n\\n\"\n",
    "        \n",
    "        # 심각도별 분류\n",
    "        severity_counts = {\"mild\": 0, \"moderate\": 0, \"severe\": 0}\n",
    "        for response in self.chat_system.strange_responses:\n",
    "            severity_counts[response.severity] += 1\n",
    "        \n",
    "        summary += f\"이상한 답변 중 심각도별 분류:\\n\"\n",
    "        summary += f\"  • 경미 (Mild): {severity_counts['mild']}회 ({(severity_counts['mild']/self.chat_system.strange_response_count*100):.1f}%)\\n\"\n",
    "        summary += f\"  • 보통 (Moderate): {severity_counts['moderate']}회 ({(severity_counts['moderate']/self.chat_system.strange_response_count*100):.1f}%)\\n\"\n",
    "        summary += f\"  • 심각 (Severe): {severity_counts['severe']}회 ({(severity_counts['severe']/self.chat_system.strange_response_count*100):.1f}%)\\n\\n\"\n",
    "        \n",
    "        # 질문 타입별 이상 답변 분석\n",
    "        cognitive_strange = [r for r in self.chat_system.strange_responses if r.question_type == \"cognitive\"]\n",
    "        keyword_strange = [r for r in self.chat_system.strange_responses if r.question_type == \"keyword\"]\n",
    "        normal_strange = [r for r in self.chat_system.strange_responses if r.question_type == \"normal\"]\n",
    "        \n",
    "        summary += f\"질문 타입별 이상 답변 분석:\\n\"\n",
    "        summary += f\"  • 인지 검사: {len(cognitive_strange)}회 ({(len(cognitive_strange)/question_type_counts['cognitive']*100 if question_type_counts['cognitive'] > 0 else 0):.1f}% 이상률)\\n\"\n",
    "        summary += f\"  • 키워드 기반: {len(keyword_strange)}회 ({(len(keyword_strange)/question_type_counts['keyword']*100 if question_type_counts['keyword'] > 0 else 0):.1f}% 이상률)\\n\"\n",
    "        summary += f\"  • 일반 대화: {len(normal_strange)}회 ({(len(normal_strange)/question_type_counts['normal']*100 if question_type_counts['normal'] > 0 else 0):.1f}% 이상률)\\n\\n\"\n",
    "        \n",
    "        # 가중치 기반 위험도 점수 계산\n",
    "        risk_score = (severity_counts['mild'] * 1 + \n",
    "                     severity_counts['moderate'] * 3 + \n",
    "                     severity_counts['severe'] * 5)\n",
    "        max_risk_score = self.chat_system.strange_response_count * 5\n",
    "        risk_percentage = (risk_score / max_risk_score * 100)\n",
    "        \n",
    "        summary += f\"위험도 점수: {risk_score}점 / {max_risk_score}점 ({risk_percentage:.1f}%)\\n\"\n",
    "        summary += f\"   (경미=1점, 보통=3점, 심각=5점 가중치 적용)\\n\\n\"\n",
    "        \n",
    "        # 권장사항\n",
    "        cognitive_risk = len(cognitive_strange) / question_type_counts['cognitive'] * 100 if question_type_counts['cognitive'] > 0 else 0\n",
    "        \n",
    "        if severity_counts['severe'] >= 2 or risk_percentage > 80 or cognitive_risk > 60:\n",
    "            summary += f\"\\n⚠️  권장사항: 심각한 수준의 이상 답변이 {severity_counts['severe']}회 관찰되었으며, \"\n",
    "            summary += f\"전체 위험도가 {risk_percentage:.1f}%, 인지검사 이상률이 {cognitive_risk:.1f}%로 매우 높습니다. \"\n",
    "            summary += f\"즉시 전문의 상담을 받으시기 바랍니다.\\n\"\n",
    "        elif severity_counts['severe'] >= 1 or risk_percentage > 60 or cognitive_risk > 40:\n",
    "            summary += f\"\\n🔶 권장사항: 심각한 답변이 포함되어 있으며, 위험도가 {risk_percentage:.1f}%, \"\n",
    "            summary += f\"인지검사 이상률이 {cognitive_risk:.1f}%입니다. 전문의 상담을 권장합니다.\\n\"\n",
    "        elif risk_percentage > 40 or cognitive_risk > 30:\n",
    "            summary += f\"\\n🔷 권장사항: 이상 답변의 위험도가 {risk_percentage:.1f}%, 인지검사 이상률이 {cognitive_risk:.1f}%로 \"\n",
    "            summary += f\"중간 수준입니다. 정기적인 관찰과 추적 검사를 받으시기 바랍니다.\\n\"\n",
    "        else:\n",
    "            summary += f\"\\n💚 이상 답변의 위험도가 {risk_percentage:.1f}%로 낮은 수준입니다. \"\n",
    "            summary += f\"현재 상태를 잘 유지하시기 바랍니다.\\n\"\n",
    "        \n",
    "        summary += f\"{'='*60}\\n\"\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def save_conversation_to_file(self, filename_prefix=\"conversation\", image_path=None):\n",
    "        \"\"\"대화 내용을 텍스트 파일로 저장\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # 이미지 파일명 추출 (확장자 제외)\n",
    "        if image_path:\n",
    "            image_basename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "            base_filename = f\"{image_basename}_{timestamp}\"\n",
    "        else:\n",
    "            base_filename = f\"{filename_prefix}_{timestamp}\"\n",
    "        \n",
    "        # 폴더 생성 (없는 경우)\n",
    "        conversation_dir = \"conversation_log\"\n",
    "        analysis_dir = \"analysis\"\n",
    "        os.makedirs(conversation_dir, exist_ok=True)\n",
    "        os.makedirs(analysis_dir, exist_ok=True)\n",
    "        \n",
    "        # 대화 기록 파일 저장\n",
    "        conversation_filename = os.path.join(conversation_dir, f\"{base_filename}.txt\")\n",
    "        with open(conversation_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"=== 대화 기록 ===\\n\")\n",
    "            f.write(f\"생성 시간: {datetime.now().strftime('%Y년 %m월 %d일 %H:%M:%S')}\\n\")\n",
    "            f.write(f\"{'='*50}\\n\\n\")\n",
    "            \n",
    "            for i, turn in enumerate(self.chat_system.conversation_turns, 1):\n",
    "                type_name = {\"normal\": \"일반대화\", \"keyword\": \"키워드기반\", \"cognitive\": \"인지검사\"}\n",
    "                f.write(f\"[대화 {i}] {turn.timestamp} [{type_name[turn.question_type]}]\\n\")\n",
    "                f.write(f\"질문: {turn.question}\\n\")\n",
    "                f.write(f\"답변: {turn.answer}\\n\")\n",
    "                f.write(f\"{'-'*30}\\n\\n\")\n",
    "        \n",
    "        print(f\"📁 대화 기록이 '{conversation_filename}' 파일로 저장되었습니다.\")\n",
    "        \n",
    "        # 이상 답변 분석 파일 저장\n",
    "        analysis_filename = None\n",
    "        if self.chat_system.strange_response_count > 0:\n",
    "            analysis_filename = os.path.join(analysis_dir, f\"{base_filename}_analysis.txt\")\n",
    "            with open(analysis_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(self.save_conversation_summary())\n",
    "            \n",
    "            print(f\"📊 이상 답변 분석이 '{analysis_filename}' 파일로 저장되었습니다.\")\n",
    "        \n",
    "        return conversation_filename, analysis_filename\n",
    "\n",
    "# 테스트 함수\n",
    "def test_story_generator():\n",
    "    \"\"\"스토리 생성기 테스트\"\"\"\n",
    "    # 더미 채팅 시스템 생성 (실제로는 chat_system에서 가져와야 함)\n",
    "    print(\"스토리 생성기 테스트를 위해 실제 채팅 시스템이 필요합니다.\")\n",
    "    return None\n",
    "\n",
    "print(\"✅ 스토리 생성기 모듈이 로드되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f467019",
   "metadata": {},
   "source": [
    "# 코드 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0e4ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DementiaAnalysisSystem:\n",
    "    \"\"\"치매 진단 대화 분석 통합 시스템\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.image_analyzer = None\n",
    "        self.chat_system = None\n",
    "        self.report_generator = None\n",
    "        self.story_generator = None\n",
    "        \n",
    "    def initialize_system(self):\n",
    "        \"\"\"시스템 초기화\"\"\"\n",
    "        try:\n",
    "            print(\"🔄 시스템 초기화 중...\")\n",
    "            \n",
    "            # 이미지 분석기 초기화\n",
    "            self.image_analyzer = ImageAnalysisGPT()\n",
    "            print(\"✅ 이미지 분석기 초기화 완료\")\n",
    "            \n",
    "            # 채팅 시스템 초기화\n",
    "            self.chat_system = ChatSystem()\n",
    "            print(\"✅ 채팅 시스템 초기화 완료\")\n",
    "            \n",
    "            print(\"🎯 치매 진단 대화 분석 시스템이 준비되었습니다!\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 시스템 초기화 실패: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def analyze_image(self, image_path):\n",
    "        \"\"\"이미지 분석 실행\"\"\"\n",
    "        if not self.image_analyzer:\n",
    "            print(\"❌ 이미지 분석기가 초기화되지 않았습니다.\")\n",
    "            return None\n",
    "            \n",
    "        print(f\"🖼️  이미지 분석 중: {image_path}\")\n",
    "        \n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"❌ 이미지 파일을 찾을 수 없습니다: {image_path}\")\n",
    "            return None\n",
    "            \n",
    "        analysis_result = self.image_analyzer.analyze_image_with_gpt(image_path)\n",
    "        \n",
    "        if analysis_result:\n",
    "            print(\"✅ 이미지 분석 완료\")\n",
    "            return analysis_result\n",
    "        else:\n",
    "            print(\"❌ 이미지 분석 실패\")\n",
    "            return None\n",
    "    \n",
    "    def setup_conversation(self, analysis_result, user_description=\"\", user_description_date=\"\"):\n",
    "        \"\"\"대화 컨텍스트 설정\"\"\"\n",
    "        if not self.chat_system:\n",
    "            print(\"❌ 채팅 시스템이 초기화되지 않았습니다.\")\n",
    "            return False\n",
    "            \n",
    "        print(\"🗣️  대화 컨텍스트 설정 중...\")\n",
    "        self.chat_system.setup_conversation_context(analysis_result, user_description, user_description_date)\n",
    "        \n",
    "        # 리포트 생성기 및 스토리 생성기 초기화\n",
    "        self.report_generator = ReportGenerator(self.chat_system)\n",
    "        self.story_generator = StoryGenerator(self.chat_system)\n",
    "        \n",
    "        print(\"✅ 대화 컨텍스트 설정 완료\")\n",
    "        return True\n",
    "    \n",
    "    def start_conversation(self):\n",
    "        \"\"\"대화 시작\"\"\"\n",
    "        if not self.chat_system:\n",
    "            print(\"❌ 채팅 시스템이 준비되지 않았습니다.\")\n",
    "            return None\n",
    "            \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"🎯 치매 진단 대화 분석 시작\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"💡 기능: 실시간 대화 + 키워드 감지 + 인지 검사 + 이상 답변 분석\")\n",
    "        \n",
    "        # 첫 질문 생성\n",
    "        initial_question = self.chat_system.generate_initial_question()\n",
    "        print(f\"\\n🤖 AI: {initial_question}\")\n",
    "        \n",
    "        print(f\"\\n💡 대화를 종료하려면 'exit' 또는 '종료'를 입력하세요.\")\n",
    "        print(f\"📋 3턴마다 인지 검사 질문이 자동으로 추가됩니다.\")\n",
    "        print(f\"🔍 키워드 감지 시 관련 질문이 자동으로 생성됩니다.\")\n",
    "        \n",
    "        return initial_question\n",
    "    \n",
    "    def process_user_input(self, user_input):\n",
    "        \"\"\"사용자 입력 처리\"\"\"\n",
    "        if not self.chat_system:\n",
    "            return None, True, \"error\"\n",
    "            \n",
    "        # 종료 조건 확인\n",
    "        if user_input.lower() in ['exit', '종료', 'quit', 'q']:\n",
    "            print(\"👋 대화를 종료합니다.\")\n",
    "            return \"대화 종료\", True, \"normal\"\n",
    "        \n",
    "        # 채팅 시스템에 입력 전달\n",
    "        answer, should_end, question_type = self.chat_system.chat_about_image(user_input)\n",
    "        \n",
    "        # 질문 타입에 따른 이모지 추가\n",
    "        type_emoji = {\n",
    "            \"normal\": \"🤖\",\n",
    "            \"keyword\": \"💝\", \n",
    "            \"cognitive\": \"🧠\"\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{type_emoji.get(question_type, '🤖')} AI: {answer}\")\n",
    "        \n",
    "        # 특별 질문일 때 추가 안내\n",
    "        if question_type == \"keyword\":\n",
    "            print(\"   💡 키워드 기반 질문이 생성되었습니다.\")\n",
    "        elif question_type == \"cognitive\":\n",
    "            print(\"   🧠 인지 능력 검사 질문입니다.\")\n",
    "        \n",
    "        # 토큰 제한으로 인한 종료 확인\n",
    "        if should_end:\n",
    "            print(\"\\n⏰ 대화 토큰 제한에 도달했습니다. 대화를 종료합니다.\")\n",
    "        \n",
    "        return answer, should_end, question_type\n",
    "    \n",
    "    def generate_reports(self, image_path):\n",
    "        \"\"\"리포트 및 스토리 생성\"\"\"\n",
    "        if not self.report_generator or not self.story_generator:\n",
    "            print(\"❌ 리포트 생성기가 준비되지 않았습니다.\")\n",
    "            return None, None, None\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"📊 분석 결과 생성 중...\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 1. 대화 기록 저장\n",
    "        print(\"📁 대화 기록을 저장하는 중...\")\n",
    "        conversation_file, analysis_file = self.story_generator.save_conversation_to_file(image_path=image_path)\n",
    "        \n",
    "        # 2. 추억 스토리 생성\n",
    "        print(\"📖 추억 이야기를 생성하는 중...\")\n",
    "        story, story_file = self.story_generator.generate_story_from_conversation(image_path)\n",
    "        \n",
    "        if story:\n",
    "            print(f\"\\n=== 생성된 추억 이야기 ===\")\n",
    "            print(story)\n",
    "            print(\"=\"*40)\n",
    "        \n",
    "        # 3. 모바일 리포트 생성\n",
    "        print(\"📱 모바일 리포트를 생성하는 중...\")\n",
    "        mobile_report_file = self.report_generator.generate_mobile_report(image_path)\n",
    "        \n",
    "        if mobile_report_file:\n",
    "            print(f\"✅ 모바일 리포트가 성공적으로 생성되었습니다!\")\n",
    "            print(f\"📂 파일 경로: {mobile_report_file}\")\n",
    "        \n",
    "        \n",
    "        return {\n",
    "            'conversation_file': conversation_file,\n",
    "            'analysis_file': analysis_file,\n",
    "            'story_file': story_file,\n",
    "            'mobile_report_file': mobile_report_file,\n",
    "        }\n",
    "    \n",
    "    def run_full_analysis(self, image_path, user_description=\"\", user_description_date=\"\"):\n",
    "        \"\"\"전체 분석 프로세스 실행\"\"\"\n",
    "        print(\"🚀 치매 진단 대화 분석 시스템 시작\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 1. 시스템 초기화\n",
    "        if not self.initialize_system():\n",
    "            return None\n",
    "        \n",
    "        # 2. 이미지 분석\n",
    "        analysis_result = self.analyze_image(image_path)\n",
    "        if not analysis_result:\n",
    "            return None\n",
    "        \n",
    "        # 3. 대화 설정\n",
    "        if not self.setup_conversation(analysis_result, user_description, user_description_date):\n",
    "            return None\n",
    "        \n",
    "        # 4. 대화 시작\n",
    "        initial_question = self.start_conversation()\n",
    "        if not initial_question:\n",
    "            return None\n",
    "        \n",
    "        # 5. 대화 루프 (Jupyter에서는 수동으로 실행)\n",
    "        print(\"\\n📝 이제 대화를 시작할 수 있습니다!\")\n",
    "        print(\"📌 process_user_input() 메서드를 사용해서 사용자 입력을 처리하세요.\")\n",
    "        print(\"📌 대화가 끝나면 generate_reports() 메서드를 호출하세요.\")\n",
    "        \n",
    "        return {\n",
    "            'system': self,\n",
    "            'initial_question': initial_question,\n",
    "            'analysis_result': analysis_result\n",
    "        }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67166dd2",
   "metadata": {},
   "source": [
    "# 9. 음성인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "663d21e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. 음성 통합 시스템 (voice_integrated_system.ipynb)\n",
    "\n",
    "# 기존 모듈들 import (실제 사용시에는 %run 또는 import 사용)\n",
    "# %run config.ipynb\n",
    "# %run image_analyzer.ipynb\n",
    "# %run conversation_manager.ipynb\n",
    "# %run chat_system.ipynb\n",
    "# %run report_generator.ipynb\n",
    "# %run story_generator.ipynb\n",
    "# %run main_system.ipynb\n",
    "\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import requests\n",
    "import pygame\n",
    "import time\n",
    "from pathlib import Path\n",
    "import threading\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "\n",
    "class VoiceIntegratedSystem(DementiaAnalysisSystem):\n",
    "    \"\"\"음성 기능이 통합된 치매 진단 대화 시스템\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Azure Speech 설정\n",
    "        self.speech_key = os.getenv(\"speech-key\")\n",
    "        self.speech_endpoint = os.getenv(\"speech-endpoint\")\n",
    "        self.region = \"eastus\"  # speech-endpoint에서 추출하거나 직접 설정\n",
    "        \n",
    "        if not self.speech_key:\n",
    "            raise ValueError(\"환경 변수 'speech-key'가 설정되지 않았습니다.\")\n",
    "        \n",
    "        # STT 설정\n",
    "        self.speech_config = speechsdk.SpeechConfig(subscription=self.speech_key, region=self.region)\n",
    "        self.speech_config.speech_recognition_language = \"ko-KR\"\n",
    "        \n",
    "        # TTS 설정\n",
    "        self.tts_voice = \"ko-KR-SunHiNeural\"  # 기본 여성 음성\n",
    "        \n",
    "        # 음성 파일 저장 폴더\n",
    "        self.audio_dir = Path(\"audio_files\")\n",
    "        self.audio_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # pygame 초기화 (음성 재생용)\n",
    "        try:\n",
    "            pygame.mixer.init()\n",
    "            self.audio_enabled = True\n",
    "            print(\"✅ 오디오 시스템 초기화 완료\")\n",
    "        except:\n",
    "            self.audio_enabled = False\n",
    "            print(\"⚠️ 오디오 시스템 초기화 실패 - 음성 재생 불가\")\n",
    "        \n",
    "        print(\"🎤 음성 통합 시스템이 준비되었습니다!\")\n",
    "    \n",
    "    def transcribe_speech(self, show_details: bool = False) -> str:\n",
    "        \"\"\"\n",
    "        STT: 음성을 텍스트로 변환 (종료 명령어 감지 포함)\n",
    "        + recognize_once() 완료 시점을 기준으로 녹음 자동 종료 → .wav 저장\n",
    "        \"\"\"\n",
    "        # 1) 저장할 파일 경로 준비\n",
    "        # timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "        # wav_path = self.audio_dir / f\"input_{timestamp}.wav\"\n",
    "        input_subdir = self.audio_dir / \"input\"\n",
    "        input_subdir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "        wav_path  = input_subdir / f\"input_{timestamp}.wav\"\n",
    "\n",
    "        # 2) 백그라운드 녹음 함수 정의\n",
    "        def _record_to_file(path: Path, stop_evt: threading.Event):\n",
    "            samplerate = 16000\n",
    "            channels = 1\n",
    "            with sf.SoundFile(str(path), mode='w', samplerate=samplerate, channels=channels) as f:\n",
    "                def callback(indata, frames, t, status):\n",
    "                    if stop_evt.is_set():\n",
    "                        raise sd.CallbackStop()\n",
    "                    f.write(indata)\n",
    "                with sd.InputStream(samplerate=samplerate,\n",
    "                                    channels=channels,\n",
    "                                    callback=callback):\n",
    "                    stop_evt.wait()\n",
    "\n",
    "        # 3) 녹음 스레드 시작\n",
    "        stop_event = threading.Event()\n",
    "        recorder = threading.Thread(\n",
    "            target=_record_to_file,\n",
    "            args=(wav_path, stop_event),\n",
    "            daemon=True\n",
    "        )\n",
    "        recorder.start()\n",
    "\n",
    "        # 4) Azure STT 호출\n",
    "        try:\n",
    "            if show_details:\n",
    "                print(\"🎙️ 말씀해 주세요...\")\n",
    "            audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "            recognizer   = speechsdk.SpeechRecognizer(\n",
    "                speech_config=self.speech_config,\n",
    "                audio_config=audio_config\n",
    "            )\n",
    "            result = recognizer.recognize_once()\n",
    "\n",
    "        finally:\n",
    "            # 인식 완료 시 녹음 중단\n",
    "            stop_event.set()\n",
    "            recorder.join()\n",
    "\n",
    "        # 5) 결과 처리\n",
    "        if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "            text = result.text.strip()\n",
    "            if show_details:\n",
    "                print(f\"👤 \\\"{text}\\\"  (음성 파일 저장됨: {wav_path})\")\n",
    "            return text\n",
    "\n",
    "        if result.reason == speechsdk.ResultReason.NoMatch:\n",
    "            if show_details:\n",
    "                print(\"❌ 음성을 인식할 수 없습니다. 다시 시도해 주세요.\")\n",
    "            return \"\"\n",
    "\n",
    "        # Cancellation 등\n",
    "        if show_details:\n",
    "            cancel = result.cancellation_details\n",
    "            print(f\"❌ 인식 실패: {cancel.reason}\")\n",
    "            if cancel.reason == speechsdk.CancellationReason.Error:\n",
    "                print(f\"   오류 상세: {cancel.error_details}\")\n",
    "        return \"\"\n",
    "    \n",
    "    def get_access_token(self):\n",
    "        \"\"\"Azure Speech Service 액세스 토큰 요청\"\"\"\n",
    "        url = f\"https://{self.region}.api.cognitive.microsoft.com/sts/v1.0/issueToken\"\n",
    "        headers = {\n",
    "            \"Ocp-Apim-Subscription-Key\": self.speech_key\n",
    "        }\n",
    "        try:\n",
    "            res = requests.post(url, headers=headers)\n",
    "            res.raise_for_status()\n",
    "            return res.text\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 토큰 요청 실패: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def synthesize_speech(self, text: str, play_audio: bool = True, show_details: bool = False) -> str:\n",
    "        \"\"\"TTS: 텍스트를 음성으로 변환하고 재생\"\"\"\n",
    "        if not text.strip():\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            token = self.get_access_token()\n",
    "            if not token:\n",
    "                return None\n",
    "                \n",
    "            tts_url = f\"https://{self.region}.tts.speech.microsoft.com/cognitiveservices/v1\"\n",
    "            \n",
    "            headers = {\n",
    "                \"Authorization\": f\"Bearer {token}\",\n",
    "                \"Content-Type\": \"application/ssml+xml\",\n",
    "                \"X-Microsoft-OutputFormat\": \"riff-16khz-16bit-mono-pcm\",\n",
    "                \"User-Agent\": \"DementiaAnalysisSystem\"\n",
    "            }\n",
    "            \n",
    "            ssml = f\"\"\"\n",
    "            <speak version='1.0' xml:lang='ko-KR'>\n",
    "                <voice xml:lang='ko-KR' xml:gender='Female' name='{self.tts_voice}'>\n",
    "                    {text}\n",
    "                </voice>\n",
    "            </speak>\n",
    "            \"\"\"\n",
    "            \n",
    "            res = requests.post(tts_url, headers=headers, data=ssml.encode(\"utf-8\"))\n",
    "            res.raise_for_status()\n",
    "            \n",
    "            # 음성 파일 저장\n",
    "            timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_path = self.audio_dir / f\"tts_{timestamp}.wav\"\n",
    "            \n",
    "            with open(output_path, \"wb\") as f:\n",
    "                f.write(res.content)\n",
    "            \n",
    "            # 음성 재생\n",
    "            if play_audio and self.audio_enabled:\n",
    "                self.play_audio(output_path)\n",
    "            \n",
    "            if show_details:\n",
    "                print(f\"✅ TTS 완료: {output_path}\")\n",
    "            \n",
    "            return str(output_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            if show_details:\n",
    "                print(f\"❌ TTS 오류: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def play_audio(self, file_path: str):\n",
    "        \"\"\"음성 파일 재생\"\"\"\n",
    "        try:\n",
    "            pygame.mixer.music.load(file_path)\n",
    "            pygame.mixer.music.play()\n",
    "            \n",
    "            # 재생 완료까지 대기\n",
    "            while pygame.mixer.music.get_busy():\n",
    "                time.sleep(0.1)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 음성 재생 오류: {e}\")\n",
    "    \n",
    "    def voice_chat_about_image(self, use_voice_input: bool = True, use_voice_output: bool = True, show_details: bool = False):\n",
    "        \"\"\"음성 기능이 통합된 채팅 (개선된 종료 감지)\"\"\"\n",
    "        if not self.chat_system:\n",
    "            if show_details:\n",
    "                print(\"❌ 채팅 시스템이 준비되지 않았습니다.\")\n",
    "            return None, True, \"error\"\n",
    "        \n",
    "        # 음성 입력\n",
    "        if use_voice_input:\n",
    "            user_input = self.transcribe_speech(show_details=show_details)\n",
    "            if not user_input:\n",
    "                print(\"💬 음성을 다시 말씀해 주세요.\")\n",
    "                return None, False, \"retry\"\n",
    "        else:\n",
    "            user_input = input(\"👤 텍스트 입력: \")\n",
    "        \n",
    "        if not user_input.strip():\n",
    "            return None, False, \"error\"\n",
    "        \n",
    "        # 확장된 종료 조건 확인\n",
    "        exit_commands = [\n",
    "            '종료', '그만', '끝', '나가기', 'exit', 'quit', 'q', 'stop', \n",
    "            '대화 끝', '대화 종료', '마치기', '끝내기', '그만하기'\n",
    "        ]\n",
    "        \n",
    "        # 대소문자 무관하고 공백/특수문자 제거 후 비교\n",
    "        cleaned_input = user_input.lower().replace(' ', '').replace('.', '').replace('!', '').replace(',', '')\n",
    "        \n",
    "        is_exit_command = False\n",
    "        for exit_cmd in exit_commands:\n",
    "            if exit_cmd.lower() in cleaned_input or exit_cmd in user_input:\n",
    "                is_exit_command = True\n",
    "                break\n",
    "        \n",
    "        if is_exit_command:\n",
    "            goodbye_messages = [\n",
    "                \"대화를 마치겠습니다. 수고하셨습니다.\",\n",
    "                \"좋은 시간이었습니다. 감사합니다.\",\n",
    "                \"대화가 끝났습니다. 고생하셨어요.\",\n",
    "                \"수고 많으셨습니다. 건강하세요.\"\n",
    "            ]\n",
    "            goodbye_message = random.choice(goodbye_messages)\n",
    "            print(f\"🤖 {goodbye_message}\")\n",
    "            \n",
    "            if use_voice_output:\n",
    "                self.synthesize_speech(goodbye_message, show_details=show_details)\n",
    "            \n",
    "            return goodbye_message, True, \"normal\"\n",
    "        \n",
    "        # 채팅 시스템에 입력 전달\n",
    "        answer, should_end, question_type = self.chat_system.chat_about_image(user_input)\n",
    "        \n",
    "        # 질문 타입에 따른 이모지 추가\n",
    "        type_emoji = {\n",
    "            \"normal\": \"🤖\",\n",
    "            \"keyword\": \"💝\", \n",
    "            \"cognitive\": \"🧠\"\n",
    "        }\n",
    "        \n",
    "        print(f\"{type_emoji.get(question_type, '🤖')} {answer}\")\n",
    "        \n",
    "        # 특별 질문일 때 추가 안내 (디버그 모드에서만)\n",
    "        if show_details:\n",
    "            if question_type == \"keyword\":\n",
    "                print(\"   💡 키워드 기반 질문이 생성되었습니다.\")\n",
    "            elif question_type == \"cognitive\":\n",
    "                print(\"   🧠 인지 능력 검사 질문입니다.\")\n",
    "        \n",
    "        # 음성 출력\n",
    "        if use_voice_output and answer:\n",
    "            self.synthesize_speech(answer, show_details=show_details)\n",
    "        \n",
    "        # 토큰 제한으로 인한 종료 확인\n",
    "        if should_end:\n",
    "            end_message = \"대화 시간이 종료되었습니다. 분석 결과를 생성하겠습니다.\"\n",
    "            print(f\"⏰ {end_message}\")\n",
    "            \n",
    "            if use_voice_output:\n",
    "                self.synthesize_speech(end_message, show_details=show_details)\n",
    "        \n",
    "        return answer, should_end, question_type\n",
    "    \n",
    "    def start_voice_conversation(self, image_path: str, user_description: str = \"\", user_description_date: str = \"\"):\n",
    "        \"\"\"음성 대화 시스템 시작\"\"\"\n",
    "        print(\"🚀 음성 치매 진단 대화 분석 시스템 시작\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 1. 시스템 초기화\n",
    "        if not self.initialize_system():\n",
    "            return None\n",
    "        \n",
    "        # 2. 이미지 분석\n",
    "        analysis_result = self.analyze_image(image_path)\n",
    "        if not analysis_result:\n",
    "            return None\n",
    "        \n",
    "        # 3. 대화 설정\n",
    "        if not self.setup_conversation(analysis_result, user_description, user_description_date):\n",
    "            return None\n",
    "        \n",
    "        # 4. 첫 질문 생성 및 음성 출력\n",
    "        initial_question = self.chat_system.generate_initial_question()\n",
    "        \n",
    "        # welcome_message = \"안녕하세요!\"\n",
    "        # print(f\"🎤 {welcome_message}\")\n",
    "        # self.synthesize_speech(welcome_message)\n",
    "        \n",
    "        print(f\"\\n🤖 AI: {initial_question}\")\n",
    "        self.synthesize_speech(initial_question)\n",
    "        \n",
    "        print(f\"\\n💡 음성으로 답변해 주세요. 대화를 종료하려면 '종료'라고 말씀하세요.\")\n",
    "        print(f\"📋 3턴마다 인지 검사 질문이 자동으로 추가됩니다.\")\n",
    "        print(f\"🔍 키워드 감지 시 관련 질문이 자동으로 생성됩니다.\")\n",
    "        \n",
    "        return initial_question\n",
    "    \n",
    "    def run_full_voice_conversation(self, image_path: str, user_description: str = \"\", user_description_date: str = \"\"):\n",
    "        \"\"\"전체 음성 대화 프로세스 실행\"\"\"\n",
    "        # 대화 시작\n",
    "        initial_question = self.start_voice_conversation(image_path, user_description, user_description_date)\n",
    "        if not initial_question:\n",
    "            return None\n",
    "        \n",
    "        # 대화 루프\n",
    "        conversation_count = 0\n",
    "        max_conversations = 20  # 최대 대화 수 제한\n",
    "        \n",
    "        while conversation_count < max_conversations:\n",
    "            print(f\"\\n--- 대화 {conversation_count + 1} ---\")\n",
    "            \n",
    "            try:\n",
    "                answer, should_end, question_type = self.voice_chat_about_image(\n",
    "                    use_voice_input=True, \n",
    "                    use_voice_output=True\n",
    "                )\n",
    "                \n",
    "                if should_end:\n",
    "                    break\n",
    "                    \n",
    "                conversation_count += 1\n",
    "                \n",
    "                # 잠깐 대기 (자연스러운 대화 흐름)\n",
    "                time.sleep(1)\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n\\n⏹️ 사용자가 대화를 중단했습니다.\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"❌ 대화 중 오류 발생: {e}\")\n",
    "                break\n",
    "        \n",
    "        # 리포트 생성\n",
    "        print(f\"\\n📊 대화 분석 및 리포트 생성 중...\")\n",
    "        completion_message = \"대화가 완료되었습니다. 잠시만 기다려주세요.\"\n",
    "        # self.synthesize_speech(completion_message)\n",
    "        \n",
    "        reports = self.generate_reports(image_path)\n",
    "        \n",
    "        if reports:\n",
    "            final_message = \"분석이 완료되었습니다. 감사합니다.\"\n",
    "            # print(f\"✅ {final_message}\")\n",
    "            # self.synthesize_speech(final_message)\n",
    "        \n",
    "        return reports\n",
    "    \n",
    "    def set_voice_settings(self, voice_type: str = \"female\", speed: str = \"normal\"):\n",
    "        \"\"\"음성 설정 변경\"\"\"\n",
    "        voice_options = {\n",
    "            \"female\": \"ko-KR-SunHiNeural\",\n",
    "            \"female_bright\": \"ko-KR-YooJinNeural\", \n",
    "            \"female_calm\": \"ko-KR-SeoHyunNeural\",\n",
    "            \"male\": \"ko-KR-InJoonNeural\",\n",
    "            \"male_deep\": \"ko-KR-BongJinNeural\",\n",
    "            \"male_stable\": \"ko-KR-GookMinNeural\"\n",
    "        }\n",
    "        \n",
    "        if voice_type in voice_options:\n",
    "            self.tts_voice = voice_options[voice_type]\n",
    "            print(f\"🎤 음성 설정 변경: {voice_type} ({self.tts_voice})\")\n",
    "        else:\n",
    "            print(f\"❌ 지원하지 않는 음성 타입: {voice_type}\")\n",
    "            print(f\"지원 타입: {list(voice_options.keys())}\")\n",
    "\n",
    "# 음성 대화 함수\n",
    "def interactive_voice_conversation():\n",
    "    \"\"\"interactive_conversation()의 음성 버전 - 가장 쉬운 실행 방법\"\"\"\n",
    "    print(\"=== 🎤 음성 통합 치매 진단 대화 시스템 ===\")\n",
    "    print(\"🔊 음성으로 입력받고 음성으로 출력하는 대화 시스템입니다.\")\n",
    "    \n",
    "    try:\n",
    "        # 이미지 경로 입력\n",
    "        print(\"\\n📁 이미지 파일 선택:\")\n",
    "        image_path = input(\"이미지 경로를 입력하세요 (예: image.jpg): \").strip()\n",
    "        \n",
    "        if not image_path:\n",
    "            print(\"❌ 이미지 경로가 입력되지 않았습니다.\")\n",
    "            return None\n",
    "        \n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"❌ 파일을 찾을 수 없습니다: {image_path}\")\n",
    "            return None\n",
    "        \n",
    "        # 음성 설정 선택\n",
    "        print(\"\\n🎤 음성 설정:\")\n",
    "        print(\"1. 여성 음성 (기본)\")\n",
    "        print(\"2. 남성 음성\")\n",
    "        print(\"3. 밝은 여성 음성\")\n",
    "        print(\"4. 차분한 여성 음성\")\n",
    "        \n",
    "        voice_choice = input(\"음성을 선택하세요 (1-4, 엔터시 기본): \").strip()\n",
    "        \n",
    "        voice_mapping = {\n",
    "            \"1\": \"female\",\n",
    "            \"2\": \"male\", \n",
    "            \"3\": \"female_bright\",\n",
    "            \"4\": \"female_calm\",\n",
    "            \"\": \"female\"  # 기본값\n",
    "        }\n",
    "        \n",
    "        selected_voice = voice_mapping.get(voice_choice, \"female\")\n",
    "        \n",
    "        # 시스템 초기화\n",
    "        print(\"\\n🚀 음성 시스템 초기화 중...\")\n",
    "        voice_system = VoiceIntegratedSystem()\n",
    "        \n",
    "        # 음성 설정 적용\n",
    "        voice_system.set_voice_settings(selected_voice)\n",
    "        \n",
    "        # 시스템 초기화\n",
    "        if not voice_system.initialize_system():\n",
    "            print(\"❌ 시스템 초기화에 실패했습니다.\")\n",
    "            return None\n",
    "        \n",
    "        # 이미지 분석\n",
    "        print(f\"🖼️ 이미지 분석 중: {image_path}\")\n",
    "        analysis_result = voice_system.analyze_image(image_path)\n",
    "        if not analysis_result:\n",
    "            print(\"❌ 이미지 분석에 실패했습니다.\")\n",
    "            return None\n",
    "        \n",
    "        # 대화 설정\n",
    "        print(\"🗣️ 대화 컨텍스트 설정 중...\")\n",
    "        voice_system.setup_conversation(analysis_result)\n",
    "        \n",
    "        # 시작 안내\n",
    "        welcome_msg = \"안녕하세요. 사진을 보며 대화를 시작하겠습니다.\"\n",
    "        print(f\"\\n🤖 {welcome_msg}\")\n",
    "        voice_system.synthesize_speech(welcome_msg)\n",
    "        \n",
    "        # 첫 질문 생성\n",
    "        initial_question = voice_system.chat_system.generate_initial_question()\n",
    "        print(f\"🤖 AI: {initial_question}\")\n",
    "        voice_system.synthesize_speech(initial_question)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"🎙️ 음성 대화 시작!\")\n",
    "        print(\"💡 자연스럽게 답변해 주세요\")\n",
    "        print(\"💡 '종료'라고 말하면 대화가 끝납니다\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # 대화 루프\n",
    "        conversation_count = 0\n",
    "        max_conversations = 20\n",
    "        \n",
    "        while conversation_count < max_conversations:\n",
    "            print(f\"\\n--- 대화 {conversation_count + 1} ---\")\n",
    "            \n",
    "            try:\n",
    "                # 음성 입력 받기\n",
    "                user_input = voice_system.transcribe_speech()\n",
    "                \n",
    "                # 음성 인식 실패시 텍스트 입력 옵션\n",
    "                if not user_input.strip():\n",
    "                    print(\"💬 음성이 인식되지 않았습니다.\")\n",
    "                    fallback = input(\"텍스트로 입력하시겠습니까? (y/엔터-재시도): \").strip().lower()\n",
    "                    \n",
    "                    if fallback == 'y':\n",
    "                        user_input = input(\"👤 \").strip()\n",
    "                    else:\n",
    "                        continue\n",
    "                \n",
    "                if not user_input.strip():\n",
    "                    continue\n",
    "                \n",
    "                # 종료 명령 확인 (확장된 버전)\n",
    "                exit_commands = [\n",
    "                    '종료', '그만', '끝', '나가기', 'exit', 'quit', 'q', 'stop',\n",
    "                    '대화 끝', '대화 종료', '마치기', '끝내기', '그만하기'\n",
    "                ]\n",
    "                \n",
    "                # 대소문자 무관하고 공백/특수문자 제거 후 비교\n",
    "                cleaned_input = user_input.lower().replace(' ', '').replace('.', '').replace('!', '').replace(',', '')\n",
    "                \n",
    "                is_exit_command = False\n",
    "                \n",
    "                for exit_cmd in exit_commands:\n",
    "                    if exit_cmd.lower() in cleaned_input or exit_cmd in user_input:\n",
    "                        is_exit_command = True\n",
    "                        break\n",
    "                \n",
    "                if is_exit_command:\n",
    "                    end_msg = \"대화를 마치겠습니다. 감사합니다.\"\n",
    "                    break\n",
    "                \n",
    "                # AI 응답 생성\n",
    "                answer, should_end, question_type = voice_system.chat_system.chat_about_image(user_input)\n",
    "                \n",
    "                # AI 응답 출력\n",
    "                type_emoji = {\"normal\": \"🤖\", \"keyword\": \"💝\", \"cognitive\": \"🧠\"}\n",
    "                print(f\"{type_emoji.get(question_type, '🤖')} {answer}\")\n",
    "                \n",
    "                # AI 응답 음성 출력\n",
    "                voice_system.synthesize_speech(answer)\n",
    "                \n",
    "                # 토큰 제한 도달\n",
    "                if should_end:\n",
    "                    end_msg = \"대화 시간이 종료되었습니다. 분석 결과를 생성하겠습니다.\"\n",
    "                    print(f\"⏰ {end_msg}\")\n",
    "                    voice_system.synthesize_speech(end_msg)\n",
    "                    break\n",
    "                \n",
    "                conversation_count += 1\n",
    "                time.sleep(0.5)  # 자연스러운 대화 흐름\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n⏹️ 대화가 중단되었습니다.\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"❌ 오류가 발생했습니다. 다시 시도해주세요.\")\n",
    "                continue\n",
    "        \n",
    "        \n",
    "        # 리포트 생성\n",
    "        print(\"📈 리포트 생성 중...\")\n",
    "        reports = voice_system.generate_reports(image_path)\n",
    "        \n",
    "\n",
    "        return voice_system, reports\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 시스템 오류: {e}\")\n",
    "        return None\n",
    "\n",
    "def quick_voice_conversation():\n",
    "    \"\"\"더 간단한 음성 대화 시작 (기본 설정 사용)\"\"\"\n",
    "    print(\"=== 🚀 빠른 음성 대화 시작 ===\")\n",
    "    \n",
    "    # 기본 이미지 경로 (현재 디렉토리에서 이미지 파일 찾기)\n",
    "    image_files = [f for f in os.listdir('.') if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
    "    \n",
    "    if image_files:\n",
    "        image_path = image_files[0]\n",
    "        print(f\"📁 발견된 이미지 사용: {image_path}\")\n",
    "    else:\n",
    "        image_path = input(\"이미지 경로를 입력하세요: \").strip()\n",
    "    \n",
    "    try:\n",
    "        # 시스템 생성 및 실행\n",
    "        voice_system = VoiceIntegratedSystem()\n",
    "        return voice_system.run_full_voice_conversation(image_path)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9ef023",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "932a3658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 🚀 빠른 음성 대화 시작 ===\n",
      "📁 발견된 이미지 사용: images.jpg\n",
      "✅ 오디오 시스템 초기화 완료\n",
      "🎤 음성 통합 시스템이 준비되었습니다!\n",
      "🚀 음성 치매 진단 대화 분석 시스템 시작\n",
      "============================================================\n",
      "🔄 시스템 초기화 중...\n",
      "✅ 이미지 분석기 초기화 완료\n",
      "✅ 채팅 시스템 초기화 완료\n",
      "🎯 치매 진단 대화 분석 시스템이 준비되었습니다!\n",
      "🖼️  이미지 분석 중: images.jpg\n",
      "\n",
      "Caption: 한 가족이 거실에서 함께 시간을 보내며 사진을 찍고 있는 모습으로, 따뜻하고 아늑한 분위기가 느껴진다. 부모와 두 자녀가 함께 앉아 있으며, 바닥에는 애완견이 편안하게 누워 있다. 가족의 화목함과 사랑이 담긴 순간을 포착한 사진이다.\n",
      "Mood: 따뜻하고 화목한 분위기\n",
      "Time Period: 1950년대 추정\n",
      "People Count: 4\n",
      "Time of Day: 낮\n",
      "\n",
      "Dense Captions:\n",
      "- 왼쪽에는 정장을 입은 남성이 의자에 앉아 있다.\n",
      "- 중앙에는 스커트를 입은 소녀가 바닥에 앉아 있으며, 그녀 옆에는 애완견이 누워 있다.\n",
      "- 오른쪽에는 블라우스를 입은 여성이 의자에 앉아 있다.\n",
      "- 그 옆에는 셔츠를 입은 어린 소년이 바닥에 앉아 있다.\n",
      "- 배경에는 램프와 테이블이 놓여 있으며, 벽에는 액자가 걸려 있다.\n",
      "✅ 이미지 분석 완료\n",
      "🗣️  대화 컨텍스트 설정 중...\n",
      "✅ 대화 컨텍스트 설정 완료\n",
      "\n",
      "🤖 AI: \"어르신, 가족들과 함께 거실에서 시간을 보내던 추억이 있으신가요?\"\n",
      "\n",
      "💡 음성으로 답변해 주세요. 대화를 종료하려면 '종료'라고 말씀하세요.\n",
      "📋 3턴마다 인지 검사 질문이 자동으로 추가됩니다.\n",
      "🔍 키워드 감지 시 관련 질문이 자동으로 생성됩니다.\n",
      "\n",
      "--- 대화 1 ---\n",
      "🤖 \"그렇군요, 어르신. 가족들과 함께한 시간이 참 따뜻했을 것 같아요. 혹시 거실에서 뭘 주로 하셨는지 기억나세요?\"\n",
      "\n",
      "--- 대화 2 ---\n",
      "🤖 \"아, 괜찮아요, 어르신. 기억이 안 나셔도 괜찮습니다. 그저 함께하는 시간이 참 소중했을 거예요. 혹시 애완동물과 함께한 기억은 있으신가요?\"\n",
      "\n",
      "--- 대화 3 ---\n",
      "🧠 사진이 낮에 찍힌 것 같나요, 밤인가요?\n",
      "\n",
      "--- 대화 4 ---\n",
      "🤖 \"어르신, 죄송합니다. 제가 잘못 말씀드린 것 같아요. 혹시 이 사진 속 배경이 낮인지, 밤인지 궁금해서 여쭤봤어요. 화내셨다면 정말 죄송하고, 제가 더 조심하겠습니다. 그럼 혹시 이 사진 속 분위기가 어르신께 어떤 느낌을 주었는지 말씀해 주실 수 있을까요?\"\n",
      "\n",
      "--- 대화 5 ---\n",
      "🤖 대화를 마치겠습니다. 수고하셨습니다.\n",
      "\n",
      "📊 대화 분석 및 리포트 생성 중...\n",
      "\n",
      "============================================================\n",
      "📊 분석 결과 생성 중...\n",
      "============================================================\n",
      "📁 대화 기록을 저장하는 중...\n",
      "📁 대화 기록이 'conversation_log\\images_20250528_010221.txt' 파일로 저장되었습니다.\n",
      "📊 이상 답변 분석이 'analysis\\images_20250528_010221_analysis.txt' 파일로 저장되었습니다.\n",
      "📖 추억 이야기를 생성하는 중...\n",
      "📖 추억 이야기가 'story_telling\\images_story.txt' 파일로 저장되었습니다.\n",
      "\n",
      "=== 생성된 추억 이야기 ===\n",
      "아, 그 사진 말이지? 참, 옛날이야기라니 별스럽네. 저게 낮이었는지 밤이었는지, 그런 건 모르겠다만, 내가 기억나는 건 거실의 분위기야. 우리 집 거실은 항상 따뜻했어. 그때는 가족들이 다 모였던 곳이었지. 큰 탁자 위에는 과일 몇 개가 놓여 있었고, 저 멀리서 작은 라디오가 흘려보내는 음악 소리가 은은하게 들렸어. 그 소리, 마치 바람결처럼 부드러웠지.  \n",
      "\n",
      "아마도 저 사진은 누군가가 장난스럽게 찍었을 거야. 나야, 사진 찍히는 걸 별로 좋아하진 않았는데, 그때는 저도 몰랐지. 지금 보면 우습게도, 시선에 살짝 짜증이 묻어 있는 것 같아. 그런데도 그 사진만 보면 이상하게 마음이 따뜻해져. 내 바로 옆에는 우리 식구들이 앉아 있었을 거야. 엄마는 뭔가를 바느질하고 계셨던 것 같아. 손끝에서 나는 실의 부드러운 소리, 그리고 바느질 솜씨가 참 놀라웠지. 아버지는 아마도 신문을 읽고 계셨을 거고, 아이들은 바닥에 앉아 노래도 부르고 장난도 치고.  \n",
      "\n",
      "우리 집엔 애완동물은 없었어. 대신 우리 가족이 서로에게 애완동물만큼이나 다정했지. 웃음소리, 장난스러운 대화, 그리고 거실에 퍼지던 따뜻한 나무 냄새. 나는 지금도 그 냄새를 떠올리면 마음이 차분해져. 알지? 그 나무 바닥에 맨발로 서면, 살짝 차갑고 매끈한 촉감이 느껴졌던 것도 기억나.  \n",
      "\n",
      "사진 속 내가 바보 같아 보일지는 몰라도, 그 순간만큼은 우리 가족이 함께였다는 게 참 좋았어. 이젠 기억이 희미해져서 정확히 뭘 했는지는 모르겠지만, 소리나 냄새 같은 작은 것들이 여전히 내 마음에 남아있어. 그래, 누가 봐도 그 사진은 나한테 찍힌 거라니까. 그래도 손주야, 나중엔 너도 이런 따뜻한 추억을 간직하게 될 거야. 나를 닮아서 말이지.\n",
      "========================================\n",
      "📱 모바일 리포트를 생성하는 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10764\\754271693.py:148: UserWarning: Glyph 9642 (\\N{BLACK SMALL SQUARE}) missing from font(s) Malgun Gothic.\n",
      "  plt.tight_layout(rect=[0, 0.08, 1, 0.95], pad=2.0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10764\\754271693.py:155: UserWarning: Glyph 9642 (\\N{BLACK SMALL SQUARE}) missing from font(s) Malgun Gothic.\n",
      "  plt.savefig(report_filename, dpi=200, bbox_inches='tight',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📱 모바일 리포트가 생성되었습니다: reports\\images_report_20250528_010234.png\n",
      "✅ 모바일 리포트가 성공적으로 생성되었습니다!\n",
      "📂 파일 경로: reports\\images_report_20250528_010234.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'conversation_file': 'conversation_log\\\\images_20250528_010221.txt',\n",
       " 'analysis_file': 'analysis\\\\images_20250528_010221_analysis.txt',\n",
       " 'story_file': 'story_telling\\\\images_story.txt',\n",
       " 'mobile_report_file': 'reports\\\\images_report_20250528_010234.png'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quick_voice_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82abd12e",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "832eedb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "선택된 파일: audio_files\\input\\input_20250528_010132.wav (250476 bytes)\n",
      "✅ 전처리 완료: audio_files\\preprocessed\\input_20250528_010132.wav (250510 bytes)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def select_largest_wav(input_dir: Path) -> Path:\n",
    "    wav_files = list(input_dir.glob(\"*.wav\"))\n",
    "    if not wav_files:\n",
    "        raise FileNotFoundError(f\"No .wav files found in {input_dir}\")\n",
    "    # 파일 크기 기준으로 최대값 선택\n",
    "    return max(wav_files, key=lambda p: p.stat().st_size)\n",
    "\n",
    "def preprocess_single_wav(\n",
    "    wav_file: Path,\n",
    "    output_dir: Path,\n",
    "    sample_rate: int = 16000\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    단일 .wav 파일을 지정한 sample_rate, mono, 16bit PCM 으로 변환해 저장.\n",
    "    반환값은 생성된 파일 경로입니다.\n",
    "    \"\"\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    output_file = output_dir / wav_file.name\n",
    "\n",
    "    cmd = [\n",
    "        \"ffmpeg\",\n",
    "        \"-y\",                        # 덮어쓰기\n",
    "        \"-i\", str(wav_file),         # 입력 파일\n",
    "        \"-ar\", str(sample_rate),     # 리샘플링\n",
    "        \"-ac\", \"1\",                  # 모노\n",
    "        \"-acodec\", \"pcm_s16le\",      # 16bit PCM\n",
    "        str(output_file)             # 출력 파일\n",
    "    ]\n",
    "    subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    print(f\"✅ 전처리 완료: {output_file} ({output_file.stat().st_size} bytes)\")\n",
    "    return output_file\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 실제 사용 예시\n",
    "input_dir  = Path(\"audio_files/input\")\n",
    "output_dir = Path(\"audio_files/preprocessed\")\n",
    "\n",
    "# 1) 가장 큰 파일 선택\n",
    "largest_wav = select_largest_wav(input_dir)\n",
    "print(f\"선택된 파일: {largest_wav} ({largest_wav.stat().st_size} bytes)\")\n",
    "\n",
    "# 2) 전처리 실행\n",
    "preprocessed = preprocess_single_wav(largest_wav, output_dir, sample_rate=16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0013042",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpreprocessed\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocessed' is not defined"
     ]
    }
   ],
   "source": [
    "print(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff65328e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m prompt_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m이건 예시 프롬프트입니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# wav_path = \"test.wav\"  # 환자 음성 파일\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m wav_path \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessed\u001b[49m\n\u001b[0;32m     10\u001b[0m files \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mopen\u001b[39m(wav_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)}\n\u001b[0;32m     11\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: text,\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_text\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_text\n\u001b[0;32m     14\u001b[0m }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocessed' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "# 하고싶은거\n",
    "text = \"안녕\" \n",
    "# with open(\"story_telling/images_story.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     text = f.read()\n",
    "preprocessed ='audio_files\\preprocessed\\input_20250528_010132.wav'\n",
    "prompt_text = \"이건 예시 프롬프트입니다.\"\n",
    "# wav_path = \"test.wav\"  # 환자 음성 파일\n",
    "wav_path = preprocessed\n",
    "files = {\"file\": open(wav_path, \"rb\")}\n",
    "data = {\n",
    "    \"text\": text,\n",
    "    \"prompt_text\": prompt_text\n",
    "}\n",
    "\n",
    "res = requests.post(\"http://20.41.115.128:8000/synthesize\", data=data, files=files)\n",
    "\n",
    "with open(\"result.wav\", \"wb\") as f:\n",
    "    f.write(res.content)\n",
    "\n",
    "print(\"✅ 결과 저장 완료: result.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13831b74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
