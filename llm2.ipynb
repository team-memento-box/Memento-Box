{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ebe0481",
   "metadata": {},
   "source": [
    "# 1. ë°ì´í„° í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ac3b483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì„¤ì • ë° ë°ì´í„° í´ë˜ìŠ¤ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# 1. ì„¤ì • ë° ë°ì´í„° í´ë˜ìŠ¤ (config.ipynb)\n",
    "\n",
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
    "import json\n",
    "import base64\n",
    "import os\n",
    "import tiktoken\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "@dataclass\n",
    "class StrangeResponse:\n",
    "    \"\"\"ì´ìƒí•œ ë‹µë³€ì„ ì €ì¥í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤\"\"\"\n",
    "    question: str\n",
    "    answer: str\n",
    "    timestamp: str\n",
    "    severity: str  # \"mild\", \"moderate\", \"severe\"\n",
    "    question_type: str = \"normal\"  # \"keyword\", \"cognitive\", \"normal\"\n",
    "\n",
    "@dataclass\n",
    "class ConversationTurn:\n",
    "    \"\"\"ëŒ€í™” í„´ì„ ì €ì¥í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤\"\"\"\n",
    "    question: str\n",
    "    answer: str\n",
    "    timestamp: str\n",
    "    question_type: str = \"normal\"  # \"keyword\", \"cognitive\", \"normal\"\n",
    "\n",
    "# ì„¤ì • ìƒìˆ˜\n",
    "class Config:\n",
    "    \"\"\"ì‹œìŠ¤í…œ ì„¤ì • ìƒìˆ˜\"\"\"\n",
    "    # Azure OpenAI ì„¤ì •\n",
    "    ENDPOINT = os.getenv(\"gpt-endpoint\")\n",
    "    DEPLOYMENT = \"gpt-4o\"\n",
    "    SUBSCRIPTION_KEY = os.getenv(\"gpt-key\")\n",
    "    API_VERSION = \"2024-12-01-preview\"\n",
    "    \n",
    "    # í† í° ì œí•œ\n",
    "    MAX_TOKENS = 4000\n",
    "    \n",
    "    # í‚¤ì›Œë“œ ê¸°ë°˜ ì§ˆë¬¸\n",
    "    KEYWORD_QUESTIONS = {\n",
    "        \"ë‚¨í¸\": \"ë‚¨í¸ì—ê²Œ ì „í•˜ê³  ì‹¶ì€ ë§ì´ ìˆë‚˜ìš”?\",\n",
    "        \"ì•„ë‚´\": \"ì•„ë‚´ë¶„ê³¼ì˜ ì¢‹ì€ ì¶”ì–µì´ ë˜ ìˆë‚˜ìš”?\",\n",
    "        \"ì†ì\": \"ìš”ì¦˜ ì†ìëŠ” í•™êµ ì˜ ë‹¤ë‹ˆë‚˜ìš”?\",\n",
    "        \"ì†ë…€\": \"ì†ë…€ëŠ” ìš”ì¦˜ ë­˜ í•˜ë©° ì§€ë‚´ë‚˜ìš”?\",\n",
    "        \"ì•„ë“¤\": \"ì•„ë“¤ì€ ìš”ì¦˜ ì–´ë–»ê²Œ ì§€ë‚´ë‚˜ìš”?\",\n",
    "        \"ë”¸\": \"ë”¸ê³¼ì˜ ì¶”ì–µ ì¤‘ì— íŠ¹ë³„í•œ ê²Œ ìˆë‚˜ìš”?\",\n",
    "        \"ì—„ë§ˆ\": \"ì–´ë¨¸ë‹˜ì€ ì–´ë–¤ ë¶„ì´ì…¨ì–´ìš”?\",\n",
    "        \"ì•„ë²„ì§€\": \"ì•„ë²„ë‹˜ì€ ì–´ë–¤ ë¶„ì´ì…¨ë‚˜ìš”?\",\n",
    "        \"ì¹œêµ¬\": \"ê·¸ ì¹œêµ¬ë¶„ê³¼ëŠ” ìì£¼ ë§Œë‚˜ì…¨ë‚˜ìš”?\",\n",
    "        \"ì—¬í–‰\": \"ê·¸ë•Œ ì—¬í–‰ì´ ì¦ê±°ìš°ì…¨ë‚˜ìš”?\",\n",
    "        \"ì§‘\": \"ê·¸ ì§‘ì—ì„œ ì‚´ ë•Œê°€ ê·¸ë¦¬ìš°ì‹œë‚˜ìš”?\",\n",
    "    }\n",
    "    \n",
    "    # ê¸°ë³¸ ì¸ì§€ ëŠ¥ë ¥ ê²€ì‚¬ ì§ˆë¬¸\n",
    "    BASE_COGNITIVE_QUESTIONS = [\n",
    "        \"ì´ ì‚¬ì§„ì—ëŠ” ëª‡ ëª…ì´ ìˆëŠ”ì§€ ê¸°ì–µë‚˜ì„¸ìš”?\",\n",
    "        \"ì‚¬ì§„ì´ ë‚®ì— ì°íŒ ê²ƒ ê°™ë‚˜ìš”, ë°¤ì¸ê°€ìš”?\",\n",
    "        \"ì´ ì‚¬ì§„ì—ì„œ ê°€ì¥ ëˆˆì— ë„ëŠ” ê²ƒì´ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    ]\n",
    "\n",
    "print(\"âœ… ì„¤ì • ë° ë°ì´í„° í´ë˜ìŠ¤ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11205c56",
   "metadata": {},
   "source": [
    "# 2 ì´ë¯¸ì§€ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ebaf6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì´ë¯¸ì§€ ë¶„ì„ê¸° ëª¨ë“ˆì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ImageAnalysisGPT:\n",
    "    \"\"\"GPT-4oë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë¶„ì„ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Azure OpenAI ê´€ë ¨ ì„¤ì •\n",
    "        self.endpoint = Config.ENDPOINT\n",
    "        self.deployment = Config.DEPLOYMENT\n",
    "        self.subscription_key = Config.SUBSCRIPTION_KEY\n",
    "        self.api_version = Config.API_VERSION\n",
    "        \n",
    "        if not self.endpoint or not self.subscription_key:\n",
    "            raise ValueError(\"Please set the gpt-endpoint and gpt-key in the environment variables.\")\n",
    "        \n",
    "        # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "        self.client = AzureOpenAI(\n",
    "            api_version=self.api_version,\n",
    "            azure_endpoint=self.endpoint,\n",
    "            api_key=self.subscription_key,\n",
    "        )\n",
    "    \n",
    "    def encode_image_to_base64(self, image_path):\n",
    "        \"\"\"ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©\"\"\"\n",
    "        try:\n",
    "            with open(image_path, \"rb\") as image_file:\n",
    "                return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"ì´ë¯¸ì§€ ì¸ì½”ë”© ì˜¤ë¥˜: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def analyze_image_with_gpt(self, image_path):\n",
    "        \"\"\"GPT-4oë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë¶„ì„\"\"\"\n",
    "        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©\n",
    "        base64_image = self.encode_image_to_base64(image_path)\n",
    "        if not base64_image:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.deployment,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": \"\"\"ì´ ì´ë¯¸ì§€ë¥¼ ìì„¸íˆ ë¶„ì„í•´ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:\n",
    "\n",
    "1. caption: ì´ë¯¸ì§€ì˜ ì „ì²´ì ì¸ ì„¤ëª… (êµ¬ì²´ì ìœ¼ë¡œ ê·¸ë¦¬ê³  í•œí¸ì˜ ì´ì•¼ê¸°ì²˜ëŸ¼)\n",
    "2. dense_captions: ì´ë¯¸ì§€ì˜ ì„¸ë¶€ì ì¸ ìš”ì†Œë“¤ì„ ì—¬ëŸ¬ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª… (ë°°ì—´ í˜•íƒœ)\n",
    "3. mood: ì´ë¯¸ì§€ì—ì„œ ëŠê»´ì§€ëŠ” ë¶„ìœ„ê¸°ë‚˜ ê°ì •\n",
    "4. time_period: ì¶”ì •ë˜ëŠ” ì‹œëŒ€ë‚˜ ì‹œê¸°\n",
    "5. key_objects: ì£¼ìš” ê°ì²´ë“¤ (ë°°ì—´ í˜•íƒœ)\n",
    "6. people_description: ì‚¬ëŒì´ ìˆë‹¤ë©´ ê·¸ë“¤ì— ëŒ€í•œ ì„¤ëª…\n",
    "7. people_count: ì‚¬ì§„ ì† ì‚¬ëŒ ìˆ˜ (ìˆ«ìë¡œ)\n",
    "8. time_of_day: ì´¬ì˜ ì‹œê°„ëŒ€ (ë‚®/ë°¤/ì €ë… ë“±)\n",
    "\n",
    "ë‹¤ìŒê³¼ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œ ë‹µí•´ì£¼ì„¸ìš”:\n",
    "{\n",
    "    \"caption\": \"ì „ì²´ ì´ë¯¸ì§€ ì„¤ëª…\",\n",
    "    \"dense_captions\": [\"ì„¸ë¶€ì‚¬í•­1\", \"ì„¸ë¶€ì‚¬í•­2\", \"ì„¸ë¶€ì‚¬í•­3\"],\n",
    "    \"mood\": \"ë¶„ìœ„ê¸° ì„¤ëª…\",\n",
    "    \"time_period\": \"ì¶”ì • ì‹œëŒ€\",\n",
    "    \"key_objects\": [\"ê°ì²´1\", \"ê°ì²´2\", \"ê°ì²´3\"],\n",
    "    \"people_description\": \"ì‚¬ëŒë“¤ì— ëŒ€í•œ ì„¤ëª…\",\n",
    "    \"people_count\": 2,\n",
    "    \"time_of_day\": \"ë‚®\"\n",
    "}\"\"\"\n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"image_url\",\n",
    "                                \"image_url\": {\n",
    "                                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                                }\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "                max_tokens=1000,\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            # ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ\n",
    "            response_text = response.choices[0].message.content\n",
    "            \n",
    "            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (```jsonìœ¼ë¡œ ê°ì‹¸ì ¸ ìˆì„ ìˆ˜ ìˆìŒ)\n",
    "            if \"```json\" in response_text:\n",
    "                json_start = response_text.find(\"```json\") + 7\n",
    "                json_end = response_text.find(\"```\", json_start)\n",
    "                response_text = response_text[json_start:json_end].strip()\n",
    "            elif \"{\" in response_text:\n",
    "                json_start = response_text.find(\"{\")\n",
    "                json_end = response_text.rfind(\"}\") + 1\n",
    "                response_text = response_text[json_start:json_end]\n",
    "            \n",
    "            analysis_result = json.loads(response_text)\n",
    "            \n",
    "            # ê²°ê³¼ ì¶œë ¥\n",
    "            print(f\"\\nCaption: {analysis_result.get('caption', 'N/A')}\")\n",
    "            print(f\"Mood: {analysis_result.get('mood', 'N/A')}\")\n",
    "            print(f\"Time Period: {analysis_result.get('time_period', 'N/A')}\")\n",
    "            print(f\"People Count: {analysis_result.get('people_count', 'N/A')}\")\n",
    "            print(f\"Time of Day: {analysis_result.get('time_of_day', 'N/A')}\")\n",
    "            print(\"\\nDense Captions:\")\n",
    "            for caption in analysis_result.get('dense_captions', []):\n",
    "                print(f\"- {caption}\")\n",
    "            \n",
    "            return analysis_result\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON íŒŒì‹± ì˜¤ë¥˜: {e}\")\n",
    "            print(f\"ì›ë³¸ ì‘ë‹µ: {response_text}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
    "            return None\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜\n",
    "def test_image_analyzer():\n",
    "    \"\"\"ì´ë¯¸ì§€ ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    # í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ ê²½ë¡œ (ì‹¤ì œ ì‚¬ìš©ì‹œ ë³€ê²½ í•„ìš”)\n",
    "    test_image_path = \"test_image.jpg\"\n",
    "    \n",
    "    if os.path.exists(test_image_path):\n",
    "        analyzer = ImageAnalysisGPT()\n",
    "        result = analyzer.analyze_image_with_gpt(test_image_path)\n",
    "        return result\n",
    "    else:\n",
    "        print(f\"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {test_image_path}\")\n",
    "        return None\n",
    "\n",
    "print(\"âœ… ì´ë¯¸ì§€ ë¶„ì„ê¸° ëª¨ë“ˆì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41573b1",
   "metadata": {},
   "source": [
    "# 3. ëŒ€í™” ê´€ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e30f9309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëŒ€í™” ê´€ë¦¬ì ëª¨ë“ˆì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ConversationManager:\n",
    "    \"\"\"ëŒ€í™” ê´€ë¦¬ ë° í‰ê°€ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Azure OpenAI ê´€ë ¨ ì„¤ì •\n",
    "        self.endpoint = Config.ENDPOINT\n",
    "        self.deployment = Config.DEPLOYMENT\n",
    "        self.subscription_key = Config.SUBSCRIPTION_KEY\n",
    "        self.api_version = Config.API_VERSION\n",
    "        \n",
    "        if not self.endpoint or not self.subscription_key:\n",
    "            raise ValueError(\"Please set the gpt-endpoint and gpt-key in the environment variables.\")\n",
    "        \n",
    "        # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "        self.client = AzureOpenAI(\n",
    "            api_version=self.api_version,\n",
    "            azure_endpoint=self.endpoint,\n",
    "            api_key=self.subscription_key,\n",
    "        )\n",
    "        \n",
    "        # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”\n",
    "        self.conversation_history = []\n",
    "        \n",
    "        # í† í° ì¹´ìš´í„° ì´ˆê¸°í™”\n",
    "        self.tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        self.token_count = 0\n",
    "        self.MAX_TOKENS = Config.MAX_TOKENS\n",
    "        \n",
    "        # ì´ìƒí•œ ë‹µë³€ ì¶”ì \n",
    "        self.strange_responses = []\n",
    "        self.strange_response_count = 0\n",
    "        self.last_question = \"\"\n",
    "        self.last_question_type = \"normal\"\n",
    "        \n",
    "        # ëŒ€í™” ê¸°ë¡ ì¶”ì \n",
    "        self.conversation_turns = []\n",
    "        \n",
    "        # ì‹¤ì‹œê°„ ëŒ€í™” ì‹œìŠ¤í…œ ê´€ë ¨ ë³€ìˆ˜\n",
    "        self.turn_count = 0\n",
    "        self.image_analysis_result = None\n",
    "        \n",
    "    def _count_tokens(self, text: str) -> int:\n",
    "        \"\"\"ë¬¸ìì—´ì˜ í† í° ìˆ˜ ê³„ì‚°\"\"\"\n",
    "        return len(self.tokenizer.encode(text))\n",
    "    \n",
    "    def _count_message_tokens(self, messages: List[Dict[str, Any]]) -> int:\n",
    "        \"\"\"ëŒ€í™” ë©”ì‹œì§€ ëª©ë¡ì˜ ì´ í† í° ìˆ˜ ê³„ì‚°\"\"\"\n",
    "        total = 0\n",
    "        for message in messages:\n",
    "            total += self._count_tokens(message.get(\"content\", \"\"))\n",
    "        return total\n",
    "    \n",
    "    def _evaluate_response_relevance(self, question: str, answer: str, question_type: str = \"normal\") -> Dict[str, Any]:\n",
    "        \"\"\"ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ì„±ì´ ìˆëŠ”ì§€ LLMìœ¼ë¡œ í‰ê°€\"\"\"\n",
    "        \n",
    "        # ì§ˆë¬¸ íƒ€ì…ì— ë”°ë¥¸ í‰ê°€ ê¸°ì¤€ ì¡°ì •\n",
    "        if question_type == \"cognitive\":\n",
    "            evaluation_criteria = \"\"\"\n",
    "íŠ¹ë³„íˆ ì´ ì§ˆë¬¸ì€ ì¸ì§€ ëŠ¥ë ¥ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ì§ˆë¬¸ì…ë‹ˆë‹¤. ë‹¤ìŒì„ ì¤‘ì ì ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”:\n",
    "- ì§ˆë¬¸ì—ì„œ ìš”êµ¬í•˜ëŠ” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì œê³µí–ˆëŠ”ì§€ (ì˜ˆ: ìˆ«ì, ì‹œê°„ëŒ€ ë“±)\n",
    "- í˜„ì‹¤ ì¸ì‹ ëŠ¥ë ¥ì´ ì ì ˆí•œì§€\n",
    "- ì‹œê³µê°„ ì§€ë‚¨ë ¥ì´ ìœ ì§€ë˜ê³  ìˆëŠ”ì§€\n",
    "\"\"\"\n",
    "        elif question_type == \"keyword\":\n",
    "            evaluation_criteria = \"\"\"\n",
    "ì´ ì§ˆë¬¸ì€ íŠ¹ì • í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ê°ì •ì  ì—°ê²° ì§ˆë¬¸ì…ë‹ˆë‹¤. ë‹¤ìŒì„ í‰ê°€í•´ì£¼ì„¸ìš”:\n",
    "- ì§ˆë¬¸ì˜ ëŒ€ìƒ(ì‚¬ëŒì´ë‚˜ ìƒí™©)ì— ëŒ€í•œ ì ì ˆí•œ ë°˜ì‘ì¸ì§€\n",
    "- ê°ì •ì  ì—°ê²°ì„±ì´ ìˆëŠ”ì§€\n",
    "- ê¸°ì–µê³¼ ê´€ë ¨ëœ ì ì ˆí•œ ë‚´ìš©ì¸ì§€\n",
    "\"\"\"\n",
    "        else:\n",
    "            evaluation_criteria = \"\"\"\n",
    "ì¼ë°˜ì ì¸ ëŒ€í™” ì§ˆë¬¸ì…ë‹ˆë‹¤. ë‹¤ìŒì„ í‰ê°€í•´ì£¼ì„¸ìš”:\n",
    "- ì§ˆë¬¸ê³¼ ë‹µë³€ì˜ ì¼ë°˜ì ì¸ ê´€ë ¨ì„±\n",
    "- ëŒ€í™”ì˜ ìì—°ìŠ¤ëŸ¬ìš´ íë¦„\n",
    "\"\"\"\n",
    "        \n",
    "        evaluation_prompt = f\"\"\"\n",
    "ë‹¤ìŒ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë¶„ì„í•´ì„œ ë‹µë³€ì´ ì–¼ë§ˆë‚˜ ì ì ˆí•œì§€ í‰ê°€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "ë‹µë³€: {answer}\n",
    "ì§ˆë¬¸ íƒ€ì…: {question_type}\n",
    "\n",
    "{evaluation_criteria}\n",
    "\n",
    "í‰ê°€ ê¸°ì¤€:\n",
    "1. ì§ˆë¬¸ê³¼ ë‹µë³€ì˜ ê´€ë ¨ì„±\n",
    "2. ë‹µë³€ì˜ ì¼ê´€ì„±\n",
    "3. ë§¥ë½ì  ì ì ˆì„±\n",
    "\n",
    "ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•´ì£¼ì„¸ìš”:\n",
    "{{\n",
    "    \"is_strange\": true/false,\n",
    "    \"severity\": \"normal/mild/moderate/severe\",\n",
    "    \"reason\": \"í‰ê°€ ì´ìœ ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…\"\n",
    "}}\n",
    "\n",
    "severity ê¸°ì¤€:\n",
    "- normal: ì™„ì „íˆ ì ì ˆí•œ ë‹µë³€\n",
    "- mild: ì•½ê°„ ë²—ì–´ë‚¬ì§€ë§Œ ì´í•´ ê°€ëŠ¥\n",
    "- moderate: ìƒë‹¹íˆ ì—‰ëš±í•˜ì§€ë§Œ ì™„ì „íˆ ë¬´ê´€í•˜ì§€ëŠ” ì•ŠìŒ\n",
    "- severe: ì™„ì „íˆ ë¬´ê´€í•˜ê±°ë‚˜ ë¹„ë…¼ë¦¬ì ì¸ ë‹µë³€\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.deployment,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ ì¹˜ë§¤ í™˜ìì˜ ë‹µë³€ì„ í‰ê°€í•˜ëŠ” ì˜ë£Œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê°ê´€ì ì´ê³  ì •í™•í•˜ê²Œ í‰ê°€í•´ì£¼ì„¸ìš”.\"},\n",
    "                    {\"role\": \"user\", \"content\": evaluation_prompt}\n",
    "                ],\n",
    "                max_tokens=256,\n",
    "                temperature=0.1,\n",
    "                top_p=1.0,\n",
    "            )\n",
    "            \n",
    "            evaluation_text = response.choices[0].message.content\n",
    "            \n",
    "            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ\n",
    "            if \"```json\" in evaluation_text:\n",
    "                json_start = evaluation_text.find(\"```json\") + 7\n",
    "                json_end = evaluation_text.find(\"```\", json_start)\n",
    "                evaluation_text = evaluation_text[json_start:json_end].strip()\n",
    "            elif \"{\" in evaluation_text:\n",
    "                json_start = evaluation_text.find(\"{\")\n",
    "                json_end = evaluation_text.rfind(\"}\") + 1\n",
    "                evaluation_text = evaluation_text[json_start:json_end]\n",
    "            \n",
    "            evaluation_json = json.loads(evaluation_text)\n",
    "            return evaluation_json\n",
    "            \n",
    "        except (json.JSONDecodeError, Exception) as e:\n",
    "            print(f\"ë‹µë³€ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            # ê¸°ë³¸ê°’ ë°˜í™˜\n",
    "            return {\n",
    "                \"is_strange\": False,\n",
    "                \"severity\": \"normal\",\n",
    "                \"reason\": \"í‰ê°€ ì‹¤íŒ¨\"\n",
    "            }\n",
    "    \n",
    "    def _store_strange_response(self, question: str, answer: str, severity: str, reason: str, question_type: str = \"normal\"):\n",
    "        \"\"\"ì´ìƒí•œ ë‹µë³€ì„ ì €ì¥\"\"\"\n",
    "        strange_response = StrangeResponse(\n",
    "            question=question,\n",
    "            answer=answer,\n",
    "            timestamp=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            severity=severity,\n",
    "            question_type=question_type\n",
    "        )\n",
    "        \n",
    "        self.strange_responses.append(strange_response)\n",
    "        self.strange_response_count += 1\n",
    "    \n",
    "    def _generate_dynamic_cognitive_questions(self):\n",
    "        \"\"\"ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë™ì  ì¸ì§€ ì§ˆë¬¸ ìƒì„±\"\"\"\n",
    "        if not self.image_analysis_result:\n",
    "            return Config.BASE_COGNITIVE_QUESTIONS\n",
    "        \n",
    "        dynamic_questions = []\n",
    "        \n",
    "        # ì‚¬ëŒ ìˆ˜ ê´€ë ¨ ì§ˆë¬¸\n",
    "        people_count = self.image_analysis_result.get('people_count', 0)\n",
    "        if people_count > 0:\n",
    "            dynamic_questions.append(f\"ì´ ì‚¬ì§„ì—ëŠ” ëª‡ ëª…ì´ ìˆëŠ”ì§€ ê¸°ì–µë‚˜ì„¸ìš”?\")\n",
    "        \n",
    "        # ì‹œê°„ëŒ€ ê´€ë ¨ ì§ˆë¬¸\n",
    "        time_of_day = self.image_analysis_result.get('time_of_day', '')\n",
    "        if time_of_day:\n",
    "            dynamic_questions.append(f\"ì‚¬ì§„ì´ ë‚®ì— ì°íŒ ê²ƒ ê°™ë‚˜ìš”, ë°¤ì¸ê°€ìš”?\")\n",
    "        \n",
    "        # ì£¼ìš” ê°ì²´ ê´€ë ¨ ì§ˆë¬¸\n",
    "        key_objects = self.image_analysis_result.get('key_objects', [])\n",
    "        if key_objects:\n",
    "            obj = random.choice(key_objects)\n",
    "            dynamic_questions.append(f\"ì´ ì‚¬ì§„ì—ì„œ {obj}ì´(ê°€) ë³´ì´ì‹œë‚˜ìš”?\")\n",
    "        \n",
    "        # ê¸°ë³¸ ì§ˆë¬¸ê³¼ í•©ì³ì„œ ë°˜í™˜\n",
    "        all_questions = Config.BASE_COGNITIVE_QUESTIONS + dynamic_questions\n",
    "        return all_questions\n",
    "    \n",
    "    def _get_next_question_type_and_content(self, user_input):\n",
    "        \"\"\"ë‹¤ìŒ ì§ˆë¬¸ì˜ íƒ€ì…ê³¼ ë‚´ìš©ì„ ê²°ì •í•˜ëŠ” í†µí•© ë¡œì§\"\"\"\n",
    "        self.turn_count += 1\n",
    "        \n",
    "        # 1. í‚¤ì›Œë“œ ê¸°ë°˜ ì§ˆë¬¸ ì²´í¬ (ìš°ì„ ìˆœìœ„ 1)\n",
    "        for keyword, question in Config.KEYWORD_QUESTIONS.items():\n",
    "            if keyword in user_input:\n",
    "                return \"keyword\", question\n",
    "        \n",
    "        # 2. ì¸ì§€ ëŠ¥ë ¥ ê²€ì‚¬ ì§ˆë¬¸ (3í„´ë§ˆë‹¤, ìš°ì„ ìˆœìœ„ 2)\n",
    "        if self.turn_count > 0 and self.turn_count % 3 == 0:\n",
    "            cognitive_questions = self._generate_dynamic_cognitive_questions()\n",
    "            question = random.choice(cognitive_questions)\n",
    "            return \"cognitive\", question\n",
    "        \n",
    "        # 3. ì¼ë°˜ ëŒ€í™” ê³„ì† (ìš°ì„ ìˆœìœ„ 3)\n",
    "        return \"normal\", None\n",
    "\n",
    "print(\"âœ… ëŒ€í™” ê´€ë¦¬ì ëª¨ë“ˆì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2332180e",
   "metadata": {},
   "source": [
    "# 4. ì±„íŒ… ì‹œìŠ¤í…œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82e24316",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ChatSystem(ConversationManager):\n",
    "    \"\"\"ì‹¤ì‹œê°„ ì±„íŒ… ì‹œìŠ¤í…œ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def setup_conversation_context(self, analysis_result, user_description=\"\", user_description_date=\"\"):\n",
    "        \"\"\"ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì„¤ì •\"\"\"\n",
    "        self.image_analysis_result = analysis_result  # ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ì €ì¥\n",
    "        \n",
    "        caption = analysis_result.get(\"caption\", \"\")\n",
    "        dense_captions = analysis_result.get(\"dense_captions\", [])\n",
    "        mood = analysis_result.get(\"mood\", \"\")\n",
    "        time_period = analysis_result.get(\"time_period\", \"\")\n",
    "        key_objects = analysis_result.get(\"key_objects\", [])\n",
    "        people_description = analysis_result.get(\"people_description\", \"\")\n",
    "        \n",
    "        # ìƒì„¸ ìº¡ì…˜ í…ìŠ¤íŠ¸ í¬ë§·íŒ…\n",
    "        dense_captions_text = \"\\n\".join([f\"- {dc}\" for dc in dense_captions])\n",
    "        key_objects_text = \", \".join(key_objects)\n",
    "        \n",
    "        # í†µí•©ëœ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„¤ì •\n",
    "        system_message = f\"\"\"ë„ˆëŠ” ë…¸ì¸ê³¼ ëŒ€í™”í•˜ëŠ” ìš”ì–‘ë³´í˜¸ì‚¬ì•¼. ë…¸ì¸ê³¼ íŠ¹ì • ì´ë¯¸ì§€ì— ëŒ€í•´ì„œ ì§ˆì˜ì‘ë‹µì„ ì£¼ê³ ë°›ì•„. \n",
    "ë…¸ì¸ì€ ì¹˜ë§¤ ì¦ìƒì´ ê°‘ìê¸° ë‚˜íƒ€ë‚  ìˆ˜ë„ ìˆì–´. ë°˜ë³µë˜ëŠ” ë§ì—ë„ ë˜‘ê°™ì´ ëŒ€ë‹µí•´ì¤˜ì•¼ í•´. \n",
    "ì¹œì ˆí•˜ê³  ì–´ë¥¸ì„ ê³µê²½í•˜ëŠ” ë§íˆ¬ì—¬ì•¼ í•´. ê·¸ë¦¬ê³  ê³µê°ì„ ì˜ í•´ì•¼ í•´. ì˜ˆì˜ë„ ì§€ì¼œ. \n",
    "ë„ˆëŠ” ì£¼ë¡œ ì§ˆë¬¸ì„ í•˜ëŠ” ìª½ì´ê³ , ë…¸ì¸ì€ ëŒ€ë‹µì„ í•´ì¤„ê±°ì•¼. ëŒ€ë‹µì— ëŒ€í•œ ë¦¬ì•¡ì…˜ê³¼ í•¨ê»˜ ì ì ˆíˆ ëŒ€í™”ë¥¼ ì´ì–´ ê°€.\n",
    "ë…¸ì¸ì˜ ë°œì–¸ì´ ëë‚˜ë©´ ê·¸ì™€ ê´€ë ¨ëœ ê³µê° ë¬¸ì¥ì„ ë¨¼ì € ë§í•œ í›„, ìì—°ìŠ¤ëŸ½ê²Œ ê·¸ ê¸°ì–µì— ëŒ€í•´ ë” ë¬¼ì–´ë³´ëŠ” ê¼¬ë¦¬ ì§ˆë¬¸ì„ ë§ë¶™ì—¬.\n",
    "ê·¸ë¦¬ê³  ì§ˆë¬¸ì„ ì¤„ ë•Œ í•œë¬¸ì¥ìœ¼ë¡œ ê°„ë‹¨ ëª…ë£Œí•˜ê²Œ í•´ì¤˜.\n",
    "\n",
    "=== ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ===\n",
    "ì£¼ìš” ì„¤ëª…(Caption): {caption}\n",
    "ë¶„ìœ„ê¸°/ê°ì •: {mood}\n",
    "ì¶”ì • ì‹œëŒ€: {time_period}\n",
    "ì£¼ìš” ê°ì²´ë“¤: {key_objects_text}\n",
    "ì¸ë¬¼ ì„¤ëª…: {people_description}\n",
    "\n",
    "ì„¸ë¶€ ìš”ì†Œë“¤:\n",
    "{dense_captions_text}\n",
    "\n",
    "=== ëŒ€í™” ê°€ì´ë“œë¼ì¸ ===\n",
    "1. ì–´ë¥´ì‹ ë“¤(íŠ¹íˆ ì¹˜ë§¤ í™˜ì)ê³¼ ëŒ€í™”í•œë‹¤ê³  ê°€ì •í•˜ê³  ì¹œê·¼í•˜ê³  ë”°ëœ»í•˜ê²Œ ëŒ€í™”í•˜ì„¸ìš”.\n",
    "2. ì´ë¯¸ì§€ì— ëŒ€í•œ í¥ë¯¸ë¡œìš´ ì§ˆë¬¸ì„ ë¨¼ì € ë˜ì ¸ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”.\n",
    "3. ì‚¬ìš©ìê°€ ì—‰ëš±í•œ ë‹µë³€ì„ í•´ë„ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°€ë©° ì¹œì ˆí•˜ê²Œ ì´ëŒì–´ì£¼ì„¸ìš”.\n",
    "4. ê·¸ë•Œ ë‹¹ì‹œì˜ ê°ì •ì´ë‚˜ ê²½í—˜ì— ëŒ€í•´ ë¬¼ì–´ë³´ë©° ì¶”ì–µì„ ë˜ì‚´ë ¤ì£¼ì„¸ìš”.\n",
    "5. ê·¸ë¦¬ê³  ê¸´ ì§ˆë¬¸ì€ í”¼í•˜ê³ , í•œë¬¸ì¥ìœ¼ë¡œ ê°„ë‹¨í•˜ê³  ê°ì„±ì ìœ¼ë¡œ ì§ˆë¬¸í•´ì¤˜.\n",
    "=== ëŒ€í™” ì „ëµ ===\n",
    "ë¬¸ì œ ìƒí™©ë³„ í•´ê²° ë°©ë²•:\n",
    "\n",
    "â–ª ì§ˆë¬¸ì„ ì´í•´í•˜ì§€ ëª»í•  ê²½ìš°:\n",
    "  - ì§ˆë¬¸ì„ ë‹¨ìˆœí™”í•˜ì—¬ ì¬êµ¬ì„±\n",
    "  - ì„ íƒì§€ë¥¼ ì œê³µí•˜ì—¬ ë‹µí•˜ê¸° ì‰½ê²Œ ë§Œë“¤ê¸°\n",
    "  - ì˜ˆì‹œë‚˜ ë§¥ë½ì„ í•¨ê»˜ ì œê³µ\n",
    "\n",
    "â–ª ì—‰ëš±í•œ ëŒ€ë‹µì„ í•  ê²½ìš°:\n",
    "  - ëŒ€ë‹µì„ ìˆ˜ìš©í•˜ë©´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ì£¼ì œë¡œ ìœ ë„\n",
    "  - ëŒ€ë‹µì˜ ì¼ë¶€ë¶„ì´ë¼ë„ ì—°ê²°ì ì„ ì°¾ì•„ ì´ì–´ê°€ê¸°\n",
    "\n",
    "â–ª ëŒ€ë‹µì„ ëª»í•  ê²½ìš°:\n",
    "  - ì‹¬ë¦¬ì  ë¶€ë‹´ ì—†ì´ ë„˜ì–´ê°€ê¸°\n",
    "  - \"ê¸°ì–µì´ ì•ˆ ë‚˜ì…”ë„ ê´œì°®ë‹¤\"ê³  ì•ˆì‹¬ì‹œí‚¤ê¸°\n",
    "\n",
    "ì´ë¯¸ì§€ì˜ ì‹œê°ì  ìš”ì†Œë“¤ì„ ìƒìƒí•˜ê²Œ ë¬˜ì‚¬í•˜ë©°, ê·¸ë•Œì˜ ê°ì •ê³¼ ìƒí™©ì— ëŒ€í•´ ê¶ê¸ˆí•´í•˜ëŠ” ì†ì/ì†ë…€ì˜ ë§ˆìŒìœ¼ë¡œ ëŒ€í™”í•˜ì„¸ìš”.\"\"\"\n",
    "        \n",
    "        # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ë° í† í° ìˆ˜ ê³„ì‚°\n",
    "        self.conversation_history = [{\"role\": \"system\", \"content\": system_message}]\n",
    "        self.token_count = self._count_tokens(system_message)\n",
    "        \n",
    "        return system_message\n",
    "    \n",
    "    def generate_initial_question(self):\n",
    "        \"\"\"ì²« ì§ˆë¬¸ ìƒì„± í•¨ìˆ˜\"\"\"\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.deployment,\n",
    "            messages=self.conversation_history + [\n",
    "                {\"role\": \"user\", \"content\": \"ì´ ì˜›ë‚  ì‚¬ì§„ì— ëŒ€í•´ ì–´ë¥´ì‹ ì—ê²Œ ë¬¼ì–´ë³¼ ì²« ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”. ê°„ë‹¨í•˜ê³  ê¸°ì–µí•˜ê¸° ì‰¬ìš°ë©°, ê°ì •ì ìœ¼ë¡œ ì—°ê²°ë  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\"}\n",
    "            ],\n",
    "            max_tokens=512,\n",
    "            temperature=0.8,\n",
    "            top_p=1.0,\n",
    "        )\n",
    "        \n",
    "        initial_question = response.choices[0].message.content\n",
    "        \n",
    "        # ì§ˆë¬¸ ì¶”ê°€ ë° í† í° ìˆ˜ ì—…ë°ì´íŠ¸\n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": initial_question})\n",
    "        self.token_count += self._count_tokens(initial_question)\n",
    "        \n",
    "        # ë§ˆì§€ë§‰ ì§ˆë¬¸ ì €ì¥\n",
    "        self.last_question = initial_question\n",
    "        self.last_question_type = \"normal\"\n",
    "        \n",
    "        return initial_question\n",
    "    \n",
    "    def chat_about_image(self, user_query):\n",
    "        \"\"\"ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±\"\"\"\n",
    "        # í† í° ì œí•œ í™•ì¸\n",
    "        user_tokens = self._count_tokens(user_query)\n",
    "        \n",
    "        # ì‚¬ìš©ì ë‹µë³€ì˜ ì ì ˆì„± í‰ê°€ (ì´ì „ ì§ˆë¬¸ì´ ìˆëŠ” ê²½ìš°)\n",
    "        if self.last_question:\n",
    "            evaluation = self._evaluate_response_relevance(\n",
    "                self.last_question, \n",
    "                user_query, \n",
    "                self.last_question_type\n",
    "            )\n",
    "            \n",
    "            if evaluation.get(\"is_strange\", False):\n",
    "                severity = evaluation.get(\"severity\", \"mild\")\n",
    "                reason = evaluation.get(\"reason\", \"ê´€ë ¨ì„± ë¶€ì¡±\")\n",
    "                \n",
    "                # ì´ìƒí•œ ë‹µë³€ ì €ì¥\n",
    "                self._store_strange_response(\n",
    "                    question=self.last_question,\n",
    "                    answer=user_query,\n",
    "                    severity=severity,\n",
    "                    reason=reason,\n",
    "                    question_type=self.last_question_type\n",
    "                )\n",
    "        \n",
    "        # ëŒ€í™” í„´ ì €ì¥ (ì§ˆë¬¸-ë‹µë³€ ìŒ)\n",
    "        if self.last_question:\n",
    "            conversation_turn = ConversationTurn(\n",
    "                question=self.last_question,\n",
    "                answer=user_query,\n",
    "                timestamp=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                question_type=self.last_question_type\n",
    "            )\n",
    "            self.conversation_turns.append(conversation_turn)\n",
    "        \n",
    "        # ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": user_query})\n",
    "        self.token_count += user_tokens\n",
    "        \n",
    "        # í† í° ì œí•œ ì´ˆê³¼ í™•ì¸\n",
    "        if self.token_count > self.MAX_TOKENS:\n",
    "            answer = \"ì£„ì†¡í•©ë‹ˆë‹¤, ë‚˜ì¤‘ì— ë‹¤ì‹œ ì–˜ê¸°í•´ìš”. ì§€ê¸ˆì€ ì ì‹œ ì‰¬ì–´ì•¼ í•  ê²ƒ ê°™ì•„ìš”. ë§Œì•½ ë” ë§ì€ ëŒ€í™”ë¥¼ ì›í•œë‹¤ë©´ MEMENTO BOX Premiumì„ ì‚¬ìš©í•´ë³´ì„¸ìš”.\"\n",
    "            self.conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "            return answer, True, \"normal\"  # TrueëŠ” ëŒ€í™” ì¢…ë£Œ ì‹ í˜¸\n",
    "        \n",
    "        # ë‹¤ìŒ ì§ˆë¬¸ íƒ€ì…ê³¼ ë‚´ìš© ê²°ì •\n",
    "        next_question_type, special_question = self._get_next_question_type_and_content(user_query)\n",
    "        \n",
    "        if special_question:\n",
    "            # íŠ¹ë³„ ì§ˆë¬¸ (í‚¤ì›Œë“œ ê¸°ë°˜ ë˜ëŠ” ì¸ì§€ ê²€ì‚¬)\n",
    "            answer = special_question\n",
    "            question_type = next_question_type\n",
    "        else:\n",
    "            # ì¼ë°˜ LLM ì‘ë‹µ ìƒì„±\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.deployment,\n",
    "                messages=self.conversation_history,\n",
    "                max_tokens=1024,\n",
    "                temperature=0.7,\n",
    "                top_p=1.0,\n",
    "            )\n",
    "            answer = response.choices[0].message.content\n",
    "            question_type = \"normal\"\n",
    "        \n",
    "        # ì‘ë‹µ ì¶”ê°€ ë° í† í° ìˆ˜ ì—…ë°ì´íŠ¸\n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "        self.token_count += self._count_tokens(answer)\n",
    "        \n",
    "        # ë‹¤ìŒ í‰ê°€ë¥¼ ìœ„í•´ í˜„ì¬ AI ì‘ë‹µì„ ì§ˆë¬¸ìœ¼ë¡œ ì €ì¥\n",
    "        self.last_question = answer\n",
    "        self.last_question_type = question_type\n",
    "        \n",
    "        # í† í° ì œí•œ ì´ˆê³¼ í™•ì¸ (ì‘ë‹µ í›„)\n",
    "        if self.token_count > self.MAX_TOKENS:\n",
    "            return answer, True, question_type  # ëŒ€í™” ì¢…ë£Œ ì‹ í˜¸\n",
    "        \n",
    "        return answer, False, question_type  # ëŒ€í™” ê³„ì†\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1bd3a9",
   "metadata": {},
   "source": [
    "# 5. ë¦¬í¬íŠ¸ ìƒì„±ê¸° "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b24ee02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¦¬í¬íŠ¸ ìƒì„±ê¸° ëª¨ë“ˆì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ReportGenerator:\n",
    "    \"\"\"ë¦¬í¬íŠ¸ ìƒì„± í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, chat_system):\n",
    "        self.chat_system = chat_system\n",
    "        \n",
    "    def setup_korean_font(self):\n",
    "        \"\"\"í•œê¸€ í°íŠ¸ ì„¤ì •\"\"\"\n",
    "        try:\n",
    "            # Windows\n",
    "            font_path = \"C:/Windows/Fonts/malgun.ttf\"\n",
    "            if not os.path.exists(font_path):\n",
    "                # macOS\n",
    "                font_path = \"/System/Library/Fonts/AppleGothic.ttf\"\n",
    "                if not os.path.exists(font_path):\n",
    "                    # Linux (Ubuntu)\n",
    "                    font_path = \"/usr/share/fonts/truetype/nanum/NanumGothic.ttf\"\n",
    "            \n",
    "            if os.path.exists(font_path):\n",
    "                font_prop = fm.FontProperties(fname=font_path)\n",
    "                plt.rcParams['font.family'] = font_prop.get_name()\n",
    "            else:\n",
    "                # ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©\n",
    "                plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "        except:\n",
    "            plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "        \n",
    "        plt.rcParams['axes.unicode_minus'] = False\n",
    "    \n",
    "    def generate_mobile_report(self, image_path, output_dir=\"reports\"):\n",
    "        \"\"\"ëª¨ë°”ì¼ í™”ë©´ì— ìµœì í™”ëœ ë¦¬í¬íŠ¸ ìƒì„±\"\"\"\n",
    "        \n",
    "        # í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "        self.setup_korean_font()\n",
    "        \n",
    "        # ë¦¬í¬íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # ì „ì²´ ë‹µë³€ íšŸìˆ˜ ê³„ì‚°\n",
    "        total_responses = len(self.chat_system.conversation_turns)\n",
    "        \n",
    "        if total_responses == 0:\n",
    "            print(\"ëŒ€í™”ê°€ ì§„í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "            return None\n",
    "        \n",
    "        # ì‹¬ê°ë„ë³„ ë¶„ë¥˜\n",
    "        severity_counts = {\"mild\": 0, \"moderate\": 0, \"severe\": 0}\n",
    "        question_type_counts = {\"normal\": 0, \"keyword\": 0, \"cognitive\": 0}\n",
    "        \n",
    "        for response in self.chat_system.strange_responses:\n",
    "            severity_counts[response.severity] += 1\n",
    "        \n",
    "        for turn in self.chat_system.conversation_turns:\n",
    "            question_type_counts[turn.question_type] += 1\n",
    "        \n",
    "        # ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚°\n",
    "        risk_score = (severity_counts['mild'] * 1 + \n",
    "                     severity_counts['moderate'] * 3 + \n",
    "                     severity_counts['severe'] * 5)\n",
    "        max_risk_score = self.chat_system.strange_response_count * 5 if self.chat_system.strange_response_count > 0 else 1\n",
    "        risk_percentage = (risk_score / max_risk_score * 100) if max_risk_score > 0 else 0\n",
    "        \n",
    "        # ëª¨ë°”ì¼ í™”ë©´ì— ìµœì í™”ëœ ì„¸ë¡œí˜• ë ˆì´ì•„ì›ƒ ìƒì„±\n",
    "        fig = plt.figure(figsize=(9, 16), facecolor='#f8f9fa')\n",
    "        \n",
    "        # ì „ì²´ íƒ€ì´í‹€ ì¶”ê°€\n",
    "        fig.suptitle('í†µí•© ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ë¶„ì„ ë¦¬í¬íŠ¸', fontsize=18, fontweight='bold', y=0.98, color='#2c3e50')\n",
    "        \n",
    "        # 1. ìƒë‹¨: ì›ë³¸ ì´ë¯¸ì§€ í‘œì‹œ\n",
    "        ax1 = plt.subplot2grid((8, 2), (0, 0), colspan=2, rowspan=1)\n",
    "        try:\n",
    "            img = Image.open(image_path)\n",
    "            img.thumbnail((500, 300), Image.Resampling.LANCZOS)\n",
    "            ax1.imshow(img)\n",
    "            ax1.axis('off')\n",
    "            for spine in ax1.spines.values():\n",
    "                spine.set_visible(True)\n",
    "                spine.set_linewidth(2)\n",
    "                spine.set_color('#34495e')\n",
    "        except Exception as e:\n",
    "            ax1.text(0.5, 0.5, f'ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨\\n{os.path.basename(image_path)}', \n",
    "                    ha='center', va='center', fontsize=12, \n",
    "                    bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"#e74c3c\", alpha=0.8, edgecolor='none'))\n",
    "            ax1.set_xlim(0, 1)\n",
    "            ax1.set_ylim(0, 1)\n",
    "            ax1.axis('off')\n",
    "        \n",
    "        # 2. ì™¼ìª½: ì£¼ìš” ìˆ˜ì¹˜ í‘œì‹œ\n",
    "        ax2 = plt.subplot2grid((8, 2), (1, 0), rowspan=2)\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        stats_text = f\"\"\"[í†µí•© ëŒ€í™” ë¶„ì„ ê²°ê³¼]\n",
    "\n",
    "â–ª ì „ì²´ ë‹µë³€: {total_responses}íšŒ\n",
    "â–ª ì´ìƒ ë‹µë³€: {self.chat_system.strange_response_count}íšŒ ({(self.chat_system.strange_response_count/total_responses*100):.1f}%)\n",
    "â–ª ìœ„í—˜ë„: {risk_percentage:.1f}% ({risk_score}/{max_risk_score}ì )\n",
    "\n",
    "ëŒ€í™” íƒ€ì…ë³„ ë¶„ë¥˜:\n",
    "  â— ì¼ë°˜: {question_type_counts['normal']}íšŒ\n",
    "  â— í‚¤ì›Œë“œ: {question_type_counts['keyword']}íšŒ\n",
    "  â— ì¸ì§€ê²€ì‚¬: {question_type_counts['cognitive']}íšŒ\n",
    "\n",
    "ì‹¬ê°ë„ë³„ ë¶„ë¥˜:\n",
    "  â— ê²½ë¯¸: {severity_counts['mild']}íšŒ\n",
    "  â— ë³´í†µ: {severity_counts['moderate']}íšŒ  \n",
    "  â— ì‹¬ê°: {severity_counts['severe']}íšŒ\"\"\"\n",
    "        \n",
    "        ax2.text(0.05, 0.95, stats_text, fontsize=11, va='top', \n",
    "                bbox=dict(boxstyle=\"round,pad=0.8\", facecolor=\"#ecf0f1\", alpha=0.9, \n",
    "                         edgecolor='#bdc3c7', linewidth=1.5))\n",
    "        \n",
    "        # 3. ì˜¤ë¥¸ìª½: ìƒì„¸ ê¸°ë¡ ì˜ˆì‹œ\n",
    "        ax3 = plt.subplot2grid((8, 2), (1, 1), rowspan=2)\n",
    "        ax3.axis('off')\n",
    "        \n",
    "        detail_examples = \"[ìƒì„¸ ê¸°ë¡ ì˜ˆì‹œ]\\n\\n\"\n",
    "        \n",
    "        if self.chat_system.strange_response_count > 0:\n",
    "            examples_to_show = min(3, len(self.chat_system.strange_responses))\n",
    "            for i, response in enumerate(self.chat_system.strange_responses[:examples_to_show]):\n",
    "                severity_symbol = {\"mild\": \"â—\", \"moderate\": \"â—\", \"severe\": \"â—\"}\n",
    "                severity_name = {\"mild\": \"ê²½ë¯¸\", \"moderate\": \"ë³´í†µ\", \"severe\": \"ì‹¬ê°\"}\n",
    "                type_name = {\"normal\": \"ì¼ë°˜\", \"keyword\": \"í‚¤ì›Œë“œ\", \"cognitive\": \"ì¸ì§€\"}\n",
    "                \n",
    "                detail_examples += f\"{severity_symbol[response.severity]} [{severity_name[response.severity]}][{type_name[response.question_type]}]\\n\"\n",
    "                detail_examples += f\"Q: {response.question[:20]}...\\n\"\n",
    "                detail_examples += f\"A: {response.answer[:20]}...\\n\\n\"\n",
    "            \n",
    "            if len(self.chat_system.strange_responses) > 3:\n",
    "                detail_examples += f\"... ì™¸ {len(self.chat_system.strange_responses) - 3}ê±´ ë”\"\n",
    "        else:\n",
    "            detail_examples += \"âœ“ ì´ìƒ ë‹µë³€ì´ ê°ì§€ë˜ì§€\\n    ì•Šì•˜ìŠµë‹ˆë‹¤.\\n\\nì •ìƒì ì¸ ëŒ€í™”ê°€\\nì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        ax3.text(0.05, 0.95, detail_examples, fontsize=10, va='top',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.8\", \n",
    "                         facecolor=\"#fff3cd\" if self.chat_system.strange_response_count > 0 else \"#d4edda\", \n",
    "                         alpha=0.9, \n",
    "                         edgecolor='#ffeaa7' if self.chat_system.strange_response_count > 0 else '#c3e6cb', \n",
    "                         linewidth=1.5))\n",
    "        \n",
    "        # 4-7. ì°¨íŠ¸ë“¤ (ê°„ì†Œí™”)\n",
    "        self._add_charts(fig, severity_counts, question_type_counts, total_responses)\n",
    "        \n",
    "        # 8. í•˜ë‹¨: ê¶Œì¥ì‚¬í•­\n",
    "        self._add_recommendation(fig, severity_counts, risk_percentage, question_type_counts)\n",
    "        \n",
    "        # ì „ì²´ ë ˆì´ì•„ì›ƒ ì¡°ì •\n",
    "        plt.tight_layout(rect=[0, 0.08, 1, 0.95], pad=2.0)\n",
    "        \n",
    "        # íŒŒì¼ëª… ìƒì„± ë° ì €ì¥\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        image_basename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        report_filename = os.path.join(output_dir, f\"{image_basename}_report_{timestamp}.png\")\n",
    "        \n",
    "        plt.savefig(report_filename, dpi=200, bbox_inches='tight', \n",
    "                    facecolor='#f8f9fa', edgecolor='none', format='png')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"ğŸ“± ëª¨ë°”ì¼ ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {report_filename}\")\n",
    "        return report_filename\n",
    "    \n",
    "    def _add_charts(self, fig, severity_counts, question_type_counts, total_responses):\n",
    "        \"\"\"ì°¨íŠ¸ ì¶”ê°€ (ê°„ì†Œí™”ëœ ë²„ì „)\"\"\"\n",
    "        # 4. ëŒ€í™” ë¶„ì„ ë°” ê·¸ë˜í”„\n",
    "        ax4 = plt.subplot2grid((8, 2), (3, 0), rowspan=2)\n",
    "        \n",
    "        categories = ['ì •ìƒ\\në‹µë³€', 'ì´ìƒ\\në‹µë³€']\n",
    "        counts = [total_responses - self.chat_system.strange_response_count, self.chat_system.strange_response_count]\n",
    "        colors = ['#27ae60', '#e74c3c']\n",
    "        \n",
    "        bars1 = ax4.bar(categories, counts, color=colors, alpha=0.8, width=0.6, edgecolor='white', linewidth=2)\n",
    "        ax4.set_title('ëŒ€í™” ë¶„ì„', fontsize=13, fontweight='bold', pad=15, color='#2c3e50')\n",
    "        ax4.set_ylabel('ë‹µë³€ íšŸìˆ˜', fontsize=11, color='#34495e')\n",
    "        \n",
    "        for bar, count in zip(bars1, counts):\n",
    "            height = bar.get_height()\n",
    "            ax4.text(bar.get_x() + bar.get_width()/2., height + 0.2,\n",
    "                    f'{count}íšŒ', ha='center', va='bottom', fontsize=11, fontweight='bold', color='#2c3e50')\n",
    "        \n",
    "        ax4.set_ylim(0, max(counts) * 1.3)\n",
    "        ax4.grid(axis='y', alpha=0.2, linestyle='--')\n",
    "        ax4.spines['top'].set_visible(False)\n",
    "        ax4.spines['right'].set_visible(False)\n",
    "        ax4.tick_params(colors='#34495e')\n",
    "        \n",
    "        # 5. ì‹¬ê°ë„ë³„ ì´ìƒ ë‹µë³€ ë°” ê·¸ë˜í”„\n",
    "        ax5 = plt.subplot2grid((8, 2), (3, 1), rowspan=2)\n",
    "        \n",
    "        if self.chat_system.strange_response_count > 0:\n",
    "            severity_labels = ['ê²½ë¯¸', 'ë³´í†µ', 'ì‹¬ê°']\n",
    "            severity_values = [severity_counts['mild'], severity_counts['moderate'], severity_counts['severe']]\n",
    "            severity_colors = ['#f39c12', '#e67e22', '#e74c3c']\n",
    "            \n",
    "            bars2 = ax5.bar(severity_labels, severity_values, color=severity_colors, alpha=0.8, \n",
    "                           width=0.6, edgecolor='white', linewidth=2)\n",
    "            ax5.set_title('ì´ìƒ ë‹µë³€ ì‹¬ê°ë„', fontsize=13, fontweight='bold', pad=15, color='#2c3e50')\n",
    "            ax5.set_ylabel('ë‹µë³€ íšŸìˆ˜', fontsize=11, color='#34495e')\n",
    "            \n",
    "            for bar, count in zip(bars2, severity_values):\n",
    "                height = bar.get_height()\n",
    "                if height > 0:\n",
    "                    ax5.text(bar.get_x() + bar.get_width()/2., height + 0.05,\n",
    "                            f'{count}íšŒ', ha='center', va='bottom', fontsize=11, fontweight='bold', color='#2c3e50')\n",
    "            \n",
    "            ax5.set_ylim(0, max(severity_values) * 1.4 if max(severity_values) > 0 else 1)\n",
    "            ax5.grid(axis='y', alpha=0.2, linestyle='--')\n",
    "            ax5.spines['top'].set_visible(False)\n",
    "            ax5.spines['right'].set_visible(False)\n",
    "            ax5.tick_params(colors='#34495e')\n",
    "        else:\n",
    "            ax5.text(0.5, 0.5, 'ì´ìƒ ë‹µë³€ ì—†ìŒ', ha='center', va='center', \n",
    "                    fontsize=13, fontweight='bold', color='#27ae60', transform=ax5.transAxes,\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"#d4edda\", alpha=0.8, edgecolor='#c3e6cb'))\n",
    "            ax5.set_xlim(0, 1)\n",
    "            ax5.set_ylim(0, 1)\n",
    "            ax5.axis('off')\n",
    "    \n",
    "    def _add_recommendation(self, fig, severity_counts, risk_percentage, question_type_counts):\n",
    "        \"\"\"ê¶Œì¥ì‚¬í•­ ì¶”ê°€\"\"\"\n",
    "        cognitive_strange = [r for r in self.chat_system.strange_responses if r.question_type == \"cognitive\"]\n",
    "        cognitive_risk = len(cognitive_strange) / question_type_counts['cognitive'] * 100 if question_type_counts['cognitive'] > 0 else 0\n",
    "        \n",
    "        if severity_counts['severe'] >= 2 or risk_percentage > 80 or cognitive_risk > 60:\n",
    "            recommendation = \"[ê¸´ê¸‰] ì „ë¬¸ì˜ ìƒë‹´ ì‹œê¸‰\"\n",
    "            rec_color = '#e74c3c'\n",
    "            bg_color = '#fadbd8'\n",
    "        elif severity_counts['severe'] >= 1 or risk_percentage > 60 or cognitive_risk > 40:\n",
    "            recommendation = \"[ì£¼ì˜] ê´€ì°° í•„ìš”\"\n",
    "            rec_color = '#e67e22'\n",
    "            bg_color = '#fdeaa7'\n",
    "        elif risk_percentage > 40 or cognitive_risk > 30:\n",
    "            recommendation = \"[ì•ˆë‚´] ì •ê¸°ì  ê´€ì°° ê¶Œì¥\"\n",
    "            rec_color = '#f39c12'\n",
    "            bg_color = '#fcf3cf'\n",
    "        else:\n",
    "            recommendation = \"[ì •ìƒ] ì–‘í˜¸í•œ ìƒíƒœ\"\n",
    "            rec_color = '#27ae60'\n",
    "            bg_color = '#d5f4e6'\n",
    "        \n",
    "        fig.text(0.5, 0.04, recommendation, ha='center', va='center', \n",
    "                fontsize=16, fontweight='bold', color=rec_color,\n",
    "                bbox=dict(boxstyle=\"round,pad=1.0\", facecolor=bg_color, alpha=0.9, \n",
    "                         edgecolor=rec_color, linewidth=2))\n",
    "\n",
    "print(\"âœ… ë¦¬í¬íŠ¸ ìƒì„±ê¸° ëª¨ë“ˆì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8caa205",
   "metadata": {},
   "source": [
    "# 6. ìŠ¤í† ë¦¬ ìƒì„±ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67e26855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ìŠ¤í† ë¦¬ ìƒì„±ê¸° ëª¨ë“ˆì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# 6. ìŠ¤í† ë¦¬ ìƒì„±ê¸° (story_generator.ipynb)\n",
    "\n",
    "# ì´ì „ ëª¨ë“ˆë“¤ import (ì‹¤ì œ ì‚¬ìš©ì‹œì—ëŠ” %run ë˜ëŠ” import ì‚¬ìš©)\n",
    "# %run config.ipynb\n",
    "\n",
    "class StoryGenerator:\n",
    "    \"\"\"ì¶”ì–µ ìŠ¤í† ë¦¬ ìƒì„± í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, chat_system):\n",
    "        self.chat_system = chat_system\n",
    "        \n",
    "        # Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©\n",
    "        self.client = self.chat_system.client\n",
    "        self.deployment = self.chat_system.deployment\n",
    "    \n",
    "    def generate_story_from_conversation(self, image_path):\n",
    "        \"\"\"ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë…¸ì¸ë¶„ì˜ ê´€ì ì—ì„œ ìŠ¤í† ë¦¬ ìƒì„±\"\"\"\n",
    "        # ëŒ€í™” ë‚´ìš© ì •ë¦¬\n",
    "        conversation_text = \"\"\n",
    "        for turn in self.chat_system.conversation_turns:\n",
    "            type_name = {\"normal\": \"ì¼ë°˜\", \"keyword\": \"í‚¤ì›Œë“œ\", \"cognitive\": \"ì¸ì§€ê²€ì‚¬\"}\n",
    "            conversation_text += f\"[{type_name[turn.question_type]}] ì§ˆë¬¸: {turn.question}\\në‹µë³€: {turn.answer}\\n\\n\"\n",
    "        \n",
    "        # ìŠ¤í† ë¦¬ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸\n",
    "        story_prompt = f\"\"\"\n",
    "ë‹¤ìŒì€ í•œ ì–´ë¥´ì‹ ì´ ì˜›ë‚  ì‚¬ì§„ì„ ë³´ë©° ë‚˜ëˆˆ ëŒ€í™”ì…ë‹ˆë‹¤:\n",
    "\n",
    "{conversation_text}\n",
    "\n",
    "ì´ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ì§„ ì† ìˆœê°„ì— ëŒ€í•œ ì–´ë¥´ì‹ ì˜ ì¶”ì–µì„ 1ì¸ì¹­ ì‹œì ìœ¼ë¡œ 15ì¤„ ì •ë„ì˜ ì´ì•¼ê¸°ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì‘ì„± ì§€ì¹¨:\n",
    "1. ì–´ë¥´ì‹ ì˜ ê°ì •ê³¼ ë‹¹ì‹œì˜ ëŠë‚Œì„ ìƒìƒí•˜ê²Œ í‘œí˜„\n",
    "2. êµ¬ì²´ì ì¸ ê°ê°ì  ë¬˜ì‚¬ í¬í•¨ (ì†Œë¦¬, ëƒ„ìƒˆ, ì´‰ê° ë“±)\n",
    "3. ë”°ëœ»í•˜ê³  í–¥ìˆ˜ë¥¼ ë¶ˆëŸ¬ì¼ìœ¼í‚¤ëŠ” í†¤\n",
    "4. ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ ë‚´ìš©ì„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨\n",
    "5. ë§ˆì¹˜ ì†ì/ì†ë…€ì—ê²Œ ë“¤ë ¤ì£¼ëŠ” ê²ƒì²˜ëŸ¼ ì¹œê·¼í•œ ì–´íˆ¬\n",
    "6. í‚¤ì›Œë“œ ê¸°ë°˜ ëŒ€í™”ì™€ ì¸ì§€ê²€ì‚¬ ë‚´ìš©ë„ ìì—°ìŠ¤ëŸ½ê²Œ ë°˜ì˜\n",
    "\n",
    "ìŠ¤í† ë¦¬ë§Œ ì‘ì„±í•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.deployment,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ ë…¸ì¸ì˜ ì¶”ì–µì„ ì•„ë¦„ë‹µê²Œ ì¬êµ¬ì„±í•˜ëŠ” ìŠ¤í† ë¦¬í…”ëŸ¬ì…ë‹ˆë‹¤.\"},\n",
    "                    {\"role\": \"user\", \"content\": story_prompt}\n",
    "                ],\n",
    "                max_tokens=1024,\n",
    "                temperature=0.8,\n",
    "                top_p=1.0,\n",
    "            )\n",
    "            \n",
    "            story = response.choices[0].message.content\n",
    "            \n",
    "            # story_telling í´ë” ìƒì„±\n",
    "            story_dir = \"story_telling\"\n",
    "            os.makedirs(story_dir, exist_ok=True)\n",
    "            \n",
    "            # ì´ë¯¸ì§€ íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°í•˜ì—¬ ìŠ¤í† ë¦¬ íŒŒì¼ëª… ìƒì„±\n",
    "            image_basename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "            story_filename = os.path.join(story_dir, f\"{image_basename}_story.txt\")\n",
    "            \n",
    "            # ìŠ¤í† ë¦¬ íŒŒì¼ ì €ì¥\n",
    "            with open(story_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(story)\n",
    "            \n",
    "            print(f\"ğŸ“– ì¶”ì–µ ì´ì•¼ê¸°ê°€ '{story_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "            \n",
    "            return story, story_filename\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"ìŠ¤í† ë¦¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            return None, None\n",
    "    \n",
    "    def save_conversation_summary(self, image_path=None):\n",
    "        \"\"\"ëŒ€í™” ì¢…ë£Œ í›„ ìš”ì•½ ì œê³µ\"\"\"\n",
    "        # ì „ì²´ ë‹µë³€ íšŸìˆ˜ ê³„ì‚°\n",
    "        total_responses = len(self.chat_system.conversation_turns)\n",
    "        \n",
    "        if total_responses == 0:\n",
    "            return \"ëŒ€í™”ê°€ ì§„í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        if self.chat_system.strange_response_count == 0:\n",
    "            return f\"ğŸ‰ ëŒ€í™” ì¤‘ íŠ¹ë³„íˆ ì´ìƒí•œ ë‹µë³€ì€ ì—†ì—ˆìŠµë‹ˆë‹¤. ì¢‹ì€ ëŒ€í™”ì˜€ì–´ìš”!\\nì „ì²´ ë‹µë³€ íšŸìˆ˜: {total_responses}íšŒ\"\n",
    "        \n",
    "        summary = f\"\\n{'='*60}\\n\"\n",
    "        summary += f\"ğŸ“Š ëŒ€í™” ì¢…ë£Œ - ë¶„ì„ ê²°ê³¼\\n\"\n",
    "        summary += f\"{'='*60}\\n\"\n",
    "        summary += f\"ğŸ“Œ ì „ì²´ ë‹µë³€ íšŸìˆ˜: {total_responses}íšŒ\\n\"\n",
    "        summary += f\"ğŸ” ì´ìƒí•œ ë‹µë³€ íšŸìˆ˜: {self.chat_system.strange_response_count}íšŒ ({(self.chat_system.strange_response_count/total_responses*100):.1f}%)\\n\\n\"\n",
    "        \n",
    "        # ì§ˆë¬¸ íƒ€ì…ë³„ ë¶„ë¥˜\n",
    "        question_type_counts = {\"normal\": 0, \"keyword\": 0, \"cognitive\": 0}\n",
    "        for turn in self.chat_system.conversation_turns:\n",
    "            question_type_counts[turn.question_type] += 1\n",
    "        \n",
    "        summary += f\"ì§ˆë¬¸ íƒ€ì…ë³„ ëŒ€í™” ë¶„ì„:\\n\"\n",
    "        summary += f\"  â€¢ ì¼ë°˜ ëŒ€í™”: {question_type_counts['normal']}íšŒ\\n\"\n",
    "        summary += f\"  â€¢ í‚¤ì›Œë“œ ê¸°ë°˜: {question_type_counts['keyword']}íšŒ\\n\"\n",
    "        summary += f\"  â€¢ ì¸ì§€ ê²€ì‚¬: {question_type_counts['cognitive']}íšŒ\\n\\n\"\n",
    "        \n",
    "        # ì‹¬ê°ë„ë³„ ë¶„ë¥˜\n",
    "        severity_counts = {\"mild\": 0, \"moderate\": 0, \"severe\": 0}\n",
    "        for response in self.chat_system.strange_responses:\n",
    "            severity_counts[response.severity] += 1\n",
    "        \n",
    "        summary += f\"ì´ìƒí•œ ë‹µë³€ ì¤‘ ì‹¬ê°ë„ë³„ ë¶„ë¥˜:\\n\"\n",
    "        summary += f\"  â€¢ ê²½ë¯¸ (Mild): {severity_counts['mild']}íšŒ ({(severity_counts['mild']/self.chat_system.strange_response_count*100):.1f}%)\\n\"\n",
    "        summary += f\"  â€¢ ë³´í†µ (Moderate): {severity_counts['moderate']}íšŒ ({(severity_counts['moderate']/self.chat_system.strange_response_count*100):.1f}%)\\n\"\n",
    "        summary += f\"  â€¢ ì‹¬ê° (Severe): {severity_counts['severe']}íšŒ ({(severity_counts['severe']/self.chat_system.strange_response_count*100):.1f}%)\\n\\n\"\n",
    "        \n",
    "        # ì§ˆë¬¸ íƒ€ì…ë³„ ì´ìƒ ë‹µë³€ ë¶„ì„\n",
    "        cognitive_strange = [r for r in self.chat_system.strange_responses if r.question_type == \"cognitive\"]\n",
    "        keyword_strange = [r for r in self.chat_system.strange_responses if r.question_type == \"keyword\"]\n",
    "        normal_strange = [r for r in self.chat_system.strange_responses if r.question_type == \"normal\"]\n",
    "        \n",
    "        summary += f\"ì§ˆë¬¸ íƒ€ì…ë³„ ì´ìƒ ë‹µë³€ ë¶„ì„:\\n\"\n",
    "        summary += f\"  â€¢ ì¸ì§€ ê²€ì‚¬: {len(cognitive_strange)}íšŒ ({(len(cognitive_strange)/question_type_counts['cognitive']*100 if question_type_counts['cognitive'] > 0 else 0):.1f}% ì´ìƒë¥ )\\n\"\n",
    "        summary += f\"  â€¢ í‚¤ì›Œë“œ ê¸°ë°˜: {len(keyword_strange)}íšŒ ({(len(keyword_strange)/question_type_counts['keyword']*100 if question_type_counts['keyword'] > 0 else 0):.1f}% ì´ìƒë¥ )\\n\"\n",
    "        summary += f\"  â€¢ ì¼ë°˜ ëŒ€í™”: {len(normal_strange)}íšŒ ({(len(normal_strange)/question_type_counts['normal']*100 if question_type_counts['normal'] > 0 else 0):.1f}% ì´ìƒë¥ )\\n\\n\"\n",
    "        \n",
    "        # ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚°\n",
    "        risk_score = (severity_counts['mild'] * 1 + \n",
    "                     severity_counts['moderate'] * 3 + \n",
    "                     severity_counts['severe'] * 5)\n",
    "        max_risk_score = self.chat_system.strange_response_count * 5\n",
    "        risk_percentage = (risk_score / max_risk_score * 100)\n",
    "        \n",
    "        summary += f\"ìœ„í—˜ë„ ì ìˆ˜: {risk_score}ì  / {max_risk_score}ì  ({risk_percentage:.1f}%)\\n\"\n",
    "        summary += f\"   (ê²½ë¯¸=1ì , ë³´í†µ=3ì , ì‹¬ê°=5ì  ê°€ì¤‘ì¹˜ ì ìš©)\\n\\n\"\n",
    "        \n",
    "        # ê¶Œì¥ì‚¬í•­\n",
    "        cognitive_risk = len(cognitive_strange) / question_type_counts['cognitive'] * 100 if question_type_counts['cognitive'] > 0 else 0\n",
    "        \n",
    "        if severity_counts['severe'] >= 2 or risk_percentage > 80 or cognitive_risk > 60:\n",
    "            summary += f\"\\nâš ï¸  ê¶Œì¥ì‚¬í•­: ì‹¬ê°í•œ ìˆ˜ì¤€ì˜ ì´ìƒ ë‹µë³€ì´ {severity_counts['severe']}íšŒ ê´€ì°°ë˜ì—ˆìœ¼ë©°, \"\n",
    "            summary += f\"ì „ì²´ ìœ„í—˜ë„ê°€ {risk_percentage:.1f}%, ì¸ì§€ê²€ì‚¬ ì´ìƒë¥ ì´ {cognitive_risk:.1f}%ë¡œ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤. \"\n",
    "            summary += f\"ì¦‰ì‹œ ì „ë¬¸ì˜ ìƒë‹´ì„ ë°›ìœ¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\\n\"\n",
    "        elif severity_counts['severe'] >= 1 or risk_percentage > 60 or cognitive_risk > 40:\n",
    "            summary += f\"\\nğŸ”¶ ê¶Œì¥ì‚¬í•­: ì‹¬ê°í•œ ë‹µë³€ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©°, ìœ„í—˜ë„ê°€ {risk_percentage:.1f}%, \"\n",
    "            summary += f\"ì¸ì§€ê²€ì‚¬ ì´ìƒë¥ ì´ {cognitive_risk:.1f}%ì…ë‹ˆë‹¤. ì „ë¬¸ì˜ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤.\\n\"\n",
    "        elif risk_percentage > 40 or cognitive_risk > 30:\n",
    "            summary += f\"\\nğŸ”· ê¶Œì¥ì‚¬í•­: ì´ìƒ ë‹µë³€ì˜ ìœ„í—˜ë„ê°€ {risk_percentage:.1f}%, ì¸ì§€ê²€ì‚¬ ì´ìƒë¥ ì´ {cognitive_risk:.1f}%ë¡œ \"\n",
    "            summary += f\"ì¤‘ê°„ ìˆ˜ì¤€ì…ë‹ˆë‹¤. ì •ê¸°ì ì¸ ê´€ì°°ê³¼ ì¶”ì  ê²€ì‚¬ë¥¼ ë°›ìœ¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\\n\"\n",
    "        else:\n",
    "            summary += f\"\\nğŸ’š ì´ìƒ ë‹µë³€ì˜ ìœ„í—˜ë„ê°€ {risk_percentage:.1f}%ë¡œ ë‚®ì€ ìˆ˜ì¤€ì…ë‹ˆë‹¤. \"\n",
    "            summary += f\"í˜„ì¬ ìƒíƒœë¥¼ ì˜ ìœ ì§€í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\\n\"\n",
    "        \n",
    "        summary += f\"{'='*60}\\n\"\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def save_conversation_to_file(self, filename_prefix=\"conversation\", image_path=None):\n",
    "        \"\"\"ëŒ€í™” ë‚´ìš©ì„ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # ì´ë¯¸ì§€ íŒŒì¼ëª… ì¶”ì¶œ (í™•ì¥ì ì œì™¸)\n",
    "        if image_path:\n",
    "            image_basename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "            base_filename = f\"{image_basename}_{timestamp}\"\n",
    "        else:\n",
    "            base_filename = f\"{filename_prefix}_{timestamp}\"\n",
    "        \n",
    "        # í´ë” ìƒì„± (ì—†ëŠ” ê²½ìš°)\n",
    "        conversation_dir = \"conversation_log\"\n",
    "        analysis_dir = \"analysis\"\n",
    "        os.makedirs(conversation_dir, exist_ok=True)\n",
    "        os.makedirs(analysis_dir, exist_ok=True)\n",
    "        \n",
    "        # ëŒ€í™” ê¸°ë¡ íŒŒì¼ ì €ì¥\n",
    "        conversation_filename = os.path.join(conversation_dir, f\"{base_filename}.txt\")\n",
    "        with open(conversation_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"=== ëŒ€í™” ê¸°ë¡ ===\\n\")\n",
    "            f.write(f\"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}\\n\")\n",
    "            f.write(f\"{'='*50}\\n\\n\")\n",
    "            \n",
    "            for i, turn in enumerate(self.chat_system.conversation_turns, 1):\n",
    "                type_name = {\"normal\": \"ì¼ë°˜ëŒ€í™”\", \"keyword\": \"í‚¤ì›Œë“œê¸°ë°˜\", \"cognitive\": \"ì¸ì§€ê²€ì‚¬\"}\n",
    "                f.write(f\"[ëŒ€í™” {i}] {turn.timestamp} [{type_name[turn.question_type]}]\\n\")\n",
    "                f.write(f\"ì§ˆë¬¸: {turn.question}\\n\")\n",
    "                f.write(f\"ë‹µë³€: {turn.answer}\\n\")\n",
    "                f.write(f\"{'-'*30}\\n\\n\")\n",
    "        \n",
    "        print(f\"ğŸ“ ëŒ€í™” ê¸°ë¡ì´ '{conversation_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        # ì´ìƒ ë‹µë³€ ë¶„ì„ íŒŒì¼ ì €ì¥\n",
    "        analysis_filename = None\n",
    "        if self.chat_system.strange_response_count > 0:\n",
    "            analysis_filename = os.path.join(analysis_dir, f\"{base_filename}_analysis.txt\")\n",
    "            with open(analysis_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(self.save_conversation_summary())\n",
    "            \n",
    "            print(f\"ğŸ“Š ì´ìƒ ë‹µë³€ ë¶„ì„ì´ '{analysis_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        return conversation_filename, analysis_filename\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜\n",
    "def test_story_generator():\n",
    "    \"\"\"ìŠ¤í† ë¦¬ ìƒì„±ê¸° í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    # ë”ë¯¸ ì±„íŒ… ì‹œìŠ¤í…œ ìƒì„± (ì‹¤ì œë¡œëŠ” chat_systemì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)\n",
    "    print(\"ìŠ¤í† ë¦¬ ìƒì„±ê¸° í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì‹¤ì œ ì±„íŒ… ì‹œìŠ¤í…œì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "    return None\n",
    "\n",
    "print(\"âœ… ìŠ¤í† ë¦¬ ìƒì„±ê¸° ëª¨ë“ˆì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f467019",
   "metadata": {},
   "source": [
    "# ì½”ë“œ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0e4ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DementiaAnalysisSystem:\n",
    "    \"\"\"ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ë¶„ì„ í†µí•© ì‹œìŠ¤í…œ\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.image_analyzer = None\n",
    "        self.chat_system = None\n",
    "        self.report_generator = None\n",
    "        self.story_generator = None\n",
    "        \n",
    "    def initialize_system(self):\n",
    "        \"\"\"ì‹œìŠ¤í…œ ì´ˆê¸°í™”\"\"\"\n",
    "        try:\n",
    "            print(\"ğŸ”„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...\")\n",
    "            \n",
    "            # ì´ë¯¸ì§€ ë¶„ì„ê¸° ì´ˆê¸°í™”\n",
    "            self.image_analyzer = ImageAnalysisGPT()\n",
    "            print(\"âœ… ì´ë¯¸ì§€ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "            \n",
    "            # ì±„íŒ… ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "            self.chat_system = ChatSystem()\n",
    "            print(\"âœ… ì±„íŒ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "            \n",
    "            print(\"ğŸ¯ ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ë¶„ì„ ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def analyze_image(self, image_path):\n",
    "        \"\"\"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤í–‰\"\"\"\n",
    "        if not self.image_analyzer:\n",
    "            print(\"âŒ ì´ë¯¸ì§€ ë¶„ì„ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "            return None\n",
    "            \n",
    "        print(f\"ğŸ–¼ï¸  ì´ë¯¸ì§€ ë¶„ì„ ì¤‘: {image_path}\")\n",
    "        \n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"âŒ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}\")\n",
    "            return None\n",
    "            \n",
    "        analysis_result = self.image_analyzer.analyze_image_with_gpt(image_path)\n",
    "        \n",
    "        if analysis_result:\n",
    "            print(\"âœ… ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ\")\n",
    "            return analysis_result\n",
    "        else:\n",
    "            print(\"âŒ ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨\")\n",
    "            return None\n",
    "    \n",
    "    def setup_conversation(self, analysis_result, user_description=\"\", user_description_date=\"\"):\n",
    "        \"\"\"ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì„¤ì •\"\"\"\n",
    "        if not self.chat_system:\n",
    "            print(\"âŒ ì±„íŒ… ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "            return False\n",
    "            \n",
    "        print(\"ğŸ—£ï¸  ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì„¤ì • ì¤‘...\")\n",
    "        self.chat_system.setup_conversation_context(analysis_result, user_description, user_description_date)\n",
    "        \n",
    "        # ë¦¬í¬íŠ¸ ìƒì„±ê¸° ë° ìŠ¤í† ë¦¬ ìƒì„±ê¸° ì´ˆê¸°í™”\n",
    "        self.report_generator = ReportGenerator(self.chat_system)\n",
    "        self.story_generator = StoryGenerator(self.chat_system)\n",
    "        \n",
    "        print(\"âœ… ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì„¤ì • ì™„ë£Œ\")\n",
    "        return True\n",
    "    \n",
    "    def start_conversation(self):\n",
    "        \"\"\"ëŒ€í™” ì‹œì‘\"\"\"\n",
    "        if not self.chat_system:\n",
    "            print(\"âŒ ì±„íŒ… ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "            return None\n",
    "            \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ğŸ¯ ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ë¶„ì„ ì‹œì‘\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"ğŸ’¡ ê¸°ëŠ¥: ì‹¤ì‹œê°„ ëŒ€í™” + í‚¤ì›Œë“œ ê°ì§€ + ì¸ì§€ ê²€ì‚¬ + ì´ìƒ ë‹µë³€ ë¶„ì„\")\n",
    "        \n",
    "        # ì²« ì§ˆë¬¸ ìƒì„±\n",
    "        initial_question = self.chat_system.generate_initial_question()\n",
    "        print(f\"\\nğŸ¤– AI: {initial_question}\")\n",
    "        \n",
    "        print(f\"\\nğŸ’¡ ëŒ€í™”ë¥¼ ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'ì¢…ë£Œ'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\")\n",
    "        print(f\"ğŸ“‹ 3í„´ë§ˆë‹¤ ì¸ì§€ ê²€ì‚¬ ì§ˆë¬¸ì´ ìë™ìœ¼ë¡œ ì¶”ê°€ë©ë‹ˆë‹¤.\")\n",
    "        print(f\"ğŸ” í‚¤ì›Œë“œ ê°ì§€ ì‹œ ê´€ë ¨ ì§ˆë¬¸ì´ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.\")\n",
    "        \n",
    "        return initial_question\n",
    "    \n",
    "    def process_user_input(self, user_input):\n",
    "        \"\"\"ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬\"\"\"\n",
    "        if not self.chat_system:\n",
    "            return None, True, \"error\"\n",
    "            \n",
    "        # ì¢…ë£Œ ì¡°ê±´ í™•ì¸\n",
    "        if user_input.lower() in ['exit', 'ì¢…ë£Œ', 'quit', 'q']:\n",
    "            print(\"ğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "            return \"ëŒ€í™” ì¢…ë£Œ\", True, \"normal\"\n",
    "        \n",
    "        # ì±„íŒ… ì‹œìŠ¤í…œì— ì…ë ¥ ì „ë‹¬\n",
    "        answer, should_end, question_type = self.chat_system.chat_about_image(user_input)\n",
    "        \n",
    "        # ì§ˆë¬¸ íƒ€ì…ì— ë”°ë¥¸ ì´ëª¨ì§€ ì¶”ê°€\n",
    "        type_emoji = {\n",
    "            \"normal\": \"ğŸ¤–\",\n",
    "            \"keyword\": \"ğŸ’\", \n",
    "            \"cognitive\": \"ğŸ§ \"\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{type_emoji.get(question_type, 'ğŸ¤–')} AI: {answer}\")\n",
    "        \n",
    "        # íŠ¹ë³„ ì§ˆë¬¸ì¼ ë•Œ ì¶”ê°€ ì•ˆë‚´\n",
    "        if question_type == \"keyword\":\n",
    "            print(\"   ğŸ’¡ í‚¤ì›Œë“œ ê¸°ë°˜ ì§ˆë¬¸ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        elif question_type == \"cognitive\":\n",
    "            print(\"   ğŸ§  ì¸ì§€ ëŠ¥ë ¥ ê²€ì‚¬ ì§ˆë¬¸ì…ë‹ˆë‹¤.\")\n",
    "        \n",
    "        # í† í° ì œí•œìœ¼ë¡œ ì¸í•œ ì¢…ë£Œ í™•ì¸\n",
    "        if should_end:\n",
    "            print(\"\\nâ° ëŒ€í™” í† í° ì œí•œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "        \n",
    "        return answer, should_end, question_type\n",
    "    \n",
    "    def generate_reports(self, image_path):\n",
    "        \"\"\"ë¦¬í¬íŠ¸ ë° ìŠ¤í† ë¦¬ ìƒì„±\"\"\"\n",
    "        if not self.report_generator or not self.story_generator:\n",
    "            print(\"âŒ ë¦¬í¬íŠ¸ ìƒì„±ê¸°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "            return None, None, None\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ğŸ“Š ë¶„ì„ ê²°ê³¼ ìƒì„± ì¤‘...\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 1. ëŒ€í™” ê¸°ë¡ ì €ì¥\n",
    "        print(\"ğŸ“ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” ì¤‘...\")\n",
    "        conversation_file, analysis_file = self.story_generator.save_conversation_to_file(image_path=image_path)\n",
    "        \n",
    "        # 2. ì¶”ì–µ ìŠ¤í† ë¦¬ ìƒì„±\n",
    "        print(\"ğŸ“– ì¶”ì–µ ì´ì•¼ê¸°ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘...\")\n",
    "        story, story_file = self.story_generator.generate_story_from_conversation(image_path)\n",
    "        \n",
    "        if story:\n",
    "            print(f\"\\n=== ìƒì„±ëœ ì¶”ì–µ ì´ì•¼ê¸° ===\")\n",
    "            print(story)\n",
    "            print(\"=\"*40)\n",
    "        \n",
    "        # 3. ëª¨ë°”ì¼ ë¦¬í¬íŠ¸ ìƒì„±\n",
    "        print(\"ğŸ“± ëª¨ë°”ì¼ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘...\")\n",
    "        mobile_report_file = self.report_generator.generate_mobile_report(image_path)\n",
    "        \n",
    "        if mobile_report_file:\n",
    "            print(f\"âœ… ëª¨ë°”ì¼ ë¦¬í¬íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "            print(f\"ğŸ“‚ íŒŒì¼ ê²½ë¡œ: {mobile_report_file}\")\n",
    "        \n",
    "        \n",
    "        return {\n",
    "            'conversation_file': conversation_file,\n",
    "            'analysis_file': analysis_file,\n",
    "            'story_file': story_file,\n",
    "            'mobile_report_file': mobile_report_file,\n",
    "        }\n",
    "    \n",
    "    def run_full_analysis(self, image_path, user_description=\"\", user_description_date=\"\"):\n",
    "        \"\"\"ì „ì²´ ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰\"\"\"\n",
    "        print(\"ğŸš€ ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ë¶„ì„ ì‹œìŠ¤í…œ ì‹œì‘\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 1. ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "        if not self.initialize_system():\n",
    "            return None\n",
    "        \n",
    "        # 2. ì´ë¯¸ì§€ ë¶„ì„\n",
    "        analysis_result = self.analyze_image(image_path)\n",
    "        if not analysis_result:\n",
    "            return None\n",
    "        \n",
    "        # 3. ëŒ€í™” ì„¤ì •\n",
    "        if not self.setup_conversation(analysis_result, user_description, user_description_date):\n",
    "            return None\n",
    "        \n",
    "        # 4. ëŒ€í™” ì‹œì‘\n",
    "        initial_question = self.start_conversation()\n",
    "        if not initial_question:\n",
    "            return None\n",
    "        \n",
    "        # 5. ëŒ€í™” ë£¨í”„ (Jupyterì—ì„œëŠ” ìˆ˜ë™ìœ¼ë¡œ ì‹¤í–‰)\n",
    "        print(\"\\nğŸ“ ì´ì œ ëŒ€í™”ë¥¼ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\")\n",
    "        print(\"ğŸ“Œ process_user_input() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•´ì„œ ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•˜ì„¸ìš”.\")\n",
    "        print(\"ğŸ“Œ ëŒ€í™”ê°€ ëë‚˜ë©´ generate_reports() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.\")\n",
    "        \n",
    "        return {\n",
    "            'system': self,\n",
    "            'initial_question': initial_question,\n",
    "            'analysis_result': analysis_result\n",
    "        }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67166dd2",
   "metadata": {},
   "source": [
    "# 9. ìŒì„±ì¸ì‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "663d21e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. ìŒì„± í†µí•© ì‹œìŠ¤í…œ (voice_integrated_system.ipynb)\n",
    "\n",
    "# ê¸°ì¡´ ëª¨ë“ˆë“¤ import (ì‹¤ì œ ì‚¬ìš©ì‹œì—ëŠ” %run ë˜ëŠ” import ì‚¬ìš©)\n",
    "# %run config.ipynb\n",
    "# %run image_analyzer.ipynb\n",
    "# %run conversation_manager.ipynb\n",
    "# %run chat_system.ipynb\n",
    "# %run report_generator.ipynb\n",
    "# %run story_generator.ipynb\n",
    "# %run main_system.ipynb\n",
    "\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import requests\n",
    "import pygame\n",
    "import time\n",
    "from pathlib import Path\n",
    "import threading\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "\n",
    "class VoiceIntegratedSystem(DementiaAnalysisSystem):\n",
    "    \"\"\"ìŒì„± ê¸°ëŠ¥ì´ í†µí•©ëœ ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ì‹œìŠ¤í…œ\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Azure Speech ì„¤ì •\n",
    "        self.speech_key = os.getenv(\"speech-key\")\n",
    "        self.speech_endpoint = os.getenv(\"speech-endpoint\")\n",
    "        self.region = \"eastus\"  # speech-endpointì—ì„œ ì¶”ì¶œí•˜ê±°ë‚˜ ì§ì ‘ ì„¤ì •\n",
    "        \n",
    "        if not self.speech_key:\n",
    "            raise ValueError(\"í™˜ê²½ ë³€ìˆ˜ 'speech-key'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        # STT ì„¤ì •\n",
    "        self.speech_config = speechsdk.SpeechConfig(subscription=self.speech_key, region=self.region)\n",
    "        self.speech_config.speech_recognition_language = \"ko-KR\"\n",
    "        \n",
    "        # TTS ì„¤ì •\n",
    "        self.tts_voice = \"ko-KR-SunHiNeural\"  # ê¸°ë³¸ ì—¬ì„± ìŒì„±\n",
    "        \n",
    "        # ìŒì„± íŒŒì¼ ì €ì¥ í´ë”\n",
    "        self.audio_dir = Path(\"audio_files\")\n",
    "        self.audio_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # pygame ì´ˆê¸°í™” (ìŒì„± ì¬ìƒìš©)\n",
    "        try:\n",
    "            pygame.mixer.init()\n",
    "            self.audio_enabled = True\n",
    "            print(\"âœ… ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "        except:\n",
    "            self.audio_enabled = False\n",
    "            print(\"âš ï¸ ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨ - ìŒì„± ì¬ìƒ ë¶ˆê°€\")\n",
    "        \n",
    "        print(\"ğŸ¤ ìŒì„± í†µí•© ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    \n",
    "    def transcribe_speech(self, show_details: bool = False) -> str:\n",
    "        \"\"\"\n",
    "        STT: ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì¢…ë£Œ ëª…ë ¹ì–´ ê°ì§€ í¬í•¨)\n",
    "        + recognize_once() ì™„ë£Œ ì‹œì ì„ ê¸°ì¤€ìœ¼ë¡œ ë…¹ìŒ ìë™ ì¢…ë£Œ â†’ .wav ì €ì¥\n",
    "        \"\"\"\n",
    "        # 1) ì €ì¥í•  íŒŒì¼ ê²½ë¡œ ì¤€ë¹„\n",
    "        # timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "        # wav_path = self.audio_dir / f\"input_{timestamp}.wav\"\n",
    "        input_subdir = self.audio_dir / \"input\"\n",
    "        input_subdir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "        wav_path  = input_subdir / f\"input_{timestamp}.wav\"\n",
    "\n",
    "        # 2) ë°±ê·¸ë¼ìš´ë“œ ë…¹ìŒ í•¨ìˆ˜ ì •ì˜\n",
    "        def _record_to_file(path: Path, stop_evt: threading.Event):\n",
    "            samplerate = 16000\n",
    "            channels = 1\n",
    "            with sf.SoundFile(str(path), mode='w', samplerate=samplerate, channels=channels) as f:\n",
    "                def callback(indata, frames, t, status):\n",
    "                    if stop_evt.is_set():\n",
    "                        raise sd.CallbackStop()\n",
    "                    f.write(indata)\n",
    "                with sd.InputStream(samplerate=samplerate,\n",
    "                                    channels=channels,\n",
    "                                    callback=callback):\n",
    "                    stop_evt.wait()\n",
    "\n",
    "        # 3) ë…¹ìŒ ìŠ¤ë ˆë“œ ì‹œì‘\n",
    "        stop_event = threading.Event()\n",
    "        recorder = threading.Thread(\n",
    "            target=_record_to_file,\n",
    "            args=(wav_path, stop_event),\n",
    "            daemon=True\n",
    "        )\n",
    "        recorder.start()\n",
    "\n",
    "        # 4) Azure STT í˜¸ì¶œ\n",
    "        try:\n",
    "            if show_details:\n",
    "                print(\"ğŸ™ï¸ ë§ì”€í•´ ì£¼ì„¸ìš”...\")\n",
    "            audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "            recognizer   = speechsdk.SpeechRecognizer(\n",
    "                speech_config=self.speech_config,\n",
    "                audio_config=audio_config\n",
    "            )\n",
    "            result = recognizer.recognize_once()\n",
    "\n",
    "        finally:\n",
    "            # ì¸ì‹ ì™„ë£Œ ì‹œ ë…¹ìŒ ì¤‘ë‹¨\n",
    "            stop_event.set()\n",
    "            recorder.join()\n",
    "\n",
    "        # 5) ê²°ê³¼ ì²˜ë¦¬\n",
    "        if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "            text = result.text.strip()\n",
    "            if show_details:\n",
    "                print(f\"ğŸ‘¤ \\\"{text}\\\"  (ìŒì„± íŒŒì¼ ì €ì¥ë¨: {wav_path})\")\n",
    "            return text\n",
    "\n",
    "        if result.reason == speechsdk.ResultReason.NoMatch:\n",
    "            if show_details:\n",
    "                print(\"âŒ ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.\")\n",
    "            return \"\"\n",
    "\n",
    "        # Cancellation ë“±\n",
    "        if show_details:\n",
    "            cancel = result.cancellation_details\n",
    "            print(f\"âŒ ì¸ì‹ ì‹¤íŒ¨: {cancel.reason}\")\n",
    "            if cancel.reason == speechsdk.CancellationReason.Error:\n",
    "                print(f\"   ì˜¤ë¥˜ ìƒì„¸: {cancel.error_details}\")\n",
    "        return \"\"\n",
    "    \n",
    "    def get_access_token(self):\n",
    "        \"\"\"Azure Speech Service ì•¡ì„¸ìŠ¤ í† í° ìš”ì²­\"\"\"\n",
    "        url = f\"https://{self.region}.api.cognitive.microsoft.com/sts/v1.0/issueToken\"\n",
    "        headers = {\n",
    "            \"Ocp-Apim-Subscription-Key\": self.speech_key\n",
    "        }\n",
    "        try:\n",
    "            res = requests.post(url, headers=headers)\n",
    "            res.raise_for_status()\n",
    "            return res.text\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ í† í° ìš”ì²­ ì‹¤íŒ¨: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def synthesize_speech(self, text: str, play_audio: bool = True, show_details: bool = False) -> str:\n",
    "        \"\"\"TTS: í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì¬ìƒ\"\"\"\n",
    "        if not text.strip():\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            token = self.get_access_token()\n",
    "            if not token:\n",
    "                return None\n",
    "                \n",
    "            tts_url = f\"https://{self.region}.tts.speech.microsoft.com/cognitiveservices/v1\"\n",
    "            \n",
    "            headers = {\n",
    "                \"Authorization\": f\"Bearer {token}\",\n",
    "                \"Content-Type\": \"application/ssml+xml\",\n",
    "                \"X-Microsoft-OutputFormat\": \"riff-16khz-16bit-mono-pcm\",\n",
    "                \"User-Agent\": \"DementiaAnalysisSystem\"\n",
    "            }\n",
    "            \n",
    "            ssml = f\"\"\"\n",
    "            <speak version='1.0' xml:lang='ko-KR'>\n",
    "                <voice xml:lang='ko-KR' xml:gender='Female' name='{self.tts_voice}'>\n",
    "                    {text}\n",
    "                </voice>\n",
    "            </speak>\n",
    "            \"\"\"\n",
    "            \n",
    "            res = requests.post(tts_url, headers=headers, data=ssml.encode(\"utf-8\"))\n",
    "            res.raise_for_status()\n",
    "            \n",
    "            # ìŒì„± íŒŒì¼ ì €ì¥\n",
    "            timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_path = self.audio_dir / f\"tts_{timestamp}.wav\"\n",
    "            \n",
    "            with open(output_path, \"wb\") as f:\n",
    "                f.write(res.content)\n",
    "            \n",
    "            # ìŒì„± ì¬ìƒ\n",
    "            if play_audio and self.audio_enabled:\n",
    "                self.play_audio(output_path)\n",
    "            \n",
    "            if show_details:\n",
    "                print(f\"âœ… TTS ì™„ë£Œ: {output_path}\")\n",
    "            \n",
    "            return str(output_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            if show_details:\n",
    "                print(f\"âŒ TTS ì˜¤ë¥˜: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def play_audio(self, file_path: str):\n",
    "        \"\"\"ìŒì„± íŒŒì¼ ì¬ìƒ\"\"\"\n",
    "        try:\n",
    "            pygame.mixer.music.load(file_path)\n",
    "            pygame.mixer.music.play()\n",
    "            \n",
    "            # ì¬ìƒ ì™„ë£Œê¹Œì§€ ëŒ€ê¸°\n",
    "            while pygame.mixer.music.get_busy():\n",
    "                time.sleep(0.1)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ìŒì„± ì¬ìƒ ì˜¤ë¥˜: {e}\")\n",
    "    \n",
    "    def voice_chat_about_image(self, use_voice_input: bool = True, use_voice_output: bool = True, show_details: bool = False):\n",
    "        \"\"\"ìŒì„± ê¸°ëŠ¥ì´ í†µí•©ëœ ì±„íŒ… (ê°œì„ ëœ ì¢…ë£Œ ê°ì§€)\"\"\"\n",
    "        if not self.chat_system:\n",
    "            if show_details:\n",
    "                print(\"âŒ ì±„íŒ… ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "            return None, True, \"error\"\n",
    "        \n",
    "        # ìŒì„± ì…ë ¥\n",
    "        if use_voice_input:\n",
    "            user_input = self.transcribe_speech(show_details=show_details)\n",
    "            if not user_input:\n",
    "                print(\"ğŸ’¬ ìŒì„±ì„ ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”.\")\n",
    "                return None, False, \"retry\"\n",
    "        else:\n",
    "            user_input = input(\"ğŸ‘¤ í…ìŠ¤íŠ¸ ì…ë ¥: \")\n",
    "        \n",
    "        if not user_input.strip():\n",
    "            return None, False, \"error\"\n",
    "        \n",
    "        # í™•ì¥ëœ ì¢…ë£Œ ì¡°ê±´ í™•ì¸\n",
    "        exit_commands = [\n",
    "            'ì¢…ë£Œ', 'ê·¸ë§Œ', 'ë', 'ë‚˜ê°€ê¸°', 'exit', 'quit', 'q', 'stop', \n",
    "            'ëŒ€í™” ë', 'ëŒ€í™” ì¢…ë£Œ', 'ë§ˆì¹˜ê¸°', 'ëë‚´ê¸°', 'ê·¸ë§Œí•˜ê¸°'\n",
    "        ]\n",
    "        \n",
    "        # ëŒ€ì†Œë¬¸ì ë¬´ê´€í•˜ê³  ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ì œê±° í›„ ë¹„êµ\n",
    "        cleaned_input = user_input.lower().replace(' ', '').replace('.', '').replace('!', '').replace(',', '')\n",
    "        \n",
    "        is_exit_command = False\n",
    "        for exit_cmd in exit_commands:\n",
    "            if exit_cmd.lower() in cleaned_input or exit_cmd in user_input:\n",
    "                is_exit_command = True\n",
    "                break\n",
    "        \n",
    "        if is_exit_command:\n",
    "            goodbye_messages = [\n",
    "                \"ëŒ€í™”ë¥¼ ë§ˆì¹˜ê² ìŠµë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.\",\n",
    "                \"ì¢‹ì€ ì‹œê°„ì´ì—ˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.\",\n",
    "                \"ëŒ€í™”ê°€ ëë‚¬ìŠµë‹ˆë‹¤. ê³ ìƒí•˜ì…¨ì–´ìš”.\",\n",
    "                \"ìˆ˜ê³  ë§ìœ¼ì…¨ìŠµë‹ˆë‹¤. ê±´ê°•í•˜ì„¸ìš”.\"\n",
    "            ]\n",
    "            goodbye_message = random.choice(goodbye_messages)\n",
    "            print(f\"ğŸ¤– {goodbye_message}\")\n",
    "            \n",
    "            if use_voice_output:\n",
    "                self.synthesize_speech(goodbye_message, show_details=show_details)\n",
    "            \n",
    "            return goodbye_message, True, \"normal\"\n",
    "        \n",
    "        # ì±„íŒ… ì‹œìŠ¤í…œì— ì…ë ¥ ì „ë‹¬\n",
    "        answer, should_end, question_type = self.chat_system.chat_about_image(user_input)\n",
    "        \n",
    "        # ì§ˆë¬¸ íƒ€ì…ì— ë”°ë¥¸ ì´ëª¨ì§€ ì¶”ê°€\n",
    "        type_emoji = {\n",
    "            \"normal\": \"ğŸ¤–\",\n",
    "            \"keyword\": \"ğŸ’\", \n",
    "            \"cognitive\": \"ğŸ§ \"\n",
    "        }\n",
    "        \n",
    "        print(f\"{type_emoji.get(question_type, 'ğŸ¤–')} {answer}\")\n",
    "        \n",
    "        # íŠ¹ë³„ ì§ˆë¬¸ì¼ ë•Œ ì¶”ê°€ ì•ˆë‚´ (ë””ë²„ê·¸ ëª¨ë“œì—ì„œë§Œ)\n",
    "        if show_details:\n",
    "            if question_type == \"keyword\":\n",
    "                print(\"   ğŸ’¡ í‚¤ì›Œë“œ ê¸°ë°˜ ì§ˆë¬¸ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "            elif question_type == \"cognitive\":\n",
    "                print(\"   ğŸ§  ì¸ì§€ ëŠ¥ë ¥ ê²€ì‚¬ ì§ˆë¬¸ì…ë‹ˆë‹¤.\")\n",
    "        \n",
    "        # ìŒì„± ì¶œë ¥\n",
    "        if use_voice_output and answer:\n",
    "            self.synthesize_speech(answer, show_details=show_details)\n",
    "        \n",
    "        # í† í° ì œí•œìœ¼ë¡œ ì¸í•œ ì¢…ë£Œ í™•ì¸\n",
    "        if should_end:\n",
    "            end_message = \"ëŒ€í™” ì‹œê°„ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤.\"\n",
    "            print(f\"â° {end_message}\")\n",
    "            \n",
    "            if use_voice_output:\n",
    "                self.synthesize_speech(end_message, show_details=show_details)\n",
    "        \n",
    "        return answer, should_end, question_type\n",
    "    \n",
    "    def start_voice_conversation(self, image_path: str, user_description: str = \"\", user_description_date: str = \"\"):\n",
    "        \"\"\"ìŒì„± ëŒ€í™” ì‹œìŠ¤í…œ ì‹œì‘\"\"\"\n",
    "        print(\"ğŸš€ ìŒì„± ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ë¶„ì„ ì‹œìŠ¤í…œ ì‹œì‘\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 1. ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "        if not self.initialize_system():\n",
    "            return None\n",
    "        \n",
    "        # 2. ì´ë¯¸ì§€ ë¶„ì„\n",
    "        analysis_result = self.analyze_image(image_path)\n",
    "        if not analysis_result:\n",
    "            return None\n",
    "        \n",
    "        # 3. ëŒ€í™” ì„¤ì •\n",
    "        if not self.setup_conversation(analysis_result, user_description, user_description_date):\n",
    "            return None\n",
    "        \n",
    "        # 4. ì²« ì§ˆë¬¸ ìƒì„± ë° ìŒì„± ì¶œë ¥\n",
    "        initial_question = self.chat_system.generate_initial_question()\n",
    "        \n",
    "        # welcome_message = \"ì•ˆë…•í•˜ì„¸ìš”!\"\n",
    "        # print(f\"ğŸ¤ {welcome_message}\")\n",
    "        # self.synthesize_speech(welcome_message)\n",
    "        \n",
    "        print(f\"\\nğŸ¤– AI: {initial_question}\")\n",
    "        self.synthesize_speech(initial_question)\n",
    "        \n",
    "        print(f\"\\nğŸ’¡ ìŒì„±ìœ¼ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”. ëŒ€í™”ë¥¼ ì¢…ë£Œí•˜ë ¤ë©´ 'ì¢…ë£Œ'ë¼ê³  ë§ì”€í•˜ì„¸ìš”.\")\n",
    "        print(f\"ğŸ“‹ 3í„´ë§ˆë‹¤ ì¸ì§€ ê²€ì‚¬ ì§ˆë¬¸ì´ ìë™ìœ¼ë¡œ ì¶”ê°€ë©ë‹ˆë‹¤.\")\n",
    "        print(f\"ğŸ” í‚¤ì›Œë“œ ê°ì§€ ì‹œ ê´€ë ¨ ì§ˆë¬¸ì´ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.\")\n",
    "        \n",
    "        return initial_question\n",
    "    \n",
    "    def run_full_voice_conversation(self, image_path: str, user_description: str = \"\", user_description_date: str = \"\"):\n",
    "        \"\"\"ì „ì²´ ìŒì„± ëŒ€í™” í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰\"\"\"\n",
    "        # ëŒ€í™” ì‹œì‘\n",
    "        initial_question = self.start_voice_conversation(image_path, user_description, user_description_date)\n",
    "        if not initial_question:\n",
    "            return None\n",
    "        \n",
    "        # ëŒ€í™” ë£¨í”„\n",
    "        conversation_count = 0\n",
    "        max_conversations = 20  # ìµœëŒ€ ëŒ€í™” ìˆ˜ ì œí•œ\n",
    "        \n",
    "        while conversation_count < max_conversations:\n",
    "            print(f\"\\n--- ëŒ€í™” {conversation_count + 1} ---\")\n",
    "            \n",
    "            try:\n",
    "                answer, should_end, question_type = self.voice_chat_about_image(\n",
    "                    use_voice_input=True, \n",
    "                    use_voice_output=True\n",
    "                )\n",
    "                \n",
    "                if should_end:\n",
    "                    break\n",
    "                    \n",
    "                conversation_count += 1\n",
    "                \n",
    "                # ì ê¹ ëŒ€ê¸° (ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„)\n",
    "                time.sleep(1)\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n\\nâ¹ï¸ ì‚¬ìš©ìê°€ ëŒ€í™”ë¥¼ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ëŒ€í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "                break\n",
    "        \n",
    "        # ë¦¬í¬íŠ¸ ìƒì„±\n",
    "        print(f\"\\nğŸ“Š ëŒ€í™” ë¶„ì„ ë° ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...\")\n",
    "        completion_message = \"ëŒ€í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.\"\n",
    "        # self.synthesize_speech(completion_message)\n",
    "        \n",
    "        reports = self.generate_reports(image_path)\n",
    "        \n",
    "        if reports:\n",
    "            final_message = \"ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.\"\n",
    "            # print(f\"âœ… {final_message}\")\n",
    "            # self.synthesize_speech(final_message)\n",
    "        \n",
    "        return reports\n",
    "    \n",
    "    def set_voice_settings(self, voice_type: str = \"female\", speed: str = \"normal\"):\n",
    "        \"\"\"ìŒì„± ì„¤ì • ë³€ê²½\"\"\"\n",
    "        voice_options = {\n",
    "            \"female\": \"ko-KR-SunHiNeural\",\n",
    "            \"female_bright\": \"ko-KR-YooJinNeural\", \n",
    "            \"female_calm\": \"ko-KR-SeoHyunNeural\",\n",
    "            \"male\": \"ko-KR-InJoonNeural\",\n",
    "            \"male_deep\": \"ko-KR-BongJinNeural\",\n",
    "            \"male_stable\": \"ko-KR-GookMinNeural\"\n",
    "        }\n",
    "        \n",
    "        if voice_type in voice_options:\n",
    "            self.tts_voice = voice_options[voice_type]\n",
    "            print(f\"ğŸ¤ ìŒì„± ì„¤ì • ë³€ê²½: {voice_type} ({self.tts_voice})\")\n",
    "        else:\n",
    "            print(f\"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ìŒì„± íƒ€ì…: {voice_type}\")\n",
    "            print(f\"ì§€ì› íƒ€ì…: {list(voice_options.keys())}\")\n",
    "\n",
    "# ìŒì„± ëŒ€í™” í•¨ìˆ˜\n",
    "def interactive_voice_conversation():\n",
    "    \"\"\"interactive_conversation()ì˜ ìŒì„± ë²„ì „ - ê°€ì¥ ì‰¬ìš´ ì‹¤í–‰ ë°©ë²•\"\"\"\n",
    "    print(\"=== ğŸ¤ ìŒì„± í†µí•© ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ì‹œìŠ¤í…œ ===\")\n",
    "    print(\"ğŸ”Š ìŒì„±ìœ¼ë¡œ ì…ë ¥ë°›ê³  ìŒì„±ìœ¼ë¡œ ì¶œë ¥í•˜ëŠ” ëŒ€í™” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.\")\n",
    "    \n",
    "    try:\n",
    "        # ì´ë¯¸ì§€ ê²½ë¡œ ì…ë ¥\n",
    "        print(\"\\nğŸ“ ì´ë¯¸ì§€ íŒŒì¼ ì„ íƒ:\")\n",
    "        image_path = input(\"ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: image.jpg): \").strip()\n",
    "        \n",
    "        if not image_path:\n",
    "            print(\"âŒ ì´ë¯¸ì§€ ê²½ë¡œê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "            return None\n",
    "        \n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}\")\n",
    "            return None\n",
    "        \n",
    "        # ìŒì„± ì„¤ì • ì„ íƒ\n",
    "        print(\"\\nğŸ¤ ìŒì„± ì„¤ì •:\")\n",
    "        print(\"1. ì—¬ì„± ìŒì„± (ê¸°ë³¸)\")\n",
    "        print(\"2. ë‚¨ì„± ìŒì„±\")\n",
    "        print(\"3. ë°ì€ ì—¬ì„± ìŒì„±\")\n",
    "        print(\"4. ì°¨ë¶„í•œ ì—¬ì„± ìŒì„±\")\n",
    "        \n",
    "        voice_choice = input(\"ìŒì„±ì„ ì„ íƒí•˜ì„¸ìš” (1-4, ì—”í„°ì‹œ ê¸°ë³¸): \").strip()\n",
    "        \n",
    "        voice_mapping = {\n",
    "            \"1\": \"female\",\n",
    "            \"2\": \"male\", \n",
    "            \"3\": \"female_bright\",\n",
    "            \"4\": \"female_calm\",\n",
    "            \"\": \"female\"  # ê¸°ë³¸ê°’\n",
    "        }\n",
    "        \n",
    "        selected_voice = voice_mapping.get(voice_choice, \"female\")\n",
    "        \n",
    "        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "        print(\"\\nğŸš€ ìŒì„± ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...\")\n",
    "        voice_system = VoiceIntegratedSystem()\n",
    "        \n",
    "        # ìŒì„± ì„¤ì • ì ìš©\n",
    "        voice_system.set_voice_settings(selected_voice)\n",
    "        \n",
    "        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "        if not voice_system.initialize_system():\n",
    "            print(\"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "            return None\n",
    "        \n",
    "        # ì´ë¯¸ì§€ ë¶„ì„\n",
    "        print(f\"ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘: {image_path}\")\n",
    "        analysis_result = voice_system.analyze_image(image_path)\n",
    "        if not analysis_result:\n",
    "            print(\"âŒ ì´ë¯¸ì§€ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
    "            return None\n",
    "        \n",
    "        # ëŒ€í™” ì„¤ì •\n",
    "        print(\"ğŸ—£ï¸ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì„¤ì • ì¤‘...\")\n",
    "        voice_system.setup_conversation(analysis_result)\n",
    "        \n",
    "        # ì‹œì‘ ì•ˆë‚´\n",
    "        welcome_msg = \"ì•ˆë…•í•˜ì„¸ìš”. ì‚¬ì§„ì„ ë³´ë©° ëŒ€í™”ë¥¼ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.\"\n",
    "        print(f\"\\nğŸ¤– {welcome_msg}\")\n",
    "        voice_system.synthesize_speech(welcome_msg)\n",
    "        \n",
    "        # ì²« ì§ˆë¬¸ ìƒì„±\n",
    "        initial_question = voice_system.chat_system.generate_initial_question()\n",
    "        print(f\"ğŸ¤– AI: {initial_question}\")\n",
    "        voice_system.synthesize_speech(initial_question)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"ğŸ™ï¸ ìŒì„± ëŒ€í™” ì‹œì‘!\")\n",
    "        print(\"ğŸ’¡ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”\")\n",
    "        print(\"ğŸ’¡ 'ì¢…ë£Œ'ë¼ê³  ë§í•˜ë©´ ëŒ€í™”ê°€ ëë‚©ë‹ˆë‹¤\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # ëŒ€í™” ë£¨í”„\n",
    "        conversation_count = 0\n",
    "        max_conversations = 20\n",
    "        \n",
    "        while conversation_count < max_conversations:\n",
    "            print(f\"\\n--- ëŒ€í™” {conversation_count + 1} ---\")\n",
    "            \n",
    "            try:\n",
    "                # ìŒì„± ì…ë ¥ ë°›ê¸°\n",
    "                user_input = voice_system.transcribe_speech()\n",
    "                \n",
    "                # ìŒì„± ì¸ì‹ ì‹¤íŒ¨ì‹œ í…ìŠ¤íŠ¸ ì…ë ¥ ì˜µì…˜\n",
    "                if not user_input.strip():\n",
    "                    print(\"ğŸ’¬ ìŒì„±ì´ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "                    fallback = input(\"í…ìŠ¤íŠ¸ë¡œ ì…ë ¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/ì—”í„°-ì¬ì‹œë„): \").strip().lower()\n",
    "                    \n",
    "                    if fallback == 'y':\n",
    "                        user_input = input(\"ğŸ‘¤ \").strip()\n",
    "                    else:\n",
    "                        continue\n",
    "                \n",
    "                if not user_input.strip():\n",
    "                    continue\n",
    "                \n",
    "                # ì¢…ë£Œ ëª…ë ¹ í™•ì¸ (í™•ì¥ëœ ë²„ì „)\n",
    "                exit_commands = [\n",
    "                    'ì¢…ë£Œ', 'ê·¸ë§Œ', 'ë', 'ë‚˜ê°€ê¸°', 'exit', 'quit', 'q', 'stop',\n",
    "                    'ëŒ€í™” ë', 'ëŒ€í™” ì¢…ë£Œ', 'ë§ˆì¹˜ê¸°', 'ëë‚´ê¸°', 'ê·¸ë§Œí•˜ê¸°'\n",
    "                ]\n",
    "                \n",
    "                # ëŒ€ì†Œë¬¸ì ë¬´ê´€í•˜ê³  ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ì œê±° í›„ ë¹„êµ\n",
    "                cleaned_input = user_input.lower().replace(' ', '').replace('.', '').replace('!', '').replace(',', '')\n",
    "                \n",
    "                is_exit_command = False\n",
    "                \n",
    "                for exit_cmd in exit_commands:\n",
    "                    if exit_cmd.lower() in cleaned_input or exit_cmd in user_input:\n",
    "                        is_exit_command = True\n",
    "                        break\n",
    "                \n",
    "                if is_exit_command:\n",
    "                    end_msg = \"ëŒ€í™”ë¥¼ ë§ˆì¹˜ê² ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.\"\n",
    "                    break\n",
    "                \n",
    "                # AI ì‘ë‹µ ìƒì„±\n",
    "                answer, should_end, question_type = voice_system.chat_system.chat_about_image(user_input)\n",
    "                \n",
    "                # AI ì‘ë‹µ ì¶œë ¥\n",
    "                type_emoji = {\"normal\": \"ğŸ¤–\", \"keyword\": \"ğŸ’\", \"cognitive\": \"ğŸ§ \"}\n",
    "                print(f\"{type_emoji.get(question_type, 'ğŸ¤–')} {answer}\")\n",
    "                \n",
    "                # AI ì‘ë‹µ ìŒì„± ì¶œë ¥\n",
    "                voice_system.synthesize_speech(answer)\n",
    "                \n",
    "                # í† í° ì œí•œ ë„ë‹¬\n",
    "                if should_end:\n",
    "                    end_msg = \"ëŒ€í™” ì‹œê°„ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤.\"\n",
    "                    print(f\"â° {end_msg}\")\n",
    "                    voice_system.synthesize_speech(end_msg)\n",
    "                    break\n",
    "                \n",
    "                conversation_count += 1\n",
    "                time.sleep(0.5)  # ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\nâ¹ï¸ ëŒ€í™”ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\")\n",
    "                continue\n",
    "        \n",
    "        \n",
    "        # ë¦¬í¬íŠ¸ ìƒì„±\n",
    "        print(\"ğŸ“ˆ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...\")\n",
    "        reports = voice_system.generate_reports(image_path)\n",
    "        \n",
    "\n",
    "        return voice_system, reports\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}\")\n",
    "        return None\n",
    "\n",
    "def quick_voice_conversation():\n",
    "    \"\"\"ë” ê°„ë‹¨í•œ ìŒì„± ëŒ€í™” ì‹œì‘ (ê¸°ë³¸ ì„¤ì • ì‚¬ìš©)\"\"\"\n",
    "    print(\"=== ğŸš€ ë¹ ë¥¸ ìŒì„± ëŒ€í™” ì‹œì‘ ===\")\n",
    "    \n",
    "    # ê¸°ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ (í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°)\n",
    "    image_files = [f for f in os.listdir('.') if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
    "    \n",
    "    if image_files:\n",
    "        image_path = image_files[0]\n",
    "        print(f\"ğŸ“ ë°œê²¬ëœ ì´ë¯¸ì§€ ì‚¬ìš©: {image_path}\")\n",
    "    else:\n",
    "        image_path = input(\"ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: \").strip()\n",
    "    \n",
    "    try:\n",
    "        # ì‹œìŠ¤í…œ ìƒì„± ë° ì‹¤í–‰\n",
    "        voice_system = VoiceIntegratedSystem()\n",
    "        return voice_system.run_full_voice_conversation(image_path)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9ef023",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "932a3658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ğŸš€ ë¹ ë¥¸ ìŒì„± ëŒ€í™” ì‹œì‘ ===\n",
      "ğŸ“ ë°œê²¬ëœ ì´ë¯¸ì§€ ì‚¬ìš©: images.jpg\n",
      "âœ… ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ\n",
      "ğŸ¤ ìŒì„± í†µí•© ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "ğŸš€ ìŒì„± ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ë¶„ì„ ì‹œìŠ¤í…œ ì‹œì‘\n",
      "============================================================\n",
      "ğŸ”„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...\n",
      "âœ… ì´ë¯¸ì§€ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ\n",
      "âœ… ì±„íŒ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ\n",
      "ğŸ¯ ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ë¶„ì„ ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "ğŸ–¼ï¸  ì´ë¯¸ì§€ ë¶„ì„ ì¤‘: images.jpg\n",
      "\n",
      "Caption: í•œ ê°€ì¡±ì´ ê±°ì‹¤ì—ì„œ í•¨ê»˜ ì‹œê°„ì„ ë³´ë‚´ë©° ì‚¬ì§„ì„ ì°ê³  ìˆëŠ” ëª¨ìŠµìœ¼ë¡œ, ë”°ëœ»í•˜ê³  ì•„ëŠ‘í•œ ë¶„ìœ„ê¸°ê°€ ëŠê»´ì§„ë‹¤. ë¶€ëª¨ì™€ ë‘ ìë…€ê°€ í•¨ê»˜ ì•‰ì•„ ìˆìœ¼ë©°, ë°”ë‹¥ì—ëŠ” ì• ì™„ê²¬ì´ í¸ì•ˆí•˜ê²Œ ëˆ„ì›Œ ìˆë‹¤. ê°€ì¡±ì˜ í™”ëª©í•¨ê³¼ ì‚¬ë‘ì´ ë‹´ê¸´ ìˆœê°„ì„ í¬ì°©í•œ ì‚¬ì§„ì´ë‹¤.\n",
      "Mood: ë”°ëœ»í•˜ê³  í™”ëª©í•œ ë¶„ìœ„ê¸°\n",
      "Time Period: 1950ë…„ëŒ€ ì¶”ì •\n",
      "People Count: 4\n",
      "Time of Day: ë‚®\n",
      "\n",
      "Dense Captions:\n",
      "- ì™¼ìª½ì—ëŠ” ì •ì¥ì„ ì…ì€ ë‚¨ì„±ì´ ì˜ìì— ì•‰ì•„ ìˆë‹¤.\n",
      "- ì¤‘ì•™ì—ëŠ” ìŠ¤ì»¤íŠ¸ë¥¼ ì…ì€ ì†Œë…€ê°€ ë°”ë‹¥ì— ì•‰ì•„ ìˆìœ¼ë©°, ê·¸ë…€ ì˜†ì—ëŠ” ì• ì™„ê²¬ì´ ëˆ„ì›Œ ìˆë‹¤.\n",
      "- ì˜¤ë¥¸ìª½ì—ëŠ” ë¸”ë¼ìš°ìŠ¤ë¥¼ ì…ì€ ì—¬ì„±ì´ ì˜ìì— ì•‰ì•„ ìˆë‹¤.\n",
      "- ê·¸ ì˜†ì—ëŠ” ì…”ì¸ ë¥¼ ì…ì€ ì–´ë¦° ì†Œë…„ì´ ë°”ë‹¥ì— ì•‰ì•„ ìˆë‹¤.\n",
      "- ë°°ê²½ì—ëŠ” ë¨í”„ì™€ í…Œì´ë¸”ì´ ë†“ì—¬ ìˆìœ¼ë©°, ë²½ì—ëŠ” ì•¡ìê°€ ê±¸ë ¤ ìˆë‹¤.\n",
      "âœ… ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ\n",
      "ğŸ—£ï¸  ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì„¤ì • ì¤‘...\n",
      "âœ… ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì„¤ì • ì™„ë£Œ\n",
      "\n",
      "ğŸ¤– AI: \"ì–´ë¥´ì‹ , ê°€ì¡±ë“¤ê³¼ í•¨ê»˜ ê±°ì‹¤ì—ì„œ ì‹œê°„ì„ ë³´ë‚´ë˜ ì¶”ì–µì´ ìˆìœ¼ì‹ ê°€ìš”?\"\n",
      "\n",
      "ğŸ’¡ ìŒì„±ìœ¼ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”. ëŒ€í™”ë¥¼ ì¢…ë£Œí•˜ë ¤ë©´ 'ì¢…ë£Œ'ë¼ê³  ë§ì”€í•˜ì„¸ìš”.\n",
      "ğŸ“‹ 3í„´ë§ˆë‹¤ ì¸ì§€ ê²€ì‚¬ ì§ˆë¬¸ì´ ìë™ìœ¼ë¡œ ì¶”ê°€ë©ë‹ˆë‹¤.\n",
      "ğŸ” í‚¤ì›Œë“œ ê°ì§€ ì‹œ ê´€ë ¨ ì§ˆë¬¸ì´ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.\n",
      "\n",
      "--- ëŒ€í™” 1 ---\n",
      "ğŸ¤– \"ê·¸ë ‡êµ°ìš”, ì–´ë¥´ì‹ . ê°€ì¡±ë“¤ê³¼ í•¨ê»˜í•œ ì‹œê°„ì´ ì°¸ ë”°ëœ»í–ˆì„ ê²ƒ ê°™ì•„ìš”. í˜¹ì‹œ ê±°ì‹¤ì—ì„œ ë­˜ ì£¼ë¡œ í•˜ì…¨ëŠ”ì§€ ê¸°ì–µë‚˜ì„¸ìš”?\"\n",
      "\n",
      "--- ëŒ€í™” 2 ---\n",
      "ğŸ¤– \"ì•„, ê´œì°®ì•„ìš”, ì–´ë¥´ì‹ . ê¸°ì–µì´ ì•ˆ ë‚˜ì…”ë„ ê´œì°®ìŠµë‹ˆë‹¤. ê·¸ì € í•¨ê»˜í•˜ëŠ” ì‹œê°„ì´ ì°¸ ì†Œì¤‘í–ˆì„ ê±°ì˜ˆìš”. í˜¹ì‹œ ì• ì™„ë™ë¬¼ê³¼ í•¨ê»˜í•œ ê¸°ì–µì€ ìˆìœ¼ì‹ ê°€ìš”?\"\n",
      "\n",
      "--- ëŒ€í™” 3 ---\n",
      "ğŸ§  ì‚¬ì§„ì´ ë‚®ì— ì°íŒ ê²ƒ ê°™ë‚˜ìš”, ë°¤ì¸ê°€ìš”?\n",
      "\n",
      "--- ëŒ€í™” 4 ---\n",
      "ğŸ¤– \"ì–´ë¥´ì‹ , ì£„ì†¡í•©ë‹ˆë‹¤. ì œê°€ ì˜ëª» ë§ì”€ë“œë¦° ê²ƒ ê°™ì•„ìš”. í˜¹ì‹œ ì´ ì‚¬ì§„ ì† ë°°ê²½ì´ ë‚®ì¸ì§€, ë°¤ì¸ì§€ ê¶ê¸ˆí•´ì„œ ì—¬ì­¤ë´¤ì–´ìš”. í™”ë‚´ì…¨ë‹¤ë©´ ì •ë§ ì£„ì†¡í•˜ê³ , ì œê°€ ë” ì¡°ì‹¬í•˜ê² ìŠµë‹ˆë‹¤. ê·¸ëŸ¼ í˜¹ì‹œ ì´ ì‚¬ì§„ ì† ë¶„ìœ„ê¸°ê°€ ì–´ë¥´ì‹ ê»˜ ì–´ë–¤ ëŠë‚Œì„ ì£¼ì—ˆëŠ”ì§€ ë§ì”€í•´ ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?\"\n",
      "\n",
      "--- ëŒ€í™” 5 ---\n",
      "ğŸ¤– ëŒ€í™”ë¥¼ ë§ˆì¹˜ê² ìŠµë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“Š ëŒ€í™” ë¶„ì„ ë° ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š ë¶„ì„ ê²°ê³¼ ìƒì„± ì¤‘...\n",
      "============================================================\n",
      "ğŸ“ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” ì¤‘...\n",
      "ğŸ“ ëŒ€í™” ê¸°ë¡ì´ 'conversation_log\\images_20250528_010221.txt' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ“Š ì´ìƒ ë‹µë³€ ë¶„ì„ì´ 'analysis\\images_20250528_010221_analysis.txt' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ“– ì¶”ì–µ ì´ì•¼ê¸°ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘...\n",
      "ğŸ“– ì¶”ì–µ ì´ì•¼ê¸°ê°€ 'story_telling\\images_story.txt' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "=== ìƒì„±ëœ ì¶”ì–µ ì´ì•¼ê¸° ===\n",
      "ì•„, ê·¸ ì‚¬ì§„ ë§ì´ì§€? ì°¸, ì˜›ë‚ ì´ì•¼ê¸°ë¼ë‹ˆ ë³„ìŠ¤ëŸ½ë„¤. ì €ê²Œ ë‚®ì´ì—ˆëŠ”ì§€ ë°¤ì´ì—ˆëŠ”ì§€, ê·¸ëŸ° ê±´ ëª¨ë¥´ê² ë‹¤ë§Œ, ë‚´ê°€ ê¸°ì–µë‚˜ëŠ” ê±´ ê±°ì‹¤ì˜ ë¶„ìœ„ê¸°ì•¼. ìš°ë¦¬ ì§‘ ê±°ì‹¤ì€ í•­ìƒ ë”°ëœ»í–ˆì–´. ê·¸ë•ŒëŠ” ê°€ì¡±ë“¤ì´ ë‹¤ ëª¨ì˜€ë˜ ê³³ì´ì—ˆì§€. í° íƒì ìœ„ì—ëŠ” ê³¼ì¼ ëª‡ ê°œê°€ ë†“ì—¬ ìˆì—ˆê³ , ì € ë©€ë¦¬ì„œ ì‘ì€ ë¼ë””ì˜¤ê°€ í˜ë ¤ë³´ë‚´ëŠ” ìŒì•… ì†Œë¦¬ê°€ ì€ì€í•˜ê²Œ ë“¤ë ¸ì–´. ê·¸ ì†Œë¦¬, ë§ˆì¹˜ ë°”ëŒê²°ì²˜ëŸ¼ ë¶€ë“œëŸ¬ì› ì§€.  \n",
      "\n",
      "ì•„ë§ˆë„ ì € ì‚¬ì§„ì€ ëˆ„êµ°ê°€ê°€ ì¥ë‚œìŠ¤ëŸ½ê²Œ ì°ì—ˆì„ ê±°ì•¼. ë‚˜ì•¼, ì‚¬ì§„ ì°íˆëŠ” ê±¸ ë³„ë¡œ ì¢‹ì•„í•˜ì§„ ì•Šì•˜ëŠ”ë°, ê·¸ë•ŒëŠ” ì €ë„ ëª°ëì§€. ì§€ê¸ˆ ë³´ë©´ ìš°ìŠµê²Œë„, ì‹œì„ ì— ì‚´ì§ ì§œì¦ì´ ë¬»ì–´ ìˆëŠ” ê²ƒ ê°™ì•„. ê·¸ëŸ°ë°ë„ ê·¸ ì‚¬ì§„ë§Œ ë³´ë©´ ì´ìƒí•˜ê²Œ ë§ˆìŒì´ ë”°ëœ»í•´ì ¸. ë‚´ ë°”ë¡œ ì˜†ì—ëŠ” ìš°ë¦¬ ì‹êµ¬ë“¤ì´ ì•‰ì•„ ìˆì—ˆì„ ê±°ì•¼. ì—„ë§ˆëŠ” ë­”ê°€ë¥¼ ë°”ëŠì§ˆí•˜ê³  ê³„ì…¨ë˜ ê²ƒ ê°™ì•„. ì†ëì—ì„œ ë‚˜ëŠ” ì‹¤ì˜ ë¶€ë“œëŸ¬ìš´ ì†Œë¦¬, ê·¸ë¦¬ê³  ë°”ëŠì§ˆ ì†œì”¨ê°€ ì°¸ ë†€ë¼ì› ì§€. ì•„ë²„ì§€ëŠ” ì•„ë§ˆë„ ì‹ ë¬¸ì„ ì½ê³  ê³„ì…¨ì„ ê±°ê³ , ì•„ì´ë“¤ì€ ë°”ë‹¥ì— ì•‰ì•„ ë…¸ë˜ë„ ë¶€ë¥´ê³  ì¥ë‚œë„ ì¹˜ê³ .  \n",
      "\n",
      "ìš°ë¦¬ ì§‘ì—” ì• ì™„ë™ë¬¼ì€ ì—†ì—ˆì–´. ëŒ€ì‹  ìš°ë¦¬ ê°€ì¡±ì´ ì„œë¡œì—ê²Œ ì• ì™„ë™ë¬¼ë§Œí¼ì´ë‚˜ ë‹¤ì •í–ˆì§€. ì›ƒìŒì†Œë¦¬, ì¥ë‚œìŠ¤ëŸ¬ìš´ ëŒ€í™”, ê·¸ë¦¬ê³  ê±°ì‹¤ì— í¼ì§€ë˜ ë”°ëœ»í•œ ë‚˜ë¬´ ëƒ„ìƒˆ. ë‚˜ëŠ” ì§€ê¸ˆë„ ê·¸ ëƒ„ìƒˆë¥¼ ë– ì˜¬ë¦¬ë©´ ë§ˆìŒì´ ì°¨ë¶„í•´ì ¸. ì•Œì§€? ê·¸ ë‚˜ë¬´ ë°”ë‹¥ì— ë§¨ë°œë¡œ ì„œë©´, ì‚´ì§ ì°¨ê°‘ê³  ë§¤ëˆí•œ ì´‰ê°ì´ ëŠê»´ì¡Œë˜ ê²ƒë„ ê¸°ì–µë‚˜.  \n",
      "\n",
      "ì‚¬ì§„ ì† ë‚´ê°€ ë°”ë³´ ê°™ì•„ ë³´ì¼ì§€ëŠ” ëª°ë¼ë„, ê·¸ ìˆœê°„ë§Œí¼ì€ ìš°ë¦¬ ê°€ì¡±ì´ í•¨ê»˜ì˜€ë‹¤ëŠ” ê²Œ ì°¸ ì¢‹ì•˜ì–´. ì´ì   ê¸°ì–µì´ í¬ë¯¸í•´ì ¸ì„œ ì •í™•íˆ ë­˜ í–ˆëŠ”ì§€ëŠ” ëª¨ë¥´ê² ì§€ë§Œ, ì†Œë¦¬ë‚˜ ëƒ„ìƒˆ ê°™ì€ ì‘ì€ ê²ƒë“¤ì´ ì—¬ì „íˆ ë‚´ ë§ˆìŒì— ë‚¨ì•„ìˆì–´. ê·¸ë˜, ëˆ„ê°€ ë´ë„ ê·¸ ì‚¬ì§„ì€ ë‚˜í•œí…Œ ì°íŒ ê±°ë¼ë‹ˆê¹Œ. ê·¸ë˜ë„ ì†ì£¼ì•¼, ë‚˜ì¤‘ì—” ë„ˆë„ ì´ëŸ° ë”°ëœ»í•œ ì¶”ì–µì„ ê°„ì§í•˜ê²Œ ë  ê±°ì•¼. ë‚˜ë¥¼ ë‹®ì•„ì„œ ë§ì´ì§€.\n",
      "========================================\n",
      "ğŸ“± ëª¨ë°”ì¼ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10764\\754271693.py:148: UserWarning: Glyph 9642 (\\N{BLACK SMALL SQUARE}) missing from font(s) Malgun Gothic.\n",
      "  plt.tight_layout(rect=[0, 0.08, 1, 0.95], pad=2.0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10764\\754271693.py:155: UserWarning: Glyph 9642 (\\N{BLACK SMALL SQUARE}) missing from font(s) Malgun Gothic.\n",
      "  plt.savefig(report_filename, dpi=200, bbox_inches='tight',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“± ëª¨ë°”ì¼ ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: reports\\images_report_20250528_010234.png\n",
      "âœ… ëª¨ë°”ì¼ ë¦¬í¬íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "ğŸ“‚ íŒŒì¼ ê²½ë¡œ: reports\\images_report_20250528_010234.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'conversation_file': 'conversation_log\\\\images_20250528_010221.txt',\n",
       " 'analysis_file': 'analysis\\\\images_20250528_010221_analysis.txt',\n",
       " 'story_file': 'story_telling\\\\images_story.txt',\n",
       " 'mobile_report_file': 'reports\\\\images_report_20250528_010234.png'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quick_voice_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82abd12e",
   "metadata": {},
   "source": [
    "## ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "832eedb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì„ íƒëœ íŒŒì¼: audio_files\\input\\input_20250528_010132.wav (250476 bytes)\n",
      "âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: audio_files\\preprocessed\\input_20250528_010132.wav (250510 bytes)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def select_largest_wav(input_dir: Path) -> Path:\n",
    "    wav_files = list(input_dir.glob(\"*.wav\"))\n",
    "    if not wav_files:\n",
    "        raise FileNotFoundError(f\"No .wav files found in {input_dir}\")\n",
    "    # íŒŒì¼ í¬ê¸° ê¸°ì¤€ìœ¼ë¡œ ìµœëŒ€ê°’ ì„ íƒ\n",
    "    return max(wav_files, key=lambda p: p.stat().st_size)\n",
    "\n",
    "def preprocess_single_wav(\n",
    "    wav_file: Path,\n",
    "    output_dir: Path,\n",
    "    sample_rate: int = 16000\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    ë‹¨ì¼ .wav íŒŒì¼ì„ ì§€ì •í•œ sample_rate, mono, 16bit PCM ìœ¼ë¡œ ë³€í™˜í•´ ì €ì¥.\n",
    "    ë°˜í™˜ê°’ì€ ìƒì„±ëœ íŒŒì¼ ê²½ë¡œì…ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    output_file = output_dir / wav_file.name\n",
    "\n",
    "    cmd = [\n",
    "        \"ffmpeg\",\n",
    "        \"-y\",                        # ë®ì–´ì“°ê¸°\n",
    "        \"-i\", str(wav_file),         # ì…ë ¥ íŒŒì¼\n",
    "        \"-ar\", str(sample_rate),     # ë¦¬ìƒ˜í”Œë§\n",
    "        \"-ac\", \"1\",                  # ëª¨ë…¸\n",
    "        \"-acodec\", \"pcm_s16le\",      # 16bit PCM\n",
    "        str(output_file)             # ì¶œë ¥ íŒŒì¼\n",
    "    ]\n",
    "    subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    print(f\"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {output_file} ({output_file.stat().st_size} bytes)\")\n",
    "    return output_file\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ\n",
    "input_dir  = Path(\"audio_files/input\")\n",
    "output_dir = Path(\"audio_files/preprocessed\")\n",
    "\n",
    "# 1) ê°€ì¥ í° íŒŒì¼ ì„ íƒ\n",
    "largest_wav = select_largest_wav(input_dir)\n",
    "print(f\"ì„ íƒëœ íŒŒì¼: {largest_wav} ({largest_wav.stat().st_size} bytes)\")\n",
    "\n",
    "# 2) ì „ì²˜ë¦¬ ì‹¤í–‰\n",
    "preprocessed = preprocess_single_wav(largest_wav, output_dir, sample_rate=16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0013042",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpreprocessed\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocessed' is not defined"
     ]
    }
   ],
   "source": [
    "print(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff65328e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m prompt_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mì´ê±´ ì˜ˆì‹œ í”„ë¡¬í”„íŠ¸ì…ë‹ˆë‹¤.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# wav_path = \"test.wav\"  # í™˜ì ìŒì„± íŒŒì¼\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m wav_path \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessed\u001b[49m\n\u001b[0;32m     10\u001b[0m files \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mopen\u001b[39m(wav_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)}\n\u001b[0;32m     11\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: text,\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_text\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_text\n\u001b[0;32m     14\u001b[0m }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocessed' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "# í•˜ê³ ì‹¶ì€ê±°\n",
    "text = \"ì•ˆë…•\" \n",
    "# with open(\"story_telling/images_story.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     text = f.read()\n",
    "preprocessed ='audio_files\\preprocessed\\input_20250528_010132.wav'\n",
    "prompt_text = \"ì´ê±´ ì˜ˆì‹œ í”„ë¡¬í”„íŠ¸ì…ë‹ˆë‹¤.\"\n",
    "# wav_path = \"test.wav\"  # í™˜ì ìŒì„± íŒŒì¼\n",
    "wav_path = preprocessed\n",
    "files = {\"file\": open(wav_path, \"rb\")}\n",
    "data = {\n",
    "    \"text\": text,\n",
    "    \"prompt_text\": prompt_text\n",
    "}\n",
    "\n",
    "res = requests.post(\"http://20.41.115.128:8000/synthesize\", data=data, files=files)\n",
    "\n",
    "with open(\"result.wav\", \"wb\") as f:\n",
    "    f.write(res.content)\n",
    "\n",
    "print(\"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: result.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13831b74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
