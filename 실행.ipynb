{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0e0e3d9",
   "metadata": {},
   "source": [
    "## WavíŒŒì¼ ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c4db4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def preprocess_wav_directory(input_dir, output_dir, sample_rate=16000):\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for wav_file in input_dir.glob(\"*.wav\"):\n",
    "        output_file = output_dir / wav_file.name\n",
    "        command = [\n",
    "            \"ffmpeg\",\n",
    "            \"-y\",  # overwrite without asking\n",
    "            \"-i\", str(wav_file),\n",
    "            \"-ar\", str(sample_rate),       # Resample to 16kHz\n",
    "            \"-ac\", \"1\",                    # Convert to mono\n",
    "            \"-acodec\", \"pcm_s16le\",        # 16-bit PCM\n",
    "            str(output_file)\n",
    "        ]\n",
    "        subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "    print(f\"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {len(list(output_dir.glob('*.wav')))}ê°œ íŒŒì¼ì´ {output_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ì˜ˆì‹œ ì‚¬ìš©\n",
    "input_path = 'input_wav'\n",
    "output_path = \"output_wav\"\n",
    "preprocess_wav_directory(input_path,output_path )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950f9ee0",
   "metadata": {},
   "source": [
    "## STT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001a19a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°\n",
    "speech_key = os.getenv(\"speech_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e0d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "def transcribe_speech(audio_path: str, speech_key: str, region: str) -> str:\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=region)\n",
    "    speech_config.speech_recognition_language = \"ko-KR\"  # âœ… í•œêµ­ì–´ ì„¤ì •\n",
    "\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=audio_path)\n",
    "\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    print(\"ğŸ™ï¸ STT ì‹¤í–‰ ì¤‘...\")\n",
    "    result = speech_recognizer.recognize_once()\n",
    "\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print(\"ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸:\", result.text)\n",
    "        return result.text\n",
    "    else:\n",
    "        print(\"âŒ ìŒì„± ì¸ì‹ ì‹¤íŒ¨:\", result.reason)\n",
    "        return \"\"\n",
    "\n",
    "# ì˜ˆì‹œ ì‹¤í–‰\n",
    "region = \"eastus\"\n",
    "prompt_audio_path = \"output_wav/ë…¸ì¸ë‚¨ì—¬_ë…¸ì¸ëŒ€í™”07_F_1526682663_63_ìˆ˜ë„ê¶Œ_ì‹¤ë‚´_08352.wav\"\n",
    "\n",
    "prompt_text = transcribe_speech(prompt_audio_path, speech_key, region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed15eef",
   "metadata": {},
   "source": [
    "## TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f897e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference_module import init_engine, run_tts\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write as write_wav\n",
    "engine = init_engine()\n",
    "\n",
    "input_text = \"\"\"\n",
    "ì´ ì‚¬ì§„ì€ ë‚´ê°€ ìŠ¤ë¬´ ì‚´ ë•Œ, ì²˜ìŒ ì„œìš¸ êµ¬ê²½ ê°”ì„ ë•Œ ì°ì€ ê±°ì•¼.\n",
    "ì €ê¸° ì˜†ì— ìˆëŠ” ì¹œêµ¬ëŠ” ìˆœì´, ì°¸ ë§ë„ ë§ê³  ì›ƒìŒë„ ë§ë˜ ì•„ì´ì˜€ì§€.\n",
    "ê·¸ë‚  ë‚¨ëŒ€ë¬¸ì‹œì¥ì—ì„œ ì‚° í•˜ëŠ˜ìƒ‰ ì›í”¼ìŠ¤ë¥¼ ì•„ì§ë„ ê¸°ì–µí•´.\n",
    "ì‚¬ì§„ ì† ë‚˜ëŠ” ì°¸ í•´ë§‘ì€ë°, ê·¸ë• ì„¸ìƒì´ ë‹¤ ì„¤ë ˆê³  ì‹ ê¸°í–ˆì§€.\n",
    "ìš”ì¦˜ë„ ì´ ì‚¬ì§„ ë³´ë©´ ê°€ë” ê·¸ ì‹œì ˆ ëƒ„ìƒˆê°€ ë‚˜ëŠ” ê²ƒ ê°™ì•„.\n",
    "\"\"\"\n",
    "prompt_audio_path = \"output_wav/ë…¸ì¸ë‚¨ì—¬_ë…¸ì¸ëŒ€í™”07_F_1526682663_63_ìˆ˜ë„ê¶Œ_ì‹¤ë‚´_08352.wav\"\n",
    "\n",
    "# 3. ì¶”ë¡  ì‹¤í–‰\n",
    "sample_rate, waveform = run_tts(engine, input_text, prompt_audio_path, prompt_text)\n",
    "\n",
    "# 4. float32 â†’ int16ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥\n",
    "waveform_int16 = (waveform * 32767).astype(np.int16)\n",
    "write_wav(\"model_output/8000/1.wav\", sample_rate, waveform_int16)\n",
    "\n",
    "print(\"âœ… ìƒì„± ì™„ë£Œ: output.wav\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
