from dataclasses import dataclass, field
from typing import List, Optional
from datetime import datetime
from fastapi import HTTPException
from azure.storage.blob import BlobServiceClient
from uuid import uuid4

from services.image_analyzer import ImageAnalyzer
from services.chat_system import ChatSystem
from services.voice_system import VoiceSystem
from services.story_and_report_system import StoryGenerator
import os
import uuid

from core.config import settings
from db.database import get_db

@dataclass
class SessionData:
    conversation_id: str
    photo_path: Optional[str] = None
    turns: List[dict] = field(default_factory=list)  # {"question": ..., "answer": ..., "timestamp": ...}
    created_at: datetime = field(default_factory=datetime.now)

class OptimizedDementiaSystem:
    """ìµœì í™”ëœ ì¹˜ë§¤ ì§„ë‹¨ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.sessions: dict[str, SessionData] = {}  # ì—¬ê¸° keyê°€ conv_id
        self.speech_key = os.getenv("AZURE_SPEECH_KEY")

        self.image_analyzer = ImageAnalyzer()
        self.chat_system = ChatSystem()
        self.voice_system = VoiceSystem() if self.speech_key else None
        self.story_generator = StoryGenerator(self.chat_system)
    
    def analyze_and_start_conversation(self, image_path):
        """ì´ë¯¸ì§€ ë¶„ì„ ë° ëŒ€í™” ì‹œì‘"""
        if not os.path.exists(image_path):
            return None
        

        # ì´ë¯¸ì§€ ë¶„ì„
        analysis_result = self.image_analyzer.analyze_image(image_path)
        if not analysis_result:
            return None
        
        # ëŒ€í™” ì„¤ì •
        self.chat_system.setup_conversation_context(analysis_result)
    
        # ì²« ì§ˆë¬¸ ìƒì„±
        initial_question = self.chat_system.generate_initial_question()

        # ì²« ì§ˆë¬¸ TTS
        audio_path = self.voice_system.synthesize_speech(initial_question)
        
        return initial_question, audio_path
    
    # def generate_complete_analysis(self, image_path):
    #     """ì™„ì „í•œ ë¶„ì„ ìƒì„±"""
    #     print("\nğŸ“Š ì¢…í•© ë¶„ì„ ê²°ê³¼ ìƒì„± ì¤‘...")
        
    #     # 1. ëŒ€í™” ê¸°ë¡ ì €ì¥ (ìƒˆë¡œìš´ í´ë” êµ¬ì¡°)
    #     conversation_file, analysis_file = self.story_generator.save_conversation_to_file(image_path)
        
    #     # 2. ì¶”ì–µ ìŠ¤í† ë¦¬ ìƒì„±
    #     story, story_file = self.story_generator.generate_story_from_conversation(image_path)
        
    #     # 3. ì½˜ì†”ì— ìš”ì•½ ì¶œë ¥
    #     summary = self.story_generator.save_conversation_summary()
    #     print(summary)
        
    #     # 4. ìŠ¤í† ë¦¬ ì¶œë ¥
    #     if story:
    #         print(f"\n{'='*50}")
    #         print("ğŸ“– ìƒì„±ëœ ì¶”ì–µ ì´ì•¼ê¸°")
    #         print(f"{'='*50}")
    #         print(story)
    #         print(f"{'='*50}")
        
    #     return {
    #         'conversation_file': conversation_file,
    #         'analysis_file': analysis_file,
    #         'story_file': story_file,
    #         'story_content': story,
    #         'summary': summary,
    #         'conversation_id': self.story_generator.conversation_id
    #     }

    def generate_complete_analysis_from_turns(self, turns, conversation_id):
        """Turn ë°ì´í„°ë¡œë¶€í„° ì™„ì „í•œ ë¶„ì„ ìƒì„±"""
        print("\nğŸ“Š Turn ë°ì´í„° ê¸°ë°˜ ì¢…í•© ë¶„ì„ ê²°ê³¼ ìƒì„± ì¤‘...")
        
        # Turn ë°ì´í„°ë¥¼ ConversationTurn í˜•íƒœë¡œ ë³€í™˜
        from services.chat_system import ConversationTurn
        conversation_turns = []
        
        for turn in turns:
            if turn.turn and isinstance(turn.turn, dict):
                question = turn.turn.get('q_text', '')
                answer = turn.turn.get('a_text', '')
                
                # ì§ˆë¬¸ì´ ìˆê³ , ë‹µë³€ì´ nullì´ ì•„ë‹Œ ê²½ìš°ë§Œ í¬í•¨ (ë¹ˆ ë¬¸ìì—´ë„ í¬í•¨)
                if question and answer is not None:
                    conversation_turn = ConversationTurn(
                        question=question,
                        answer=answer,
                        timestamp=turn.recorded_at.strftime("%Y-%m-%d %H:%M:%S"),
                        answer_length=len(answer.strip()) if answer else 0,
                        audio_file=turn.turn.get('a_voice', '') or ''
                    )
                    conversation_turns.append(conversation_turn)
        
        if not conversation_turns:
            return {
                'error': 'No valid conversation turns found',
                'conversation_id': str(conversation_id)
            }
        
        # StoryGeneratorì˜ chat_systemì— conversation_turns ì„¤ì •
        self.story_generator.chat_system.conversation_turns = conversation_turns
        self.story_generator.conversation_id = str(conversation_id)
        
        # 1. ì¶”ì–µ ìŠ¤í† ë¦¬ ìƒì„± (Turn ë°ì´í„° ì§ì ‘ ì‚¬ìš©)
        story = self.story_generator.generate_story_from_turns(conversation_turns)
        
        # 2. ëŒ€í™” ê¸°ë¡ ì €ì¥
        conversation_file, analysis_file = self.story_generator.save_conversation_to_file_from_turns(conversation_turns, str(conversation_id))
        
        # 3. ìŠ¤í† ë¦¬ íŒŒì¼ ì €ì¥
        story_file = None
        if story:
            story_dir = "story_telling"
            os.makedirs(story_dir, exist_ok=True)
            story_file = os.path.join(story_dir, f"{conversation_id}_story.txt")
            
            with open(story_file, 'w', encoding='utf-8') as f:
                f.write(story)
        
        # 4. ìš”ì•½ ìƒì„±
        summary = self.story_generator.save_conversation_summary()
        print(summary)
        
        # 5. ìŠ¤í† ë¦¬ ì¶œë ¥
        if story:
            print(f"\n{'='*50}")
            print("ğŸ“– ìƒì„±ëœ ì¶”ì–µ ì´ì•¼ê¸°")
            print(f"{'='*50}")
            print(story)
            print(f"{'='*50}")
        
        return {
            'conversation_file': conversation_file,
            'analysis_file': analysis_file,
            'story_file': story_file,
            'story_content': story,
            'summary': summary,
            'conversation_id': str(conversation_id),
            'turns_processed': len(conversation_turns)
        }
    
    def _run_conversation(self, initial_question, is_voice=False):
        """ëŒ€í™” ë£¨í”„ ì‹¤í–‰ (ìŒì„±/í…ìŠ¤íŠ¸ ê³µí†µ)"""
        
        # if is_voice and self.voice_system:
        #     welcome_msg = "ì•ˆë…•í•˜ì„¸ìš”. ì‚¬ì§„ì„ ë³´ë©° ëŒ€í™”í•´ìš”."
        #     print(f"ğŸ¤– {welcome_msg}")
        #     self.voice_system.synthesize_speech(welcome_msg)
            
        #     print(f"ğŸ¤– {initial_question}")
        #     self.voice_system.synthesize_speech(initial_question)
        # else:
        #     print(f"ğŸ¤– {initial_question}")
        
        # conversation_type = "ìŒì„±" if is_voice else "í…ìŠ¤íŠ¸"
        # print(f"\n" + "="*40)
        # print(f"{'ğŸ™ï¸' if is_voice else 'ğŸ’¬'} {conversation_type} ëŒ€í™” ì‹œì‘!")
        # print(f"ğŸ’¡ {'ì¢…ë£Œë¼ê³  ë§í•˜ë©´' if is_voice else 'exit ë˜ëŠ” ì¢…ë£Œë¥¼ ì…ë ¥í•˜ë©´'} ëë‚©ë‹ˆë‹¤")
        # print("="*40)
        
        # ëŒ€ë‹µ
        should_end = False
        if is_voice and self.voice_system:
            print("ğŸ™ï¸ ë§ì”€í•´ ì£¼ì„¸ìš”...")
            # ìŒì„± ë…¹ìŒ ì‹œì‘
            self.chat_system.start_recording()
            user_input = self.voice_system.transcribe_speech()
            # ìŒì„± ë…¹ìŒ ì¤‘ì§€
            audio_path = self.chat_system.stop_recording()
            
            if user_input == "ì¢…ë£Œ":
                end_msg = "ëŒ€í™”ë¥¼ ë§ˆì¹˜ê² ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤."
                print(f"ğŸ¤– {end_msg}")
                self.voice_system.synthesize_speech(end_msg)
                should_end = True
        else:
            user_input = input("\nğŸ‘¤ ë‹µë³€: ").strip()
            if user_input.lower() in ['exit', 'ì¢…ë£Œ', 'quit', 'ê·¸ë§Œ']:
                print("ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                should_end = True

        return user_input, audio_path, should_end

    def check_end_keywords(self, user_answer):
        """ì‚¬ìš©ì ë‹µë³€ì—ì„œ ì¢…ë£Œ í‚¤ì›Œë“œ í™•ì¸"""
        if not user_answer:
            return False
            
        # ì¢…ë£Œ í‚¤ì›Œë“œ ëª©ë¡
        end_keywords = ['ì¢…ë£Œ', 'exit', 'quit', 'q', 'ê·¸ë§Œ', 'ë', 'ì¢…ë£Œí•´ì¤˜', 'ê·¸ë§Œí•´', 'ë©ˆì¶°']
        
        user_answer_lower = user_answer.lower().strip()
        
        # ì •í™•í•œ ë§¤ì¹­ ë˜ëŠ” í¬í•¨ ì—¬ë¶€ í™•ì¸
        for keyword in end_keywords:
            if keyword in user_answer_lower:
                print(f"ğŸ”š ì¢…ë£Œ í‚¤ì›Œë“œ ê°ì§€: '{keyword}' in '{user_answer}'")
                return True
        
        return False
    
    def generate_next_question(self, previous_question, user_answer):
        """ì‚¬ìš©ì ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ ìƒì„±"""
        try:
            # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ì— ì‚¬ìš©ì ë‹µë³€ ì¶”ê°€
            self.chat_system.conversation_history.append({
                "role": "user", 
                "content": user_answer
            })
            
            # ë‹¤ìŒ ì§ˆë¬¸ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
            next_question_prompt = """ì´ì „ ì§ˆë¬¸ì— ëŒ€í•œ ì–´ë¥´ì‹ ì˜ ë‹µë³€ì„ ë“£ê³ , ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°ˆ ë‹¤ìŒ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”. 
ë‹¤ìŒ ì›ì¹™ì„ ì§€ì¼œì£¼ì„¸ìš”:
1. 50ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ
2. ì–´ë¥´ì‹ ì˜ ë‹µë³€ì— ê³µê°í•˜ëŠ” í‘œí˜„ í¬í•¨
3. ì‚¬ì§„ê³¼ ê´€ë ¨ëœ ì¶”ê°€ ì§ˆë¬¸
4. ë”°ëœ»í•˜ê³  ì¹œê·¼í•œ ì–´ì¡°
5. í•œ ë²ˆì— í•˜ë‚˜ì˜ ì§ˆë¬¸ë§Œ

ì–´ë¥´ì‹ ì˜ ë‹µë³€ì— ë§ì¶° ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ëŠ” ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”."""

            response = self.chat_system.client.chat.completions.create(
                model=self.chat_system.deployment,
                messages=self.chat_system.conversation_history + [
                    {"role": "user", "content": next_question_prompt}
                ],
                max_tokens=512,
                temperature=0.8
            )
            
            next_question = response.choices[0].message.content.strip()
            
            # ìƒì„±ëœ ì§ˆë¬¸ì„ ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.chat_system.conversation_history.append({
                "role": "assistant", 
                "content": next_question
            })
            
            # í† í° ìˆ˜ ì—…ë°ì´íŠ¸
            user_tokens = len(self.chat_system.tokenizer.encode(user_answer))
            question_tokens = len(self.chat_system.tokenizer.encode(next_question))
            self.chat_system.token_count += user_tokens + question_tokens
            
            # í† í° ì œí•œ í™•ì¸
            if self.chat_system.token_count > int(self.chat_system.max_tokens):
                return "ëŒ€í™” ì‹œê°„ì´ ë‹¤ ë˜ì—ˆì–´ìš”. ì˜¤ëŠ˜ë„ ì¦ê±°ìš´ ì‹œê°„ì´ì—ˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤."
            
            return next_question
            
        except Exception as e:
            print(f"âŒ ë‹¤ìŒ ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return "ê³„ì†í•´ì„œ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ ë³¼ê¹Œìš”?"

    
    def voice_conversation(self, image_path):
        """ìŒì„± ëŒ€í™” ì‹¤í–‰"""
        if not self.voice_system:
            return None
        return self._run_conversation_loop(image_path, is_voice=True)
    
    def text_conversation(self, image_path):
        """í…ìŠ¤íŠ¸ ëŒ€í™” ì‹¤í–‰"""
        return self._run_conversation_loop(image_path, is_voice=False)


async def upload_audio_to_blob(file_path: str, original_filename: str, blob_service_client) -> str:
    """
    Azure Blob Storageì— wav ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì£¼ì†Œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    blob_name = f"{uuid.uuid4()}_{original_filename}"
    try:
        # BlobStorageService ì¸ìŠ¤í„´ìŠ¤ì¼ ê²½ìš°
        if hasattr(blob_service_client, 'container_client'):
            blob_client = blob_service_client.container_client.get_blob_client(blob_name)
            with open(file_path, "rb") as data:
                blob_client.upload_blob(data, overwrite=True)
                return blob_client.url
        else:
            # (ê¸°ì¡´ ë¹„ë™ê¸° BlobServiceClient ì‚¬ìš© ì¼€ì´ìŠ¤ê°€ ìˆë‹¤ë©´ ì—¬ê¸°ì— ì¶”ê°€)
            raise Exception('ì§€ì›í•˜ì§€ ì•ŠëŠ” blob_service_client íƒ€ì…ì…ë‹ˆë‹¤.')
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Blob Storage ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
