import azure.cognitiveservices.speech as speechsdk
import requests
import os, time
import uuid
from pathlib import Path
from dotenv import load_dotenv
import pygame
from fastapi import UploadFile

from core.config import settings

AUDIO_DIR = "audio_files"

class VoiceSystem:
    """ìŒì„± ì…ì¶œë ¥ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.speech_key    = os.getenv("AZURE_SPEECH_KEY")
        self.region = os.getenv("AZURE_SPEECH_REGION")
        
        # STT ì„¤ì •
        self.speech_config = speechsdk.SpeechConfig(subscription=self.speech_key, region=self.region)
        self.speech_config.speech_recognition_language = "ko-KR"
        
        # TTS ì„¤ì •
        self.tts_voice = "ko-KR-SunHiNeural"
        
        # ì˜¤ë””ì˜¤ í´ë”
        self.audio_dir = Path("audio_files")
        self.audio_dir.mkdir(exist_ok=True)
        
        # pygame ì´ˆê¸°í™”
        try:
            pygame.mixer.init()
            self.audio_enabled = True
        except:
            self.audio_enabled = False
    
    def transcribe_speech(self) -> str:
        """STT: ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        try:
            audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)
            speech_recognizer = speechsdk.SpeechRecognizer(
                speech_config=self.speech_config, 
                audio_config=audio_config
            )
            
            print("ğŸ™ï¸ ë§ì”€í•´ ì£¼ì„¸ìš”...")
            result = speech_recognizer.recognize_once()
            
            if result.reason == speechsdk.ResultReason.RecognizedSpeech:
                recognized_text = result.text.strip()
                print(f"ğŸ‘¤ \"{recognized_text}\"")
                
                # ì¢…ë£Œ ëª…ë ¹ì–´ ê°ì§€
                exit_commands = ['ì¢…ë£Œ', 'ê·¸ë§Œ', 'ë', 'ë‚˜ê°€ê¸°', 'exit', 'quit', 'stop']
                cleaned_text = recognized_text.lower().replace(' ', '').replace('.', '')
                
                for exit_cmd in exit_commands:
                    if exit_cmd.lower() in cleaned_text:
                        return "ì¢…ë£Œ"
                
                return recognized_text
            else:
                print("âŒ ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”.")
                return ""
        except Exception:
            return ""
        
    def transcribe_speech_wav(self, audio_file) -> str:
        """STT: ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        try:
            input_path = self.audio_dir / f"{audio_file}"
            audio_config = speechsdk.audio.AudioConfig(filename=input_path)
            speech_recognizer = speechsdk.SpeechRecognizer(
                speech_config=self.speech_config, 
                audio_config=audio_config
            )
            
            result = speech_recognizer.recognize_once()
            
            if result.reason == speechsdk.ResultReason.RecognizedSpeech:
                recognized_text = result.text.strip()
                print(f"ğŸ‘¤ \"{recognized_text}\"")
                
                # ì¢…ë£Œ ëª…ë ¹ì–´ ê°ì§€
                exit_commands = ['ì¢…ë£Œ', 'ê·¸ë§Œ', 'ë', 'ë‚˜ê°€ê¸°', 'exit', 'quit', 'stop']
                cleaned_text = recognized_text.lower().replace(' ', '').replace('.', '')
                
                for exit_cmd in exit_commands:
                    if exit_cmd.lower() in cleaned_text:
                        return "ì¢…ë£Œ"
                
                return recognized_text
            else:
                print("âŒ ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”.")
                return ""
        except Exception:
            return ""
        
    def transcribe_speech_wav2(self, file: UploadFile) -> str:
        """STT: ì—…ë¡œë“œëœ UploadFile ê°ì²´ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        try:
            # ì„ì‹œ íŒŒì¼ ì €ì¥
            unique_name = f"{uuid.uuid4().hex}.wav"
            temp_path = self.audio_dir / unique_name
            with open(temp_path, "wb") as f:
                f.write(file.file.read())

            # Azure Speech SDKë¡œ ì¸ì‹
            audio_config = speechsdk.audio.AudioConfig(filename=str(temp_path))
            speech_recognizer = speechsdk.SpeechRecognizer(
                speech_config=self.speech_config,
                audio_config=audio_config
            )

            result = speech_recognizer.recognize_once()

            # ì¸ì‹ ê²°ê³¼ í™•ì¸
            if result.reason == speechsdk.ResultReason.RecognizedSpeech:
                recognized_text = result.text.strip()
                return recognized_text
            else:
                print("âŒ ì¸ì‹ ì‹¤íŒ¨:", result.reason)
                return ""

        except Exception as e:
            print("âŒ ì˜ˆì™¸ ë°œìƒ:", e)
            return ""
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            try:
                temp_path.unlink()
            except Exception:
                pass

    
    def get_access_token(self):
        """Azure Speech Service ì•¡ì„¸ìŠ¤ í† í° ìš”ì²­"""
        url = f"https://{self.region}.api.cognitive.microsoft.com/sts/v1.0/issueToken"
        headers = {"Ocp-Apim-Subscription-Key": self.speech_key}
        try:
            res = requests.post(url, headers=headers)
            res.raise_for_status()
            return res.text
        except Exception:
            return None
    
    def synthesize_speech(self, text: str) -> str:
        """TTS: í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì¬ìƒ"""
        if not text.strip():
            return None
            
        try:
            token = self.get_access_token()
            if not token:
                return None
                
            tts_url = f"https://{self.region}.tts.speech.microsoft.com/cognitiveservices/v1"
            
            headers = {
                "Authorization": f"Bearer {token}",
                "Content-Type": "application/ssml+xml",
                "X-Microsoft-OutputFormat": "riff-16khz-16bit-mono-pcm",
                "User-Agent": "DementiaAnalysisSystem"
            }
            
            ssml = f"""
            <speak version='1.0' xml:lang='ko-KR'>
                <voice xml:lang='ko-KR' xml:gender='Female' name='{self.tts_voice}'>
                    {text}
                </voice>
            </speak>
            """
            
            res = requests.post(tts_url, headers=headers, data=ssml.encode("utf-8"))
            res.raise_for_status()
            
            # ìŒì„± íŒŒì¼ ì €ì¥
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            output_path = self.audio_dir / f"tts_{timestamp}.wav"
            
            with open(output_path, "wb") as f:
                f.write(res.content)
            
            # ìŒì„± ì¬ìƒ
            if self.audio_enabled:
                try:
                    pygame.mixer.music.load(str(output_path))
                    pygame.mixer.music.play()
                    while pygame.mixer.music.get_busy():
                        time.sleep(0.1)
                except Exception:
                    pass
            
            return str(output_path)
            
        except Exception:
            return None