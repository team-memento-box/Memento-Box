# from dotenv import load_dotenv
# from dataclasses import dataclass
# from openai import AzureOpenAI
# import os, time
# import tiktoken
# from pathlib import Path
# import numpy as np
# from datetime import datetime
# import soundfile as sf
# # import sounddevice as sd
# import json

# from chat_system import StrangeResponse

# load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), "..", ".env"))

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€í™˜ê²½ë³€ìˆ˜â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# API_KEY    = os.getenv("AZURE_OPENAI_KEY")
# ENDPOINT   = os.getenv("AZURE_OPENAI_ENDPOINT")
# DEPLOYMENT = os.getenv("AZURE_OPENAI_DEPLOYMENT")
# SPEECH_KEY    = os.getenv("AZURE_SPEECH_KEY")
# SPEECH_REGION = os.getenv("AZURE_SPEECH_REGION")

# API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION")
# MAX_TOKENS = os.getenv("AZURE_OPENAI_MAX_TOKENS")
# #â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


# class StoryGenerator:
#     def __init__(self, chat_system):
#         self.chat_system = chat_system
#         self.client = chat_system.client
#         self.strange_responses = []
#         self.rule_based_alerts = []
#         self.conversation_id = ""
    
#     def _create_conversation_folders(self, image_path):
#         image_basename = os.path.splitext(os.path.basename(image_path))[0]
        
#         # conversation_log/{ì´ë¯¸ì§€ëª…}/ í´ë” ìƒì„±
#         image_dir = Path("conversation_log") / image_basename
#         image_dir.mkdir(parents=True, exist_ok=True)
        
#         # ê¸°ì¡´ ëŒ€í™” í´ë”ë“¤ í™•ì¸í•˜ì—¬ ë‹¤ìŒ ë²ˆí˜¸ ê²°ì •
#         existing_dirs = list(image_dir.glob(f"{image_basename}_conv*"))
#         conv_number = len(existing_dirs) + 1
        
#         # ëŒ€í™” ID: {ì´ë¯¸ì§€ëª…}_conv{ë²ˆí˜¸}
#         self.conversation_id = f"{image_basename}_conv{conv_number}"
        
#         # ëŒ€í™”ë³„ í´ë”: {ì´ë¯¸ì§€ëª…}_conv{ë²ˆí˜¸}/
#         conversation_dir = image_dir / self.conversation_id
#         conversation_dir.mkdir(exist_ok=True)
        
#         print(f"ğŸ“ ì €ì¥ êµ¬ì¡°:")
#         print(f"   ë©”ì¸ í´ë”: conversation_log/{image_basename}/{self.conversation_id}/")
#         print(f"   ëŒ€í™” íŒŒì¼: {self.conversation_id}.txt")
#         return conversation_dir
    
#     def _save_individual_qa_pairs(self, conversation_dir):
#         """ê°œë³„ ì§ˆì˜ì‘ë‹µ ìŒ ì €ì¥ - ê°„ì†Œí™”ëœ í˜•ì‹"""
#         for i, turn in enumerate(self.chat_system.conversation_turns, 1):
#             qa_filename = conversation_dir / f"qa_{i:02d}.txt"
            
#             with open(qa_filename, 'w', encoding='utf-8') as f:
#                 f.write(f"=== ì§ˆì˜ì‘ë‹µ {i}ë²ˆ ===\n")
#                 f.write(f"ëŒ€í™” ID: {self.conversation_id}\n")
#                 f.write(f"ì‹œê°„: {turn.timestamp}\n")
#                 f.write(f"{'='*25}\n\n")
#                 f.write(f"ğŸ¤– ì§ˆë¬¸:\n{turn.question}\n\n")
#                 f.write(f"ğŸ‘¤ ë‹µë³€:\n{turn.answer}\n")
#                 f.write(f"{'='*25}\n")
    
#     def _load_qa_pairs_for_report(self, pairs_dir):
#         qa_files = sorted([f for f in pairs_dir.glob("qa_*.txt")])
#         qa_data = []
#         for qa_file in qa_files:
#             try:
#                 with open(qa_file, 'r', encoding='utf-8') as f:
#                     qa_data.append({'file': qa_file.name, 'content': f.read()})
#             except Exception:
#                 continue
#         return qa_data
    
#     def analyze_speech_patterns(self):
#         if not self.chat_system.conversation_turns:
#             return
        
#         patterns = {
#             'severe_depression': ["ì£½ê³ ì‹¶", "ì‚´ê¸°ì‹«", "ì˜ë¯¸ì—†", "í¬ê¸°í•˜ê³ ì‹¶", "ì§€ì³¤", "í˜ë“¤ì–´ì£½ê² ", "ì„¸ìƒì´ì‹«", "ì ˆë§"],
#             'severe_anxiety': ["ë¬´ì„œì›Œì£½ê² ", "ë¶ˆì•ˆí•´ë¯¸ì³", "ê±±ì •ë¼ì£½ê² ", "ë‘ë ¤ì›Œ", "ìˆ¨ë§‰í˜€", "ê³µí™©", "íŒ¨ë‹‰"],
#             'severe_anger': ["í™”ë‚˜ì£½ê² ", "ë¯¸ì³ë²„ë¦¬ê² ", "ì§œì¦ë‚˜ì£½ê² ", "ì—´ë°›ì•„", "ë¹¡ì³", "ë¶„í•´", "ì°¸ì„ìˆ˜ì—†"],
#             'cognitive_decline': ["ê¸°ì–µì•ˆë‚˜", "ëª¨ë¥´ê² ", "ìŠì–´ë²„ë ¸", "ìƒê°ì•ˆë‚˜", "ê¹Œë¨¹ì—ˆ", "í—·ê°ˆë ¤", "ëˆ„êµ¬ì˜€ëŠ”ì§€", "ëª°ë¼"]
#         }
        
#         memory_issues = very_short_answers = meaningless_answers = 0
#         repetitive_patterns = []
        
#         for i, turn in enumerate(self.chat_system.conversation_turns):
#             answer = turn.answer.replace(" ", "").lower()
            
#             for pattern_type, keywords in patterns.items():
#                 for keyword in keywords:
#                     if keyword in answer:
#                         severity = "critical" if pattern_type == 'severe_depression' else "high"
#                         self.rule_based_alerts.append({
#                             "type": pattern_type,
#                             "turn_number": i + 1,
#                             "keyword": keyword,
#                             "answer": turn.answer,
#                             "timestamp": turn.timestamp,
#                             "severity": severity
#                         })
#                         if pattern_type == 'cognitive_decline':
#                             memory_issues += 1
            
#             if len(turn.answer.strip()) <= 5:
#                 very_short_answers += 1
            
#             if turn.answer.strip() in ["ìŒ", "ì–´", "ê·¸ëƒ¥", "ë„¤", "ì•„ë‹ˆ", "ì‘", "ì–´?"]:
#                 meaningless_answers += 1
            
#             if i >= 3:
#                 recent_answers = [t.answer.strip() for t in self.chat_system.conversation_turns[i-3:i]]
#                 if turn.answer.strip() in recent_answers:
#                     repetitive_patterns.append(i + 1)
        
#         total_turns = len(self.chat_system.conversation_turns)
        
#         thresholds = [
#             (memory_issues >= total_turns * 0.7, "severe_memory_loss", "critical", f"ì „ì²´ {total_turns}íšŒ ì¤‘ {memory_issues}íšŒ ê¸°ì–µ ë¬¸ì œ"),
#             (very_short_answers >= total_turns * 0.8, "communication_difficulty", "high", f"ì „ì²´ {total_turns}íšŒ ì¤‘ {very_short_answers}íšŒ ì§§ì€ ë‹µë³€"),
#             (meaningless_answers >= total_turns * 0.6, "cognitive_confusion", "high", f"ì „ì²´ {total_turns}íšŒ ì¤‘ {meaningless_answers}íšŒ ë¬´ì˜ë¯¸í•œ ë‹µë³€"),
#             (len(repetitive_patterns) >= 3, "repetitive_behavior", "moderate", f"ë‹µë³€ ë°˜ë³µ {len(repetitive_patterns)}íšŒ")
#         ]
        
#         for condition, alert_type, severity, description in thresholds:
#             if condition:
#                 self.rule_based_alerts.append({"type": alert_type, "description": description, "severity": severity})

#     def calculate_ratings(self):
#         total_responses = len(self.chat_system.conversation_turns)
#         strange_count = len(self.strange_responses)
        
#         if total_responses == 0:
#             return {"emotion": 3, "coherence": 3, "overall": 3}
        
#         emotions = [turn.emotion for turn in self.chat_system.conversation_turns if hasattr(turn, 'emotion')]
#         emotion_counts = {}
#         for emotion in emotions:
#             emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1
        
#         positive_emotions = ["ê¸°ì¨", "ê·¸ë¦¬ì›€", "ê°ì‚¬", "ì• ì •", "í¥ë¯¸"]
#         negative_emotions = ["ìŠ¬í””", "ë¬´ë ¥ê°", "ìš°ìš¸ê°", "ë¶„ë…¸", "ë¶ˆì•ˆ", "ì§œì¦"]
        
#         positive_count = sum(emotion_counts.get(e, 0) for e in positive_emotions)
#         negative_count = sum(emotion_counts.get(e, 0) for e in negative_emotions)
        
#         critical_emotion_alerts = [alert for alert in self.rule_based_alerts 
#                                  if alert.get('severity') == 'critical' and 
#                                  alert.get('type') in ['severe_depression', 'severe_anxiety', 'severe_anger']]
        
#         if len(critical_emotion_alerts) > 0:
#             emotion_rating = 1
#         elif negative_count > positive_count * 2:
#             emotion_rating = 2
#         elif negative_count > positive_count:
#             emotion_rating = 3
#         elif positive_count > negative_count:
#             emotion_rating = 4
#         else:
#             emotion_rating = 5 if positive_count > negative_count * 2 else 3
        
#         strange_percentage = (strange_count / total_responses * 100) if total_responses > 0 else 0
#         severe_count = sum(1 for resp in self.strange_responses if resp.severity == 'severe')
        
#         if strange_percentage == 0:
#             coherence_rating = 5
#         elif strange_percentage <= 20 and severe_count == 0:
#             coherence_rating = 4
#         elif strange_percentage <= 40 and severe_count <= 1:
#             coherence_rating = 3
#         elif strange_percentage <= 60 or severe_count <= 2:
#             coherence_rating = 2
#         else:
#             coherence_rating = 1
        
#         answer_qualities = [turn.answer_quality for turn in self.chat_system.conversation_turns if hasattr(turn, 'answer_quality')]
#         quality_counts = {"poor": 0, "normal": 0, "good": 0, "excellent": 0}
#         for quality in answer_qualities:
#             quality_counts[quality] += 1
        
#         excellent_percentage = (quality_counts["excellent"] / total_responses * 100) if total_responses > 0 else 0
#         good_percentage = (quality_counts["good"] / total_responses * 100) if total_responses > 0 else 0
#         poor_percentage = (quality_counts["poor"] / total_responses * 100) if total_responses > 0 else 0
        
#         critical_cognitive_alerts = [alert for alert in self.rule_based_alerts 
#                                    if alert.get('severity') == 'critical' and 
#                                    alert.get('type') in ['severe_memory_loss', 'communication_difficulty']]
        
#         if len(critical_cognitive_alerts) > 0 or poor_percentage >= 50:
#             overall_rating = 1
#         elif poor_percentage >= 30 or (strange_percentage > 50 and severe_count >= 2):
#             overall_rating = 2
#         elif excellent_percentage >= 30 or (good_percentage >= 50 and strange_percentage <= 20):
#             overall_rating = 5
#         elif good_percentage >= 30 or strange_percentage <= 30:
#             overall_rating = 4
#         else:
#             overall_rating = 3
        
#         return {"emotion": emotion_rating, "coherence": coherence_rating, "overall": overall_rating}
    
#     def format_star_rating(self, rating):
#         stars = "â­" * rating + "â˜†" * (5 - rating)
#         return f"{stars} ({rating}/5)"

#     def analyze_entire_conversation(self):
#         if not self.chat_system.conversation_turns:
#             return
        
#         self.strange_responses = []
#         self.rule_based_alerts = []
#         self.analyze_speech_patterns()
        
#         conversation_text = ""
#         for i, turn in enumerate(self.chat_system.conversation_turns, 1):
#             conversation_text += f"[{i}] ì§ˆë¬¸: {turn.question}\në‹µë³€: {turn.answer} (ê¸¸ì´: {turn.answer_length}ì)\n\n"
        
#         analysis_prompt = f"""ì¹˜ë§¤ í™˜ì ëŒ€í™” ë¶„ì„í•˜ì—¬ JSON ì‘ë‹µ:
# {conversation_text}

# JSON: {{"conversation_analysis": [{{"turn_number": 1, "is_strange": true/false, "severity": "normal/mild/moderate/severe", "emotion": "ê°ì •", "answer_quality": "poor/normal/good/excellent", "reason": "ì´ìœ "}}], "overall_assessment": {{"dominant_emotion": "ì£¼ìš”ê°ì •", "cognitive_level": "normal/mild_concern/moderate_concern/severe_concern"}}}}

# ê°ì •: ê¸°ì¨,ìŠ¬í””,ê·¸ë¦¬ì›€,ë¬´ë ¥ê°,ìš°ìš¸ê°,ë¶„ë…¸,ë¶ˆì•ˆ,ì¤‘ë¦½,ê°ì‚¬,ì• ì •,í¥ë¯¸,ì§œì¦"""

#         try:
#             response = self.client.chat.completions.create(
#                 model=DEPLOYMENT,
#                 messages=[
#                     {"role": "system", "content": "ì¹˜ë§¤ í™˜ì ëŒ€í™” ë¶„ì„ ì „ë¬¸ AI"},
#                     {"role": "user", "content": analysis_prompt}
#                 ],
#                 max_tokens=1024,
#                 temperature=0.1
#             )
            
#             analysis_text = response.choices[0].message.content
            
#             if "```json" in analysis_text:
#                 json_start = analysis_text.find("```json") + 7
#                 json_end = analysis_text.find("```", json_start)
#                 analysis_text = analysis_text[json_start:json_end].strip()
#             elif "{" in analysis_text:
#                 json_start = analysis_text.find("{")
#                 json_end = analysis_text.rfind("}") + 1
#                 analysis_text = analysis_text[json_start:json_end]
            
#             analysis_result = json.loads(analysis_text)
            
#             conversation_analyses = analysis_result.get("conversation_analysis", [])
#             for i, analysis in enumerate(conversation_analyses):
#                 if i < len(self.chat_system.conversation_turns):
#                     turn = self.chat_system.conversation_turns[i]
#                     turn.emotion = analysis.get("emotion", "ì¤‘ë¦½")
#                     turn.answer_quality = analysis.get("answer_quality", "normal")
                    
#                     if analysis.get("is_strange", False):
#                         strange_response = StrangeResponse(
#                             question=turn.question,
#                             answer=turn.answer,
#                             timestamp=turn.timestamp,
#                             severity=analysis.get("severity", "mild"),
#                             emotion=turn.emotion,
#                             answer_quality=turn.answer_quality
#                         )
#                         self.strange_responses.append(strange_response)
            
#             return analysis_result
            
#         except Exception as e:
#             return None
        
#     def generate_story_from_conversation(self, image_path):
#         conversation_text = ""
#         for turn in self.chat_system.conversation_turns:
#             conversation_text += f"ì§ˆë¬¸: {turn.question}\në‹µë³€: {turn.answer}\n\n"
        
#         if not conversation_text.strip():
#             return None, None
        
#         story_prompt = f"""ëŒ€í™” ê¸°ë°˜ìœ¼ë¡œ ì–´ë¥´ì‹  1ì¸ì¹­ ì¶”ì–µ ìŠ¤í† ë¦¬ 15ì¤„ ì‘ì„±:
# {conversation_text}
# ì§€ì¹¨: ë‹µë³€ ê¸°ë°˜ ì‘ì„±, ê°ì •ê³¼ ê°ê° í¬í•¨, ë”°ëœ»í•œ í†¤, ì†ì/ì†ë…€ì—ê²Œ ë“¤ë ¤ì£¼ëŠ” ì–´íˆ¬"""
        
#         try:
#             response = self.client.chat.completions.create(
#                 model=DEPLOYMENT,
#                 messages=[
#                     {"role": "system", "content": "ë…¸ì¸ ì¶”ì–µ ìŠ¤í† ë¦¬í…”ëŸ¬"},
#                     {"role": "user", "content": story_prompt}
#                 ],
#                 max_tokens=512,
#                 temperature=0.8
#             )
            
#             story = response.choices[0].message.content
#             story_dir = "story_telling"
#             os.makedirs(story_dir, exist_ok=True)
            
#             image_basename = os.path.splitext(os.path.basename(image_path))[0]
#             story_filename = os.path.join(story_dir, f"{image_basename}_story.txt")
            
#             with open(story_filename, 'w', encoding='utf-8') as f:
#                 f.write(story)
            
#             return story, story_filename
            
#         except Exception:
#             return None, None
    
#     def save_conversation_summary(self, conversation_dir=None):
#         if conversation_dir:
#             qa_data = self._load_qa_pairs_for_report(conversation_dir)
        
#         analysis_result = self.analyze_entire_conversation()
#         total_responses = len(self.chat_system.conversation_turns)
#         strange_count = len(self.strange_responses)
        
#         if total_responses == 0:
#             return "ëŒ€í™”ê°€ ì§„í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
#         emotions = [turn.emotion for turn in self.chat_system.conversation_turns if hasattr(turn, 'emotion')]
#         emotion_counts = {}
#         for emotion in emotions:
#             emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1
        
#         if emotion_counts:
#             dominant_emotion = max(emotion_counts, key=emotion_counts.get)
#             positive_emotions = ["ê¸°ì¨", "ê·¸ë¦¬ì›€", "ê°ì‚¬", "ì• ì •", "í¥ë¯¸"]
#             negative_emotions = ["ìŠ¬í””", "ë¬´ë ¥ê°", "ìš°ìš¸ê°", "ë¶„ë…¸", "ë¶ˆì•ˆ", "ì§œì¦"]
            
#             positive_count = sum(emotion_counts.get(e, 0) for e in positive_emotions)
#             negative_count = sum(emotion_counts.get(e, 0) for e in negative_emotions)
            
#             if positive_count > negative_count:
#                 overall_mood = "ê¸ì •ì "
#                 mood_icon = "ğŸ˜Š"
#             elif negative_count > positive_count:
#                 overall_mood = "ë¶€ì •ì " 
#                 mood_icon = "ğŸ˜”"
#             else:
#                 overall_mood = "ì¤‘ë¦½ì "
#                 mood_icon = "ğŸ˜"
#         else:
#             dominant_emotion = "ì¤‘ë¦½"
#             overall_mood = "ì¤‘ë¦½ì "
#             mood_icon = "ğŸ˜"
        
#         critical_alerts = [alert for alert in self.rule_based_alerts if alert.get('severity') == 'critical']
#         high_alerts = [alert for alert in self.rule_based_alerts if alert.get('severity') == 'high']
#         ratings = self.calculate_ratings()
        
#         summary = f"\n{'='*60}\nğŸ“‹ ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ë¶„ì„ ë¦¬í¬íŠ¸\n{'='*60}\n"
#         summary += f"ğŸ“… ë¶„ì„ ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}\n"
#         summary += f"ğŸ†” ëŒ€í™” ID: {self.conversation_id}\n{'='*60}\n\n"
        
#         summary += f"ğŸ¯ ì¢…í•© í‰ê°€\n{'â”€'*30}\n"
#         summary += f"ğŸ˜Š ê°ì • ìƒíƒœ:     {self.format_star_rating(ratings['emotion'])}\n"
#         summary += f"ğŸ’¬ ë‹µë³€ ì¼ê´€ì„±:   {self.format_star_rating(ratings['coherence'])}\n"
#         summary += f"ğŸ§  ì „ë°˜ì  ì¸ì§€:   {self.format_star_rating(ratings['overall'])}\n{'â”€'*30}\n\n"
        
#         summary += f"ğŸ“Š ëŒ€í™” ê°œìš”\n{'â”€'*30}\n"
#         summary += f"ğŸ’¬ ì´ ëŒ€í™” íšŸìˆ˜: {total_responses}íšŒ\n"
#         summary += f"{mood_icon} ì „ë°˜ì  ê°ì •: {overall_mood} (ì£¼ìš”: {dominant_emotion})\n"
#         summary += f"{'âœ… ì–´ê¸‹ë‚œ ë‹µë³€: ì—†ìŒ' if strange_count == 0 else f'âš ï¸ ì–´ê¸‹ë‚œ ë‹µë³€: {strange_count}íšŒ'}\n"
#         summary += f"{'âœ… ë°œí™” íŒ¨í„´: íŠ¹ì´ì‚¬í•­ ì—†ìŒ' if len(self.rule_based_alerts) == 0 else f'ğŸ” ë°œí™” íŒ¨í„´: {len(self.rule_based_alerts)}ê±´ ê´€ì°°'}"
#         if len(critical_alerts) > 0:
#             summary += f" (âš ï¸ ì£¼ì˜: {len(critical_alerts)}ê±´)"
#         summary += f"\n{'â”€'*30}\n\n"
        
#         if strange_count == 0 and len(critical_alerts) == 0:
#             summary += f"ğŸ‰ ëŒ€í™” ê²°ê³¼\n{'â”€'*30}\n"
#             summary += f"âœ… ëŒ€í™” ì¤‘ íŠ¹ë³„íˆ ê±±ì •ë˜ëŠ” ë‹µë³€ì€ ì—†ì—ˆìŠµë‹ˆë‹¤.\n"
#             summary += f"ğŸ’š ì–´ë¥´ì‹ ê»˜ì„œ ì•ˆì •ì ìœ¼ë¡œ ì˜ ì‘ë‹µí•´ì£¼ì…¨ì–´ìš”.\n"
#             if len(high_alerts) > 0:
#                 summary += f"ğŸ’¡ ì°¸ê³ : {len(high_alerts)}ë²ˆì˜ ë°œí™” íŒ¨í„´ì´ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
#             summary += f"ğŸŒŸ ì§€ê¸ˆì²˜ëŸ¼ ë”°ëœ»í•œ í™˜ê²½ê³¼ ê¾¸ì¤€í•œ ê´€ì‹¬ ì†ì— ê³„ì‹œë©´ ì¢‹ê² ìŠµë‹ˆë‹¤.\n"
#             summary += f"{'='*60}\n"
#             return summary
        
#         if len(self.rule_based_alerts) > 0 or strange_count > 0:
#             summary += f"ğŸš¨ ì£¼ìš” ë°œê²¬ì‚¬í•­\n{'â”€'*30}\n"
            
#             if len(self.rule_based_alerts) > 0:
#                 alert_types = {
#                     'severe_depression': 'ğŸ˜” ìš°ìš¸í•œ í‘œí˜„',
#                     'severe_anxiety': 'ğŸ˜° ë¶ˆì•ˆí•œ í‘œí˜„', 
#                     'severe_anger': 'ğŸ˜¡ í™”ê°€ ë‚œ í‘œí˜„',
#                     'severe_memory_loss': 'ğŸ§  ê¸°ì–µ ê´€ë ¨ ì–´ë ¤ì›€',
#                     'communication_difficulty': 'ğŸ’¬ ëŒ€í™” ì–´ë ¤ì›€',
#                     'cognitive_confusion': 'â“ í˜¼ë€ìŠ¤ëŸ¬ìš´ ë‹µë³€',
#                     'repetitive_behavior': 'ğŸ”„ ë°˜ë³µë˜ëŠ” ë‹µë³€'
#                 }
                
#                 alert_summary = {}
#                 for alert in self.rule_based_alerts:
#                     alert_name = alert_types.get(alert['type'], f"âš ï¸ {alert['type']}")
#                     alert_summary[alert_name] = alert_summary.get(alert_name, 0) + 1
                
#                 for alert_name, count in alert_summary.items():
#                     summary += f"{alert_name}: {count}ë²ˆ\n"
#                 summary += f"\n"
            
#             if strange_count > 0:
#                 severity_counts = {"mild": 0, "moderate": 0, "severe": 0}
#                 for response in self.strange_responses:
#                     severity_counts[response.severity] += 1
                
#                 summary += f"ğŸ” ì–´ê¸‹ë‚œ ë‹µë³€ ë¶„ì„:\n"
#                 if severity_counts['mild'] > 0:
#                     summary += f"  ğŸŸ¡ ì¡°ê¸ˆ ì–´ê¸‹ë‚¨: {severity_counts['mild']}íšŒ\n"
#                 if severity_counts['moderate'] > 0:
#                     summary += f"  ğŸŸ  ê½¤ ì–´ê¸‹ë‚¨: {severity_counts['moderate']}íšŒ\n"
#                 if severity_counts['severe'] > 0:
#                     summary += f"  ğŸ”´ ë§ì´ ì–´ê¸‹ë‚¨: {severity_counts['severe']}íšŒ\n"
#                 summary += f"\n"
            
#             summary += f"{'â”€'*30}\n\n"
        
#         if strange_count > 0 and strange_count <= 5:
#             summary += f"ğŸ“ ì–´ê¸‹ë‚œ ë‹µë³€ ìƒì„¸\n{'â”€'*30}\n"
#             for i, response in enumerate(self.strange_responses, 1):
#                 summary += f"{i}. {response.timestamp}\n"
#                 summary += f"   â“ ì§ˆë¬¸: {response.question}\n"
#                 summary += f"   ğŸ’¬ ë‹µë³€: {response.answer}\n"
#                 summary += f"   ğŸ˜Š ìƒíƒœ: {response.emotion} | ğŸ¯ í’ˆì§ˆ: {response.answer_quality}\n\n"
#             summary += f"{'â”€'*30}\n\n"
        
#         summary += f"ğŸ’¡ ê¶Œì¥ì‚¬í•­\n{'â”€'*30}\n"
        
#         if len(critical_alerts) > 0:
#             summary += f"ğŸš¨ ê¸´ê¸‰ ê¶Œì¥ì‚¬í•­:\n   ì‹¬ê°í•œ ì •ì‹ ê±´ê°• ìœ„í—˜ ì‹ í˜¸ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\n   ë¹ ë¥¸ ì‹œì¼ ë‚´ë¡œ ì—°ë½ì„ ë“œë¦¬ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n\n"
#             for alert in critical_alerts:
#                 if alert['type'] == 'severe_depression':
#                     summary += f"   âš ï¸ ê·¹ì‹¬í•œ ìš°ìš¸ê° í‘œí˜„ ê°ì§€\n      â†’ ì—°ë½ë“œë ¤ ê¸°ë¶„ì „í™˜ì„ ë„ì™€ë“œë¦¬ì„¸ìš”.\n\n"
#                 elif alert['type'] == 'severe_memory_loss':
#                     summary += f"   âš ï¸ ì‹¬ê°í•œ ê¸°ì–µë ¥ ì €í•˜ ê°ì§€\n      â†’ ê°€ì¡±ê³¼ í•¨ê»˜ ì¶”ì–µì„ ë˜ìƒˆê²¨ë³´ì„¸ìš”.\n\n"
#         elif len(high_alerts) >= 2:
#             summary += f"âš ï¸ ì£¼ì˜ ê¶Œì¥ì‚¬í•­:\n   ìµœê·¼ ëŒ€í™”ì—ì„œ í˜¼ë€ìŠ¤ëŸ¬ìš´ ë‹µë³€ì´ ìì£¼ ë³´ì˜€ìŠµë‹ˆë‹¤.\n   ê°€ì¡±ê³¼ í•¨ê»˜ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ ë³´ì‹œê¸¸ ê¶Œì¥í•©ë‹ˆë‹¤.\n\n"
#         elif len(high_alerts) >= 1:
#             summary += f"ğŸ”¶ ì¼ë°˜ ê¶Œì¥ì‚¬í•­:\n   ì•½ê°„ ê±±ì •ë˜ëŠ” ë‹µë³€ì´ ìˆì—ˆìŠµë‹ˆë‹¤.\n   ì‹œê°„ì„ ë‚´ì–´ ì•ˆë¶€ ì „í™”ë¥¼ ë“œë ¤ë³´ì„¸ìš”.\n\n"
#         elif strange_count > 0:
#             summary += f"ğŸ’™ ê´€ì‹¬ ê¶Œì¥ì‚¬í•­:\n   ì „ë°˜ì ìœ¼ë¡œ ì˜ ì‘ë‹µí•´ì£¼ì…¨ì§€ë§Œ, ê°„í˜¹ ì–´ê¸‹ë‚œ ë‹µë³€ì´ ë³´ì…ë‹ˆë‹¤.\n   ê°€ë³ê²Œë¼ë„ ì£¼ë³€ì˜ ê´€ì‹¬ê³¼ í™•ì¸ì´ ìˆìœ¼ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤.\n\n"
#         else:
#             summary += f"ğŸ’š í›Œë¥­í•œ ìƒíƒœ:\n   ì–´ë¥´ì‹ ê»˜ì„œ ë¬´ì²™ ì•ˆì •ì ìœ¼ë¡œ ì˜ ì‘ë‹µí•´ì£¼ì…¨ìŠµë‹ˆë‹¤.\n   ì§€ê¸ˆì²˜ëŸ¼ ë”°ëœ»í•œ í™˜ê²½ê³¼ ê¾¸ì¤€í•œ ê´€ì‹¬ì„ ìœ ì§€í•´ì£¼ì„¸ìš”.\n\n"
        
#         summary += f"ğŸ  ê°€ì¡±ì„ ìœ„í•œ ì¡°ì–¸\n{'â”€'*30}\n"
        
#         emotion_advice = {
#             "ì§œì¦": "ğŸ”´ ìµœê·¼ ì§œì¦ìŠ¤ëŸ¬ìš´ ê°ì •ì„ í‘œí˜„í•˜ì…¨ì–´ìš”.\n   â†’ ê°ì •ì„ ìì—°ìŠ¤ëŸ½ê²Œ í‘œí˜„í•˜ë„ë¡ ë”°ëœ»í•˜ê²Œ ê³µê°í•´ì£¼ì„¸ìš”.\n   â†’ ìš”ì¦˜ ì–´ë– ì‹ ì§€ ìì£¼ ì•ˆë¶€ë¥¼ ì—¬ì­¤ë³´ì‹œë©´ í° í˜ì´ ë©ë‹ˆë‹¤.",
#             "ìš°ìš¸ê°": "ğŸŸ  ìŠ¬í””ì´ë‚˜ ìš°ìš¸ê°ì„ í‘œí˜„í•˜ì…¨ì–´ìš”.\n   â†’ í•¨ê»˜ ì˜› ì¶”ì–µì„ ë‚˜ëˆ„ê±°ë‚˜ ì¢‹ì•„í•˜ì‹œë˜ ì´ì•¼ê¸°ë¥¼ êº¼ë‚´ë³´ì„¸ìš”.\n   â†’ ê°ì •ì„ ì•ˆì •ì‹œí‚¤ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
#             "ìŠ¬í””": "ğŸŸ  ìŠ¬í””ì´ë‚˜ ìš°ìš¸ê°ì„ í‘œí˜„í•˜ì…¨ì–´ìš”.\n   â†’ í•¨ê»˜ ì˜› ì¶”ì–µì„ ë‚˜ëˆ„ê±°ë‚˜ ì¢‹ì•„í•˜ì‹œë˜ ì´ì•¼ê¸°ë¥¼ êº¼ë‚´ë³´ì„¸ìš”.\n   â†’ ê°ì •ì„ ì•ˆì •ì‹œí‚¤ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
#             "ë¬´ë ¥ê°": "ğŸ˜ ë¬´ê¸°ë ¥í•˜ê±°ë‚˜ ì†Œì™¸ê°ì„ í‘œí˜„í•˜ì…¨ì–´ìš”.\n   â†’ 'ì–´ë¥´ì‹  ë•ë¶„ì´ì—ìš”'ì²˜ëŸ¼ ì¸ì •í•´ë“œë¦¬ë©´ ìì¡´ê° íšŒë³µì— ë„ì›€ë©ë‹ˆë‹¤.\n   â†’ í•¨ê»˜ ì˜ë¯¸ ìˆëŠ” í™œë™ì„ í•˜ë©° í˜ì´ ë˜ì–´ ì£¼ì„¸ìš”.",
#             "ë¶„ë…¸": "ğŸ˜¡ ê°‘ì‘ìŠ¤ëŸ½ê²Œ í™”ë¥¼ ë‚´ì‹œê±°ë‚˜ ê°•í•œ ì–´ì¡°ë¥¼ ë³´ì´ì…¨ì–´ìš”.\n   â†’ ê°ì • ë’¤ì— ë¶ˆì•ˆì´ë‚˜ í˜¼ë€ê°ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ ì¡°ìš©íˆ ê³µê°í•´ì£¼ì„¸ìš”.\n   â†’ í™˜ê²½ì„ ì ê²€í•˜ê³  ë°˜ë³µ ìê·¹ì„ ì¤„ì´ë©´ ì•ˆì •ì— ë„ì›€ë©ë‹ˆë‹¤.",
#             "ë¶ˆì•ˆ": "ğŸŸ¤ ë¶ˆì•ˆê°ì„ ëŠë¼ì‹œëŠ” ê²ƒ ê°™ì•„ìš”.\n   â†’ ì–´ë¥´ì‹ ì˜ ì´ì•¼ê¸°ë¥¼ ì˜ ë“¤ì–´ì£¼ì‹œê³ , ë”°ëœ»í•œ ë§ í•œë§ˆë””ê°€ í° ìœ„ë¡œê°€ ë©ë‹ˆë‹¤.",
#             "ê·¸ë¦¬ì›€": "ğŸ’™ ê³¼ê±°ë¥¼ ê·¸ë¦¬ì›Œí•˜ì‹œëŠ” ë§ˆìŒì„ í‘œí˜„í•˜ì…¨ì–´ìš”.\n   â†’ í•¨ê»˜ ì˜›ë‚  ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ„ê±°ë‚˜ ì¶”ì–µ ì† ì¥ì†Œë‚˜ ì‚¬ëŒë“¤ì— ëŒ€í•´ ëŒ€í™”í•´ë³´ì„¸ìš”.\n   â†’ ë§ˆìŒì˜ í‰ì•ˆì„ ì°¾ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
#         }
        
#         if dominant_emotion in emotion_advice:
#             summary += emotion_advice[dominant_emotion]
#         elif dominant_emotion in ["ê¸°ì¨", "ê°ì‚¬", "ì• ì •", "í¥ë¯¸"]:
#             summary += "ğŸ˜Š ê¸ì •ì ì¸ ê°ì •ì„ í‘œí˜„í•˜ì…¨ì–´ìš”. ì •ë§ ì¢‹ë„¤ìš”!\n   â†’ ì´ëŸ° ë°ì€ ëª¨ìŠµì„ ê³„ì† ìœ ì§€í•˜ì‹¤ ìˆ˜ ìˆë„ë¡ ì¦ê±°ìš´ ëŒ€í™”ì™€ í™œë™ì„ í•¨ê»˜ í•´ë³´ì„¸ìš”."
#         elif dominant_emotion == "ì¤‘ë¦½":
#             summary += "ğŸ’¬ ëŒ€ë¶€ë¶„ì˜ ëŒ€í™”ì—ì„œ í° ê°ì • ë³€í™” ì—†ì´ ì°¨ë¶„íˆ ì‘ë‹µí•˜ì…¨ì–´ìš”.\n   â†’ ë¬´ë˜í•´ ë³´ì´ì§€ë§Œ ë‚´ë©´ì˜ ê°ì •ì„ ì˜ í‘œí˜„í•˜ì§€ ëª»í•˜ì‹¤ ìˆ˜ë„ ìˆìœ¼ë‹ˆ\n   â†’ ë”°ëœ»í•œ ë§ í•œë§ˆë””ê°€ í° ìœ„ë¡œê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
#         else:
#             summary += "ğŸŒˆ ë‹¤ì–‘í•œ ê°ì •ì´ ì„ì—¬ ìˆì—ˆì§€ë§Œ, ì „ë°˜ì ìœ¼ë¡œ ì•ˆì •ì ì¸ í¸ì…ë‹ˆë‹¤.\n   â†’ ì§€ê¸ˆì²˜ëŸ¼ ê´€ì‹¬ê³¼ ì• ì •ì„ ê¾¸ì¤€íˆ í‘œí˜„í•´ ì£¼ì‹œë©´ ì¢‹ìŠµë‹ˆë‹¤."
        
#         summary += f"\n{'â”€'*30}\n\n"
#         summary += f"ğŸ“ˆ í‰ê°€ ê¸°ì¤€\n{'â”€'*30}\n"
#         summary += f"ğŸ˜Š ê°ì • ìƒíƒœ: ê¸ì •ì ì´ê³  ì•ˆì •ì ì¸ ê°ì • í‘œí˜„ì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜\n"
#         summary += f"ğŸ’¬ ë‹µë³€ ì¼ê´€ì„±: ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì ì ˆí•œ ë‹µë³€ì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜\n"
#         summary += f"ğŸ§  ì „ë°˜ì  ì¸ì§€: ë‹µë³€ì˜ í’ˆì§ˆê³¼ ì†Œí†µ ëŠ¥ë ¥ì„ ì¢…í•©í•œ ì ìˆ˜\n"
#         summary += f"{'â”€'*30}\n\n"
#         summary += f"{'='*60}\nğŸ“‹ ë¦¬í¬íŠ¸ ë - ì–´ë¥´ì‹ ì˜ ê±´ê°•ê³¼ í–‰ë³µì„ ìœ„í•´\n{'='*60}\n"
        
#         return summary
    
#     def save_conversation_to_file(self, image_path=None):
#         if len(self.strange_responses) == 0 and len(self.rule_based_alerts) == 0:
#             self.analyze_entire_conversation()
        
#         # í´ë” êµ¬ì¡° ìƒì„±
#         conversation_dir = self._create_conversation_folders(image_path)
        
#         # ê°œë³„ ì§ˆì˜ì‘ë‹µ ìŒ ì €ì¥ (ê°™ì€ í´ë” ì•ˆì—)
#         self._save_individual_qa_pairs(conversation_dir)
        
#         # ë©”ì¸ ëŒ€í™” íŒŒì¼ ì €ì¥: {ì´ë¯¸ì§€ëª…}_conv{ë²ˆí˜¸}/{ì´ë¯¸ì§€ëª…}_conv{ë²ˆí˜¸}.txt
#         conversation_filename = conversation_dir / f"{self.conversation_id}.txt"
#         with open(conversation_filename, 'w', encoding='utf-8') as f:
#             f.write(f"{'='*50}\n")
#             f.write(f"ğŸ’¬ ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ê¸°ë¡\n")
#             f.write(f"{'='*50}\n")
#             f.write(f"ğŸ†” ëŒ€í™” ID: {self.conversation_id}\n")
#             f.write(f"ğŸ“Š ì´ ëŒ€í™” ìˆ˜: {len(self.chat_system.conversation_turns)}íšŒ\n")
#             f.write(f"{'='*50}\n\n")
            
#             # ëŒ€í™” ë‚´ìš©ë§Œ ê°„ë‹¨íˆ ì¶œë ¥ (íƒ€ì„ìŠ¤íƒ¬í”„ + ëŒ€í™”)
#             for i, turn in enumerate(self.chat_system.conversation_turns, 1):
#                 f.write(f"[{turn.timestamp}]\n")
#                 f.write(f"ğŸ¤– ì§ˆë¬¸: {turn.question}\n")
#                 f.write(f"ğŸ‘¤ ë‹µë³€: {turn.answer}\n")
#                 f.write(f"{'-'*30}\n\n")
        
#         # analysis í´ë”ì— ë¶„ì„ ë¦¬í¬íŠ¸ ì €ì¥
#         analysis_dir = Path("analysis")
#         analysis_dir.mkdir(exist_ok=True)
#         analysis_filename = analysis_dir / f"{self.conversation_id}_analysis.txt"
        
#         with open(analysis_filename, 'w', encoding='utf-8') as f:
#             f.write(self.save_conversation_summary(conversation_dir))
        
#         # ì €ì¥ ì™„ë£Œ ë©”ì‹œì§€
#         print(f"\nâœ… íŒŒì¼ ì €ì¥ ì™„ë£Œ!")
#         print(f"ğŸ“ ëŒ€í™” í´ë”: {conversation_dir}")
#         print(f"ğŸ“„ ëŒ€í™” íŒŒì¼: {conversation_filename}")
#         print(f"ğŸ“Š ë¶„ì„ íŒŒì¼: {analysis_filename}")
#         print(f"ğŸ“‹ QA íŒŒì¼ë“¤: {len(self.chat_system.conversation_turns)}ê°œ")
        
#         return str(conversation_filename), str(analysis_filename)