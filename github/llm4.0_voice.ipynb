{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "152a5597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.13.1)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import base64\n",
    "import os\n",
    "import tiktoken\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import requests\n",
    "import pygame\n",
    "import time\n",
    "from pathlib import Path\n",
    "import threading\n",
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "\n",
    "\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba48284",
   "metadata": {},
   "source": [
    "# Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab6e4545",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class StrangeResponse:\n",
    "    \"\"\"이상한 답변을 저장하는 데이터 클래스\"\"\"\n",
    "    question: str\n",
    "    answer: str\n",
    "    timestamp: str\n",
    "    severity: str  # \"mild\", \"moderate\", \"severe\"\n",
    "    emotion: str = \"중립\"\n",
    "    answer_quality: str = \"normal\"\n",
    "\n",
    "@dataclass\n",
    "class ConversationTurn:\n",
    "    \"\"\"대화 턴을 저장하는 데이터 클래스\"\"\"\n",
    "    question: str\n",
    "    answer: str\n",
    "    timestamp: str\n",
    "    emotion: str = \"중립\"\n",
    "    answer_length: int = 0\n",
    "    answer_quality: str = \"normal\"\n",
    "    audio_file: str = \"\"  # 음성 파일 경로 추가\n",
    "\n",
    "class Config:\n",
    "    \"\"\"시스템 설정\"\"\"\n",
    "    # Azure OpenAI 설정\n",
    "    ENDPOINT = os.getenv(\"gpt-endpoint\")\n",
    "    DEPLOYMENT = \"gpt-4o\"\n",
    "    SUBSCRIPTION_KEY = os.getenv(\"gpt-key\")\n",
    "    API_VERSION = \"2024-02-15-preview\"\n",
    "    \n",
    "    # Azure Speech 설정\n",
    "    SPEECH_KEY = os.getenv(\"speech-key\")\n",
    "    SPEECH_REGION = \"eastus\"\n",
    "    \n",
    "    # 토큰 제한\n",
    "    MAX_TOKENS = 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ba9d25",
   "metadata": {},
   "source": [
    "# Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f29116f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAnalyzer:\n",
    "    \"\"\"GPT-4o를 사용한 이미지 분석\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = AzureOpenAI(\n",
    "            api_version=Config.API_VERSION,\n",
    "            azure_endpoint=Config.ENDPOINT,\n",
    "            api_key=Config.SUBSCRIPTION_KEY,\n",
    "        )\n",
    "    \n",
    "    def analyze_image(self, image_path):\n",
    "        \"\"\"이미지 분석\"\"\"\n",
    "        try:\n",
    "            with open(image_path, \"rb\") as image_file:\n",
    "                base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        except Exception:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=Config.DEPLOYMENT,\n",
    "                messages=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [{\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"\"\"이미지를 분석해서 JSON으로 답해주세요:\n",
    "{\n",
    "    \"caption\": \"전체 설명\",\n",
    "    \"dense_captions\": [\"세부 설명1\", \"세부 설명2\"],\n",
    "    \"mood\": \"분위기\",\n",
    "    \"time_period\": \"시대\",\n",
    "    \"key_objects\": [\"객체1\", \"객체2\"],\n",
    "    \"people_description\": \"인물 설명\",\n",
    "    \"people_count\": 숫자,\n",
    "    \"time_of_day\": \"시간대\"\n",
    "}\"\"\"\n",
    "                    }, {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "                    }]\n",
    "                }],\n",
    "                max_tokens=1000,\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            response_text = response.choices[0].message.content\n",
    "            \n",
    "            # JSON 추출\n",
    "            if \"```json\" in response_text:\n",
    "                json_start = response_text.find(\"```json\") + 7\n",
    "                json_end = response_text.find(\"```\", json_start)\n",
    "                response_text = response_text[json_start:json_end].strip()\n",
    "            elif \"{\" in response_text:\n",
    "                json_start = response_text.find(\"{\")\n",
    "                json_end = response_text.rfind(\"}\") + 1\n",
    "                response_text = response_text[json_start:json_end]\n",
    "            \n",
    "            return json.loads(response_text)\n",
    "            \n",
    "        except Exception:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbc34f5",
   "metadata": {},
   "source": [
    "# Chat System\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8666b97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatSystem:\n",
    "    \"\"\"자연스러운 질문 통합 채팅 시스템 - 토큰 효율 개선\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = AzureOpenAI(\n",
    "            api_version=Config.API_VERSION,\n",
    "            azure_endpoint=Config.ENDPOINT,\n",
    "            api_key=Config.SUBSCRIPTION_KEY,\n",
    "        )\n",
    "        \n",
    "        self.conversation_history = []\n",
    "        self.tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        self.token_count = 0\n",
    "        self.MAX_TOKENS = Config.MAX_TOKENS\n",
    "        self.conversation_turns = []\n",
    "        self.last_question = \"\"\n",
    "        \n",
    "        # 음성 녹음 관련 설정\n",
    "        self.recording = False\n",
    "        self.audio_thread = None\n",
    "        self.audio_data = []\n",
    "        self.sample_rate = 44100\n",
    "        \n",
    "        # 음성 파일 저장 디렉토리 생성\n",
    "        self.audio_dir = Path(\"audio_records\")\n",
    "        self.audio_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    def start_recording(self):\n",
    "        \"\"\"음성 녹음 시작\"\"\"\n",
    "        if self.recording:\n",
    "            return\n",
    "        \n",
    "        self.recording = True\n",
    "        self.audio_data = []\n",
    "        \n",
    "        def audio_callback(indata, frames, time, status):\n",
    "            if status:\n",
    "                print(f\"Status: {status}\")\n",
    "            if self.recording:\n",
    "                self.audio_data.append(indata.copy())\n",
    "        \n",
    "        self.audio_thread = sd.InputStream(\n",
    "            samplerate=self.sample_rate,\n",
    "            channels=1,\n",
    "            callback=audio_callback\n",
    "        )\n",
    "        self.audio_thread.start()\n",
    "    \n",
    "    def stop_recording(self):\n",
    "        \"\"\"음성 녹음 중지 및 파일 저장\"\"\"\n",
    "        if not self.recording:\n",
    "            return None\n",
    "        \n",
    "        self.recording = False\n",
    "        if self.audio_thread:\n",
    "            self.audio_thread.stop()\n",
    "            self.audio_thread.close()\n",
    "            self.audio_thread = None\n",
    "        \n",
    "        if not self.audio_data:\n",
    "            return None\n",
    "        \n",
    "        # 녹음된 데이터를 하나의 배열로 합치기\n",
    "        audio_data = np.concatenate(self.audio_data, axis=0)\n",
    "        \n",
    "        # 파일명 생성 (timestamp 사용)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = self.audio_dir / f\"record_{timestamp}.wav\"\n",
    "        \n",
    "        # WAV 파일로 저장\n",
    "        sf.write(filename, audio_data, self.sample_rate)\n",
    "        \n",
    "        return str(filename)\n",
    "        \n",
    "    def setup_conversation_context(self, analysis_result):\n",
    "        \"\"\"대화 컨텍스트 설정\"\"\"\n",
    "        caption = analysis_result.get(\"caption\", \"\")\n",
    "        dense_captions = analysis_result.get(\"dense_captions\", [])\n",
    "        mood = analysis_result.get(\"mood\", \"\")\n",
    "        time_period = analysis_result.get(\"time_period\", \"\")\n",
    "        key_objects = analysis_result.get(\"key_objects\", [])\n",
    "        people_description = analysis_result.get(\"people_description\", \"\")\n",
    "        people_count = analysis_result.get(\"people_count\", 0)\n",
    "        time_of_day = analysis_result.get(\"time_of_day\", \"\")\n",
    "        \n",
    "        dense_captions_text = \"\\n\".join([f\"- {dc}\" for dc in dense_captions])\n",
    "        key_objects_text = \", \".join(key_objects)\n",
    "        \n",
    "        system_message = f\"\"\"너는 노인과 대화하는 요양보호사야. 노인과 특정 이미지에 대해서 질의응답을 주고받아. \n",
    "노인은 치매 증상이 갑자기 나타날 수도 있어. 반복되는 말에도 똑같이 대답해줘야 해. \n",
    "친절하고 어른을 공경하는 말투여야 해. 그리고 공감을 잘 해야 해. 예의도 지켜. \n",
    "너는 주로 질문을 하는 쪽이고, 노인은 대답을 해줄거야. 대답에 대한 리액션과 함께 적절히 대화를 이어 가.\n",
    "노인의 발언이 끝나면 그와 관련된 공감 문장을 먼저 말한 후, 자연스럽게 그 기억에 대해 더 물어보는 꼬리 질문을 덧붙여. 하지만 메인 주제는 주어진 이미지 정보에 대해 어르신께 대화 문맥에 맞춰 자연스럽게 질문하는 거야.\n",
    "\n",
    "=== 이미지 정보 ===\n",
    "주요 설명: {caption}\n",
    "분위기/감정: {mood}\n",
    "추정 시대: {time_period}\n",
    "시간대: {time_of_day}\n",
    "인원 수: {people_count}명\n",
    "주요 객체들: {key_objects_text}\n",
    "인물 설명: {people_description}\n",
    "\n",
    "세부 요소들:\n",
    "{dense_captions_text}\n",
    "\n",
    "=== 대화 원칙 ===\n",
    "간결하게: 50자 이내로 질문하기\n",
    "사진: 대화도 대화지만 사진에 대한 주제에서 벗아나진 말아줘\n",
    "심도있는: 사람과 깊고 의미있게 대화하기 \n",
    "흥미롭게: 이미지에 대한 흥미로운 질문을 먼저 던져 대화를 시작하세요\n",
    "공감하기: 사진에 대하여 공감을 하고 친근하게 대화\n",
    "하나씩만: 한 번에 질문 하나만\n",
    "자연스럽게: 답변에 따라 연관 질문\n",
    "따뜻하게: 공감 후 질문, 사람의 마음을 따듯하게 해주는 대화들\"\"\"\n",
    "        \n",
    "        self.conversation_history = [{\"role\": \"system\", \"content\": system_message}]\n",
    "        self.token_count = len(self.tokenizer.encode(system_message))\n",
    "    \n",
    "    def generate_initial_question(self):\n",
    "        \"\"\"첫 질문 생성\"\"\"\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=Config.DEPLOYMENT,\n",
    "            messages=self.conversation_history + [\n",
    "                {\"role\": \"user\", \"content\": \"어르신께 따듯하고 친근하게 사진에 대하여 질문을 해주세요. 50자 이내로 간결하게 질문해주세요.\"}\n",
    "            ],\n",
    "            max_tokens=512,\n",
    "            temperature=0.8\n",
    "        )\n",
    "        \n",
    "        initial_question = response.choices[0].message.content\n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": initial_question})\n",
    "        self.token_count += len(self.tokenizer.encode(initial_question))\n",
    "        self.last_question = initial_question\n",
    "        \n",
    "        return initial_question\n",
    "\n",
    "    def chat_about_image(self, user_query, with_audio=False):\n",
    "        \"\"\"대화 처리\"\"\"\n",
    "        user_tokens = len(self.tokenizer.encode(user_query))\n",
    "        \n",
    "        # 음성 녹음 시작 (if requested)\n",
    "        audio_file = None\n",
    "        if with_audio:\n",
    "            self.start_recording()\n",
    "        \n",
    "        # 대화 턴 저장\n",
    "        if self.last_question:\n",
    "            # 음성 녹음 중지 및 파일 저장 (if recording)\n",
    "            if with_audio:\n",
    "                audio_file = self.stop_recording()\n",
    "            \n",
    "            conversation_turn = ConversationTurn(\n",
    "                question=self.last_question,\n",
    "                answer=user_query,\n",
    "                timestamp=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                answer_length=len(user_query.strip()),\n",
    "                audio_file=audio_file if audio_file else \"\"\n",
    "            )\n",
    "            self.conversation_turns.append(conversation_turn)\n",
    "        \n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": user_query})\n",
    "        self.token_count += user_tokens\n",
    "        \n",
    "        # 토큰 제한 확인\n",
    "        if self.token_count > self.MAX_TOKENS:\n",
    "            answer = \"대화 시간이 다 되었어요. 수고하셨습니다.\"\n",
    "            self.conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "            return answer, True\n",
    "        \n",
    "        # AI 응답 생성\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=Config.DEPLOYMENT,\n",
    "            messages=self.conversation_history,\n",
    "            max_tokens=1024,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        answer = response.choices[0].message.content\n",
    "        \n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "        self.token_count += len(self.tokenizer.encode(answer))\n",
    "        self.last_question = answer\n",
    "        \n",
    "        if self.token_count > self.MAX_TOKENS:\n",
    "            return answer, True\n",
    "        \n",
    "        return answer, False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5deb43",
   "metadata": {},
   "source": [
    "# Voice System Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caef8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoiceSystem:\n",
    "    \"\"\"음성 입출력 시스템\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.speech_key = Config.SPEECH_KEY\n",
    "        self.region = Config.SPEECH_REGION\n",
    "        \n",
    "        # STT 설정\n",
    "        self.speech_config = speechsdk.SpeechConfig(subscription=self.speech_key, region=self.region)\n",
    "        self.speech_config.speech_recognition_language = \"ko-KR\"\n",
    "        \n",
    "        # TTS 설정\n",
    "        self.tts_voice = \"ko-KR-SunHiNeural\"\n",
    "        \n",
    "        # 오디오 폴더\n",
    "        self.audio_dir = Path(\"audio_files\")\n",
    "        self.audio_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # pygame 초기화\n",
    "        try:\n",
    "            pygame.mixer.init()\n",
    "            self.audio_enabled = True\n",
    "        except:\n",
    "            self.audio_enabled = False\n",
    "    \n",
    "    def transcribe_speech(self) -> str:\n",
    "        \"\"\"STT: 음성을 텍스트로 변환\"\"\"\n",
    "        try:\n",
    "            audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "            speech_recognizer = speechsdk.SpeechRecognizer(\n",
    "                speech_config=self.speech_config, \n",
    "                audio_config=audio_config\n",
    "            )\n",
    "            \n",
    "            print(\"🎙️ 말씀해 주세요...\")\n",
    "            result = speech_recognizer.recognize_once()\n",
    "            \n",
    "            if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "                recognized_text = result.text.strip()\n",
    "                print(f\"👤 \\\"{recognized_text}\\\"\")\n",
    "                \n",
    "                # 종료 명령어 감지\n",
    "                exit_commands = ['종료', '그만', '끝', '나가기', 'exit', 'quit', 'stop']\n",
    "                cleaned_text = recognized_text.lower().replace(' ', '').replace('.', '')\n",
    "                \n",
    "                for exit_cmd in exit_commands:\n",
    "                    if exit_cmd.lower() in cleaned_text:\n",
    "                        return \"종료\"\n",
    "                \n",
    "                return recognized_text\n",
    "            else:\n",
    "                print(\"❌ 음성을 인식할 수 없습니다. 다시 말씀해 주세요.\")\n",
    "                return \"\"\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "    \n",
    "    def get_access_token(self):\n",
    "        \"\"\"Azure Speech Service 액세스 토큰 요청\"\"\"\n",
    "        url = f\"https://{self.region}.api.cognitive.microsoft.com/sts/v1.0/issueToken\"\n",
    "        headers = {\"Ocp-Apim-Subscription-Key\": self.speech_key}\n",
    "        try:\n",
    "            res = requests.post(url, headers=headers)\n",
    "            res.raise_for_status()\n",
    "            return res.text\n",
    "        except Exception:\n",
    "            return None\n",
    "    \n",
    "    def synthesize_speech(self, text: str) -> str:\n",
    "        \"\"\"TTS: 텍스트를 음성으로 변환하고 재생\"\"\"\n",
    "        if not text.strip():\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            token = self.get_access_token()\n",
    "            if not token:\n",
    "                return None\n",
    "                \n",
    "            tts_url = f\"https://{self.region}.tts.speech.microsoft.com/cognitiveservices/v1\"\n",
    "            \n",
    "            headers = {\n",
    "                \"Authorization\": f\"Bearer {token}\",\n",
    "                \"Content-Type\": \"application/ssml+xml\",\n",
    "                \"X-Microsoft-OutputFormat\": \"riff-16khz-16bit-mono-pcm\",\n",
    "                \"User-Agent\": \"DementiaAnalysisSystem\"\n",
    "            }\n",
    "            \n",
    "            ssml = f\"\"\"\n",
    "            <speak version='1.0' xml:lang='ko-KR'>\n",
    "                <voice xml:lang='ko-KR' xml:gender='Female' name='{self.tts_voice}'>\n",
    "                    {text}\n",
    "                </voice>\n",
    "            </speak>\n",
    "            \"\"\"\n",
    "            \n",
    "            res = requests.post(tts_url, headers=headers, data=ssml.encode(\"utf-8\"))\n",
    "            res.raise_for_status()\n",
    "            \n",
    "            # 음성 파일 저장\n",
    "            timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_path = self.audio_dir / f\"tts_{timestamp}.wav\"\n",
    "            \n",
    "            with open(output_path, \"wb\") as f:\n",
    "                f.write(res.content)\n",
    "            \n",
    "            # 음성 재생\n",
    "            if self.audio_enabled:\n",
    "                try:\n",
    "                    pygame.mixer.music.load(str(output_path))\n",
    "                    pygame.mixer.music.play()\n",
    "                    while pygame.mixer.music.get_busy():\n",
    "                        time.sleep(0.1)\n",
    "                except Exception:\n",
    "                    pass\n",
    "            \n",
    "            return str(output_path)\n",
    "            \n",
    "        except Exception:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6ab6ba",
   "metadata": {},
   "source": [
    "# Audio Dementia Detection_Gwona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013b01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import azure.storage.blob as blob\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from blob import BlobServiceClient\n",
    "\n",
    "\n",
    "\"\"\"\n",
    ".wav 음성 파일\n",
    "   ↓\n",
    "(preprocess_audio_slices)\n",
    "   ↓\n",
    "정규화된 log-mel 이미지 여러 장 (30초 단위)\n",
    "   ↓\n",
    "(predict_audio_category)\n",
    "   ↓\n",
    "각 슬라이스마다 예측 → 평균 → 최종 판별 (치매:cd vs 정상:cc)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Define the categories \n",
    "# cc: 치매 증상이 없음\n",
    "# cd: 치매 증상이 있음  \n",
    "category = {\n",
    "    0: 'cc',\n",
    "    1: 'cd'\n",
    "}\n",
    "\n",
    "# ✅ 기본 설정\n",
    "SR = 16000  # 샘플링 레이트\n",
    "FIXED_DURATION = 30  # 슬라이싱 길이 30(초)\n",
    "\n",
    "\n",
    "# =============[데이터 전처리]================\n",
    "# ✅ 30초 단위 슬라이싱 기반 Mel-spectrogram 전처리 함수\n",
    "def preprocess_audio_slices_from_blob(blob_url: str, save_path: str, connection_string: str, container_name: str, add_noise=True):\n",
    "    \"\"\"\n",
    "    Azure Blob Storage의 wav 파일을 직접 불러와 30초 단위로 슬라이싱,\n",
    "    멜 스펙트로그램 이미지로 저장하는 함수.\n",
    "    \"\"\"\n",
    "    # Blob 설정 및 다운로드\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "    blob_name = blob_url.split(\"/\")[-1]\n",
    "    blob_client = blob_service_client.get_container_client(container_name).get_blob_client(blob_name)\n",
    "\n",
    "    byte_stream = BytesIO()\n",
    "    blob_data = blob_client.download_blob()\n",
    "    blob_data.readinto(byte_stream)\n",
    "    byte_stream.seek(0)\n",
    "\n",
    "    # librosa 로드\n",
    "    y, sr = librosa.load(byte_stream, sr=SR)\n",
    "\n",
    "    # 30초 기준 슬라이싱\n",
    "    slice_length = FIXED_DURATION * sr\n",
    "    total_slices = len(y) // slice_length\n",
    "\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    base_name = os.path.splitext(blob_name)[0]\n",
    "    saved_files = []\n",
    "\n",
    "    for i in range(total_slices):\n",
    "        y_slice = y[i * slice_length : (i + 1) * slice_length]\n",
    "\n",
    "        # Noise Augmentation (선택)\n",
    "        if add_noise:\n",
    "            noise_amp = 0.005 * np.random.uniform() * np.amax(y_slice)\n",
    "            noise = noise_amp * np.random.normal(size=y_slice.shape[0])\n",
    "            y_slice = y_slice + noise\n",
    "\n",
    "        # log-Mel 변환 + 정규화\n",
    "        mel = librosa.feature.melspectrogram(y=y_slice, sr=sr, n_mels=128)\n",
    "        mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "        mel_norm = (mel_db - mel_db.min()) / (mel_db.max() - mel_db.min())\n",
    "\n",
    "        # 이미지 저장\n",
    "        save_file = os.path.join(save_path, f\"{base_name}_slice{i+1}.jpg\")\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        librosa.display.specshow(mel_norm, sr=sr, x_axis='time', y_axis='mel')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_file, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "\n",
    "        saved_files.append(save_file)\n",
    "\n",
    "    return saved_files\n",
    "\n",
    "# =============[리포트 생성 함수]================\n",
    "# 전체 슬라이스 수 중 치매로 분류된 비율을 기준으로 \"높음\", \"중간\", \"낮음\"으로 요약함\n",
    "def summarize_prediction_result(predictions: list[float]) -> str:\n",
    "    threshold = 0.5\n",
    "    total = len(predictions)\n",
    "    positive = sum(1 for p in predictions if p >= threshold)\n",
    "    ratio = positive / total\n",
    "\n",
    "    if ratio >= 0.7:\n",
    "        level = \"높음\"\n",
    "        icon = \"🔴\"\n",
    "    elif ratio >= 0.4:\n",
    "        level = \"중간\"\n",
    "        icon = \"🟠\"\n",
    "    else:\n",
    "        level = \"낮음\"\n",
    "        icon = \"🟢\"\n",
    "\n",
    "    return f\"\"\"🎙️ 음성 기반 치매 예측 결과\n",
    "            ──────────────────────────────\n",
    "            🧪 전체 분석 클립: {total}개\n",
    "            🧠 치매 가능성으로 분류된 클립: {positive}개\n",
    "            📊 예측 비율: {ratio:.0%}\n",
    "            {icon} 치매 가능성 수준: {level}\n",
    "            ──────────────────────────────\n",
    "            📌 참고: 이 결과는 음성의 억양, 피치, 떨림 등 음향적 특성을 기반으로 하며, 대화 내용과 함께 종합적으로 판단하는 것이 중요합니다.\n",
    "            ──────────────────────────────\n",
    "            \"\"\"\n",
    "\n",
    "# =============[분류 모델 예측 파이프라인]================\n",
    "def run_prediction_pipeline_from_blob(blob_url: str, connection_string: str, container_name: str,\n",
    "                                      model_path: str, save_path: str = \"./mel_slices/\",\n",
    "                                      add_noise: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    [1] Blob에서 .wav 로드 → [2] 슬라이싱 & 멜스펙 저장 → [3] 모델 예측 → [4] 결과 요약 반환\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. 슬라이싱 + 멜 스펙 이미지 생성\n",
    "    saved_images = preprocess_audio_slices_from_blob(\n",
    "        blob_url=blob_url,\n",
    "        save_path=save_path,\n",
    "        connection_string=connection_string,\n",
    "        container_name=container_name,\n",
    "        add_noise=add_noise\n",
    "    )\n",
    "\n",
    "    if not saved_images:\n",
    "        return \"❗ 슬라이스된 멜 스펙트로그램 이미지가 생성되지 않았습니다.\"\n",
    "\n",
    "    # 2. 모델 로드\n",
    "    model = load_model('models-05-0.7188.hdf5')\n",
    "\n",
    "    # 3. 이미지 순회하며 예측\n",
    "    predictions = []\n",
    "    for img_path in saved_images:\n",
    "        img = image.load_img(img_path, target_size=(250, 250))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_processed = np.expand_dims(img_array, axis=0)\n",
    "        img_processed /= 255.0\n",
    "        pred = model.predict(img_processed)[0]\n",
    "        predictions.append(pred)\n",
    "\n",
    "    # 4. 결과 요약\n",
    "    return summarize_prediction_result(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9426b8",
   "metadata": {},
   "source": [
    "#### 일단 함수 구현은 끝났는데, 리포트에 추가하는것 남음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc84aef",
   "metadata": {},
   "source": [
    "# Story Telling / Report System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c83c2a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoryGenerator:\n",
    "    def __init__(self, chat_system):\n",
    "        self.chat_system = chat_system\n",
    "        self.client = chat_system.client\n",
    "        self.strange_responses = []\n",
    "        self.rule_based_alerts = []\n",
    "        self.conversation_id = \"\"\n",
    "    \n",
    "    def _create_conversation_folders(self, image_path):\n",
    "        image_basename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        \n",
    "        # conversation_log/{이미지명}/ 폴더 생성\n",
    "        image_dir = Path(\"conversation_log\") / image_basename\n",
    "        image_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # 기존 대화 폴더들 확인하여 다음 번호 결정\n",
    "        existing_dirs = list(image_dir.glob(f\"{image_basename}_conv*\"))\n",
    "        conv_number = len(existing_dirs) + 1\n",
    "        \n",
    "        # 대화 ID: {이미지명}_conv{번호}\n",
    "        self.conversation_id = f\"{image_basename}_conv{conv_number}\"\n",
    "        \n",
    "        # 대화별 폴더: {이미지명}_conv{번호}/\n",
    "        conversation_dir = image_dir / self.conversation_id\n",
    "        conversation_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        print(f\"📁 저장 구조:\")\n",
    "        print(f\"   메인 폴더: conversation_log/{image_basename}/{self.conversation_id}/\")\n",
    "        print(f\"   대화 파일: {self.conversation_id}.txt\")\n",
    "        return conversation_dir\n",
    "    \n",
    "    def _save_individual_qa_pairs(self, conversation_dir):\n",
    "        \"\"\"개별 질의응답 쌍 저장 - 간소화된 형식\"\"\"\n",
    "        for i, turn in enumerate(self.chat_system.conversation_turns, 1):\n",
    "            qa_filename = conversation_dir / f\"qa_{i:02d}.txt\"\n",
    "            \n",
    "            with open(qa_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(f\"=== 질의응답 {i}번 ===\\n\")\n",
    "                f.write(f\"대화 ID: {self.conversation_id}\\n\")\n",
    "                f.write(f\"시간: {turn.timestamp}\\n\")\n",
    "                f.write(f\"{'='*25}\\n\\n\")\n",
    "                f.write(f\"🤖 질문:\\n{turn.question}\\n\\n\")\n",
    "                f.write(f\"👤 답변:\\n{turn.answer}\\n\")\n",
    "                f.write(f\"{'='*25}\\n\")\n",
    "    \n",
    "    def _load_qa_pairs_for_report(self, pairs_dir):\n",
    "        qa_files = sorted([f for f in pairs_dir.glob(\"qa_*.txt\")])\n",
    "        qa_data = []\n",
    "        for qa_file in qa_files:\n",
    "            try:\n",
    "                with open(qa_file, 'r', encoding='utf-8') as f:\n",
    "                    qa_data.append({'file': qa_file.name, 'content': f.read()})\n",
    "            except Exception:\n",
    "                continue\n",
    "        return qa_data\n",
    "    \n",
    "    def analyze_speech_patterns(self):\n",
    "        if not self.chat_system.conversation_turns:\n",
    "            return\n",
    "        \n",
    "        patterns = {\n",
    "            'severe_depression': [\"죽고싶\", \"살기싫\", \"의미없\", \"포기하고싶\", \"지쳤\", \"힘들어죽겠\", \"세상이싫\", \"절망\"],\n",
    "            'severe_anxiety': [\"무서워죽겠\", \"불안해미쳐\", \"걱정돼죽겠\", \"두려워\", \"숨막혀\", \"공황\", \"패닉\"],\n",
    "            'severe_anger': [\"화나죽겠\", \"미쳐버리겠\", \"짜증나죽겠\", \"열받아\", \"빡쳐\", \"분해\", \"참을수없\"],\n",
    "            'cognitive_decline': [\"기억안나\", \"모르겠\", \"잊어버렸\", \"생각안나\", \"까먹었\", \"헷갈려\", \"누구였는지\", \"몰라\"]\n",
    "        }\n",
    "        \n",
    "        memory_issues = very_short_answers = meaningless_answers = 0\n",
    "        repetitive_patterns = []\n",
    "        \n",
    "        for i, turn in enumerate(self.chat_system.conversation_turns):\n",
    "            answer = turn.answer.replace(\" \", \"\").lower()\n",
    "            \n",
    "            for pattern_type, keywords in patterns.items():\n",
    "                for keyword in keywords:\n",
    "                    if keyword in answer:\n",
    "                        severity = \"critical\" if pattern_type == 'severe_depression' else \"high\"\n",
    "                        self.rule_based_alerts.append({\n",
    "                            \"type\": pattern_type,\n",
    "                            \"turn_number\": i + 1,\n",
    "                            \"keyword\": keyword,\n",
    "                            \"answer\": turn.answer,\n",
    "                            \"timestamp\": turn.timestamp,\n",
    "                            \"severity\": severity\n",
    "                        })\n",
    "                        if pattern_type == 'cognitive_decline':\n",
    "                            memory_issues += 1\n",
    "            \n",
    "            if len(turn.answer.strip()) <= 5:\n",
    "                very_short_answers += 1\n",
    "            \n",
    "            if turn.answer.strip() in [\"음\", \"어\", \"그냥\", \"네\", \"아니\", \"응\", \"어?\"]:\n",
    "                meaningless_answers += 1\n",
    "            \n",
    "            if i >= 3:\n",
    "                recent_answers = [t.answer.strip() for t in self.chat_system.conversation_turns[i-3:i]]\n",
    "                if turn.answer.strip() in recent_answers:\n",
    "                    repetitive_patterns.append(i + 1)\n",
    "        \n",
    "        total_turns = len(self.chat_system.conversation_turns)\n",
    "        \n",
    "        thresholds = [\n",
    "            (memory_issues >= total_turns * 0.7, \"severe_memory_loss\", \"critical\", f\"전체 {total_turns}회 중 {memory_issues}회 기억 문제\"),\n",
    "            (very_short_answers >= total_turns * 0.8, \"communication_difficulty\", \"high\", f\"전체 {total_turns}회 중 {very_short_answers}회 짧은 답변\"),\n",
    "            (meaningless_answers >= total_turns * 0.6, \"cognitive_confusion\", \"high\", f\"전체 {total_turns}회 중 {meaningless_answers}회 무의미한 답변\"),\n",
    "            (len(repetitive_patterns) >= 3, \"repetitive_behavior\", \"moderate\", f\"답변 반복 {len(repetitive_patterns)}회\")\n",
    "        ]\n",
    "        \n",
    "        for condition, alert_type, severity, description in thresholds:\n",
    "            if condition:\n",
    "                self.rule_based_alerts.append({\"type\": alert_type, \"description\": description, \"severity\": severity})\n",
    "\n",
    "    def calculate_ratings(self):\n",
    "        total_responses = len(self.chat_system.conversation_turns)\n",
    "        strange_count = len(self.strange_responses)\n",
    "        \n",
    "        if total_responses == 0:\n",
    "            return {\"emotion\": 3, \"coherence\": 3, \"overall\": 3}\n",
    "        \n",
    "        emotions = [turn.emotion for turn in self.chat_system.conversation_turns if hasattr(turn, 'emotion')]\n",
    "        emotion_counts = {}\n",
    "        for emotion in emotions:\n",
    "            emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1\n",
    "        \n",
    "        positive_emotions = [\"기쁨\", \"그리움\", \"감사\", \"애정\", \"흥미\"]\n",
    "        negative_emotions = [\"슬픔\", \"무력감\", \"우울감\", \"분노\", \"불안\", \"짜증\"]\n",
    "        \n",
    "        positive_count = sum(emotion_counts.get(e, 0) for e in positive_emotions)\n",
    "        negative_count = sum(emotion_counts.get(e, 0) for e in negative_emotions)\n",
    "        \n",
    "        critical_emotion_alerts = [alert for alert in self.rule_based_alerts \n",
    "                                 if alert.get('severity') == 'critical' and \n",
    "                                 alert.get('type') in ['severe_depression', 'severe_anxiety', 'severe_anger']]\n",
    "        \n",
    "        if len(critical_emotion_alerts) > 0:\n",
    "            emotion_rating = 1\n",
    "        elif negative_count > positive_count * 2:\n",
    "            emotion_rating = 2\n",
    "        elif negative_count > positive_count:\n",
    "            emotion_rating = 3\n",
    "        elif positive_count > negative_count:\n",
    "            emotion_rating = 4\n",
    "        else:\n",
    "            emotion_rating = 5 if positive_count > negative_count * 2 else 3\n",
    "        \n",
    "        strange_percentage = (strange_count / total_responses * 100) if total_responses > 0 else 0\n",
    "        severe_count = sum(1 for resp in self.strange_responses if resp.severity == 'severe')\n",
    "        \n",
    "        if strange_percentage == 0:\n",
    "            coherence_rating = 5\n",
    "        elif strange_percentage <= 20 and severe_count == 0:\n",
    "            coherence_rating = 4\n",
    "        elif strange_percentage <= 40 and severe_count <= 1:\n",
    "            coherence_rating = 3\n",
    "        elif strange_percentage <= 60 or severe_count <= 2:\n",
    "            coherence_rating = 2\n",
    "        else:\n",
    "            coherence_rating = 1\n",
    "        \n",
    "        answer_qualities = [turn.answer_quality for turn in self.chat_system.conversation_turns if hasattr(turn, 'answer_quality')]\n",
    "        quality_counts = {\"poor\": 0, \"normal\": 0, \"good\": 0, \"excellent\": 0}\n",
    "        for quality in answer_qualities:\n",
    "            quality_counts[quality] += 1\n",
    "        \n",
    "        excellent_percentage = (quality_counts[\"excellent\"] / total_responses * 100) if total_responses > 0 else 0\n",
    "        good_percentage = (quality_counts[\"good\"] / total_responses * 100) if total_responses > 0 else 0\n",
    "        poor_percentage = (quality_counts[\"poor\"] / total_responses * 100) if total_responses > 0 else 0\n",
    "        \n",
    "        critical_cognitive_alerts = [alert for alert in self.rule_based_alerts \n",
    "                                   if alert.get('severity') == 'critical' and \n",
    "                                   alert.get('type') in ['severe_memory_loss', 'communication_difficulty']]\n",
    "        \n",
    "        if len(critical_cognitive_alerts) > 0 or poor_percentage >= 50:\n",
    "            overall_rating = 1\n",
    "        elif poor_percentage >= 30 or (strange_percentage > 50 and severe_count >= 2):\n",
    "            overall_rating = 2\n",
    "        elif excellent_percentage >= 30 or (good_percentage >= 50 and strange_percentage <= 20):\n",
    "            overall_rating = 5\n",
    "        elif good_percentage >= 30 or strange_percentage <= 30:\n",
    "            overall_rating = 4\n",
    "        else:\n",
    "            overall_rating = 3\n",
    "        \n",
    "        return {\"emotion\": emotion_rating, \"coherence\": coherence_rating, \"overall\": overall_rating}\n",
    "    \n",
    "    def format_star_rating(self, rating):\n",
    "        stars = \"⭐\" * rating + \"☆\" * (5 - rating)\n",
    "        return f\"{stars} ({rating}/5)\"\n",
    "\n",
    "    def analyze_entire_conversation(self):\n",
    "        if not self.chat_system.conversation_turns:\n",
    "            return\n",
    "        \n",
    "        self.strange_responses = []\n",
    "        self.rule_based_alerts = []\n",
    "        self.analyze_speech_patterns()\n",
    "        \n",
    "        conversation_text = \"\"\n",
    "        for i, turn in enumerate(self.chat_system.conversation_turns, 1):\n",
    "            conversation_text += f\"[{i}] 질문: {turn.question}\\n답변: {turn.answer} (길이: {turn.answer_length}자)\\n\\n\"\n",
    "        \n",
    "        analysis_prompt = f\"\"\"치매 환자 대화 분석하여 JSON 응답:\n",
    "{conversation_text}\n",
    "\n",
    "JSON: {{\"conversation_analysis\": [{{\"turn_number\": 1, \"is_strange\": true/false, \"severity\": \"normal/mild/moderate/severe\", \"emotion\": \"감정\", \"answer_quality\": \"poor/normal/good/excellent\", \"reason\": \"이유\"}}], \"overall_assessment\": {{\"dominant_emotion\": \"주요감정\", \"cognitive_level\": \"normal/mild_concern/moderate_concern/severe_concern\"}}}}\n",
    "\n",
    "감정: 기쁨,슬픔,그리움,무력감,우울감,분노,불안,중립,감사,애정,흥미,짜증\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=Config.DEPLOYMENT,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"치매 환자 대화 분석 전문 AI\"},\n",
    "                    {\"role\": \"user\", \"content\": analysis_prompt}\n",
    "                ],\n",
    "                max_tokens=1024,\n",
    "                temperature=0.1\n",
    "            )\n",
    "            \n",
    "            analysis_text = response.choices[0].message.content\n",
    "            \n",
    "            if \"```json\" in analysis_text:\n",
    "                json_start = analysis_text.find(\"```json\") + 7\n",
    "                json_end = analysis_text.find(\"```\", json_start)\n",
    "                analysis_text = analysis_text[json_start:json_end].strip()\n",
    "            elif \"{\" in analysis_text:\n",
    "                json_start = analysis_text.find(\"{\")\n",
    "                json_end = analysis_text.rfind(\"}\") + 1\n",
    "                analysis_text = analysis_text[json_start:json_end]\n",
    "            \n",
    "            analysis_result = json.loads(analysis_text)\n",
    "            \n",
    "            conversation_analyses = analysis_result.get(\"conversation_analysis\", [])\n",
    "            for i, analysis in enumerate(conversation_analyses):\n",
    "                if i < len(self.chat_system.conversation_turns):\n",
    "                    turn = self.chat_system.conversation_turns[i]\n",
    "                    turn.emotion = analysis.get(\"emotion\", \"중립\")\n",
    "                    turn.answer_quality = analysis.get(\"answer_quality\", \"normal\")\n",
    "                    \n",
    "                    if analysis.get(\"is_strange\", False):\n",
    "                        strange_response = StrangeResponse(\n",
    "                            question=turn.question,\n",
    "                            answer=turn.answer,\n",
    "                            timestamp=turn.timestamp,\n",
    "                            severity=analysis.get(\"severity\", \"mild\"),\n",
    "                            emotion=turn.emotion,\n",
    "                            answer_quality=turn.answer_quality\n",
    "                        )\n",
    "                        self.strange_responses.append(strange_response)\n",
    "            \n",
    "            return analysis_result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return None\n",
    "        \n",
    "    def generate_story_from_conversation(self, image_path):\n",
    "        conversation_text = \"\"\n",
    "        for turn in self.chat_system.conversation_turns:\n",
    "            conversation_text += f\"질문: {turn.question}\\n답변: {turn.answer}\\n\\n\"\n",
    "        \n",
    "        if not conversation_text.strip():\n",
    "            return None, None\n",
    "        \n",
    "        story_prompt = f\"\"\"대화 기반으로 어르신 1인칭 추억 스토리 15줄 작성:\n",
    "{conversation_text}\n",
    "지침: 답변 기반 작성, 감정과 감각 포함, 따뜻한 톤, 손자/손녀에게 들려주는 어투\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=Config.DEPLOYMENT,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"노인 추억 스토리텔러\"},\n",
    "                    {\"role\": \"user\", \"content\": story_prompt}\n",
    "                ],\n",
    "                max_tokens=512,\n",
    "                temperature=0.8\n",
    "            )\n",
    "            \n",
    "            story = response.choices[0].message.content\n",
    "            story_dir = \"story_telling\"\n",
    "            os.makedirs(story_dir, exist_ok=True)\n",
    "            \n",
    "            image_basename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "            story_filename = os.path.join(story_dir, f\"{image_basename}_story.txt\")\n",
    "            \n",
    "            with open(story_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(story)\n",
    "            \n",
    "            return story, story_filename\n",
    "            \n",
    "        except Exception:\n",
    "            return None, None\n",
    "    \n",
    "    def save_conversation_summary(self, conversation_dir=None):\n",
    "        if conversation_dir:\n",
    "            qa_data = self._load_qa_pairs_for_report(conversation_dir)\n",
    "        \n",
    "        analysis_result = self.analyze_entire_conversation()\n",
    "        total_responses = len(self.chat_system.conversation_turns)\n",
    "        strange_count = len(self.strange_responses)\n",
    "        \n",
    "        if total_responses == 0:\n",
    "            return \"대화가 진행되지 않았습니다.\"\n",
    "        \n",
    "        emotions = [turn.emotion for turn in self.chat_system.conversation_turns if hasattr(turn, 'emotion')]\n",
    "        emotion_counts = {}\n",
    "        for emotion in emotions:\n",
    "            emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1\n",
    "        \n",
    "        if emotion_counts:\n",
    "            dominant_emotion = max(emotion_counts, key=emotion_counts.get)\n",
    "            positive_emotions = [\"기쁨\", \"그리움\", \"감사\", \"애정\", \"흥미\"]\n",
    "            negative_emotions = [\"슬픔\", \"무력감\", \"우울감\", \"분노\", \"불안\", \"짜증\"]\n",
    "            \n",
    "            positive_count = sum(emotion_counts.get(e, 0) for e in positive_emotions)\n",
    "            negative_count = sum(emotion_counts.get(e, 0) for e in negative_emotions)\n",
    "            \n",
    "            if positive_count > negative_count:\n",
    "                overall_mood = \"긍정적\"\n",
    "                mood_icon = \"😊\"\n",
    "            elif negative_count > positive_count:\n",
    "                overall_mood = \"부정적\" \n",
    "                mood_icon = \"😔\"\n",
    "            else:\n",
    "                overall_mood = \"중립적\"\n",
    "                mood_icon = \"😐\"\n",
    "        else:\n",
    "            dominant_emotion = \"중립\"\n",
    "            overall_mood = \"중립적\"\n",
    "            mood_icon = \"😐\"\n",
    "        \n",
    "        critical_alerts = [alert for alert in self.rule_based_alerts if alert.get('severity') == 'critical']\n",
    "        high_alerts = [alert for alert in self.rule_based_alerts if alert.get('severity') == 'high']\n",
    "        ratings = self.calculate_ratings()\n",
    "        \n",
    "        summary = f\"\\n{'='*60}\\n📋 치매 진단 대화 분석 리포트\\n{'='*60}\\n\"\n",
    "        summary += f\"📅 분석 일시: {datetime.now().strftime('%Y년 %m월 %d일 %H:%M:%S')}\\n\"\n",
    "        summary += f\"🆔 대화 ID: {self.conversation_id}\\n{'='*60}\\n\\n\"\n",
    "        \n",
    "        summary += f\"🎯 종합 평가\\n{'─'*30}\\n\"\n",
    "        summary += f\"😊 감정 상태:     {self.format_star_rating(ratings['emotion'])}\\n\"\n",
    "        summary += f\"💬 답변 일관성:   {self.format_star_rating(ratings['coherence'])}\\n\"\n",
    "        summary += f\"🧠 전반적 인지:   {self.format_star_rating(ratings['overall'])}\\n{'─'*30}\\n\\n\"\n",
    "        \n",
    "        summary += f\"📊 대화 개요\\n{'─'*30}\\n\"\n",
    "        summary += f\"💬 총 대화 횟수: {total_responses}회\\n\"\n",
    "        summary += f\"{mood_icon} 전반적 감정: {overall_mood} (주요: {dominant_emotion})\\n\"\n",
    "        summary += f\"{'✅ 어긋난 답변: 없음' if strange_count == 0 else f'⚠️ 어긋난 답변: {strange_count}회'}\\n\"\n",
    "        summary += f\"{'✅ 발화 패턴: 특이사항 없음' if len(self.rule_based_alerts) == 0 else f'🔍 발화 패턴: {len(self.rule_based_alerts)}건 관찰'}\"\n",
    "        if len(critical_alerts) > 0:\n",
    "            summary += f\" (⚠️ 주의: {len(critical_alerts)}건)\"\n",
    "        summary += f\"\\n{'─'*30}\\n\\n\"\n",
    "        \n",
    "        if strange_count == 0 and len(critical_alerts) == 0:\n",
    "            summary += f\"🎉 대화 결과\\n{'─'*30}\\n\"\n",
    "            summary += f\"✅ 대화 중 특별히 걱정되는 답변은 없었습니다.\\n\"\n",
    "            summary += f\"💚 어르신께서 안정적으로 잘 응답해주셨어요.\\n\"\n",
    "            if len(high_alerts) > 0:\n",
    "                summary += f\"💡 참고: {len(high_alerts)}번의 발화 패턴이 관찰되었습니다.\\n\"\n",
    "            summary += f\"🌟 지금처럼 따뜻한 환경과 꾸준한 관심 속에 계시면 좋겠습니다.\\n\"\n",
    "            summary += f\"{'='*60}\\n\"\n",
    "            return summary\n",
    "        \n",
    "        if len(self.rule_based_alerts) > 0 or strange_count > 0:\n",
    "            summary += f\"🚨 주요 발견사항\\n{'─'*30}\\n\"\n",
    "            \n",
    "            if len(self.rule_based_alerts) > 0:\n",
    "                alert_types = {\n",
    "                    'severe_depression': '😔 우울한 표현',\n",
    "                    'severe_anxiety': '😰 불안한 표현', \n",
    "                    'severe_anger': '😡 화가 난 표현',\n",
    "                    'severe_memory_loss': '🧠 기억 관련 어려움',\n",
    "                    'communication_difficulty': '💬 대화 어려움',\n",
    "                    'cognitive_confusion': '❓ 혼란스러운 답변',\n",
    "                    'repetitive_behavior': '🔄 반복되는 답변'\n",
    "                }\n",
    "                \n",
    "                alert_summary = {}\n",
    "                for alert in self.rule_based_alerts:\n",
    "                    alert_name = alert_types.get(alert['type'], f\"⚠️ {alert['type']}\")\n",
    "                    alert_summary[alert_name] = alert_summary.get(alert_name, 0) + 1\n",
    "                \n",
    "                for alert_name, count in alert_summary.items():\n",
    "                    summary += f\"{alert_name}: {count}번\\n\"\n",
    "                summary += f\"\\n\"\n",
    "            \n",
    "            if strange_count > 0:\n",
    "                severity_counts = {\"mild\": 0, \"moderate\": 0, \"severe\": 0}\n",
    "                for response in self.strange_responses:\n",
    "                    severity_counts[response.severity] += 1\n",
    "                \n",
    "                summary += f\"🔍 어긋난 답변 분석:\\n\"\n",
    "                if severity_counts['mild'] > 0:\n",
    "                    summary += f\"  🟡 조금 어긋남: {severity_counts['mild']}회\\n\"\n",
    "                if severity_counts['moderate'] > 0:\n",
    "                    summary += f\"  🟠 꽤 어긋남: {severity_counts['moderate']}회\\n\"\n",
    "                if severity_counts['severe'] > 0:\n",
    "                    summary += f\"  🔴 많이 어긋남: {severity_counts['severe']}회\\n\"\n",
    "                summary += f\"\\n\"\n",
    "            \n",
    "            summary += f\"{'─'*30}\\n\\n\"\n",
    "        \n",
    "        if strange_count > 0 and strange_count <= 5:\n",
    "            summary += f\"📝 어긋난 답변 상세\\n{'─'*30}\\n\"\n",
    "            for i, response in enumerate(self.strange_responses, 1):\n",
    "                summary += f\"{i}. {response.timestamp}\\n\"\n",
    "                summary += f\"   ❓ 질문: {response.question}\\n\"\n",
    "                summary += f\"   💬 답변: {response.answer}\\n\"\n",
    "                summary += f\"   😊 상태: {response.emotion} | 🎯 품질: {response.answer_quality}\\n\\n\"\n",
    "            summary += f\"{'─'*30}\\n\\n\"\n",
    "        \n",
    "        summary += f\"💡 권장사항\\n{'─'*30}\\n\"\n",
    "        \n",
    "        if len(critical_alerts) > 0:\n",
    "            summary += f\"🚨 긴급 권장사항:\\n   심각한 정신건강 위험 신호가 감지되었습니다.\\n   빠른 시일 내로 연락을 드리는 것을 권장합니다.\\n\\n\"\n",
    "            for alert in critical_alerts:\n",
    "                if alert['type'] == 'severe_depression':\n",
    "                    summary += f\"   ⚠️ 극심한 우울감 표현 감지\\n      → 연락드려 기분전환을 도와드리세요.\\n\\n\"\n",
    "                elif alert['type'] == 'severe_memory_loss':\n",
    "                    summary += f\"   ⚠️ 심각한 기억력 저하 감지\\n      → 가족과 함께 추억을 되새겨보세요.\\n\\n\"\n",
    "        elif len(high_alerts) >= 2:\n",
    "            summary += f\"⚠️ 주의 권장사항:\\n   최근 대화에서 혼란스러운 답변이 자주 보였습니다.\\n   가족과 함께 이야기를 나눠보시길 권장합니다.\\n\\n\"\n",
    "        elif len(high_alerts) >= 1:\n",
    "            summary += f\"🔶 일반 권장사항:\\n   약간 걱정되는 답변이 있었습니다.\\n   시간을 내어 안부 전화를 드려보세요.\\n\\n\"\n",
    "        elif strange_count > 0:\n",
    "            summary += f\"💙 관심 권장사항:\\n   전반적으로 잘 응답해주셨지만, 간혹 어긋난 답변이 보입니다.\\n   가볍게라도 주변의 관심과 확인이 있으면 좋겠습니다.\\n\\n\"\n",
    "        else:\n",
    "            summary += f\"💚 훌륭한 상태:\\n   어르신께서 무척 안정적으로 잘 응답해주셨습니다.\\n   지금처럼 따뜻한 환경과 꾸준한 관심을 유지해주세요.\\n\\n\"\n",
    "        \n",
    "        summary += f\"🏠 가족을 위한 조언\\n{'─'*30}\\n\"\n",
    "        \n",
    "        emotion_advice = {\n",
    "            \"짜증\": \"🔴 최근 짜증스러운 감정을 표현하셨어요.\\n   → 감정을 자연스럽게 표현하도록 따뜻하게 공감해주세요.\\n   → 요즘 어떠신지 자주 안부를 여쭤보시면 큰 힘이 됩니다.\",\n",
    "            \"우울감\": \"🟠 슬픔이나 우울감을 표현하셨어요.\\n   → 함께 옛 추억을 나누거나 좋아하시던 이야기를 꺼내보세요.\\n   → 감정을 안정시키는 데 도움이 될 수 있습니다.\",\n",
    "            \"슬픔\": \"🟠 슬픔이나 우울감을 표현하셨어요.\\n   → 함께 옛 추억을 나누거나 좋아하시던 이야기를 꺼내보세요.\\n   → 감정을 안정시키는 데 도움이 될 수 있습니다.\",\n",
    "            \"무력감\": \"😞 무기력하거나 소외감을 표현하셨어요.\\n   → '어르신 덕분이에요'처럼 인정해드리면 자존감 회복에 도움됩니다.\\n   → 함께 의미 있는 활동을 하며 힘이 되어 주세요.\",\n",
    "            \"분노\": \"😡 갑작스럽게 화를 내시거나 강한 어조를 보이셨어요.\\n   → 감정 뒤에 불안이나 혼란감이 있을 수 있으니 조용히 공감해주세요.\\n   → 환경을 점검하고 반복 자극을 줄이면 안정에 도움됩니다.\",\n",
    "            \"불안\": \"🟤 불안감을 느끼시는 것 같아요.\\n   → 어르신의 이야기를 잘 들어주시고, 따뜻한 말 한마디가 큰 위로가 됩니다.\",\n",
    "            \"그리움\": \"💙 과거를 그리워하시는 마음을 표현하셨어요.\\n   → 함께 옛날 이야기를 나누거나 추억 속 장소나 사람들에 대해 대화해보세요.\\n   → 마음의 평안을 찾는 데 도움이 될 수 있습니다.\"\n",
    "        }\n",
    "        \n",
    "        if dominant_emotion in emotion_advice:\n",
    "            summary += emotion_advice[dominant_emotion]\n",
    "        elif dominant_emotion in [\"기쁨\", \"감사\", \"애정\", \"흥미\"]:\n",
    "            summary += \"😊 긍정적인 감정을 표현하셨어요. 정말 좋네요!\\n   → 이런 밝은 모습을 계속 유지하실 수 있도록 즐거운 대화와 활동을 함께 해보세요.\"\n",
    "        elif dominant_emotion == \"중립\":\n",
    "            summary += \"💬 대부분의 대화에서 큰 감정 변화 없이 차분히 응답하셨어요.\\n   → 무던해 보이지만 내면의 감정을 잘 표현하지 못하실 수도 있으니\\n   → 따뜻한 말 한마디가 큰 위로가 될 수 있습니다.\"\n",
    "        else:\n",
    "            summary += \"🌈 다양한 감정이 섞여 있었지만, 전반적으로 안정적인 편입니다.\\n   → 지금처럼 관심과 애정을 꾸준히 표현해 주시면 좋습니다.\"\n",
    "        \n",
    "        summary += f\"\\n{'─'*30}\\n\\n\"\n",
    "        summary += f\"📈 평가 기준\\n{'─'*30}\\n\"\n",
    "        summary += f\"😊 감정 상태: 긍정적이고 안정적인 감정 표현일수록 높은 점수\\n\"\n",
    "        summary += f\"💬 답변 일관성: 질문과 관련된 적절한 답변일수록 높은 점수\\n\"\n",
    "        summary += f\"🧠 전반적 인지: 답변의 품질과 소통 능력을 종합한 점수\\n\"\n",
    "        summary += f\"{'─'*30}\\n\\n\"\n",
    "        summary += f\"{'='*60}\\n📋 리포트 끝 - 어르신의 건강과 행복을 위해\\n{'='*60}\\n\"\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def save_conversation_to_file(self, image_path=None):\n",
    "        if len(self.strange_responses) == 0 and len(self.rule_based_alerts) == 0:\n",
    "            self.analyze_entire_conversation()\n",
    "        \n",
    "        # 폴더 구조 생성\n",
    "        conversation_dir = self._create_conversation_folders(image_path)\n",
    "        \n",
    "        # 개별 질의응답 쌍 저장 (같은 폴더 안에)\n",
    "        self._save_individual_qa_pairs(conversation_dir)\n",
    "        \n",
    "        # 메인 대화 파일 저장: {이미지명}_conv{번호}/{이미지명}_conv{번호}.txt\n",
    "        conversation_filename = conversation_dir / f\"{self.conversation_id}.txt\"\n",
    "        with open(conversation_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"{'='*50}\\n\")\n",
    "            f.write(f\"💬 치매 진단 대화 기록\\n\")\n",
    "            f.write(f\"{'='*50}\\n\")\n",
    "            f.write(f\"🆔 대화 ID: {self.conversation_id}\\n\")\n",
    "            f.write(f\"📊 총 대화 수: {len(self.chat_system.conversation_turns)}회\\n\")\n",
    "            f.write(f\"{'='*50}\\n\\n\")\n",
    "            \n",
    "            # 대화 내용만 간단히 출력 (타임스탬프 + 대화)\n",
    "            for i, turn in enumerate(self.chat_system.conversation_turns, 1):\n",
    "                f.write(f\"[{turn.timestamp}]\\n\")\n",
    "                f.write(f\"🤖 질문: {turn.question}\\n\")\n",
    "                f.write(f\"👤 답변: {turn.answer}\\n\")\n",
    "                f.write(f\"{'-'*30}\\n\\n\")\n",
    "        \n",
    "        # analysis 폴더에 분석 리포트 저장\n",
    "        analysis_dir = Path(\"analysis\")\n",
    "        analysis_dir.mkdir(exist_ok=True)\n",
    "        analysis_filename = analysis_dir / f\"{self.conversation_id}_analysis.txt\"\n",
    "        \n",
    "        with open(analysis_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(self.save_conversation_summary(conversation_dir))\n",
    "        \n",
    "        # 저장 완료 메시지\n",
    "        print(f\"\\n✅ 파일 저장 완료!\")\n",
    "        print(f\"📁 대화 폴더: {conversation_dir}\")\n",
    "        print(f\"📄 대화 파일: {conversation_filename}\")\n",
    "        print(f\"📊 분석 파일: {analysis_filename}\")\n",
    "        print(f\"📋 QA 파일들: {len(self.chat_system.conversation_turns)}개\")\n",
    "        \n",
    "        return str(conversation_filename), str(analysis_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f031a9b7",
   "metadata": {},
   "source": [
    "# 코드 통합부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25bd8c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedDementiaSystem:\n",
    "    \"\"\"최적화된 치매 진단 시스템\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.image_analyzer = ImageAnalyzer()\n",
    "        self.chat_system = ChatSystem()\n",
    "        self.voice_system = VoiceSystem() if Config.SPEECH_KEY else None\n",
    "        self.story_generator = StoryGenerator(self.chat_system)\n",
    "    \n",
    "    def analyze_and_start_conversation(self, image_path):\n",
    "        \"\"\"이미지 분석 및 대화 시작\"\"\"\n",
    "        if not os.path.exists(image_path):\n",
    "            return None\n",
    "        \n",
    "        # 이미지 분석\n",
    "        analysis_result = self.image_analyzer.analyze_image(image_path)\n",
    "        if not analysis_result:\n",
    "            return None\n",
    "        \n",
    "        # 대화 설정\n",
    "        self.chat_system.setup_conversation_context(analysis_result)\n",
    "        \n",
    "        # 첫 질문 생성\n",
    "        initial_question = self.chat_system.generate_initial_question()\n",
    "        \n",
    "        return initial_question\n",
    "    \n",
    "    def generate_complete_analysis(self, image_path):\n",
    "        \"\"\"완전한 분석 생성\"\"\"\n",
    "        print(\"\\n📊 종합 분석 결과 생성 중...\")\n",
    "        \n",
    "        # 1. 대화 기록 저장 (새로운 폴더 구조)\n",
    "        conversation_file, analysis_file = self.story_generator.save_conversation_to_file(image_path)\n",
    "        \n",
    "        # 2. 추억 스토리 생성\n",
    "        story, story_file = self.story_generator.generate_story_from_conversation(image_path)\n",
    "        \n",
    "        # 3. 콘솔에 요약 출력\n",
    "        summary = self.story_generator.save_conversation_summary()\n",
    "        print(summary)\n",
    "        \n",
    "        # 4. 스토리 출력\n",
    "        if story:\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(\"📖 생성된 추억 이야기\")\n",
    "            print(f\"{'='*50}\")\n",
    "            print(story)\n",
    "            print(f\"{'='*50}\")\n",
    "        \n",
    "        return {\n",
    "            'conversation_file': conversation_file,\n",
    "            'analysis_file': analysis_file,\n",
    "            'story_file': story_file,\n",
    "            'story_content': story,\n",
    "            'summary': summary,\n",
    "            'conversation_id': self.story_generator.conversation_id\n",
    "        }\n",
    "    \n",
    "    def _run_conversation_loop(self, image_path, is_voice=False):\n",
    "        \"\"\"대화 루프 실행 (음성/텍스트 공통)\"\"\"\n",
    "        initial_question = self.analyze_and_start_conversation(image_path)\n",
    "        if not initial_question:\n",
    "            return None\n",
    "        \n",
    "        if is_voice and self.voice_system:\n",
    "            welcome_msg = \"안녕하세요. 사진을 보며 대화해요.\"\n",
    "            print(f\"🤖 {welcome_msg}\")\n",
    "            self.voice_system.synthesize_speech(welcome_msg)\n",
    "            \n",
    "            print(f\"🤖 {initial_question}\")\n",
    "            self.voice_system.synthesize_speech(initial_question)\n",
    "        else:\n",
    "            print(f\"🤖 {initial_question}\")\n",
    "        \n",
    "        conversation_type = \"음성\" if is_voice else \"텍스트\"\n",
    "        print(f\"\\n\" + \"=\"*40)\n",
    "        print(f\"{'🎙️' if is_voice else '💬'} {conversation_type} 대화 시작!\")\n",
    "        print(f\"💡 {'종료라고 말하면' if is_voice else 'exit 또는 종료를 입력하면'} 끝납니다\")\n",
    "        print(\"=\"*40)\n",
    "        \n",
    "        # 대화 루프\n",
    "        while True:\n",
    "            if is_voice and self.voice_system:\n",
    "                print(\"🎙️ 말씀해 주세요...\")\n",
    "                # 음성 녹음 시작\n",
    "                self.chat_system.start_recording()\n",
    "                user_input = self.voice_system.transcribe_speech()\n",
    "                # 음성 녹음 중지\n",
    "                audio_file = self.chat_system.stop_recording()\n",
    "                \n",
    "                if not user_input.strip():\n",
    "                    continue\n",
    "                if user_input == \"종료\":\n",
    "                    end_msg = \"대화를 마치겠습니다. 감사합니다.\"\n",
    "                    print(f\"🤖 {end_msg}\")\n",
    "                    self.voice_system.synthesize_speech(end_msg)\n",
    "                    break\n",
    "            else:\n",
    "                user_input = input(\"\\n👤 답변: \").strip()\n",
    "                if user_input.lower() in ['exit', '종료', 'quit', 'q']:\n",
    "                    print(\"대화를 종료합니다.\")\n",
    "                    break\n",
    "            \n",
    "            # AI 응답 (음성 모드일 때는 녹음된 오디오 파일 정보 전달)\n",
    "            answer, should_end = self.chat_system.chat_about_image(user_input, with_audio=is_voice)\n",
    "            print(f\"🤖 {answer}\")\n",
    "            \n",
    "            if is_voice and self.voice_system:\n",
    "                self.voice_system.synthesize_speech(answer)\n",
    "            \n",
    "            if should_end:\n",
    "                end_msg = \"대화 시간이 종료되었습니다.\"\n",
    "                print(f\"⏰ {end_msg}\")\n",
    "                if is_voice and self.voice_system:\n",
    "                    self.voice_system.synthesize_speech(end_msg)\n",
    "                break\n",
    "        \n",
    "        # 종합 분석 생성\n",
    "        analysis_results = self.generate_complete_analysis(image_path)\n",
    "        \n",
    "        if analysis_results['conversation_file']:\n",
    "            print(f\"📂 대화기록: {analysis_results['conversation_file']}\")\n",
    "            print(f\"📊 분석결과: {analysis_results['analysis_file']}\")\n",
    "            if analysis_results['story_file']:\n",
    "                print(f\"📖 스토리: {analysis_results['story_file']}\")\n",
    "        return analysis_results\n",
    "    \n",
    "    def voice_conversation(self, image_path):\n",
    "        \"\"\"음성 대화 실행\"\"\"\n",
    "        if not self.voice_system:\n",
    "            return None\n",
    "        return self._run_conversation_loop(image_path, is_voice=True)\n",
    "    \n",
    "    def text_conversation(self, image_path):\n",
    "        \"\"\"텍스트 대화 실행\"\"\"\n",
    "        return self._run_conversation_loop(image_path, is_voice=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04184284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_voice_conversation():\n",
    "    \"\"\"음성 대화 실행 함수\"\"\"\n",
    "    print(\"=== 🎤 음성 치매 진단 대화 시스템 ===\")\n",
    "    \n",
    "    image_path = input(\"이미지 경로를 입력하세요: \").strip()\n",
    "    \n",
    "    if not image_path or not os.path.exists(image_path):\n",
    "        print(\"❌ 올바른 이미지 경로를 입력해주세요.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        system = OptimizedDementiaSystem()\n",
    "        \n",
    "        if not system.voice_system:\n",
    "            print(\"❌ 음성 시스템을 초기화할 수 없습니다. Azure Speech Service 키를 확인해주세요.\")\n",
    "            return None\n",
    "        \n",
    "        return system.voice_conversation(image_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 시스템 오류: {e}\")\n",
    "        return None\n",
    "\n",
    "def interactive_conversation():\n",
    "    \"\"\"텍스트 대화 실행 함수\"\"\"\n",
    "    print(\"=== 💬 텍스트 치매 진단 대화 시스템 ===\")\n",
    "    \n",
    "    image_path = \"images.jpg\"\n",
    "    \n",
    "    if not image_path or not os.path.exists(image_path):\n",
    "        print(\"❌ 올바른 이미지 경로를 입력해주세요.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        system = OptimizedDementiaSystem()\n",
    "        return system.text_conversation(image_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 시스템 오류: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3610556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 시스템 준비 완료!\n",
      "💡 interactive_conversation() 함수를 실행해보세요!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 환경 확인\n",
    "    if not Config.ENDPOINT or not Config.SUBSCRIPTION_KEY:\n",
    "        print(\"⚠️ Azure OpenAI 설정이 필요합니다:\")\n",
    "        print(\"   - gpt-endpoint\")\n",
    "        print(\"   - gpt-key\")\n",
    "    \n",
    "    if not Config.SPEECH_KEY:\n",
    "        print(\"⚠️ 음성 기능을 위해 Azure Speech Service 설정이 필요합니다:\")\n",
    "        print(\"   - speech-key\")\n",
    "    \n",
    "    print(\"\\n✅ 시스템 준비 완료!\")\n",
    "    print(\"💡 interactive_conversation() 함수를 실행해보세요!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a4bb057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 🎤 음성 치매 진단 대화 시스템 ===\n",
      "🤖 안녕하세요. 사진을 보며 대화해요.\n",
      "🤖 \"어르신, 이런 축하 자리에 함께하셨던 기억이 있으신가요?\"\n",
      "\n",
      "========================================\n",
      "🎙️ 음성 대화 시작!\n",
      "💡 종료라고 말하면 끝납니다\n",
      "========================================\n",
      "🎙️ 말씀해 주세요...\n",
      "👤 \"아니 나는 이런 기억 없는데?\"\n",
      "🤖 \"아, 그러셨군요. 그래도 이런 화기애애한 분위기는 참 좋아 보이지 않나요? 혹시 축하 행사라면 어떤 종류를 떠올리게 되세요?\"\n",
      "🎙️ 말씀해 주세요...\n",
      "👤 \"축하 자리라면 나는 보통 생일을 떠올르지?\"\n",
      "🤖 \"생일이라니, 정말 따뜻하고 특별한 날이죠. 어르신께서는 기억에 남는 생일 파티가 있으셨나요?\"\n",
      "🎙️ 말씀해 주세요...\n",
      "👤 \"종료.\"\n",
      "🤖 대화를 마치겠습니다. 감사합니다.\n",
      "\n",
      "📊 종합 분석 결과 생성 중...\n",
      "📁 저장 구조:\n",
      "   메인 폴더: conversation_log/images/images_conv2/\n",
      "   대화 파일: images_conv2.txt\n",
      "\n",
      "✅ 파일 저장 완료!\n",
      "📁 대화 폴더: conversation_log\\images\\images_conv2\n",
      "📄 대화 파일: conversation_log\\images\\images_conv2\\images_conv2.txt\n",
      "📊 분석 파일: analysis\\images_conv2_analysis.txt\n",
      "📋 QA 파일들: 2개\n",
      "\n",
      "============================================================\n",
      "📋 치매 진단 대화 분석 리포트\n",
      "============================================================\n",
      "📅 분석 일시: 2025년 06월 08일 00:25:36\n",
      "🆔 대화 ID: images_conv2\n",
      "============================================================\n",
      "\n",
      "🎯 종합 평가\n",
      "──────────────────────────────\n",
      "😊 감정 상태:     ⭐⭐⭐⭐☆ (4/5)\n",
      "💬 답변 일관성:   ⭐⭐⭐⭐⭐ (5/5)\n",
      "🧠 전반적 인지:   ⭐⭐⭐⭐⭐ (5/5)\n",
      "──────────────────────────────\n",
      "\n",
      "📊 대화 개요\n",
      "──────────────────────────────\n",
      "💬 총 대화 횟수: 2회\n",
      "😊 전반적 감정: 긍정적 (주요: 중립)\n",
      "✅ 어긋난 답변: 없음\n",
      "✅ 발화 패턴: 특이사항 없음\n",
      "──────────────────────────────\n",
      "\n",
      "🎉 대화 결과\n",
      "──────────────────────────────\n",
      "✅ 대화 중 특별히 걱정되는 답변은 없었습니다.\n",
      "💚 어르신께서 안정적으로 잘 응답해주셨어요.\n",
      "🌟 지금처럼 따뜻한 환경과 꾸준한 관심 속에 계시면 좋겠습니다.\n",
      "============================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "📖 생성된 추억 이야기\n",
      "==================================================\n",
      "\"응, 축하 자리라면 역시 생일이 가장 먼저 떠오르지. 내가 어린 시절엔 지금처럼 대단한 생일 파티는 없었어. 그래도 그때는 뭐랄까, 참 소박하고 더 따뜻했던 기억이야. 내가 열 살 되던 해, 어머니가 직접 만든 손두부를 내 생일상에 올려주시던 날이 있었지. 그 두부 위에 간장을 살짝 뿌리고, 고소한 참기름 냄새까지 더해지니 그 맛은 지금도 잊히질 않아. 다 같이 식탁에 앉아서 식구들이 웃고 떠들며 밥 먹던 그 순간이 정말 행복했거든.\"\n",
      "\n",
      "\"그날은 비가 조금씩 내렸었는데, 우리 집 마당에 있는 대추나무 잎사귀마다 빗물이 맺혀 반짝거리던 게 아직도 눈에 선해. 아버지가 그러셨어. '올해는 대추가 잘 열릴 거야,' 하시면서 환히 웃으셨는데, 그 표정이 참 좋았어. 가족들과 함께 먹는 따뜻한 밥 한 끼, 그것만으로도 충분히 축하받는 기분이었어.\"\n",
      "\n",
      "\"그리고 우리 마을에서는 생일날 친구들이 집에 와서 나무 한 그루를 심어주는 풍습도 있었는데, 내 생일에는 복숭아나무를 하나 심었어. 손으로 흙 만지면서 함께 땅을 다졌던 그 느낌이 아직도 기억나네. 그 나무가 잘 자라서 몇 년 뒤에 큰 복숭아를 주렁주렁 열었지! 그걸 아버지가 따서 한입 베어물던 날, '우리 아들은 복숭아처럼 달콤한 인생을 살게 될 거야' 하시던 말씀도 마음 깊이 새겨져 있어.\"\n",
      "\n",
      "\"그래서인지 나는 생일 하면 누군가를 축하한다는 것뿐 아니라, 가족이 함께한다는 그 분위기가 떠올라. 너희도 나중에 생일을 맞이할 때, 뭘 먹고 어떻게 축하받든 가족들이 함께 있다는 사실이 얼마나 소중한지 꼭 기억했으면 좋겠구나. 요즘은 생일도 더 화려하게 즐기지만, 그 속\n",
      "==================================================\n",
      "✅ 모든 분석이 완료되었습니다.\n",
      "📂 대화기록: conversation_log\\images\\images_conv2\\images_conv2.txt\n",
      "📊 분석결과: analysis\\images_conv2_analysis.txt\n",
      "📖 스토리: story_telling\\images_story.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'conversation_file': 'conversation_log\\\\images\\\\images_conv2\\\\images_conv2.txt',\n",
       " 'analysis_file': 'analysis\\\\images_conv2_analysis.txt',\n",
       " 'story_file': 'story_telling\\\\images_story.txt',\n",
       " 'story_content': '\"응, 축하 자리라면 역시 생일이 가장 먼저 떠오르지. 내가 어린 시절엔 지금처럼 대단한 생일 파티는 없었어. 그래도 그때는 뭐랄까, 참 소박하고 더 따뜻했던 기억이야. 내가 열 살 되던 해, 어머니가 직접 만든 손두부를 내 생일상에 올려주시던 날이 있었지. 그 두부 위에 간장을 살짝 뿌리고, 고소한 참기름 냄새까지 더해지니 그 맛은 지금도 잊히질 않아. 다 같이 식탁에 앉아서 식구들이 웃고 떠들며 밥 먹던 그 순간이 정말 행복했거든.\"\\n\\n\"그날은 비가 조금씩 내렸었는데, 우리 집 마당에 있는 대추나무 잎사귀마다 빗물이 맺혀 반짝거리던 게 아직도 눈에 선해. 아버지가 그러셨어. \\'올해는 대추가 잘 열릴 거야,\\' 하시면서 환히 웃으셨는데, 그 표정이 참 좋았어. 가족들과 함께 먹는 따뜻한 밥 한 끼, 그것만으로도 충분히 축하받는 기분이었어.\"\\n\\n\"그리고 우리 마을에서는 생일날 친구들이 집에 와서 나무 한 그루를 심어주는 풍습도 있었는데, 내 생일에는 복숭아나무를 하나 심었어. 손으로 흙 만지면서 함께 땅을 다졌던 그 느낌이 아직도 기억나네. 그 나무가 잘 자라서 몇 년 뒤에 큰 복숭아를 주렁주렁 열었지! 그걸 아버지가 따서 한입 베어물던 날, \\'우리 아들은 복숭아처럼 달콤한 인생을 살게 될 거야\\' 하시던 말씀도 마음 깊이 새겨져 있어.\"\\n\\n\"그래서인지 나는 생일 하면 누군가를 축하한다는 것뿐 아니라, 가족이 함께한다는 그 분위기가 떠올라. 너희도 나중에 생일을 맞이할 때, 뭘 먹고 어떻게 축하받든 가족들이 함께 있다는 사실이 얼마나 소중한지 꼭 기억했으면 좋겠구나. 요즘은 생일도 더 화려하게 즐기지만, 그 속',\n",
       " 'summary': '\\n============================================================\\n📋 치매 진단 대화 분석 리포트\\n============================================================\\n📅 분석 일시: 2025년 06월 08일 00:25:36\\n🆔 대화 ID: images_conv2\\n============================================================\\n\\n🎯 종합 평가\\n──────────────────────────────\\n😊 감정 상태:     ⭐⭐⭐⭐☆ (4/5)\\n💬 답변 일관성:   ⭐⭐⭐⭐⭐ (5/5)\\n🧠 전반적 인지:   ⭐⭐⭐⭐⭐ (5/5)\\n──────────────────────────────\\n\\n📊 대화 개요\\n──────────────────────────────\\n💬 총 대화 횟수: 2회\\n😊 전반적 감정: 긍정적 (주요: 중립)\\n✅ 어긋난 답변: 없음\\n✅ 발화 패턴: 특이사항 없음\\n──────────────────────────────\\n\\n🎉 대화 결과\\n──────────────────────────────\\n✅ 대화 중 특별히 걱정되는 답변은 없었습니다.\\n💚 어르신께서 안정적으로 잘 응답해주셨어요.\\n🌟 지금처럼 따뜻한 환경과 꾸준한 관심 속에 계시면 좋겠습니다.\\n============================================================\\n',\n",
       " 'conversation_id': 'images_conv2'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactive_voice_conversation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
