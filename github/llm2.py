import json
import base64
import os
import tiktoken
import random
from dataclasses import dataclass
from typing import List, Optional, Dict, Any
from dotenv import load_dotenv
from openai import AzureOpenAI
from datetime import datetime
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from PIL import Image
import numpy as np

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

@dataclass
class StrangeResponse:
    """ì´ìƒí•œ ë‹µë³€ì„ ì €ì¥í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    question: str
    answer: str
    timestamp: str
    severity: str  # "mild", "moderate", "severe"
    question_type: str = "normal"  # "keyword", "cognitive", "normal"

@dataclass
class ConversationTurn:
    """ëŒ€í™” í„´ì„ ì €ì¥í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    question: str
    answer: str
    timestamp: str
    question_type: str = "normal"  # "keyword", "cognitive", "normal"

class ImageAnalysisGPT:
    """GPT-4oë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë¶„ì„ í´ë˜ìŠ¤"""
    def __init__(self):
        # Azure OpenAI ê´€ë ¨ ì„¤ì •
        self.endpoint = os.getenv("gpt-endpoint")
        self.deployment = "gpt-4o"
        self.subscription_key = os.getenv("gpt-key")
        self.api_version = "2024-12-01-preview"
        
        if not self.endpoint or not self.subscription_key:
            raise ValueError("Please set the gpt-endpoint and gpt-key in the environment variables.")
        
        # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = AzureOpenAI(
            api_version=self.api_version,
            azure_endpoint=self.endpoint,
            api_key=self.subscription_key,
        )
    
    def encode_image_to_base64(self, image_path):
        """ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©"""
        try:
            with open(image_path, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode('utf-8')
        except FileNotFoundError:
            print(f"Error: ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            return None
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ì¸ì½”ë”© ì˜¤ë¥˜: {e}")
            return None
    
    def analyze_image_with_gpt(self, image_path):
        """GPT-4oë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë¶„ì„"""
        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
        base64_image = self.encode_image_to_base64(image_path)
        if not base64_image:
            return None
        
        try:
            response = self.client.chat.completions.create(
                model=self.deployment,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": """ì´ ì´ë¯¸ì§€ë¥¼ ìì„¸íˆ ë¶„ì„í•´ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:

1. caption: ì´ë¯¸ì§€ì˜ ì „ì²´ì ì¸ ì„¤ëª… (êµ¬ì²´ì ìœ¼ë¡œ ê·¸ë¦¬ê³  í•œí¸ì˜ ì´ì•¼ê¸°ì²˜ëŸ¼)
2. dense_captions: ì´ë¯¸ì§€ì˜ ì„¸ë¶€ì ì¸ ìš”ì†Œë“¤ì„ ì—¬ëŸ¬ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª… (ë°°ì—´ í˜•íƒœ)
3. mood: ì´ë¯¸ì§€ì—ì„œ ëŠê»´ì§€ëŠ” ë¶„ìœ„ê¸°ë‚˜ ê°ì •
4. time_period: ì¶”ì •ë˜ëŠ” ì‹œëŒ€ë‚˜ ì‹œê¸°
5. key_objects: ì£¼ìš” ê°ì²´ë“¤ (ë°°ì—´ í˜•íƒœ)
6. people_description: ì‚¬ëŒì´ ìˆë‹¤ë©´ ê·¸ë“¤ì— ëŒ€í•œ ì„¤ëª…
7. people_count: ì‚¬ì§„ ì† ì‚¬ëŒ ìˆ˜ (ìˆ«ìë¡œ)
8. time_of_day: ì´¬ì˜ ì‹œê°„ëŒ€ (ë‚®/ë°¤/ì €ë… ë“±)

ë‹¤ìŒê³¼ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œ ë‹µí•´ì£¼ì„¸ìš”:
{
    "caption": "ì „ì²´ ì´ë¯¸ì§€ ì„¤ëª…",
    "dense_captions": ["ì„¸ë¶€ì‚¬í•­1", "ì„¸ë¶€ì‚¬í•­2", "ì„¸ë¶€ì‚¬í•­3"],
    "mood": "ë¶„ìœ„ê¸° ì„¤ëª…",
    "time_period": "ì¶”ì • ì‹œëŒ€",
    "key_objects": ["ê°ì²´1", "ê°ì²´2", "ê°ì²´3"],
    "people_description": "ì‚¬ëŒë“¤ì— ëŒ€í•œ ì„¤ëª…",
    "people_count": 2,
    "time_of_day": "ë‚®"
}"""
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=1000,
                temperature=0.3
            )
            
            # ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ
            response_text = response.choices[0].message.content
            
            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (```jsonìœ¼ë¡œ ê°ì‹¸ì ¸ ìˆì„ ìˆ˜ ìˆìŒ)
            if "```json" in response_text:
                json_start = response_text.find("```json") + 7
                json_end = response_text.find("```", json_start)
                response_text = response_text[json_start:json_end].strip()
            elif "{" in response_text:
                json_start = response_text.find("{")
                json_end = response_text.rfind("}") + 1
                response_text = response_text[json_start:json_end]
            
            analysis_result = json.loads(response_text)
            
            # ê²°ê³¼ ì¶œë ¥
            print(f"\nCaption: {analysis_result.get('caption', 'N/A')}")
            print(f"Mood: {analysis_result.get('mood', 'N/A')}")
            print(f"Time Period: {analysis_result.get('time_period', 'N/A')}")
            print(f"People Count: {analysis_result.get('people_count', 'N/A')}")
            print(f"Time of Day: {analysis_result.get('time_of_day', 'N/A')}")
            print("\nDense Captions:")
            for caption in analysis_result.get('dense_captions', []):
                print(f"- {caption}")
            
            return analysis_result
            
        except json.JSONDecodeError as e:
            print(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            print(f"ì›ë³¸ ì‘ë‹µ: {response_text}")
            return None
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return None


class IntegratedLLMDescription:
    def __init__(self):
        # Azure OpenAI ê´€ë ¨ ì„¤ì •
        self.endpoint = os.getenv("gpt-endpoint")
        self.deployment = "gpt-4o"
        self.subscription_key = os.getenv("gpt-key")
        self.api_version = "2024-12-01-preview"
        
        if not self.endpoint or not self.subscription_key:
            raise ValueError("Please set the gpt-endpoint and gpt-key in the environment variables.")
        
        # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = AzureOpenAI(
            api_version=self.api_version,
            azure_endpoint=self.endpoint,
            api_key=self.subscription_key,
        )
        
        # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
        self.conversation_history = []
        
        # í† í° ì¹´ìš´í„° ì´ˆê¸°í™”
        self.tokenizer = tiktoken.get_encoding("cl100k_base")  # GPT-4oìš© í† í¬ë‚˜ì´ì €
        self.token_count = 0
        self.MAX_TOKENS = 4000  # ìµœëŒ€ í† í° ì œí•œ
        
        # ì´ìƒí•œ ë‹µë³€ ì¶”ì 
        self.strange_responses = []
        self.strange_response_count = 0
        self.last_question = ""  # ë§ˆì§€ë§‰ ì§ˆë¬¸ ì €ì¥
        self.last_question_type = "normal"  # ë§ˆì§€ë§‰ ì§ˆë¬¸ íƒ€ì…
        
        # ëŒ€í™” ê¸°ë¡ ì¶”ì  (íŒŒì¼ ì €ì¥ìš©)
        self.conversation_turns = []
        
        # ì‹¤ì‹œê°„ ëŒ€í™” ì‹œìŠ¤í…œ ê´€ë ¨ ë³€ìˆ˜
        self.turn_count = 0
        self.image_analysis_result = None  # ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ì €ì¥
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ì§ˆë¬¸
        self.KEYWORD_QUESTIONS = {
            "ë‚¨í¸": "ë‚¨í¸ì—ê²Œ ì „í•˜ê³  ì‹¶ì€ ë§ì´ ìˆë‚˜ìš”?",
            "ì•„ë‚´": "ì•„ë‚´ë¶„ê³¼ì˜ ì¢‹ì€ ì¶”ì–µì´ ë˜ ìˆë‚˜ìš”?",
            "ì†ì": "ìš”ì¦˜ ì†ìëŠ” í•™êµ ì˜ ë‹¤ë‹ˆë‚˜ìš”?",
            "ì†ë…€": "ì†ë…€ëŠ” ìš”ì¦˜ ë­˜ í•˜ë©° ì§€ë‚´ë‚˜ìš”?",
            "ì•„ë“¤": "ì•„ë“¤ì€ ìš”ì¦˜ ì–´ë–»ê²Œ ì§€ë‚´ë‚˜ìš”?",
            "ë”¸": "ë”¸ê³¼ì˜ ì¶”ì–µ ì¤‘ì— íŠ¹ë³„í•œ ê²Œ ìˆë‚˜ìš”?",
            "ì—„ë§ˆ": "ì–´ë¨¸ë‹˜ì€ ì–´ë–¤ ë¶„ì´ì…¨ì–´ìš”?",
            "ì•„ë²„ì§€": "ì•„ë²„ë‹˜ì€ ì–´ë–¤ ë¶„ì´ì…¨ë‚˜ìš”?",
            "ì¹œêµ¬": "ê·¸ ì¹œêµ¬ë¶„ê³¼ëŠ” ìì£¼ ë§Œë‚˜ì…¨ë‚˜ìš”?",
            "ì—¬í–‰": "ê·¸ë•Œ ì—¬í–‰ì´ ì¦ê±°ìš°ì…¨ë‚˜ìš”?",
            "ì§‘": "ê·¸ ì§‘ì—ì„œ ì‚´ ë•Œê°€ ê·¸ë¦¬ìš°ì‹œë‚˜ìš”?",
        }
        
        # ì¸ì§€ ëŠ¥ë ¥ ê²€ì‚¬ ì§ˆë¬¸ (ë™ì  ìƒì„±)
        self.base_cognitive_questions = [
            "ì´ ì‚¬ì§„ì—ëŠ” ëª‡ ëª…ì´ ìˆëŠ”ì§€ ê¸°ì–µë‚˜ì„¸ìš”?",
            "ì‚¬ì§„ì´ ë‚®ì— ì°íŒ ê²ƒ ê°™ë‚˜ìš”, ë°¤ì¸ê°€ìš”?",
            "ì´ ì‚¬ì§„ì—ì„œ ê°€ì¥ ëˆˆì— ë„ëŠ” ê²ƒì´ ë¬´ì—‡ì¸ê°€ìš”?",
        ]
        
    def _count_tokens(self, text: str) -> int:
        """ë¬¸ìì—´ì˜ í† í° ìˆ˜ ê³„ì‚°"""
        return len(self.tokenizer.encode(text))
    
    def _count_message_tokens(self, messages: List[Dict[str, Any]]) -> int:
        """ëŒ€í™” ë©”ì‹œì§€ ëª©ë¡ì˜ ì´ í† í° ìˆ˜ ê³„ì‚°"""
        total = 0
        for message in messages:
            total += self._count_tokens(message.get("content", ""))
        return total
    
    def _evaluate_response_relevance(self, question: str, answer: str, question_type: str = "normal") -> Dict[str, Any]:
        """ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ì„±ì´ ìˆëŠ”ì§€ LLMìœ¼ë¡œ í‰ê°€"""
        
        # ì§ˆë¬¸ íƒ€ì…ì— ë”°ë¥¸ í‰ê°€ ê¸°ì¤€ ì¡°ì •
        if question_type == "cognitive":
            evaluation_criteria = """
íŠ¹ë³„íˆ ì´ ì§ˆë¬¸ì€ ì¸ì§€ ëŠ¥ë ¥ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ì§ˆë¬¸ì…ë‹ˆë‹¤. ë‹¤ìŒì„ ì¤‘ì ì ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”:
- ì§ˆë¬¸ì—ì„œ ìš”êµ¬í•˜ëŠ” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì œê³µí–ˆëŠ”ì§€ (ì˜ˆ: ìˆ«ì, ì‹œê°„ëŒ€ ë“±)
- í˜„ì‹¤ ì¸ì‹ ëŠ¥ë ¥ì´ ì ì ˆí•œì§€
- ì‹œê³µê°„ ì§€ë‚¨ë ¥ì´ ìœ ì§€ë˜ê³  ìˆëŠ”ì§€
"""
        elif question_type == "keyword":
            evaluation_criteria = """
ì´ ì§ˆë¬¸ì€ íŠ¹ì • í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ê°ì •ì  ì—°ê²° ì§ˆë¬¸ì…ë‹ˆë‹¤. ë‹¤ìŒì„ í‰ê°€í•´ì£¼ì„¸ìš”:
- ì§ˆë¬¸ì˜ ëŒ€ìƒ(ì‚¬ëŒì´ë‚˜ ìƒí™©)ì— ëŒ€í•œ ì ì ˆí•œ ë°˜ì‘ì¸ì§€
- ê°ì •ì  ì—°ê²°ì„±ì´ ìˆëŠ”ì§€
- ê¸°ì–µê³¼ ê´€ë ¨ëœ ì ì ˆí•œ ë‚´ìš©ì¸ì§€
"""
        else:
            evaluation_criteria = """
ì¼ë°˜ì ì¸ ëŒ€í™” ì§ˆë¬¸ì…ë‹ˆë‹¤. ë‹¤ìŒì„ í‰ê°€í•´ì£¼ì„¸ìš”:
- ì§ˆë¬¸ê³¼ ë‹µë³€ì˜ ì¼ë°˜ì ì¸ ê´€ë ¨ì„±
- ëŒ€í™”ì˜ ìì—°ìŠ¤ëŸ¬ìš´ íë¦„
"""
        
        evaluation_prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë¶„ì„í•´ì„œ ë‹µë³€ì´ ì–¼ë§ˆë‚˜ ì ì ˆí•œì§€ í‰ê°€í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {question}
ë‹µë³€: {answer}
ì§ˆë¬¸ íƒ€ì…: {question_type}

{evaluation_criteria}

í‰ê°€ ê¸°ì¤€:
1. ì§ˆë¬¸ê³¼ ë‹µë³€ì˜ ê´€ë ¨ì„±
2. ë‹µë³€ì˜ ì¼ê´€ì„±
3. ë§¥ë½ì  ì ì ˆì„±

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•´ì£¼ì„¸ìš”:
{{
    "is_strange": true/false,
    "severity": "normal/mild/moderate/severe",
    "reason": "í‰ê°€ ì´ìœ ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…"
}}

severity ê¸°ì¤€:
- normal: ì™„ì „íˆ ì ì ˆí•œ ë‹µë³€
- mild: ì•½ê°„ ë²—ì–´ë‚¬ì§€ë§Œ ì´í•´ ê°€ëŠ¥
- moderate: ìƒë‹¹íˆ ì—‰ëš±í•˜ì§€ë§Œ ì™„ì „íˆ ë¬´ê´€í•˜ì§€ëŠ” ì•ŠìŒ
- severe: ì™„ì „íˆ ë¬´ê´€í•˜ê±°ë‚˜ ë¹„ë…¼ë¦¬ì ì¸ ë‹µë³€
"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.deployment,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹˜ë§¤ í™˜ìì˜ ë‹µë³€ì„ í‰ê°€í•˜ëŠ” ì˜ë£Œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê°ê´€ì ì´ê³  ì •í™•í•˜ê²Œ í‰ê°€í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": evaluation_prompt}
                ],
                max_tokens=256,
                temperature=0.1,  # ì¼ê´€ëœ í‰ê°€ë¥¼ ìœ„í•´ ë‚®ì€ temperature
                top_p=1.0,
            )
            
            evaluation_text = response.choices[0].message.content
            
            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
            if "```json" in evaluation_text:
                json_start = evaluation_text.find("```json") + 7
                json_end = evaluation_text.find("```", json_start)
                evaluation_text = evaluation_text[json_start:json_end].strip()
            elif "{" in evaluation_text:
                json_start = evaluation_text.find("{")
                json_end = evaluation_text.rfind("}") + 1
                evaluation_text = evaluation_text[json_start:json_end]
            
            evaluation_json = json.loads(evaluation_text)
            return evaluation_json
            
        except (json.JSONDecodeError, Exception) as e:
            print(f"ë‹µë³€ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "is_strange": False,
                "severity": "normal",
                "reason": "í‰ê°€ ì‹¤íŒ¨"
            }
    
    def _store_strange_response(self, question: str, answer: str, severity: str, reason: str, question_type: str = "normal"):
        """ì´ìƒí•œ ë‹µë³€ì„ ì €ì¥ (ì½˜ì†” ì¶œë ¥ ì œê±°)"""
        strange_response = StrangeResponse(
            question=question,
            answer=answer,
            timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            severity=severity,
            question_type=question_type
        )
        
        self.strange_responses.append(strange_response)
        self.strange_response_count += 1
    
    def _generate_dynamic_cognitive_questions(self):
        """ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë™ì  ì¸ì§€ ì§ˆë¬¸ ìƒì„±"""
        if not self.image_analysis_result:
            return self.base_cognitive_questions
        
        dynamic_questions = []
        
        # ì‚¬ëŒ ìˆ˜ ê´€ë ¨ ì§ˆë¬¸
        people_count = self.image_analysis_result.get('people_count', 0)
        if people_count > 0:
            dynamic_questions.append(f"ì´ ì‚¬ì§„ì—ëŠ” ëª‡ ëª…ì´ ìˆëŠ”ì§€ ê¸°ì–µë‚˜ì„¸ìš”?")
        
        # ì‹œê°„ëŒ€ ê´€ë ¨ ì§ˆë¬¸
        time_of_day = self.image_analysis_result.get('time_of_day', '')
        if time_of_day:
            dynamic_questions.append(f"ì‚¬ì§„ì´ ë‚®ì— ì°íŒ ê²ƒ ê°™ë‚˜ìš”, ë°¤ì¸ê°€ìš”?")
        
        # ì£¼ìš” ê°ì²´ ê´€ë ¨ ì§ˆë¬¸
        key_objects = self.image_analysis_result.get('key_objects', [])
        if key_objects:
            obj = random.choice(key_objects)
            dynamic_questions.append(f"ì´ ì‚¬ì§„ì—ì„œ {obj}ì´(ê°€) ë³´ì´ì‹œë‚˜ìš”?")
        
        # ê¸°ë³¸ ì§ˆë¬¸ê³¼ í•©ì³ì„œ ë°˜í™˜
        all_questions = self.base_cognitive_questions + dynamic_questions
        return all_questions
    
    def setup_conversation_context(self, analysis_result, user_description="", user_description_date=""):
        """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì„¤ì • (í†µí•© ë²„ì „)"""
        self.image_analysis_result = analysis_result  # ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ì €ì¥
        
        caption = analysis_result.get("caption", "")
        dense_captions = analysis_result.get("dense_captions", [])
        mood = analysis_result.get("mood", "")
        time_period = analysis_result.get("time_period", "")
        key_objects = analysis_result.get("key_objects", [])
        people_description = analysis_result.get("people_description", "")
        
        # ìƒì„¸ ìº¡ì…˜ í…ìŠ¤íŠ¸ í¬ë§·íŒ…
        dense_captions_text = "\n".join([f"- {dc}" for dc in dense_captions])
        key_objects_text = ", ".join(key_objects)
        
        # í†µí•©ëœ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„¤ì •
        system_message = f"""ë„ˆëŠ” ë…¸ì¸ê³¼ ëŒ€í™”í•˜ëŠ” ìš”ì–‘ë³´í˜¸ì‚¬ì•¼. ë…¸ì¸ê³¼ íŠ¹ì • ì´ë¯¸ì§€ì— ëŒ€í•´ì„œ ì§ˆì˜ì‘ë‹µì„ ì£¼ê³ ë°›ì•„. 
ë…¸ì¸ì€ ì¹˜ë§¤ ì¦ìƒì´ ê°‘ìê¸° ë‚˜íƒ€ë‚  ìˆ˜ë„ ìˆì–´. ë°˜ë³µë˜ëŠ” ë§ì—ë„ ë˜‘ê°™ì´ ëŒ€ë‹µí•´ì¤˜ì•¼ í•´. 
ì¹œì ˆí•˜ê³  ì–´ë¥¸ì„ ê³µê²½í•˜ëŠ” ë§íˆ¬ì—¬ì•¼ í•´. ê·¸ë¦¬ê³  ê³µê°ì„ ì˜ í•´ì•¼ í•´. ì˜ˆì˜ë„ ì§€ì¼œ. 
ë„ˆëŠ” ì£¼ë¡œ ì§ˆë¬¸ì„ í•˜ëŠ” ìª½ì´ê³ , ë…¸ì¸ì€ ëŒ€ë‹µì„ í•´ì¤„ê±°ì•¼. ëŒ€ë‹µì— ëŒ€í•œ ë¦¬ì•¡ì…˜ê³¼ í•¨ê»˜ ì ì ˆíˆ ëŒ€í™”ë¥¼ ì´ì–´ ê°€.
ë…¸ì¸ì˜ ë°œì–¸ì´ ëë‚˜ë©´ ê·¸ì™€ ê´€ë ¨ëœ ê³µê° ë¬¸ì¥ì„ ë¨¼ì € ë§í•œ í›„, ìì—°ìŠ¤ëŸ½ê²Œ ê·¸ ê¸°ì–µì— ëŒ€í•´ ë” ë¬¼ì–´ë³´ëŠ” ê¼¬ë¦¬ ì§ˆë¬¸ì„ ë§ë¶™ì—¬.

=== ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ===
ì£¼ìš” ì„¤ëª…(Caption): {caption}
ë¶„ìœ„ê¸°/ê°ì •: {mood}
ì¶”ì • ì‹œëŒ€: {time_period}
ì£¼ìš” ê°ì²´ë“¤: {key_objects_text}
ì¸ë¬¼ ì„¤ëª…: {people_description}

ì„¸ë¶€ ìš”ì†Œë“¤:
{dense_captions_text}

=== ëŒ€í™” ê°€ì´ë“œë¼ì¸ ===
1. ì–´ë¥´ì‹ ë“¤(íŠ¹íˆ ì¹˜ë§¤ í™˜ì)ê³¼ ëŒ€í™”í•œë‹¤ê³  ê°€ì •í•˜ê³  ì¹œê·¼í•˜ê³  ë”°ëœ»í•˜ê²Œ ëŒ€í™”í•˜ì„¸ìš”.
2. ì´ë¯¸ì§€ì— ëŒ€í•œ í¥ë¯¸ë¡œìš´ ì§ˆë¬¸ì„ ë¨¼ì € ë˜ì ¸ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”.
3. ì‚¬ìš©ìê°€ ì—‰ëš±í•œ ë‹µë³€ì„ í•´ë„ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°€ë©° ì¹œì ˆí•˜ê²Œ ì´ëŒì–´ì£¼ì„¸ìš”.
4. ê·¸ë•Œ ë‹¹ì‹œì˜ ê°ì •ì´ë‚˜ ê²½í—˜ì— ëŒ€í•´ ë¬¼ì–´ë³´ë©° ì¶”ì–µì„ ë˜ì‚´ë ¤ì£¼ì„¸ìš”.

=== ëŒ€í™” ì „ëµ ===
ë¬¸ì œ ìƒí™©ë³„ í•´ê²° ë°©ë²•:

â–ª ì§ˆë¬¸ì„ ì´í•´í•˜ì§€ ëª»í•  ê²½ìš°:
  - ì§ˆë¬¸ì„ ë‹¨ìˆœí™”í•˜ì—¬ ì¬êµ¬ì„±
  - ì„ íƒì§€ë¥¼ ì œê³µí•˜ì—¬ ë‹µí•˜ê¸° ì‰½ê²Œ ë§Œë“¤ê¸°
  - ì˜ˆì‹œë‚˜ ë§¥ë½ì„ í•¨ê»˜ ì œê³µ

â–ª ì—‰ëš±í•œ ëŒ€ë‹µì„ í•  ê²½ìš°:
  - ëŒ€ë‹µì„ ìˆ˜ìš©í•˜ë©´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ì£¼ì œë¡œ ìœ ë„
  - ëŒ€ë‹µì˜ ì¼ë¶€ë¶„ì´ë¼ë„ ì—°ê²°ì ì„ ì°¾ì•„ ì´ì–´ê°€ê¸°

â–ª ëŒ€ë‹µì„ ëª»í•  ê²½ìš°:
  - ì‹¬ë¦¬ì  ë¶€ë‹´ ì—†ì´ ë„˜ì–´ê°€ê¸°
  - "ê¸°ì–µì´ ì•ˆ ë‚˜ì…”ë„ ê´œì°®ë‹¤"ê³  ì•ˆì‹¬ì‹œí‚¤ê¸°

ì´ë¯¸ì§€ì˜ ì‹œê°ì  ìš”ì†Œë“¤ì„ ìƒìƒí•˜ê²Œ ë¬˜ì‚¬í•˜ë©°, ê·¸ë•Œì˜ ê°ì •ê³¼ ìƒí™©ì— ëŒ€í•´ ê¶ê¸ˆí•´í•˜ëŠ” ì†ì/ì†ë…€ì˜ ë§ˆìŒìœ¼ë¡œ ëŒ€í™”í•˜ì„¸ìš”."""
        
        # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ë° í† í° ìˆ˜ ê³„ì‚°
        self.conversation_history = [{"role": "system", "content": system_message}]
        self.token_count = self._count_tokens(system_message)
        
        return system_message
    
    def generate_initial_question(self):
        """ì²« ì§ˆë¬¸ ìƒì„± í•¨ìˆ˜"""
        response = self.client.chat.completions.create(
            model=self.deployment,
            messages=self.conversation_history + [
                {"role": "user", "content": "ì´ ì˜›ë‚  ì‚¬ì§„ì— ëŒ€í•´ ì–´ë¥´ì‹ ì—ê²Œ ë¬¼ì–´ë³¼ ì²« ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”. ê°„ë‹¨í•˜ê³  ê¸°ì–µí•˜ê¸° ì‰¬ìš°ë©°, ê°ì •ì ìœ¼ë¡œ ì—°ê²°ë  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì´ì–´ì•¼ í•©ë‹ˆë‹¤."}
            ],
            max_tokens=512,
            temperature=0.8,
            top_p=1.0,
        )
        
        initial_question = response.choices[0].message.content
        
        # ì§ˆë¬¸ ì¶”ê°€ ë° í† í° ìˆ˜ ì—…ë°ì´íŠ¸
        self.conversation_history.append({"role": "assistant", "content": initial_question})
        self.token_count += self._count_tokens(initial_question)
        
        # ë§ˆì§€ë§‰ ì§ˆë¬¸ ì €ì¥
        self.last_question = initial_question
        self.last_question_type = "normal"
        
        return initial_question
    
    def _get_next_question_type_and_content(self, user_input):
        """ë‹¤ìŒ ì§ˆë¬¸ì˜ íƒ€ì…ê³¼ ë‚´ìš©ì„ ê²°ì •í•˜ëŠ” í†µí•© ë¡œì§"""
        self.turn_count += 1
        
        # 1. í‚¤ì›Œë“œ ê¸°ë°˜ ì§ˆë¬¸ ì²´í¬ (ìš°ì„ ìˆœìœ„ 1)
        for keyword, question in self.KEYWORD_QUESTIONS.items():
            if keyword in user_input:
                return "keyword", question
        
        # 2. ì¸ì§€ ëŠ¥ë ¥ ê²€ì‚¬ ì§ˆë¬¸ (3í„´ë§ˆë‹¤, ìš°ì„ ìˆœìœ„ 2)
        if self.turn_count > 0 and self.turn_count % 3 == 0:
            cognitive_questions = self._generate_dynamic_cognitive_questions()
            question = random.choice(cognitive_questions)
            return "cognitive", question
        
        # 3. ì¼ë°˜ ëŒ€í™” ê³„ì† (ìš°ì„ ìˆœìœ„ 3)
        return "normal", None
    
    def chat_about_image(self, user_query):
        """ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µ ìƒì„± (í†µí•© ë²„ì „)"""
        # í† í° ì œí•œ í™•ì¸
        user_tokens = self._count_tokens(user_query)
        
        # ì‚¬ìš©ì ë‹µë³€ì˜ ì ì ˆì„± í‰ê°€ (ì´ì „ ì§ˆë¬¸ì´ ìˆëŠ” ê²½ìš°)
        if self.last_question:
            evaluation = self._evaluate_response_relevance(
                self.last_question, 
                user_query, 
                self.last_question_type
            )
            
            if evaluation.get("is_strange", False):
                severity = evaluation.get("severity", "mild")
                reason = evaluation.get("reason", "ê´€ë ¨ì„± ë¶€ì¡±")
                
                # ì´ìƒí•œ ë‹µë³€ ì €ì¥
                self._store_strange_response(
                    question=self.last_question,
                    answer=user_query,
                    severity=severity,
                    reason=reason,
                    question_type=self.last_question_type
                )
        
        # ëŒ€í™” í„´ ì €ì¥ (ì§ˆë¬¸-ë‹µë³€ ìŒ)
        if self.last_question:
            conversation_turn = ConversationTurn(
                question=self.last_question,
                answer=user_query,
                timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                question_type=self.last_question_type
            )
            self.conversation_turns.append(conversation_turn)
        
        # ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€
        self.conversation_history.append({"role": "user", "content": user_query})
        self.token_count += user_tokens
        
        # í† í° ì œí•œ ì´ˆê³¼ í™•ì¸
        if self.token_count > self.MAX_TOKENS:
            answer = "ì£„ì†¡í•©ë‹ˆë‹¤, ë‚˜ì¤‘ì— ë‹¤ì‹œ ì–˜ê¸°í•´ìš”. ì§€ê¸ˆì€ ì ì‹œ ì‰¬ì–´ì•¼ í•  ê²ƒ ê°™ì•„ìš”. ë§Œì•½ ë” ë§ì€ ëŒ€í™”ë¥¼ ì›í•œë‹¤ë©´ MEMENTO BOX Premiumì„ ì‚¬ìš©í•´ë³´ì„¸ìš”."
            self.conversation_history.append({"role": "assistant", "content": answer})
            return answer, True, "normal"  # TrueëŠ” ëŒ€í™” ì¢…ë£Œ ì‹ í˜¸
        
        # ë‹¤ìŒ ì§ˆë¬¸ íƒ€ì…ê³¼ ë‚´ìš© ê²°ì •
        next_question_type, special_question = self._get_next_question_type_and_content(user_query)
        
        if special_question:
            # íŠ¹ë³„ ì§ˆë¬¸ (í‚¤ì›Œë“œ ê¸°ë°˜ ë˜ëŠ” ì¸ì§€ ê²€ì‚¬)
            answer = special_question
            question_type = next_question_type
        else:
            # ì¼ë°˜ LLM ì‘ë‹µ ìƒì„±
            response = self.client.chat.completions.create(
                model=self.deployment,
                messages=self.conversation_history,
                max_tokens=1024,
                temperature=0.7,
                top_p=1.0,
            )
            answer = response.choices[0].message.content
            question_type = "normal"
        
        # ì‘ë‹µ ì¶”ê°€ ë° í† í° ìˆ˜ ì—…ë°ì´íŠ¸
        self.conversation_history.append({"role": "assistant", "content": answer})
        self.token_count += self._count_tokens(answer)
        
        # ë‹¤ìŒ í‰ê°€ë¥¼ ìœ„í•´ í˜„ì¬ AI ì‘ë‹µì„ ì§ˆë¬¸ìœ¼ë¡œ ì €ì¥
        self.last_question = answer
        self.last_question_type = question_type
        
        # í† í° ì œí•œ ì´ˆê³¼ í™•ì¸ (ì‘ë‹µ í›„)
        if self.token_count > self.MAX_TOKENS:
            return answer, True, question_type  # ëŒ€í™” ì¢…ë£Œ ì‹ í˜¸
        
        return answer, False, question_type  # ëŒ€í™” ê³„ì†
    
    def generate_mobile_report(self, image_path, output_dir="reports"):
        """ëª¨ë°”ì¼ í™”ë©´ì— ìµœì í™”ëœ ë¦¬í¬íŠ¸ ìƒì„± (ê°œì„ ëœ ë²„ì „)"""
        
        # í•œê¸€ í°íŠ¸ ì„¤ì • (ì‹œìŠ¤í…œì— ìˆëŠ” í•œê¸€ í°íŠ¸ ì°¾ê¸°)
        try:
            # Windows
            font_path = "C:/Windows/Fonts/malgun.ttf"
            if not os.path.exists(font_path):
                # macOS
                font_path = "/System/Library/Fonts/AppleGothic.ttf"
                if not os.path.exists(font_path):
                    # Linux (Ubuntu)
                    font_path = "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"
            
            if os.path.exists(font_path):
                font_prop = fm.FontProperties(fname=font_path)
                plt.rcParams['font.family'] = font_prop.get_name()
            else:
                # ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
                plt.rcParams['font.family'] = 'DejaVu Sans'
        except:
            plt.rcParams['font.family'] = 'DejaVu Sans'
        
        plt.rcParams['axes.unicode_minus'] = False
        
        # ë¦¬í¬íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(output_dir, exist_ok=True)
        
        # ì „ì²´ ë‹µë³€ íšŸìˆ˜ ê³„ì‚°
        total_responses = len(self.conversation_turns)
        
        if total_responses == 0:
            print("ëŒ€í™”ê°€ ì§„í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        # ì‹¬ê°ë„ë³„ ë¶„ë¥˜
        severity_counts = {"mild": 0, "moderate": 0, "severe": 0}
        question_type_counts = {"normal": 0, "keyword": 0, "cognitive": 0}
        
        for response in self.strange_responses:
            severity_counts[response.severity] += 1
        
        for turn in self.conversation_turns:
            question_type_counts[turn.question_type] += 1
        
        # ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚°
        risk_score = (severity_counts['mild'] * 1 + 
                     severity_counts['moderate'] * 3 + 
                     severity_counts['severe'] * 5)
        max_risk_score = self.strange_response_count * 5 if self.strange_response_count > 0 else 1
        risk_percentage = (risk_score / max_risk_score * 100) if max_risk_score > 0 else 0
        
        # ëª¨ë°”ì¼ í™”ë©´ì— ìµœì í™”ëœ ì„¸ë¡œí˜• ë ˆì´ì•„ì›ƒ ìƒì„±
        fig = plt.figure(figsize=(9, 16), facecolor='#f8f9fa')  # ë” ê¹”ë”í•œ ë°°ê²½ìƒ‰
        
        # ì „ì²´ íƒ€ì´í‹€ ì¶”ê°€
        fig.suptitle('í†µí•© ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ë¶„ì„ ë¦¬í¬íŠ¸', fontsize=18, fontweight='bold', y=0.98, color='#2c3e50')
        
        # 1. ìƒë‹¨: ì›ë³¸ ì´ë¯¸ì§€ í‘œì‹œ
        ax1 = plt.subplot2grid((8, 2), (0, 0), colspan=2, rowspan=1)
        try:
            img = Image.open(image_path)
            # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (ëª¨ë°”ì¼ í™”ë©´ì— ë§ê²Œ)
            img.thumbnail((500, 300), Image.Resampling.LANCZOS)
            ax1.imshow(img)
            ax1.axis('off')
            # ì´ë¯¸ì§€ í…Œë‘ë¦¬ ì¶”ê°€
            for spine in ax1.spines.values():
                spine.set_visible(True)
                spine.set_linewidth(2)
                spine.set_color('#34495e')
        except Exception as e:
            ax1.text(0.5, 0.5, f'ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨\n{os.path.basename(image_path)}', 
                    ha='center', va='center', fontsize=12, 
                    bbox=dict(boxstyle="round,pad=0.5", facecolor="#e74c3c", alpha=0.8, edgecolor='none'))
            ax1.set_xlim(0, 1)
            ax1.set_ylim(0, 1)
            ax1.axis('off')
        
        # 2. ì™¼ìª½: ì£¼ìš” ìˆ˜ì¹˜ í‘œì‹œ
        ax2 = plt.subplot2grid((8, 2), (1, 0), rowspan=2)
        ax2.axis('off')
        
        # ìˆ˜ì¹˜ ì •ë³´ í…ìŠ¤íŠ¸ (ë” ê¹”ë”í•˜ê²Œ)
        stats_text = f"""[í†µí•© ëŒ€í™” ë¶„ì„ ê²°ê³¼]

â–ª ì „ì²´ ë‹µë³€: {total_responses}íšŒ
â–ª ì´ìƒ ë‹µë³€: {self.strange_response_count}íšŒ ({(self.strange_response_count/total_responses*100):.1f}%)
â–ª ìœ„í—˜ë„: {risk_percentage:.1f}% ({risk_score}/{max_risk_score}ì )

ëŒ€í™” íƒ€ì…ë³„ ë¶„ë¥˜:
  â— ì¼ë°˜: {question_type_counts['normal']}íšŒ
  â— í‚¤ì›Œë“œ: {question_type_counts['keyword']}íšŒ
  â— ì¸ì§€ê²€ì‚¬: {question_type_counts['cognitive']}íšŒ

ì‹¬ê°ë„ë³„ ë¶„ë¥˜:
  â— ê²½ë¯¸: {severity_counts['mild']}íšŒ
  â— ë³´í†µ: {severity_counts['moderate']}íšŒ  
  â— ì‹¬ê°: {severity_counts['severe']}íšŒ"""
        
        ax2.text(0.05, 0.95, stats_text, fontsize=11, va='top', 
                bbox=dict(boxstyle="round,pad=0.8", facecolor="#ecf0f1", alpha=0.9, 
                         edgecolor='#bdc3c7', linewidth=1.5))
        
        # 3. ì˜¤ë¥¸ìª½: ìƒì„¸ ê¸°ë¡ ì˜ˆì‹œ
        ax3 = plt.subplot2grid((8, 2), (1, 1), rowspan=2)
        ax3.axis('off')
        
        # ìƒì„¸ ê¸°ë¡ ì˜ˆì‹œ í…ìŠ¤íŠ¸
        detail_examples = "[ìƒì„¸ ê¸°ë¡ ì˜ˆì‹œ]\n\n"
        
        if self.strange_response_count > 0:
            # ìµœëŒ€ 3ê°œ ì˜ˆì‹œë§Œ í‘œì‹œ
            examples_to_show = min(3, len(self.strange_responses))
            for i, response in enumerate(self.strange_responses[:examples_to_show]):
                severity_symbol = {"mild": "â—", "moderate": "â—", "severe": "â—"}
                severity_name = {"mild": "ê²½ë¯¸", "moderate": "ë³´í†µ", "severe": "ì‹¬ê°"}
                type_name = {"normal": "ì¼ë°˜", "keyword": "í‚¤ì›Œë“œ", "cognitive": "ì¸ì§€"}
                
                detail_examples += f"{severity_symbol[response.severity]} [{severity_name[response.severity]}][{type_name[response.question_type]}]\n"
                detail_examples += f"Q: {response.question[:20]}...\n"
                detail_examples += f"A: {response.answer[:20]}...\n\n"
            
            if len(self.strange_responses) > 3:
                detail_examples += f"... ì™¸ {len(self.strange_responses) - 3}ê±´ ë”"
        else:
            detail_examples += "âœ“ ì´ìƒ ë‹µë³€ì´ ê°ì§€ë˜ì§€\n    ì•Šì•˜ìŠµë‹ˆë‹¤.\n\nì •ìƒì ì¸ ëŒ€í™”ê°€\nì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤."
        
        ax3.text(0.05, 0.95, detail_examples, fontsize=10, va='top',
                bbox=dict(boxstyle="round,pad=0.8", facecolor="#fff3cd" if self.strange_response_count > 0 else "#d4edda", 
                         alpha=0.9, edgecolor='#ffeaa7' if self.strange_response_count > 0 else '#c3e6cb', linewidth=1.5))
        
        # 4. ì™¼ìª½: ì „ì²´ ëŒ€í™” ë¶„ì„ ë°” ê·¸ë˜í”„
        ax4 = plt.subplot2grid((8, 2), (3, 0), rowspan=2)
        
        categories = ['ì •ìƒ\në‹µë³€', 'ì´ìƒ\në‹µë³€']
        counts = [total_responses - self.strange_response_count, self.strange_response_count]
        colors = ['#27ae60', '#e74c3c']  # ë” ì„ ëª…í•œ ìƒ‰ìƒ
        
        bars1 = ax4.bar(categories, counts, color=colors, alpha=0.8, width=0.6, edgecolor='white', linewidth=2)
        ax4.set_title('ëŒ€í™” ë¶„ì„', fontsize=13, fontweight='bold', pad=15, color='#2c3e50')
        ax4.set_ylabel('ë‹µë³€ íšŸìˆ˜', fontsize=11, color='#34495e')
        
        # ë°” ìœ„ì— ìˆ«ì í‘œì‹œ (ë” ê¹”ë”í•˜ê²Œ)
        for bar, count in zip(bars1, counts):
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width()/2., height + 0.2,
                    f'{count}íšŒ', ha='center', va='bottom', fontsize=11, fontweight='bold', color='#2c3e50')
        
        # ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ë§
        ax4.set_ylim(0, max(counts) * 1.3)
        ax4.grid(axis='y', alpha=0.2, linestyle='--')
        ax4.spines['top'].set_visible(False)
        ax4.spines['right'].set_visible(False)
        ax4.tick_params(colors='#34495e')
        
        # 5. ì˜¤ë¥¸ìª½: ì‹¬ê°ë„ë³„ ì´ìƒ ë‹µë³€ ë°” ê·¸ë˜í”„
        ax5 = plt.subplot2grid((8, 2), (3, 1), rowspan=2)
        
        if self.strange_response_count > 0:
            severity_labels = ['ê²½ë¯¸', 'ë³´í†µ', 'ì‹¬ê°']
            severity_values = [severity_counts['mild'], severity_counts['moderate'], severity_counts['severe']]
            severity_colors = ['#f39c12', '#e67e22', '#e74c3c']  # ë” ì„ ëª…í•œ ìƒ‰ìƒ
            
            bars2 = ax5.bar(severity_labels, severity_values, color=severity_colors, alpha=0.8, 
                           width=0.6, edgecolor='white', linewidth=2)
            ax5.set_title('ì´ìƒ ë‹µë³€ ì‹¬ê°ë„', fontsize=13, fontweight='bold', pad=15, color='#2c3e50')
            ax5.set_ylabel('ë‹µë³€ íšŸìˆ˜', fontsize=11, color='#34495e')
            
            # ë°” ìœ„ì— ìˆ«ì í‘œì‹œ
            for bar, count in zip(bars2, severity_values):
                height = bar.get_height()
                if height > 0:
                    ax5.text(bar.get_x() + bar.get_width()/2., height + 0.05,
                            f'{count}íšŒ', ha='center', va='bottom', fontsize=11, fontweight='bold', color='#2c3e50')
            
            ax5.set_ylim(0, max(severity_values) * 1.4 if max(severity_values) > 0 else 1)
            ax5.grid(axis='y', alpha=0.2, linestyle='--')
            ax5.spines['top'].set_visible(False)
            ax5.spines['right'].set_visible(False)
            ax5.tick_params(colors='#34495e')
        else:
            ax5.text(0.5, 0.5, 'ì´ìƒ ë‹µë³€ ì—†ìŒ', ha='center', va='center', 
                    fontsize=13, fontweight='bold', color='#27ae60', transform=ax5.transAxes,
                    bbox=dict(boxstyle="round,pad=0.5", facecolor="#d4edda", alpha=0.8, edgecolor='#c3e6cb'))
            ax5.set_xlim(0, 1)
            ax5.set_ylim(0, 1)
            ax5.axis('off')
        
        # 6. ìƒˆë¡œ ì¶”ê°€: ì§ˆë¬¸ íƒ€ì…ë³„ ë¶„ì„
        ax6 = plt.subplot2grid((8, 2), (5, 0), colspan=2, rowspan=1)
        
        type_labels = ['ì¼ë°˜ ëŒ€í™”', 'í‚¤ì›Œë“œ ê¸°ë°˜', 'ì¸ì§€ ê²€ì‚¬']
        type_values = [question_type_counts['normal'], question_type_counts['keyword'], question_type_counts['cognitive']]
        type_colors = ['#3498db', '#9b59b6', '#e67e22']
        
        bars3 = ax6.bar(type_labels, type_values, color=type_colors, alpha=0.8, 
                       width=0.6, edgecolor='white', linewidth=2)
        ax6.set_title('ì§ˆë¬¸ íƒ€ì…ë³„ ëŒ€í™” ë¶„ì„', fontsize=13, fontweight='bold', pad=15, color='#2c3e50')
        ax6.set_ylabel('ëŒ€í™” íšŸìˆ˜', fontsize=11, color='#34495e')
        
        # ë°” ìœ„ì— ìˆ«ì í‘œì‹œ
        for bar, count in zip(bars3, type_values):
            height = bar.get_height()
            if height > 0:
                ax6.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                        f'{count}íšŒ', ha='center', va='bottom', fontsize=11, fontweight='bold', color='#2c3e50')
        
        ax6.set_ylim(0, max(type_values) * 1.4 if max(type_values) > 0 else 1)
        ax6.grid(axis='y', alpha=0.2, linestyle='--')
        ax6.spines['top'].set_visible(False)
        ax6.spines['right'].set_visible(False)
        ax6.tick_params(colors='#34495e')
        
        # 7. ìƒˆë¡œ ì¶”ê°€: ì¸ì§€ ê²€ì‚¬ ê²°ê³¼ ìƒì„¸
        ax7 = plt.subplot2grid((8, 2), (6, 0), colspan=2, rowspan=1)
        ax7.axis('off')
        
        # ì¸ì§€ ê²€ì‚¬ ê´€ë ¨ ì´ìƒ ë‹µë³€ ë¶„ì„
        cognitive_strange = [r for r in self.strange_responses if r.question_type == "cognitive"]
        keyword_strange = [r for r in self.strange_responses if r.question_type == "keyword"]
        normal_strange = [r for r in self.strange_responses if r.question_type == "normal"]
        
        cognitive_analysis = f"""[ì§ˆë¬¸ íƒ€ì…ë³„ ì´ìƒ ë‹µë³€ ë¶„ì„]

â— ì¸ì§€ ê²€ì‚¬ ì§ˆë¬¸: {question_type_counts['cognitive']}íšŒ ì¤‘ {len(cognitive_strange)}íšŒ ì´ìƒ ({(len(cognitive_strange)/question_type_counts['cognitive']*100):.1f}% ì´ìƒë¥ )
â— í‚¤ì›Œë“œ ê¸°ë°˜ ì§ˆë¬¸: {question_type_counts['keyword']}íšŒ ì¤‘ {len(keyword_strange)}íšŒ ì´ìƒ ({(len(keyword_strange)/question_type_counts['keyword']*100 if question_type_counts['keyword'] > 0 else 0):.1f}% ì´ìƒë¥ )
â— ì¼ë°˜ ëŒ€í™”: {question_type_counts['normal']}íšŒ ì¤‘ {len(normal_strange)}íšŒ ì´ìƒ ({(len(normal_strange)/question_type_counts['normal']*100 if question_type_counts['normal'] > 0 else 0):.1f}% ì´ìƒë¥ )

â€» ì¸ì§€ ê²€ì‚¬ì—ì„œì˜ ì´ìƒ ë‹µë³€ì€ íŠ¹íˆ ì£¼ì˜ ê¹Šê²Œ ê´€ì°°í•´ì•¼ í•©ë‹ˆë‹¤."""
        
        ax7.text(0.05, 0.95, cognitive_analysis, fontsize=11, va='top',
                bbox=dict(boxstyle="round,pad=0.8", facecolor="#e8f4fd", alpha=0.9, 
                         edgecolor='#85c1e9', linewidth=1.5))
        
        # ì „ì²´ ë ˆì´ì•„ì›ƒ ì¡°ì •
        plt.tight_layout(rect=[0, 0.08, 1, 0.95], pad=2.0)
        
        # 8. í•˜ë‹¨: ê¶Œì¥ì‚¬í•­ (ë” ì •êµí•œ íŒë‹¨ ê¸°ì¤€)
        cognitive_risk = len(cognitive_strange) / question_type_counts['cognitive'] * 100 if question_type_counts['cognitive'] > 0 else 0
        
        if severity_counts['severe'] >= 2 or risk_percentage > 80 or cognitive_risk > 60:
            recommendation = "[ê¸´ê¸‰] ì „ë¬¸ì˜ ìƒë‹´ ì‹œê¸‰"
            rec_color = '#e74c3c'
            bg_color = '#fadbd8'
        elif severity_counts['severe'] >= 1 or risk_percentage > 60 or cognitive_risk > 40:
            recommendation = "[ì£¼ì˜] ê´€ì°° í•„ìš”"
            rec_color = '#e67e22'
            bg_color = '#fdeaa7'
        elif risk_percentage > 40 or cognitive_risk > 30:
            recommendation = "[ì•ˆë‚´] ì •ê¸°ì  ê´€ì°° ê¶Œì¥"
            rec_color = '#f39c12'
            bg_color = '#fcf3cf'
        else:
            recommendation = "[ì •ìƒ] ì–‘í˜¸í•œ ìƒíƒœ"
            rec_color = '#27ae60'
            bg_color = '#d5f4e6'
        
        # ê¶Œì¥ì‚¬í•­ ë°•ìŠ¤ (ë” í¬ê³  ëˆˆì— ë„ê²Œ)
        fig.text(0.5, 0.04, recommendation, ha='center', va='center', 
                fontsize=16, fontweight='bold', color=rec_color,
                bbox=dict(boxstyle="round,pad=1.0", facecolor=bg_color, alpha=0.9, 
                         edgecolor=rec_color, linewidth=2))
        
        # íŒŒì¼ëª… ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        image_basename = os.path.splitext(os.path.basename(image_path))[0]
        report_filename = os.path.join(output_dir, f"{image_basename}_integrated_report_{timestamp}.png")
        
        # ê³ í•´ìƒë„ë¡œ ì €ì¥ (ëª¨ë°”ì¼ í™”ë©´ìš©)
        plt.savefig(report_filename, dpi=200, bbox_inches='tight', 
                    facecolor='#f8f9fa', edgecolor='none', format='png')
        plt.close()
        
        print(f"ğŸ“± í†µí•© ëª¨ë°”ì¼ ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {report_filename}")
        return report_filename
    
    def get_conversation_summary(self):
        """ëŒ€í™” ì¢…ë£Œ í›„ ì´ìƒí•œ ë‹µë³€ ìš”ì•½ ì œê³µ (í†µí•© ë²„ì „)"""
        # ì „ì²´ ë‹µë³€ íšŸìˆ˜ ê³„ì‚°
        total_responses = len(self.conversation_turns)
        
        if total_responses == 0:
            return "ëŒ€í™”ê°€ ì§„í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        if self.strange_response_count == 0:
            return f"ğŸ‰ ëŒ€í™” ì¤‘ íŠ¹ë³„íˆ ì´ìƒí•œ ë‹µë³€ì€ ì—†ì—ˆìŠµë‹ˆë‹¤. ì¢‹ì€ ëŒ€í™”ì˜€ì–´ìš”!\nì „ì²´ ë‹µë³€ íšŸìˆ˜: {total_responses}íšŒ"
        
        summary = f"\n{'='*60}\n"
        summary += f"ğŸ“Š í†µí•© ëŒ€í™” ì¢…ë£Œ - ë¶„ì„ ê²°ê³¼\n"
        summary += f"{'='*60}\n"
        summary += f"ğŸ“Œ ì „ì²´ ë‹µë³€ íšŸìˆ˜: {total_responses}íšŒ\n"
        summary += f"ğŸ” ì´ìƒí•œ ë‹µë³€ íšŸìˆ˜: {self.strange_response_count}íšŒ ({(self.strange_response_count/total_responses*100):.1f}%)\n\n"
        
        # ì§ˆë¬¸ íƒ€ì…ë³„ ë¶„ë¥˜
        question_type_counts = {"normal": 0, "keyword": 0, "cognitive": 0}
        for turn in self.conversation_turns:
            question_type_counts[turn.question_type] += 1
        
        summary += f"ì§ˆë¬¸ íƒ€ì…ë³„ ëŒ€í™” ë¶„ì„:\n"
        summary += f"  â€¢ ì¼ë°˜ ëŒ€í™”: {question_type_counts['normal']}íšŒ\n"
        summary += f"  â€¢ í‚¤ì›Œë“œ ê¸°ë°˜: {question_type_counts['keyword']}íšŒ\n"
        summary += f"  â€¢ ì¸ì§€ ê²€ì‚¬: {question_type_counts['cognitive']}íšŒ\n\n"
        
        # ì‹¬ê°ë„ë³„ ë¶„ë¥˜
        severity_counts = {"mild": 0, "moderate": 0, "severe": 0}
        for response in self.strange_responses:
            severity_counts[response.severity] += 1
        
        summary += f"ì´ìƒí•œ ë‹µë³€ ì¤‘ ì‹¬ê°ë„ë³„ ë¶„ë¥˜:\n"
        summary += f"  â€¢ ê²½ë¯¸ (Mild): {severity_counts['mild']}íšŒ ({(severity_counts['mild']/self.strange_response_count*100):.1f}%)\n"
        summary += f"  â€¢ ë³´í†µ (Moderate): {severity_counts['moderate']}íšŒ ({(severity_counts['moderate']/self.strange_response_count*100):.1f}%)\n"
        summary += f"  â€¢ ì‹¬ê° (Severe): {severity_counts['severe']}íšŒ ({(severity_counts['severe']/self.strange_response_count*100):.1f}%)\n\n"
        
        # ì§ˆë¬¸ íƒ€ì…ë³„ ì´ìƒ ë‹µë³€ ë¶„ì„
        cognitive_strange = [r for r in self.strange_responses if r.question_type == "cognitive"]
        keyword_strange = [r for r in self.strange_responses if r.question_type == "keyword"]
        normal_strange = [r for r in self.strange_responses if r.question_type == "normal"]
        
        summary += f"ì§ˆë¬¸ íƒ€ì…ë³„ ì´ìƒ ë‹µë³€ ë¶„ì„:\n"
        summary += f"  â€¢ ì¸ì§€ ê²€ì‚¬: {len(cognitive_strange)}íšŒ ({(len(cognitive_strange)/question_type_counts['cognitive']*100 if question_type_counts['cognitive'] > 0 else 0):.1f}% ì´ìƒë¥ )\n"
        summary += f"  â€¢ í‚¤ì›Œë“œ ê¸°ë°˜: {len(keyword_strange)}íšŒ ({(len(keyword_strange)/question_type_counts['keyword']*100 if question_type_counts['keyword'] > 0 else 0):.1f}% ì´ìƒë¥ )\n"
        summary += f"  â€¢ ì¼ë°˜ ëŒ€í™”: {len(normal_strange)}íšŒ ({(len(normal_strange)/question_type_counts['normal']*100 if question_type_counts['normal'] > 0 else 0):.1f}% ì´ìƒë¥ )\n\n"
        
        # ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚°
        # ê²½ë¯¸: 1ì , ë³´í†µ: 3ì , ì‹¬ê°: 5ì 
        risk_score = (severity_counts['mild'] * 1 + 
                     severity_counts['moderate'] * 3 + 
                     severity_counts['severe'] * 5)
        
        # ìµœëŒ€ ê°€ëŠ¥ ì ìˆ˜ ê³„ì‚° (ëª¨ë“  ì´ìƒí•œ ë‹µë³€ì´ severeì¸ ê²½ìš°)
        max_risk_score = self.strange_response_count * 5
        
        # ìœ„í—˜ë„ í¼ì„¼íŠ¸ ê³„ì‚°
        risk_percentage = (risk_score / max_risk_score * 100)
        
        summary += f"ìœ„í—˜ë„ ì ìˆ˜: {risk_score}ì  / {max_risk_score}ì  ({risk_percentage:.1f}%)\n"
        summary += f"   (ê²½ë¯¸=1ì , ë³´í†µ=3ì , ì‹¬ê°=5ì  ê°€ì¤‘ì¹˜ ì ìš©)\n\n"
        
        summary += f"ìƒì„¸ ê¸°ë¡:\n"
        for i, response in enumerate(self.strange_responses, 1):
            type_name = {"normal": "ì¼ë°˜", "keyword": "í‚¤ì›Œë“œ", "cognitive": "ì¸ì§€ê²€ì‚¬"}
            summary += f"\n{i}. [{response.severity.upper()}][{type_name[response.question_type]}] {response.timestamp}\n"
            summary += f"   ì§ˆë¬¸: {response.question[:80]}{'...' if len(response.question) > 80 else ''}\n"
            summary += f"   ë‹µë³€: {response.answer[:80]}{'...' if len(response.answer) > 80 else ''}\n"
        
        # ê¶Œì¥ì‚¬í•­ - ìœ„í—˜ë„ ì ìˆ˜ì™€ ì‹¬ê° ë‹µë³€, ì¸ì§€ ê²€ì‚¬ ê²°ê³¼ ê¸°ë°˜ìœ¼ë¡œ íŒë‹¨
        cognitive_risk = len(cognitive_strange) / question_type_counts['cognitive'] * 100 if question_type_counts['cognitive'] > 0 else 0
        
        if severity_counts['severe'] >= 2 or risk_percentage > 80 or cognitive_risk > 60:
            summary += f"\nâš ï¸  ê¶Œì¥ì‚¬í•­: ì‹¬ê°í•œ ìˆ˜ì¤€ì˜ ì´ìƒ ë‹µë³€ì´ {severity_counts['severe']}íšŒ ê´€ì°°ë˜ì—ˆìœ¼ë©°, "
            summary += f"ì „ì²´ ìœ„í—˜ë„ê°€ {risk_percentage:.1f}%, ì¸ì§€ê²€ì‚¬ ì´ìƒë¥ ì´ {cognitive_risk:.1f}%ë¡œ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤. "
            summary += f"ì¦‰ì‹œ ì „ë¬¸ì˜ ìƒë‹´ì„ ë°›ìœ¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n"
        elif severity_counts['severe'] >= 1 or risk_percentage > 60 or cognitive_risk > 40:
            summary += f"\nğŸ”¶ ê¶Œì¥ì‚¬í•­: ì‹¬ê°í•œ ë‹µë³€ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©°, ìœ„í—˜ë„ê°€ {risk_percentage:.1f}%, "
            summary += f"ì¸ì§€ê²€ì‚¬ ì´ìƒë¥ ì´ {cognitive_risk:.1f}%ì…ë‹ˆë‹¤. ì „ë¬¸ì˜ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n"
        elif risk_percentage > 40 or cognitive_risk > 30:
            summary += f"\nğŸ”· ê¶Œì¥ì‚¬í•­: ì´ìƒ ë‹µë³€ì˜ ìœ„í—˜ë„ê°€ {risk_percentage:.1f}%, ì¸ì§€ê²€ì‚¬ ì´ìƒë¥ ì´ {cognitive_risk:.1f}%ë¡œ "
            summary += f"ì¤‘ê°„ ìˆ˜ì¤€ì…ë‹ˆë‹¤. ì •ê¸°ì ì¸ ê´€ì°°ê³¼ ì¶”ì  ê²€ì‚¬ë¥¼ ë°›ìœ¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n"
        elif risk_percentage > 20:
            summary += f"\nğŸ’™ ê¶Œì¥ì‚¬í•­: ì´ìƒ ë‹µë³€ì˜ ìœ„í—˜ë„ê°€ {risk_percentage:.1f}%ë¡œ ê²½ë¯¸í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤. "
            summary += f"ì£¼ê¸°ì ì¸ ê´€ì°°ì„ ê³„ì†í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n"
        else:
            summary += f"\nğŸ’š ì´ìƒ ë‹µë³€ì˜ ìœ„í—˜ë„ê°€ {risk_percentage:.1f}%ë¡œ ë‚®ì€ ìˆ˜ì¤€ì…ë‹ˆë‹¤. "
            summary += f"í˜„ì¬ ìƒíƒœë¥¼ ì˜ ìœ ì§€í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n"
        
        # ì¶”ê°€ ì•ˆë‚´ì‚¬í•­
        if cognitive_risk > 30:
            summary += f"\nâš ï¸  ì°¸ê³ : ì¸ì§€ ê²€ì‚¬ì—ì„œì˜ ì´ìƒë¥ ì´ {cognitive_risk:.1f}%ë¡œ ë†’ê²Œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. "
            summary += f"ì‹œê³µê°„ ì§€ë‚¨ë ¥ê³¼ ì¸ì§€ ê¸°ëŠ¥ì— íŠ¹ë³„í•œ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n"
        
        if severity_counts['severe'] > 0:
            summary += f"\nğŸ“ ì°¸ê³ : ì‹¬ê°í•œ ë‹µë³€ì€ ì‹œê³µê°„ ì§€ë‚¨ë ¥ ìƒì‹¤, ì™„ì „í•œ ë§¥ë½ ì´íƒˆ ë“±ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n"
        
        summary += f"{'='*60}\n"
        
        return summary
    
    def generate_story_from_conversation(self, image_path):
        """ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë…¸ì¸ë¶„ì˜ ê´€ì ì—ì„œ ìŠ¤í† ë¦¬ ìƒì„±"""
        # ëŒ€í™” ë‚´ìš© ì •ë¦¬
        conversation_text = ""
        for turn in self.conversation_turns:
            type_name = {"normal": "ì¼ë°˜", "keyword": "í‚¤ì›Œë“œ", "cognitive": "ì¸ì§€ê²€ì‚¬"}
            conversation_text += f"[{type_name[turn.question_type]}] ì§ˆë¬¸: {turn.question}\në‹µë³€: {turn.answer}\n\n"
        
        # ìŠ¤í† ë¦¬ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
        story_prompt = f"""
ë‹¤ìŒì€ í•œ ì–´ë¥´ì‹ ì´ ì˜›ë‚  ì‚¬ì§„ì„ ë³´ë©° ë‚˜ëˆˆ ëŒ€í™”ì…ë‹ˆë‹¤:

{conversation_text}

ì´ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ì§„ ì† ìˆœê°„ì— ëŒ€í•œ ì–´ë¥´ì‹ ì˜ ì¶”ì–µì„ 1ì¸ì¹­ ì‹œì ìœ¼ë¡œ 15ì¤„ ì •ë„ì˜ ì´ì•¼ê¸°ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì‘ì„± ì§€ì¹¨:
1. ì–´ë¥´ì‹ ì˜ ê°ì •ê³¼ ë‹¹ì‹œì˜ ëŠë‚Œì„ ìƒìƒí•˜ê²Œ í‘œí˜„
2. êµ¬ì²´ì ì¸ ê°ê°ì  ë¬˜ì‚¬ í¬í•¨ (ì†Œë¦¬, ëƒ„ìƒˆ, ì´‰ê° ë“±)
3. ë”°ëœ»í•˜ê³  í–¥ìˆ˜ë¥¼ ë¶ˆëŸ¬ì¼ìœ¼í‚¤ëŠ” í†¤
4. ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ ë‚´ìš©ì„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨
5. ë§ˆì¹˜ ì†ì/ì†ë…€ì—ê²Œ ë“¤ë ¤ì£¼ëŠ” ê²ƒì²˜ëŸ¼ ì¹œê·¼í•œ ì–´íˆ¬
6. í‚¤ì›Œë“œ ê¸°ë°˜ ëŒ€í™”ì™€ ì¸ì§€ê²€ì‚¬ ë‚´ìš©ë„ ìì—°ìŠ¤ëŸ½ê²Œ ë°˜ì˜

ìŠ¤í† ë¦¬ë§Œ ì‘ì„±í•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.
"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.deployment,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë…¸ì¸ì˜ ì¶”ì–µì„ ì•„ë¦„ë‹µê²Œ ì¬êµ¬ì„±í•˜ëŠ” ìŠ¤í† ë¦¬í…”ëŸ¬ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": story_prompt}
                ],
                max_tokens=1024,
                temperature=0.8,
                top_p=1.0,
            )
            
            story = response.choices[0].message.content
            
            # story_telling í´ë” ìƒì„±
            story_dir = "story_telling"
            os.makedirs(story_dir, exist_ok=True)
            
            # ì´ë¯¸ì§€ íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°í•˜ì—¬ ìŠ¤í† ë¦¬ íŒŒì¼ëª… ìƒì„±
            image_basename = os.path.splitext(os.path.basename(image_path))[0]
            story_filename = os.path.join(story_dir, f"{image_basename}_integrated.txt")
            
            # ìŠ¤í† ë¦¬ íŒŒì¼ ì €ì¥
            with open(story_filename, 'w', encoding='utf-8') as f:
                f.write(story)
            
            print(f"í†µí•© ì¶”ì–µ ì´ì•¼ê¸°ê°€ '{story_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            return story, story_filename
            
        except Exception as e:
            print(f"ìŠ¤í† ë¦¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None, None
    
    def save_conversation_to_file(self, filename_prefix="integrated_conversation", image_path=None):
        """ëŒ€í™” ë‚´ìš©ì„ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥ (í†µí•© ë²„ì „)"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ì´ë¯¸ì§€ íŒŒì¼ëª… ì¶”ì¶œ (í™•ì¥ì ì œì™¸)
        if image_path:
            image_basename = os.path.splitext(os.path.basename(image_path))[0]
            base_filename = f"{image_basename}_integrated_{timestamp}"
        else:
            base_filename = f"{filename_prefix}_{timestamp}"
        
        # í´ë” ìƒì„± (ì—†ëŠ” ê²½ìš°)
        conversation_dir = "conversation_log"
        analysis_dir = "analysis"
        os.makedirs(conversation_dir, exist_ok=True)
        os.makedirs(analysis_dir, exist_ok=True)
        
        # ëŒ€í™” ê¸°ë¡ íŒŒì¼ ì €ì¥
        conversation_filename = os.path.join(conversation_dir, f"{base_filename}.txt")
        with open(conversation_filename, 'w', encoding='utf-8') as f:
            f.write(f"=== í†µí•© ëŒ€í™” ê¸°ë¡ ===\n")
            f.write(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}\n")
            f.write(f"{'='*50}\n\n")
            
            for i, turn in enumerate(self.conversation_turns, 1):
                type_name = {"normal": "ì¼ë°˜ëŒ€í™”", "keyword": "í‚¤ì›Œë“œê¸°ë°˜", "cognitive": "ì¸ì§€ê²€ì‚¬"}
                f.write(f"[ëŒ€í™” {i}] {turn.timestamp} [{type_name[turn.question_type]}]\n")
                f.write(f"ì§ˆë¬¸: {turn.question}\n")
                f.write(f"ë‹µë³€: {turn.answer}\n")
                f.write(f"{'-'*30}\n\n")
        
        print(f"í†µí•© ëŒ€í™” ê¸°ë¡ì´ '{conversation_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì´ìƒ ë‹µë³€ ë¶„ì„ íŒŒì¼ ì €ì¥
        analysis_filename = None
        if self.strange_response_count > 0:
            analysis_filename = os.path.join(analysis_dir, f"{base_filename}_analysis.txt")
            with open(analysis_filename, 'w', encoding='utf-8') as f:
                f.write(self.get_conversation_summary())
            
            print(f"í†µí•© ì´ìƒ ë‹µë³€ ë¶„ì„ì´ '{analysis_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        return conversation_filename, analysis_filename


def analyze_and_describe_image_integrated(image_path, user_description="", user_description_date=""):
    """ì´ë¯¸ì§€ ë¶„ì„ ë° ì„¤ëª… í†µí•© í•¨ìˆ˜ (í†µí•© ë²„ì „)"""
    # 1. GPT-4o ì´ë¯¸ì§€ ë¶„ì„ ê°ì²´ ìƒì„±
    analyzer = ImageAnalysisGPT()
    
    # 2. ì´ë¯¸ì§€ ë¶„ì„ ìˆ˜í–‰
    print(f"GPT-4oë¡œ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘: {image_path}")
    analysis_result = analyzer.analyze_image_with_gpt(image_path)
    
    if not analysis_result:
        return "ì´ë¯¸ì§€ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", None, None
    
    # 3. í†µí•© LLM ëŒ€í™” ê°ì²´ ìƒì„±
    llm_chat = IntegratedLLMDescription()
    
    # 4. ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
    print("\ní†µí•© ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì„¤ì • ì¤‘...")
    llm_chat.setup_conversation_context(
        analysis_result, 
        user_description, 
        user_description_date
    )
    
    # 5. ê²°ê³¼ ì¶œë ¥
    print("\n===== í†µí•© GPT-4o ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ =====")
    print("ğŸ”„ ì‹¤ì‹œê°„ ëŒ€í™” ì‹œìŠ¤í…œ + ë³µì¡í•œ ë¶„ì„ ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("âœ¨ í‚¤ì›Œë“œ ê¸°ë°˜ ì§ˆë¬¸, ì¸ì§€ ê²€ì‚¬, ì´ìƒ ë‹µë³€ ê°ì§€ ê¸°ëŠ¥ì´ ëª¨ë‘ í™œì„±í™”ë©ë‹ˆë‹¤.")
    
    return "í†µí•© ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ", llm_chat, image_path


# ë©”ì¸ ì‹¤í–‰ë¶€ (í†µí•© ë²„ì „)
if __name__ == "__main__":
    # ë¶„ì„í•  ì´ë¯¸ì§€ ê²½ë¡œ ì…ë ¥
    image_path = "images.jpg"  # DBì—ì„œ ê°€ì ¸ì˜¨ ì´ë¯¸ì§€ ê²½ë¡œë¡œ ë³€ê²½ í•„ìš”
    
    # ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(image_path):
        print(f"ì˜¤ë¥˜: íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ - {image_path}")
        exit(1)
    
    # user_description_date = input("ì‚¬ì§„ì˜ ë‚ ì§œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (ì˜ˆ: 1980ë…„ëŒ€, 2000ë…„ ì—¬ë¦„): ")
    # user_description = input("ì‚¬ì§„ì— ëŒ€í•œ ì„¤ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”: ")  --> ë‘ë¶€ë¶„ë„ DBì—ì„œ ê°€ì ¸ì™€ì•¼í•¨
    
    # í†µí•© ì´ë¯¸ì§€ ë¶„ì„ ë° ëŒ€í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    result, llm_chat, img_path = analyze_and_describe_image_integrated(
        image_path
        # user_description, 
        # user_description_date
    )
    
    if llm_chat:
        print("\n===== í†µí•© ì´ë¯¸ì§€ ëŒ€í™” ì‹œì‘ =====")
        print("ğŸ¯ ê¸°ëŠ¥: ì‹¤ì‹œê°„ ëŒ€í™” + í‚¤ì›Œë“œ ê°ì§€ + ì¸ì§€ ê²€ì‚¬ + ì´ìƒ ë‹µë³€ ë¶„ì„")
        
        # GPTê°€ ë¨¼ì € ì§ˆë¬¸ ë˜ì§€ê¸°
        initial_question = llm_chat.generate_initial_question()
        print(f"\nğŸ¤– AI: {initial_question}")
        
        print(f"\nğŸ’¡ ëŒ€í™”ë¥¼ ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'ì¢…ë£Œ'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        print(f"ğŸ“‹ 3í„´ë§ˆë‹¤ ì¸ì§€ ê²€ì‚¬ ì§ˆë¬¸ì´ ìë™ìœ¼ë¡œ ì¶”ê°€ë©ë‹ˆë‹¤.")
        print(f"ğŸ” í‚¤ì›Œë“œ ê°ì§€ ì‹œ ê´€ë ¨ ì§ˆë¬¸ì´ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.")
        
        while True:
            user_query = input(f"\nğŸ‘¤ ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”: ")
            
            # ìˆ˜ë™ ì¢…ë£Œ ì¡°ê±´ í™•ì¸
            if user_query.lower() in ['exit', 'ì¢…ë£Œ', 'quit', 'q']:
                print("ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            # í†µí•© GPTì—ê²Œ ì‚¬ìš©ì ë‹µë³€ ì „ë‹¬ ë° í† í° ì œí•œ í™•ì¸
            answer, should_end, question_type = llm_chat.chat_about_image(user_query)
            
            # ì§ˆë¬¸ íƒ€ì…ì— ë”°ë¥¸ ì´ëª¨ì§€ ì¶”ê°€
            type_emoji = {
                "normal": "ğŸ¤–",
                "keyword": "ğŸ’", 
                "cognitive": "ğŸ§ "
            }
            
            print(f"\n{type_emoji.get(question_type, 'ğŸ¤–')} AI: {answer}")
            
            # íŠ¹ë³„ ì§ˆë¬¸ì¼ ë•Œ ì¶”ê°€ ì•ˆë‚´
            if question_type == "keyword":
                print("   ğŸ’¡ í‚¤ì›Œë“œ ê¸°ë°˜ ì§ˆë¬¸ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
            elif question_type == "cognitive":
                print("   ğŸ§  ì¸ì§€ ëŠ¥ë ¥ ê²€ì‚¬ ì§ˆë¬¸ì…ë‹ˆë‹¤.")
            
            # í† í° ì œí•œìœ¼ë¡œ ì¸í•œ ì¢…ë£Œ í™•ì¸
            if should_end:
                print("\nâ° ëŒ€í™” í† í° ì œí•œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
        
        # ëŒ€í™” ì¢…ë£Œ í›„ íŒŒì¼ë¡œ ì €ì¥
        print("\nğŸ“ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” ì¤‘...")
        llm_chat.save_conversation_to_file(image_path=img_path)
        
        # ì¶”ì–µ ìŠ¤í† ë¦¬ ìƒì„±
        print("\nğŸ“– í†µí•© ì¶”ì–µ ì´ì•¼ê¸°ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘...")
        story, story_file = llm_chat.generate_story_from_conversation(img_path)
        
        if story:
            print(f"\n=== ìƒì„±ëœ í†µí•© ì¶”ì–µ ì´ì•¼ê¸° ===\n{story}\n")
        
        # ğŸ“± í†µí•© ëª¨ë°”ì¼ ë¦¬í¬íŠ¸ ìƒì„±
        print("\nğŸ“± í†µí•© ëª¨ë°”ì¼ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘...")
        mobile_report_file = llm_chat.generate_mobile_report(img_path)
        
        if mobile_report_file:
            print(f"âœ… í†µí•© ëª¨ë°”ì¼ ë¦¬í¬íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
            print(f"ğŸ“‚ íŒŒì¼ ê²½ë¡œ: {mobile_report_file}")
            print(f"ğŸ” í‚¤ì›Œë“œ ê¸°ë°˜ ì§ˆë¬¸, ì¸ì§€ ê²€ì‚¬, ì‹¬ê°ë„ ë¶„ì„ì´ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        
        # ì½˜ì†”ì—ë„ í†µí•© ìš”ì•½ ì¶œë ¥
        print(llm_chat.get_conversation_summary())
        
    else:
        print("ì´ë¯¸ì§€ ë¶„ì„ì— ì‹¤íŒ¨í•˜ì—¬ ëŒ€í™”ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")