{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "152a5597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blank\\AppData\\Roaming\\Python\\Python313\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.13.1)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msoundfile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msf\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01msounddevice\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msd\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlibrosa\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mlibrosa\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m image\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import json, base64, os, tiktoken, random, time, threading\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import requests, pygame\n",
    "from pathlib import Path\n",
    "import soundfile as sf, sounddevice as sd\n",
    "import librosa, librosa.display, tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from io import BytesIO\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba48284",
   "metadata": {},
   "source": [
    "# Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6e4545",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class StrangeResponse:\n",
    "    question: str; answer: str; timestamp: str; severity: str\n",
    "    emotion: str = \"ì¤‘ë¦½\"; answer_quality: str = \"normal\"\n",
    "\n",
    "@dataclass  \n",
    "class ConversationTurn:\n",
    "    question: str; answer: str; timestamp: str\n",
    "    emotion: str = \"ì¤‘ë¦½\"; answer_length: int = 0\n",
    "    answer_quality: str = \"normal\"; audio_file: str = \"\"\n",
    "\n",
    "class Config:\n",
    "    ENDPOINT = os.getenv(\"gpt-endpoint\")\n",
    "    DEPLOYMENT = \"gpt-4o\"\n",
    "    SUBSCRIPTION_KEY = os.getenv(\"gpt-key\")\n",
    "    API_VERSION = \"2024-02-15-preview\"\n",
    "    SPEECH_KEY = os.getenv(\"speech-key\")\n",
    "    SPEECH_REGION = \"eastus\"\n",
    "    MAX_TOKENS = 4000\n",
    "\n",
    "# ìŒì„± ë¶„ì„ ì„¤ì •\n",
    "SR, FIXED_DURATION = 16000, 30\n",
    "category = {0: 'cc', 1: 'cd'}\n",
    "\n",
    "print(f\"ğŸ”§ ì„¤ì •: OpenAI {'âœ…' if Config.ENDPOINT and Config.SUBSCRIPTION_KEY else 'âŒ'} | Speech {'âœ…' if Config.SPEECH_KEY else 'âŒ'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ba9d25",
   "metadata": {},
   "source": [
    "# Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29116f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.client = AzureOpenAI(\n",
    "            api_version=Config.API_VERSION,\n",
    "            azure_endpoint=Config.ENDPOINT,\n",
    "            api_key=Config.SUBSCRIPTION_KEY,\n",
    "        )\n",
    "    \n",
    "    def analyze_image(self, image_path):\n",
    "        try:\n",
    "            with open(image_path, \"rb\") as f:\n",
    "                base64_image = base64.b64encode(f.read()).decode('utf-8')\n",
    "                \n",
    "            response = self.client.chat.completions.create(\n",
    "                model=Config.DEPLOYMENT,\n",
    "                messages=[{\"role\": \"user\", \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"\"\"ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì„œ JSONìœ¼ë¡œ ë‹µí•´ì£¼ì„¸ìš”:\n",
    "{\"caption\": \"ì „ì²´ ì„¤ëª…\", \"dense_captions\": [\"ì„¸ë¶€1\", \"ì„¸ë¶€2\"], \"mood\": \"ë¶„ìœ„ê¸°\", \n",
    "\"time_period\": \"ì‹œëŒ€\", \"key_objects\": [\"ê°ì²´1\", \"ê°ì²´2\"], \"people_description\": \"ì¸ë¬¼ ì„¤ëª…\",\n",
    "\"people_count\": ìˆ«ì, \"time_of_day\": \"ì‹œê°„ëŒ€\"}\"\"\"},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "                ]}], max_tokens=1000, temperature=0.3\n",
    "            )\n",
    "            \n",
    "            text = response.choices[0].message.content\n",
    "            if \"```json\" in text:\n",
    "                text = text[text.find(\"```json\")+7:text.find(\"```\", text.find(\"```json\")+7)]\n",
    "            elif \"{\" in text:\n",
    "                text = text[text.find(\"{\"):text.rfind(\"}\")+1]\n",
    "            return json.loads(text)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "print(\"âœ… ImageAnalyzer í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbc34f5",
   "metadata": {},
   "source": [
    "# Chat System\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8666b97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatSystem:\n",
    "    def __init__(self):\n",
    "        self.client = AzureOpenAI(api_version=Config.API_VERSION, azure_endpoint=Config.ENDPOINT, api_key=Config.SUBSCRIPTION_KEY)\n",
    "        self.conversation_history, self.conversation_turns = [], []\n",
    "        self.tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        self.token_count, self.last_question = 0, \"\"\n",
    "        self.recording, self.audio_data, self.all_audio_data = False, [], []\n",
    "        self.sample_rate = 44100\n",
    "        \n",
    "        # ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "        self.session_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        for base_dir in [\"audio_records\", \"audio_records_combined\"]:\n",
    "            (Path(base_dir) / self.session_id).mkdir(parents=True, exist_ok=True)\n",
    "        self.session_dir = Path(\"audio_records\") / self.session_id\n",
    "        self.session_audio_dir = Path(\"audio_records_combined\") / self.session_id\n",
    "    \n",
    "    def start_recording(self):\n",
    "        if self.recording: return\n",
    "        self.recording, self.audio_data = True, []\n",
    "        \n",
    "        def callback(indata, frames, time, status):\n",
    "            if self.recording: self.audio_data.append(indata.copy())\n",
    "        \n",
    "        self.audio_thread = sd.InputStream(samplerate=self.sample_rate, channels=1, callback=callback)\n",
    "        self.audio_thread.start()\n",
    "    \n",
    "    def stop_recording(self):\n",
    "        if not self.recording: return None\n",
    "        self.recording = False\n",
    "        if hasattr(self, 'audio_thread'):\n",
    "            self.audio_thread.stop(); self.audio_thread.close()\n",
    "        \n",
    "        if self.audio_data:\n",
    "            audio_data = np.concatenate(self.audio_data, axis=0)\n",
    "            filename = self.session_dir / f\"record_{datetime.now().strftime('%H%M%S')}.wav\"\n",
    "            sf.write(filename, audio_data, self.sample_rate)\n",
    "            self.all_audio_data.append(audio_data)\n",
    "            \n",
    "            # ì „ì²´ ì„¸ì…˜ íŒŒì¼ ì—…ë°ì´íŠ¸\n",
    "            combined = np.concatenate(self.all_audio_data, axis=0)\n",
    "            sf.write(self.session_audio_dir / f\"{self.session_id}.wav\", combined, self.sample_rate)\n",
    "            return str(filename)\n",
    "        return None\n",
    "    \n",
    "    def setup_conversation_context(self, analysis_result):\n",
    "        info = {k: analysis_result.get(k, \"\") for k in [\"caption\", \"mood\", \"time_period\", \"time_of_day\", \"people_description\"]}\n",
    "        info.update({\n",
    "            \"dense_captions\": \"\\n\".join(f\"- {dc}\" for dc in analysis_result.get(\"dense_captions\", [])),\n",
    "            \"key_objects\": \", \".join(analysis_result.get(\"key_objects\", [])),\n",
    "            \"people_count\": analysis_result.get(\"people_count\", 0)\n",
    "        })\n",
    "        \n",
    "        system_message = f\"\"\"ë„ˆëŠ” ë…¸ì¸ê³¼ ëŒ€í™”í•˜ëŠ” ìš”ì–‘ë³´í˜¸ì‚¬ì•¼. ë…¸ì¸ê³¼ íŠ¹ì • ì´ë¯¸ì§€ì— ëŒ€í•´ì„œ ì§ˆì˜ì‘ë‹µì„ ì£¼ê³ ë°›ì•„. \n",
    "ë…¸ì¸ì€ ì¹˜ë§¤ ì¦ìƒì´ ê°‘ìê¸° ë‚˜íƒ€ë‚  ìˆ˜ë„ ìˆì–´. ë°˜ë³µë˜ëŠ” ë§ì—ë„ ë˜‘ê°™ì´ ëŒ€ë‹µí•´ì¤˜ì•¼ í•´. \n",
    "ì¹œì ˆí•˜ê³  ì–´ë¥¸ì„ ê³µê²½í•˜ëŠ” ë§íˆ¬ì—¬ì•¼ í•´. ê·¸ë¦¬ê³  ê³µê°ì„ ì˜ í•´ì•¼ í•´. ì˜ˆì˜ë„ ì§€ì¼œ. \n",
    "ë„ˆëŠ” ì£¼ë¡œ ì§ˆë¬¸ì„ í•˜ëŠ” ìª½ì´ê³ , ë…¸ì¸ì€ ëŒ€ë‹µì„ í•´ì¤„ê±°ì•¼. ëŒ€ë‹µì— ëŒ€í•œ ë¦¬ì•¡ì…˜ê³¼ í•¨ê»˜ ì ì ˆíˆ ëŒ€í™”ë¥¼ ì´ì–´ ê°€.\n",
    "\n",
    "=== ì´ë¯¸ì§€ ì •ë³´ ===\n",
    "ì£¼ìš” ì„¤ëª…: {info['caption']} | ë¶„ìœ„ê¸°: {info['mood']} | ì‹œëŒ€: {info['time_period']}\n",
    "ì‹œê°„ëŒ€: {info['time_of_day']} | ì¸ì›: {info['people_count']}ëª… | ê°ì²´: {info['key_objects']}\n",
    "ì¸ë¬¼: {info['people_description']}\n",
    "ì„¸ë¶€: {info['dense_captions']}\n",
    "\n",
    "=== ëŒ€í™” ì›ì¹™ ===\n",
    "ê°„ê²°í•˜ê²Œ: 50ì ì´ë‚´ë¡œ ì§ˆë¬¸í•˜ê¸° | ì‚¬ì§„ ì£¼ì œ ìœ ì§€ | ì‹¬ë„ìˆëŠ” ëŒ€í™” | ê³µê°í•˜ê¸° | í•˜ë‚˜ì”©ë§Œ ì§ˆë¬¸ | ë”°ëœ»í•˜ê²Œ\"\"\"\n",
    "        \n",
    "        self.conversation_history = [{\"role\": \"system\", \"content\": system_message}]\n",
    "        self.token_count = len(self.tokenizer.encode(system_message))\n",
    "    \n",
    "    def generate_initial_question(self):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=Config.DEPLOYMENT,\n",
    "            messages=self.conversation_history + [{\"role\": \"user\", \"content\": \"ì–´ë¥´ì‹ ê»˜ ë”°ë“¯í•˜ê³  ì¹œê·¼í•˜ê²Œ ì‚¬ì§„ì— ëŒ€í•˜ì—¬ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”. 50ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.\"}],\n",
    "            max_tokens=512, temperature=0.8\n",
    "        )\n",
    "        \n",
    "        question = response.choices[0].message.content\n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": question})\n",
    "        self.token_count += len(self.tokenizer.encode(question))\n",
    "        self.last_question = question\n",
    "        return question\n",
    "\n",
    "    def chat_about_image(self, user_query, with_audio=False):\n",
    "        # ëŒ€í™” í„´ ì €ì¥\n",
    "        if self.last_question:\n",
    "            audio_file = self.stop_recording() if with_audio else \"\"\n",
    "            self.conversation_turns.append(ConversationTurn(\n",
    "                question=self.last_question, answer=user_query,\n",
    "                timestamp=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                answer_length=len(user_query.strip()), audio_file=audio_file\n",
    "            ))\n",
    "        \n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": user_query})\n",
    "        self.token_count += len(self.tokenizer.encode(user_query))\n",
    "        \n",
    "        if self.token_count > Config.MAX_TOKENS:\n",
    "            answer = \"ëŒ€í™” ì‹œê°„ì´ ë‹¤ ë˜ì—ˆì–´ìš”. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.\"\n",
    "            self.conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "            return answer, True\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=Config.DEPLOYMENT, messages=self.conversation_history,\n",
    "            max_tokens=1024, temperature=0.7\n",
    "        )\n",
    "        answer = response.choices[0].message.content\n",
    "        \n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "        self.token_count += len(self.tokenizer.encode(answer))\n",
    "        self.last_question = answer\n",
    "        \n",
    "        return answer, self.token_count > Config.MAX_TOKENS\n",
    "\n",
    "print(\"âœ… ChatSystem í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5deb43",
   "metadata": {},
   "source": [
    "# Voice System Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caef8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoiceSystem:\n",
    "    def __init__(self):\n",
    "        self.speech_config = speechsdk.SpeechConfig(subscription=Config.SPEECH_KEY, region=Config.SPEECH_REGION)\n",
    "        self.speech_config.speech_recognition_language = \"ko-KR\"\n",
    "        self.tts_voice = \"ko-KR-SunHiNeural\"\n",
    "        Path(\"audio_files\").mkdir(exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            pygame.mixer.init()\n",
    "            self.audio_enabled = True\n",
    "        except:\n",
    "            self.audio_enabled = False\n",
    "    \n",
    "    def transcribe_speech(self) -> str:\n",
    "        try:\n",
    "            recognizer = speechsdk.SpeechRecognizer(\n",
    "                speech_config=self.speech_config,\n",
    "                audio_config=speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "            )\n",
    "            \n",
    "            print(\"ğŸ™ï¸ ë§ì”€í•´ ì£¼ì„¸ìš”...\")\n",
    "            result = recognizer.recognize_once()\n",
    "            \n",
    "            if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "                text = result.text.strip()\n",
    "                print(f\"ğŸ‘¤ \\\"{text}\\\"\")\n",
    "                \n",
    "                exit_commands = ['ì¢…ë£Œ', 'ê·¸ë§Œ', 'ë', 'ë‚˜ê°€ê¸°', 'exit', 'quit', 'stop']\n",
    "                if any(cmd.lower() in text.lower().replace(' ', '') for cmd in exit_commands):\n",
    "                    return \"ì¢…ë£Œ\"\n",
    "                return text\n",
    "            else:\n",
    "                print(\"âŒ ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”.\")\n",
    "                return \"\"\n",
    "        except:\n",
    "            return \"\"\n",
    "    \n",
    "    def synthesize_speech(self, text: str) -> str:\n",
    "        if not text.strip(): return None\n",
    "        \n",
    "        try:\n",
    "            # í† í° ìš”ì²­\n",
    "            token_url = f\"https://{Config.SPEECH_REGION}.api.cognitive.microsoft.com/sts/v1.0/issueToken\"\n",
    "            token_response = requests.post(token_url, headers={\"Ocp-Apim-Subscription-Key\": Config.SPEECH_KEY})\n",
    "            if not token_response.ok: return None\n",
    "            \n",
    "            # TTS ìš”ì²­\n",
    "            tts_url = f\"https://{Config.SPEECH_REGION}.tts.speech.microsoft.com/cognitiveservices/v1\"\n",
    "            ssml = f\"\"\"<speak version='1.0' xml:lang='ko-KR'>\n",
    "                <voice xml:lang='ko-KR' xml:gender='Female' name='{self.tts_voice}'>{text}</voice>\n",
    "            </speak>\"\"\"\n",
    "            \n",
    "            tts_response = requests.post(tts_url, \n",
    "                headers={\"Authorization\": f\"Bearer {token_response.text}\",\n",
    "                        \"Content-Type\": \"application/ssml+xml\",\n",
    "                        \"X-Microsoft-OutputFormat\": \"riff-16khz-16bit-mono-pcm\"},\n",
    "                data=ssml.encode(\"utf-8\"))\n",
    "            \n",
    "            if tts_response.ok:\n",
    "                output_path = Path(\"audio_files\") / f\"tts_{time.strftime('%Y%m%d_%H%M%S')}.wav\"\n",
    "                output_path.write_bytes(tts_response.content)\n",
    "                \n",
    "                if self.audio_enabled:\n",
    "                    try:\n",
    "                        pygame.mixer.music.load(str(output_path))\n",
    "                        pygame.mixer.music.play()\n",
    "                        while pygame.mixer.music.get_busy():\n",
    "                            time.sleep(0.1)\n",
    "                    except:\n",
    "                        pass\n",
    "                return str(output_path)\n",
    "        except:\n",
    "            pass\n",
    "        return None\n",
    "\n",
    "print(\"âœ… VoiceSystem í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6ab6ba",
   "metadata": {},
   "source": [
    "# Audio Dementia Detection_Gwona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771352fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013b01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio_slices(audio_path, save_path, add_noise=True):\n",
    "    \"\"\"ë¡œì»¬ wav íŒŒì¼ì„ 30ì´ˆ ë‹¨ìœ„ë¡œ ìŠ¬ë¼ì´ì‹±í•˜ì—¬ ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ì´ë¯¸ì§€ë¡œ ì €ì¥\"\"\"\n",
    "    if not os.path.exists(audio_path): return []\n",
    "    \n",
    "    y, sr = librosa.load(audio_path, sr=SR)\n",
    "    slice_length, total_slices = FIXED_DURATION * sr, len(y) // (FIXED_DURATION * sr)\n",
    "    if total_slices == 0: return []\n",
    "    \n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    base_name = os.path.splitext(os.path.basename(audio_path))[0]\n",
    "    saved_files = []\n",
    "    \n",
    "    for i in range(total_slices):\n",
    "        y_slice = y[i * slice_length:(i + 1) * slice_length]\n",
    "        \n",
    "        if add_noise:\n",
    "            noise = 0.005 * np.random.uniform() * np.amax(y_slice) * np.random.normal(size=y_slice.shape[0])\n",
    "            y_slice = y_slice + noise\n",
    "        \n",
    "        mel = librosa.feature.melspectrogram(y=y_slice, sr=sr, n_mels=128)\n",
    "        mel_norm = (librosa.power_to_db(mel, ref=np.max) - librosa.power_to_db(mel, ref=np.max).min()) / \\\n",
    "                   (librosa.power_to_db(mel, ref=np.max).max() - librosa.power_to_db(mel, ref=np.max).min())\n",
    "        \n",
    "        save_file = os.path.join(save_path, f\"{base_name}_slice{i+1}.jpg\")\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        librosa.display.specshow(mel_norm, sr=sr, x_axis='time', y_axis='mel')\n",
    "        plt.axis('off'); plt.tight_layout()\n",
    "        plt.savefig(save_file, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "        saved_files.append(save_file)\n",
    "    \n",
    "    return saved_files\n",
    "\n",
    "def analyze_voice_patterns(audio_path, model_path='models-05-0.7188.hdf5', save_path=\"./mel_slices/\"):\n",
    "    \"\"\"ìŒì„± íŒ¨í„´ ë¶„ì„ ìˆ˜í–‰\"\"\"\n",
    "    saved_images = preprocess_audio_slices(audio_path, save_path, add_noise=False)\n",
    "    if not saved_images:\n",
    "        return {'success': False, 'message': \"ìŠ¬ë¼ì´ìŠ¤ëœ ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\", 'analysis': {}}\n",
    "    \n",
    "    try:\n",
    "        model = load_model(model_path)\n",
    "        predictions = []\n",
    "        \n",
    "        for img_path in saved_images:\n",
    "            img = image.load_img(img_path, target_size=(250, 250))\n",
    "            img_processed = np.expand_dims(image.img_to_array(img) / 255.0, axis=0)\n",
    "            pred = model.predict(img_processed)[0]\n",
    "            predictions.append(float(pred[0]) if len(pred) > 0 else float(pred))\n",
    "        \n",
    "        threshold, total = 0.5, len(predictions)\n",
    "        positive = sum(1 for p in predictions if p >= threshold)\n",
    "        ratio = positive / total if total > 0 else 0\n",
    "        \n",
    "        level_map = {ratio >= 0.7: (\"ë†’ìŒ\", \"ğŸ”´\"), ratio >= 0.4: (\"ì¤‘ê°„\", \"ğŸŸ \")}.get(True, (\"ë‚®ìŒ\", \"ğŸŸ¢\"))\n",
    "        level, icon = level_map\n",
    "        \n",
    "        return {\n",
    "            'success': True, 'predictions': predictions,\n",
    "            'analysis': {'total_clips': total, 'positive_clips': positive, 'ratio': ratio, 'level': level, 'icon': icon}\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {'success': False, 'message': f\"ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}\", 'analysis': {}}\n",
    "\n",
    "print(\"âœ… ìŒì„± ë¶„ì„ í•¨ìˆ˜ë“¤ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9426b8",
   "metadata": {},
   "source": [
    "#### ì¼ë‹¨ í•¨ìˆ˜ êµ¬í˜„ì€ ëë‚¬ëŠ”ë°, ë¦¬í¬íŠ¸ì— ì¶”ê°€í•˜ëŠ”ê²ƒ ë‚¨ìŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc84aef",
   "metadata": {},
   "source": [
    "# Story Telling / Report System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83c2a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoryGenerator:\n",
    "    def __init__(self, chat_system):\n",
    "        self.chat_system = chat_system\n",
    "        self.client = chat_system.client\n",
    "        self.strange_responses, self.rule_based_alerts = [], []\n",
    "        self.conversation_id = \"\"\n",
    "        self.voice_analysis_result = None\n",
    "    \n",
    "    def analyze_voice_patterns(self):\n",
    "        \"\"\"ìŒì„± íŒ¨í„´ ë¶„ì„ ìˆ˜í–‰ (3ë¶„ ì´ìƒ ëŒ€í™”ë§Œ)\"\"\"\n",
    "        if not self.chat_system.session_id: return None\n",
    "        \n",
    "        session_audio_file = self.chat_system.session_audio_dir / f\"{self.chat_system.session_id}.wav\"\n",
    "        if not session_audio_file.exists():\n",
    "            print(\"âš ï¸ ìŒì„± íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ìŒì„± ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            duration = librosa.get_duration(path=str(session_audio_file))\n",
    "            duration_minutes = duration / 60\n",
    "            print(f\"ğŸ™ï¸ ì „ì²´ ëŒ€í™” ì‹œê°„: {duration_minutes:.1f}ë¶„\")\n",
    "            \n",
    "            if duration < 180:\n",
    "                print(f\"âš ï¸ ëŒ€í™” ì‹œê°„ì´ {duration_minutes:.1f}ë¶„ìœ¼ë¡œ 3ë¶„ ë¯¸ë§Œì´ì–´ì„œ ìŒì„± ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "                return {'success': False, 'duration': duration_minutes, 'reason': 'insufficient_duration'}\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ìŒì„± íŒŒì¼ ê¸¸ì´ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "            return None\n",
    "        \n",
    "        print(\"ğŸ™ï¸ ìŒì„± íŒ¨í„´ ë¶„ì„ ì¤‘...\")\n",
    "        result = analyze_voice_patterns(str(session_audio_file), save_path=f\"./mel_slices/{self.chat_system.session_id}/\")\n",
    "        \n",
    "        if result['success']:\n",
    "            result['duration'] = duration_minutes\n",
    "            self.voice_analysis_result = result\n",
    "            print(f\"âœ… ìŒì„± ë¶„ì„ ì™„ë£Œ: {result['analysis']['level']} ìˆ˜ì¤€ ({duration_minutes:.1f}ë¶„ ëŒ€í™”)\")\n",
    "        else:\n",
    "            print(f\"âŒ ìŒì„± ë¶„ì„ ì‹¤íŒ¨: {result['message']}\")\n",
    "        return result\n",
    "    \n",
    "    def analyze_speech_patterns(self):\n",
    "        \"\"\"ëŒ€í™” íŒ¨í„´ ë¶„ì„\"\"\"\n",
    "        if not self.chat_system.conversation_turns: return\n",
    "        \n",
    "        patterns = {\n",
    "            'severe_depression': [\"ì£½ê³ ì‹¶\", \"ì‚´ê¸°ì‹«\", \"ì˜ë¯¸ì—†\", \"í¬ê¸°í•˜ê³ ì‹¶\", \"ì§€ì³¤\", \"í˜ë“¤ì–´ì£½ê² \", \"ì„¸ìƒì´ì‹«\", \"ì ˆë§\"],\n",
    "            'severe_anxiety': [\"ë¬´ì„œì›Œì£½ê² \", \"ë¶ˆì•ˆí•´ë¯¸ì³\", \"ê±±ì •ë¼ì£½ê² \", \"ë‘ë ¤ì›Œ\", \"ìˆ¨ë§‰í˜€\", \"ê³µí™©\", \"íŒ¨ë‹‰\"],\n",
    "            'severe_anger': [\"í™”ë‚˜ì£½ê² \", \"ë¯¸ì³ë²„ë¦¬ê² \", \"ì§œì¦ë‚˜ì£½ê² \", \"ì—´ë°›ì•„\", \"ë¹¡ì³\", \"ë¶„í•´\", \"ì°¸ì„ìˆ˜ì—†\"],\n",
    "            'cognitive_decline': [\"ê¸°ì–µì•ˆë‚˜\", \"ëª¨ë¥´ê² \", \"ìŠì–´ë²„ë ¸\", \"ìƒê°ì•ˆë‚˜\", \"ê¹Œë¨¹ì—ˆ\", \"í—·ê°ˆë ¤\", \"ëˆ„êµ¬ì˜€ëŠ”ì§€\", \"ëª°ë¼\"]\n",
    "        }\n",
    "        \n",
    "        memory_issues = very_short = meaningless = 0\n",
    "        repetitive = []\n",
    "        \n",
    "        for i, turn in enumerate(self.chat_system.conversation_turns):\n",
    "            answer = turn.answer.replace(\" \", \"\").lower()\n",
    "            \n",
    "            for pattern_type, keywords in patterns.items():\n",
    "                for keyword in keywords:\n",
    "                    if keyword in answer:\n",
    "                        self.rule_based_alerts.append({\n",
    "                            \"type\": pattern_type, \"turn_number\": i + 1, \"keyword\": keyword,\n",
    "                            \"answer\": turn.answer, \"timestamp\": turn.timestamp,\n",
    "                            \"severity\": \"critical\" if pattern_type == 'severe_depression' else \"high\"\n",
    "                        })\n",
    "                        if pattern_type == 'cognitive_decline': memory_issues += 1\n",
    "            \n",
    "            if len(turn.answer.strip()) <= 5: very_short += 1\n",
    "            if turn.answer.strip() in [\"ìŒ\", \"ì–´\", \"ê·¸ëƒ¥\", \"ë„¤\", \"ì•„ë‹ˆ\", \"ì‘\", \"ì–´?\"]: meaningless += 1\n",
    "            if i >= 3 and turn.answer.strip() in [t.answer.strip() for t in self.chat_system.conversation_turns[i-3:i]]:\n",
    "                repetitive.append(i + 1)\n",
    "        \n",
    "        total = len(self.chat_system.conversation_turns)\n",
    "        thresholds = [\n",
    "            (memory_issues >= total * 0.7, \"severe_memory_loss\", \"critical\"),\n",
    "            (very_short >= total * 0.8, \"communication_difficulty\", \"high\"),\n",
    "            (meaningless >= total * 0.6, \"cognitive_confusion\", \"high\"),\n",
    "            (len(repetitive) >= 3, \"repetitive_behavior\", \"moderate\")\n",
    "        ]\n",
    "        \n",
    "        for condition, alert_type, severity in thresholds:\n",
    "            if condition:\n",
    "                self.rule_based_alerts.append({\"type\": alert_type, \"severity\": severity})\n",
    "    \n",
    "    def analyze_entire_conversation(self):\n",
    "        \"\"\"ì „ì²´ ëŒ€í™” ë¶„ì„\"\"\"\n",
    "        if not self.chat_system.conversation_turns: return\n",
    "        \n",
    "        self.strange_responses, self.rule_based_alerts = [], []\n",
    "        self.analyze_speech_patterns()\n",
    "        \n",
    "        conversation_text = \"\\n\".join([f\"[{i}] ì§ˆë¬¸: {turn.question}\\në‹µë³€: {turn.answer} (ê¸¸ì´: {turn.answer_length}ì)\"\n",
    "                                     for i, turn in enumerate(self.chat_system.conversation_turns, 1)])\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=Config.DEPLOYMENT,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ì¹˜ë§¤ í™˜ì ëŒ€í™” ë¶„ì„ ì „ë¬¸ AI\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"\"\"ì¹˜ë§¤ í™˜ì ëŒ€í™” ë¶„ì„í•˜ì—¬ JSON ì‘ë‹µ:\n",
    "{conversation_text}\n",
    "\n",
    "JSON: {{\"conversation_analysis\": [{{\"turn_number\": 1, \"is_strange\": true/false, \"severity\": \"normal/mild/moderate/severe\", \"emotion\": \"ê°ì •\", \"answer_quality\": \"poor/normal/good/excellent\", \"reason\": \"ì´ìœ \"}}], \"overall_assessment\": {{\"dominant_emotion\": \"ì£¼ìš”ê°ì •\", \"cognitive_level\": \"normal/mild_concern/moderate_concern/severe_concern\"}}}}\n",
    "\n",
    "ê°ì •: ê¸°ì¨,ìŠ¬í””,ê·¸ë¦¬ì›€,ë¬´ë ¥ê°,ìš°ìš¸ê°,ë¶„ë…¸,ë¶ˆì•ˆ,ì¤‘ë¦½,ê°ì‚¬,ì• ì •,í¥ë¯¸,ì§œì¦\"\"\"}\n",
    "                ], max_tokens=1024, temperature=0.1\n",
    "            )\n",
    "            \n",
    "            text = response.choices[0].message.content\n",
    "            if \"```json\" in text:\n",
    "                text = text[text.find(\"```json\")+7:text.find(\"```\", text.find(\"```json\")+7)]\n",
    "            elif \"{\" in text:\n",
    "                text = text[text.find(\"{\"):text.rfind(\"}\")+1]\n",
    "            \n",
    "            result = json.loads(text)\n",
    "            \n",
    "            for i, analysis in enumerate(result.get(\"conversation_analysis\", [])):\n",
    "                if i < len(self.chat_system.conversation_turns):\n",
    "                    turn = self.chat_system.conversation_turns[i]\n",
    "                    turn.emotion = analysis.get(\"emotion\", \"ì¤‘ë¦½\")\n",
    "                    turn.answer_quality = analysis.get(\"answer_quality\", \"normal\")\n",
    "                    \n",
    "                    if analysis.get(\"is_strange\", False):\n",
    "                        self.strange_responses.append(StrangeResponse(\n",
    "                            question=turn.question, answer=turn.answer, timestamp=turn.timestamp,\n",
    "                            severity=analysis.get(\"severity\", \"mild\"), emotion=turn.emotion,\n",
    "                            answer_quality=turn.answer_quality\n",
    "                        ))\n",
    "            return result\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def calculate_ratings(self):\n",
    "        \"\"\"í‰ì  ê³„ì‚°\"\"\"\n",
    "        total = len(self.chat_system.conversation_turns)\n",
    "        if total == 0: return {\"emotion\": 3, \"coherence\": 3, \"overall\": 3}\n",
    "        \n",
    "        emotions = [turn.emotion for turn in self.chat_system.conversation_turns if hasattr(turn, 'emotion')]\n",
    "        emotion_counts = {}\n",
    "        for emotion in emotions: emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1\n",
    "        \n",
    "        positive = [\"ê¸°ì¨\", \"ê·¸ë¦¬ì›€\", \"ê°ì‚¬\", \"ì• ì •\", \"í¥ë¯¸\"]\n",
    "        negative = [\"ìŠ¬í””\", \"ë¬´ë ¥ê°\", \"ìš°ìš¸ê°\", \"ë¶„ë…¸\", \"ë¶ˆì•ˆ\", \"ì§œì¦\"]\n",
    "        pos_count = sum(emotion_counts.get(e, 0) for e in positive)\n",
    "        neg_count = sum(emotion_counts.get(e, 0) for e in negative)\n",
    "        \n",
    "        # ê°ì • í‰ì \n",
    "        critical_alerts = [a for a in self.rule_based_alerts if a.get('severity') == 'critical']\n",
    "        if critical_alerts: emotion_rating = 1\n",
    "        elif neg_count > pos_count * 2: emotion_rating = 2\n",
    "        elif neg_count > pos_count: emotion_rating = 3\n",
    "        elif pos_count > neg_count: emotion_rating = 4\n",
    "        else: emotion_rating = 5 if pos_count > neg_count * 2 else 3\n",
    "        \n",
    "        # ì¼ê´€ì„± í‰ì \n",
    "        strange_pct = len(self.strange_responses) / total * 100\n",
    "        severe_count = sum(1 for r in self.strange_responses if r.severity == 'severe')\n",
    "        if strange_pct == 0: coherence_rating = 5\n",
    "        elif strange_pct <= 20 and severe_count == 0: coherence_rating = 4\n",
    "        elif strange_pct <= 40 and severe_count <= 1: coherence_rating = 3\n",
    "        elif strange_pct <= 60 or severe_count <= 2: coherence_rating = 2\n",
    "        else: coherence_rating = 1\n",
    "        \n",
    "        # ì „ì²´ í‰ì \n",
    "        qualities = [turn.answer_quality for turn in self.chat_system.conversation_turns if hasattr(turn, 'answer_quality')]\n",
    "        quality_counts = {\"poor\": 0, \"normal\": 0, \"good\": 0, \"excellent\": 0}\n",
    "        for q in qualities: quality_counts[q] += 1\n",
    "        \n",
    "        poor_pct = quality_counts[\"poor\"] / total * 100\n",
    "        if critical_alerts or poor_pct >= 50: overall_rating = 1\n",
    "        elif poor_pct >= 30: overall_rating = 2\n",
    "        elif quality_counts[\"excellent\"] / total >= 0.3: overall_rating = 5\n",
    "        elif quality_counts[\"good\"] / total >= 0.3: overall_rating = 4\n",
    "        else: overall_rating = 3\n",
    "        \n",
    "        return {\"emotion\": emotion_rating, \"coherence\": coherence_rating, \"overall\": overall_rating}\n",
    "    \n",
    "    def format_star_rating(self, rating):\n",
    "        return f\"{'â­' * rating}{'â˜†' * (5 - rating)} ({rating}/5)\"\n",
    "    \n",
    "    def generate_report(self):\n",
    "        \"\"\"ë¦¬í¬íŠ¸ ìƒì„± (ê°„ì†Œí™”)\"\"\"\n",
    "        # ìŒì„± ë¶„ì„ ìˆ˜í–‰\n",
    "        if hasattr(self.chat_system, 'session_id') and self.chat_system.session_id:\n",
    "            self.analyze_voice_patterns()\n",
    "        \n",
    "        self.analyze_entire_conversation()\n",
    "        total = len(self.chat_system.conversation_turns)\n",
    "        if total == 0: return \"ëŒ€í™”ê°€ ì§„í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        # ê°ì • ë¶„ì„\n",
    "        emotions = [turn.emotion for turn in self.chat_system.conversation_turns if hasattr(turn, 'emotion')]\n",
    "        emotion_counts = {}\n",
    "        for emotion in emotions: emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1\n",
    "        \n",
    "        dominant_emotion = max(emotion_counts, key=emotion_counts.get) if emotion_counts else \"ì¤‘ë¦½\"\n",
    "        ratings = self.calculate_ratings()\n",
    "        critical_alerts = [a for a in self.rule_based_alerts if a.get('severity') == 'critical']\n",
    "        \n",
    "        # ë¦¬í¬íŠ¸ ìƒì„±\n",
    "        report = f\"\"\"\n",
    "{'='*60}\n",
    "ğŸ“‹ ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ë¶„ì„ ë¦¬í¬íŠ¸\n",
    "{'='*60}\n",
    "ğŸ“… ë¶„ì„ ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}\n",
    "ğŸ†” ëŒ€í™” ID: {self.conversation_id}\n",
    "{'='*60}\n",
    "\n",
    "ğŸ¯ ì¢…í•© í‰ê°€\n",
    "{'â”€'*30}\n",
    "ğŸ˜Š ê°ì • ìƒíƒœ:     {self.format_star_rating(ratings['emotion'])}\n",
    "ğŸ’¬ ë‹µë³€ ì¼ê´€ì„±:   {self.format_star_rating(ratings['coherence'])}\n",
    "ğŸ§  ì „ë°˜ì  ì¸ì§€:   {self.format_star_rating(ratings['overall'])}\"\"\"\n",
    "\n",
    "        # ìŒì„± ë¶„ì„ ê²°ê³¼ ì¶”ê°€\n",
    "        if self.voice_analysis_result:\n",
    "            if self.voice_analysis_result.get('success'):\n",
    "                va = self.voice_analysis_result['analysis']\n",
    "                duration = self.voice_analysis_result.get('duration', 0)\n",
    "                report += f\"\\nğŸ™ï¸ ìŒì„± íŒ¨í„´:     {va['icon']} {va['level']} ({va['ratio']:.0%}, {duration:.1f}ë¶„)\"\n",
    "            else:\n",
    "                duration = self.voice_analysis_result.get('duration', 0)\n",
    "                report += f\"\\nğŸ™ï¸ ìŒì„± íŒ¨í„´:     âšª ë¶„ì„ ë¶ˆê°€ (ëŒ€í™”ì‹œê°„ {duration:.1f}ë¶„ < 3ë¶„)\"\n",
    "        \n",
    "        report += f\"\\n{'â”€'*30}\\n\\nğŸ“Š ëŒ€í™” ê°œìš”\\n{'â”€'*30}\"\n",
    "        report += f\"\\nğŸ’¬ ì´ ëŒ€í™” íšŸìˆ˜: {total}íšŒ\"\n",
    "        report += f\"\\nğŸ˜Š ì „ë°˜ì  ê°ì •: {dominant_emotion}\"\n",
    "        report += f\"\\n{'âœ… ì–´ê¸‹ë‚œ ë‹µë³€: ì—†ìŒ' if len(self.strange_responses) == 0 else f'âš ï¸ ì–´ê¸‹ë‚œ ë‹µë³€: {len(self.strange_responses)}íšŒ'}\"\n",
    "        report += f\"\\n{'âœ… ë°œí™” íŒ¨í„´: íŠ¹ì´ì‚¬í•­ ì—†ìŒ' if len(self.rule_based_alerts) == 0 else f'ğŸ” ë°œí™” íŒ¨í„´: {len(self.rule_based_alerts)}ê±´ ê´€ì°°'}\"\n",
    "        \n",
    "        # ìŒì„± ë¶„ì„ ê°œìš”\n",
    "        if self.voice_analysis_result and self.voice_analysis_result.get('success'):\n",
    "            va = self.voice_analysis_result['analysis']\n",
    "            duration = self.voice_analysis_result.get('duration', 0)\n",
    "            report += f\"\\nğŸ™ï¸ ìŒì„± ë¶„ì„: {va['total_clips']}ê°œ í´ë¦½ ì¤‘ {va['positive_clips']}ê°œì—ì„œ ì¹˜ë§¤ ê°€ëŠ¥ì„± ê°ì§€ ({duration:.1f}ë¶„)\"\n",
    "        \n",
    "        report += f\"\\n{'â”€'*30}\\n\\n\"\n",
    "        \n",
    "        # ìŒì„± ë¶„ì„ ìƒì„¸ ê²°ê³¼\n",
    "        if self.voice_analysis_result:\n",
    "            if self.voice_analysis_result.get('success'):\n",
    "                va = self.voice_analysis_result['analysis']\n",
    "                duration = self.voice_analysis_result.get('duration', 0)\n",
    "                report += f\"\"\"ğŸ™ï¸ ìŒì„± ê¸°ë°˜ ì¹˜ë§¤ ì˜ˆì¸¡ ê²°ê³¼\n",
    "{'â”€'*30}\n",
    "â±ï¸ ì „ì²´ ëŒ€í™” ì‹œê°„: {duration:.1f}ë¶„\n",
    "ğŸ§ª ì „ì²´ ë¶„ì„ í´ë¦½: {va['total_clips']}ê°œ\n",
    "ğŸ§  ì¹˜ë§¤ ê°€ëŠ¥ì„±ìœ¼ë¡œ ë¶„ë¥˜ëœ í´ip: {va['positive_clips']}ê°œ\n",
    "ğŸ“Š ì˜ˆì¸¡ ë¹„ìœ¨: {va['ratio']:.0%}\n",
    "{va['icon']} ì¹˜ë§¤ ê°€ëŠ¥ì„± ìˆ˜ì¤€: {va['level']}\n",
    "ğŸ“Œ ì°¸ê³ : ì´ ê²°ê³¼ëŠ” ìŒì„±ì˜ ì–µì–‘, í”¼ì¹˜, ë–¨ë¦¼ ë“± ìŒí–¥ì  íŠ¹ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.\n",
    "{'â”€'*30}\n",
    "\n",
    "\"\"\"\n",
    "            elif self.voice_analysis_result.get('reason') == 'insufficient_duration':\n",
    "                duration = self.voice_analysis_result.get('duration', 0)\n",
    "                report += f\"\"\"ğŸ™ï¸ ìŒì„± ë¶„ì„ ì•ˆë‚´\n",
    "{'â”€'*30}\n",
    "â±ï¸ ì „ì²´ ëŒ€í™” ì‹œê°„: {duration:.1f}ë¶„\n",
    "âš ï¸ ì •í™•í•œ ìŒì„± íŒ¨í„´ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ìµœì†Œ 3ë¶„ ì´ìƒì˜ ëŒ€í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "ğŸ’¡ ë‹¤ìŒë²ˆì—ëŠ” ì¡°ê¸ˆ ë” ê¸¸ê²Œ ëŒ€í™”í•´ë³´ì‹œë©´ ìŒì„± ë¶„ì„ ê²°ê³¼ë„ í•¨ê»˜ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "{'â”€'*30}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        # ê¶Œì¥ì‚¬í•­\n",
    "        voice_warning = 0\n",
    "        if self.voice_analysis_result and self.voice_analysis_result.get('success'):\n",
    "            level = self.voice_analysis_result['analysis']['level']\n",
    "            voice_warning = 2 if level == \"ë†’ìŒ\" else 1 if level == \"ì¤‘ê°„\" else 0\n",
    "        \n",
    "        report += f\"ğŸ’¡ ê¶Œì¥ì‚¬í•­\\n{'â”€'*30}\\n\"\n",
    "        if critical_alerts:\n",
    "            report += \"ğŸš¨ ê¸´ê¸‰ ê¶Œì¥ì‚¬í•­: ì‹¬ê°í•œ ì •ì‹ ê±´ê°• ìœ„í—˜ ì‹ í˜¸ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\\n\"\n",
    "        elif len([a for a in self.rule_based_alerts if a.get('severity') == 'high']) >= 2 or voice_warning >= 2:\n",
    "            report += \"âš ï¸ ì£¼ì˜ ê¶Œì¥ì‚¬í•­: ìµœê·¼ ëŒ€í™”ì—ì„œ í˜¼ë€ìŠ¤ëŸ¬ìš´ ë‹µë³€ì´ ìì£¼ ë³´ì˜€ìŠµë‹ˆë‹¤.\\n\"\n",
    "        elif len(self.strange_responses) > 0:\n",
    "            report += \"ğŸ’™ ê´€ì‹¬ ê¶Œì¥ì‚¬í•­: ì „ë°˜ì ìœ¼ë¡œ ì˜ ì‘ë‹µí•´ì£¼ì…¨ì§€ë§Œ, ê°„í˜¹ ì–´ê¸‹ë‚œ ë‹µë³€ì´ ë³´ì…ë‹ˆë‹¤.\\n\"\n",
    "        else:\n",
    "            report += \"ğŸ’š í›Œë¥­í•œ ìƒíƒœ: ì–´ë¥´ì‹ ê»˜ì„œ ë¬´ì²™ ì•ˆì •ì ìœ¼ë¡œ ì˜ ì‘ë‹µí•´ì£¼ì…¨ìŠµë‹ˆë‹¤.\\n\"\n",
    "        \n",
    "        report += f\"{'â”€'*30}\\n\\n{'='*60}\\nğŸ“‹ ë¦¬í¬íŠ¸ ë - ì–´ë¥´ì‹ ì˜ ê±´ê°•ê³¼ í–‰ë³µì„ ìœ„í•´\\n{'='*60}\"\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def save_files(self, image_path):\n",
    "        \"\"\"íŒŒì¼ ì €ì¥\"\"\"\n",
    "        # í´ë” êµ¬ì¡° ìƒì„±\n",
    "        image_basename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        image_dir = Path(\"conversation_log\") / image_basename\n",
    "        image_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        existing_dirs = list(image_dir.glob(f\"{image_basename}_conv*\"))\n",
    "        conv_number = len(existing_dirs) + 1\n",
    "        self.conversation_id = f\"{image_basename}_conv{conv_number}\"\n",
    "        \n",
    "        conversation_dir = image_dir / self.conversation_id\n",
    "        conversation_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # ê°œë³„ QA ì €ì¥\n",
    "        for i, turn in enumerate(self.chat_system.conversation_turns, 1):\n",
    "            qa_file = conversation_dir / f\"qa_{i:02d}.txt\"\n",
    "            qa_file.write_text(f\"\"\"=== ì§ˆì˜ì‘ë‹µ {i}ë²ˆ ===\n",
    "ëŒ€í™” ID: {self.conversation_id}\n",
    "ì‹œê°„: {turn.timestamp}\n",
    "{'='*25}\n",
    "\n",
    "ğŸ¤– ì§ˆë¬¸:\n",
    "{turn.question}\n",
    "\n",
    "ğŸ‘¤ ë‹µë³€:\n",
    "{turn.answer}\n",
    "{'='*25}\"\"\", encoding='utf-8')\n",
    "        \n",
    "        # ë©”ì¸ ëŒ€í™” íŒŒì¼\n",
    "        conversation_file = conversation_dir / f\"{self.conversation_id}.txt\"\n",
    "        conversation_content = f\"\"\"{'='*50}\n",
    "ğŸ’¬ ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ê¸°ë¡\n",
    "{'='*50}\n",
    "ğŸ†” ëŒ€í™” ID: {self.conversation_id}\n",
    "ğŸ“Š ì´ ëŒ€í™” ìˆ˜: {len(self.chat_system.conversation_turns)}íšŒ\n",
    "{'='*50}\n",
    "\n",
    "\"\"\"\n",
    "        for turn in self.chat_system.conversation_turns:\n",
    "            conversation_content += f\"[{turn.timestamp}]\\nğŸ¤– ì§ˆë¬¸: {turn.question}\\nğŸ‘¤ ë‹µë³€: {turn.answer}\\n{'-'*30}\\n\\n\"\n",
    "        \n",
    "        conversation_file.write_text(conversation_content, encoding='utf-8')\n",
    "        \n",
    "        # ë¶„ì„ ë¦¬í¬íŠ¸ ì €ì¥\n",
    "        analysis_dir = Path(\"analysis\")\n",
    "        analysis_dir.mkdir(exist_ok=True)\n",
    "        analysis_file = analysis_dir / f\"{self.conversation_id}_analysis.txt\"\n",
    "        analysis_file.write_text(self.generate_report(), encoding='utf-8')\n",
    "        \n",
    "        print(f\"âœ… íŒŒì¼ ì €ì¥ ì™„ë£Œ!\\nğŸ“ ëŒ€í™” í´ë”: {conversation_dir}\\nğŸ“„ ëŒ€í™” íŒŒì¼: {conversation_file}\\nğŸ“Š ë¶„ì„ íŒŒì¼: {analysis_file}\")\n",
    "        return str(conversation_file), str(analysis_file)\n",
    "    \n",
    "    def generate_story(self, image_path):\n",
    "        \"\"\"ì¶”ì–µ ìŠ¤í† ë¦¬ ìƒì„±\"\"\"\n",
    "        conversation_text = \"\\n\".join([f\"ì§ˆë¬¸: {turn.question}\\në‹µë³€: {turn.answer}\" for turn in self.chat_system.conversation_turns])\n",
    "        if not conversation_text.strip(): return None, None\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=Config.DEPLOYMENT,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ë…¸ì¸ ì¶”ì–µ ìŠ¤í† ë¦¬í…”ëŸ¬\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"\"\"ëŒ€í™” ê¸°ë°˜ìœ¼ë¡œ ì–´ë¥´ì‹  1ì¸ì¹­ ì¶”ì–µ ìŠ¤í† ë¦¬ 15ì¤„ ì‘ì„±:\n",
    "{conversation_text}\n",
    "ì§€ì¹¨: ë‹µë³€ ê¸°ë°˜ ì‘ì„±, ê°ì •ê³¼ ê°ê° í¬í•¨, ë”°ëœ»í•œ í†¤, ì†ì/ì†ë…€ì—ê²Œ ë“¤ë ¤ì£¼ëŠ” ì–´íˆ¬\"\"\"}\n",
    "                ], max_tokens=512, temperature=0.8\n",
    "            )\n",
    "            \n",
    "            story = response.choices[0].message.content\n",
    "            story_dir = Path(\"story_telling\")\n",
    "            story_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            story_file = story_dir / f\"{os.path.splitext(os.path.basename(image_path))[0]}_story.txt\"\n",
    "            story_file.write_text(story, encoding='utf-8')\n",
    "            \n",
    "            return story, str(story_file)\n",
    "        except:\n",
    "            return None, None\n",
    "\n",
    "print(\"âœ… StoryGenerator í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f031a9b7",
   "metadata": {},
   "source": [
    "# ì½”ë“œ í†µí•©ë¶€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bd8c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedDementiaSystem:\n",
    "    def __init__(self):\n",
    "        self.image_analyzer = ImageAnalyzer()\n",
    "        self.chat_system = ChatSystem()\n",
    "        self.voice_system = VoiceSystem() if Config.SPEECH_KEY else None\n",
    "        self.story_generator = StoryGenerator(self.chat_system)\n",
    "    \n",
    "    def start_conversation(self, image_path):\n",
    "        \"\"\"ì´ë¯¸ì§€ ë¶„ì„ ë° ëŒ€í™” ì‹œì‘\"\"\"\n",
    "        if not os.path.exists(image_path): return None\n",
    "        \n",
    "        analysis_result = self.image_analyzer.analyze_image(image_path)\n",
    "        if not analysis_result: return None\n",
    "        \n",
    "        self.chat_system.setup_conversation_context(analysis_result)\n",
    "        return self.chat_system.generate_initial_question()\n",
    "    \n",
    "    def run_conversation(self, image_path, is_voice=False):\n",
    "        \"\"\"ëŒ€í™” ì‹¤í–‰\"\"\"\n",
    "        initial_question = self.start_conversation(image_path)\n",
    "        if not initial_question: return None\n",
    "        \n",
    "        # ì‹œì‘ ë©”ì‹œì§€\n",
    "        if is_voice and self.voice_system:\n",
    "            welcome = \"ì•ˆë…•í•˜ì„¸ìš”. ì‚¬ì§„ì„ ë³´ë©° ëŒ€í™”í•´ìš”.\"\n",
    "            print(f\"ğŸ¤– {welcome}\")\n",
    "            self.voice_system.synthesize_speech(welcome)\n",
    "            print(f\"ğŸ¤– {initial_question}\")\n",
    "            self.voice_system.synthesize_speech(initial_question)\n",
    "        else:\n",
    "            print(f\"ğŸ¤– {initial_question}\")\n",
    "        \n",
    "        conversation_type = \"ìŒì„±\" if is_voice else \"í…ìŠ¤íŠ¸\"\n",
    "        print(f\"\\n{'='*40}\\n{'ğŸ™ï¸' if is_voice else 'ğŸ’¬'} {conversation_type} ëŒ€í™” ì‹œì‘!\")\n",
    "        print(f\"ğŸ’¡ {'ì¢…ë£Œë¼ê³  ë§í•˜ë©´' if is_voice else 'exit ë˜ëŠ” ì¢…ë£Œë¥¼ ì…ë ¥í•˜ë©´'} ëë‚©ë‹ˆë‹¤\\n{'='*40}\")\n",
    "        \n",
    "        # ëŒ€í™” ë£¨í”„\n",
    "        while True:\n",
    "            if is_voice and self.voice_system:\n",
    "                print(\"ğŸ™ï¸ ë§ì”€í•´ ì£¼ì„¸ìš”...\")\n",
    "                self.chat_system.start_recording()\n",
    "                user_input = self.voice_system.transcribe_speech()\n",
    "                self.chat_system.stop_recording()\n",
    "                \n",
    "                if not user_input.strip(): continue\n",
    "                if user_input == \"ì¢…ë£Œ\":\n",
    "                    end_msg = \"ëŒ€í™”ë¥¼ ë§ˆì¹˜ê² ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.\"\n",
    "                    print(f\"ğŸ¤– {end_msg}\")\n",
    "                    self.voice_system.synthesize_speech(end_msg)\n",
    "                    break\n",
    "            else:\n",
    "                user_input = input(\"\\nğŸ‘¤ ë‹µë³€: \").strip()\n",
    "                if user_input.lower() in ['exit', 'ì¢…ë£Œ', 'quit', 'q']:\n",
    "                    print(\"ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "                    break\n",
    "            \n",
    "            answer, should_end = self.chat_system.chat_about_image(user_input, with_audio=is_voice)\n",
    "            print(f\"ğŸ¤– {answer}\")\n",
    "            \n",
    "            if is_voice and self.voice_system:\n",
    "                self.voice_system.synthesize_speech(answer)\n",
    "            \n",
    "            if should_end:\n",
    "                end_msg = \"ëŒ€í™” ì‹œê°„ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\"\n",
    "                print(f\"â° {end_msg}\")\n",
    "                if is_voice and self.voice_system:\n",
    "                    self.voice_system.synthesize_speech(end_msg)\n",
    "                break\n",
    "        \n",
    "        # ë¶„ì„ ë° ì €ì¥\n",
    "        print(\"\\nğŸ“Š ì¢…í•© ë¶„ì„ ê²°ê³¼ ìƒì„± ì¤‘...\")\n",
    "        conversation_file, analysis_file = self.story_generator.save_files(image_path)\n",
    "        story, story_file = self.story_generator.generate_story(image_path)\n",
    "        \n",
    "        print(self.story_generator.generate_report())\n",
    "        \n",
    "        if story:\n",
    "            print(f\"\\n{'='*50}\\nğŸ“– ìƒì„±ëœ ì¶”ì–µ ì´ì•¼ê¸°\\n{'='*50}\\n{story}\\n{'='*50}\")\n",
    "        \n",
    "        print(f\"ğŸ“‚ ëŒ€í™”ê¸°ë¡: {conversation_file}\\nğŸ“Š ë¶„ì„ê²°ê³¼: {analysis_file}\")\n",
    "        if story_file: print(f\"ğŸ“– ìŠ¤í† ë¦¬: {story_file}\")\n",
    "        \n",
    "        return {\n",
    "            'conversation_file': conversation_file, 'analysis_file': analysis_file,\n",
    "            'story_file': story_file, 'story_content': story,\n",
    "            'conversation_id': self.story_generator.conversation_id\n",
    "        }\n",
    "\n",
    "print(\"âœ… OptimizedDementiaSystem í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04184284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_conversation():\n",
    "    \"\"\"í…ìŠ¤íŠ¸ ëŒ€í™” ì‹¤í–‰\"\"\"\n",
    "    print(\"=== ğŸ’¬ í…ìŠ¤íŠ¸ ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ì‹œìŠ¤í…œ ===\")\n",
    "    image_path = \"images.jpg\"\n",
    "    \n",
    "    if not os.path.exists(image_path):\n",
    "        print(\"âŒ ì˜¬ë°”ë¥¸ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        system = OptimizedDementiaSystem()\n",
    "        return system.run_conversation(image_path, is_voice=False)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}\")\n",
    "        return None\n",
    "\n",
    "def interactive_voice_conversation():\n",
    "    \"\"\"ìŒì„± ëŒ€í™” ì‹¤í–‰\"\"\"\n",
    "    print(\"=== ğŸ¤ ìŒì„± ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ì‹œìŠ¤í…œ ===\")\n",
    "    image_path = input(\"ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: \").strip()\n",
    "    \n",
    "    if not image_path or not os.path.exists(image_path):\n",
    "        print(\"âŒ ì˜¬ë°”ë¥¸ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        system = OptimizedDementiaSystem()\n",
    "        if not system.voice_system:\n",
    "            print(\"âŒ ìŒì„± ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Azure Speech Service í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "            return None\n",
    "        return system.run_conversation(image_path, is_voice=True)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"âœ… ì‹¤í–‰ í•¨ìˆ˜ë“¤ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3610556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!\n",
      "ğŸ’¡ interactive_conversation() í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•´ë³´ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # í™˜ê²½ í™•ì¸\n",
    "    if not Config.ENDPOINT or not Config.SUBSCRIPTION_KEY:\n",
    "        print(\"âš ï¸ Azure OpenAI ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤:\")\n",
    "        print(\"   - gpt-endpoint\")\n",
    "        print(\"   - gpt-key\")\n",
    "    \n",
    "    if not Config.SPEECH_KEY:\n",
    "        print(\"âš ï¸ ìŒì„± ê¸°ëŠ¥ì„ ìœ„í•´ Azure Speech Service ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤:\")\n",
    "        print(\"   - speech-key\")\n",
    "    \n",
    "    print(\"\\nâœ… ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "    print(\"ğŸ’¡ interactive_conversation() í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•´ë³´ì„¸ìš”!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4bb057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ğŸ¤ ìŒì„± ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ì‹œìŠ¤í…œ ===\n",
      "ğŸ¤– ì•ˆë…•í•˜ì„¸ìš”. ì‚¬ì§„ì„ ë³´ë©° ëŒ€í™”í•´ìš”.\n",
      "ğŸ¤– \"ì–´ë¥´ì‹ , ì´ ì‚¬ì§„ ì† ì¶•í•˜ í–‰ì‚¬ ë¶„ìœ„ê¸°ê°€ ì°¸ ë”°ëœ»í•˜ë„¤ìš”. ì˜ˆì „ì— ì´ëŸ° ëª¨ì„ì— ì°¸ì„í•´ë³´ì‹  ì  ìˆìœ¼ì‹ ê°€ìš”?\"\n",
      "\n",
      "========================================\n",
      "ğŸ™ï¸ ìŒì„± ëŒ€í™” ì‹œì‘!\n",
      "ğŸ’¡ ì¢…ë£Œë¼ê³  ë§í•˜ë©´ ëë‚©ë‹ˆë‹¤\n",
      "========================================\n",
      "ğŸ™ï¸ ë§ì”€í•´ ì£¼ì„¸ìš”...\n",
      "ğŸ™ï¸ ë§ì”€í•´ ì£¼ì„¸ìš”...\n",
      "ğŸ‘¤ \"ì— ì°¸ì„í•´ì˜¨ ì  ìˆì–´?\"\n",
      "ğŸ¤– \"ì•„, ê·¸ëŸ¬ì…¨êµ°ìš”! ì¶•í•˜ ëª¨ì„ì€ ëŠ˜ íŠ¹ë³„í•˜ì£ . í˜¹ì‹œ ê¸°ì–µì— ë‚¨ëŠ” ì¶•í•˜ í–‰ì‚¬ë‚˜ ë¶„ìœ„ê¸°ê°€ ë– ì˜¤ë¥´ì‹œë‚˜ìš”?\"\n",
      "ğŸ™ï¸ ë§ì”€í•´ ì£¼ì„¸ìš”...\n",
      "ğŸ™ï¸ ë§ì”€í•´ ì£¼ì„¸ìš”...\n",
      "ğŸ‘¤ \"ì–´ ê¸°ì–µì— ë‚¨ëŠ”ê±´ë° ìƒì¼ ìƒì¼ë‚ ë„ ìˆì–´?\"\n",
      "ğŸ¤– \"ìƒì¼ë‚ ì´ë¼ë‹ˆ, ì •ë§ íŠ¹ë³„í•œ ë‚ ì´ì…¨ê² ì–´ìš”! ìƒì¼ë‚ ì— ì–´ë–¤ ë¶„ìœ„ê¸°ì˜€ëŠ”ì§€ ë” ìì„¸íˆ ë“¤ë ¤ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?\"\n",
      "ğŸ™ï¸ ë§ì”€í•´ ì£¼ì„¸ìš”...\n",
      "ğŸ™ï¸ ë§ì”€í•´ ì£¼ì„¸ìš”...\n",
      "ğŸ‘¤ \"ì„¸ë¯¸ë‚˜ë¥¼ ì¼€ì´í¬ ë¨¹ì—ˆì§€?\"\n",
      "ğŸ¤– \"ì„¸ë¯¸ë‚˜ì—ì„œ ì¼€ì´í¬ë¥¼ ë“œì…¨ë‹¤ë‹ˆ ì¬ë¯¸ìˆë„¤ìš”! ì„¸ë¯¸ë‚˜ ë¶„ìœ„ê¸°ëŠ” ì–´ë• ë‚˜ìš”? ì‚¬ëŒë“¤ë„ ë§ì´ ëª¨ì˜€ì—ˆë‚˜ìš”?\"\n",
      "ğŸ™ï¸ ë§ì”€í•´ ì£¼ì„¸ìš”...\n",
      "ğŸ™ï¸ ë§ì”€í•´ ì£¼ì„¸ìš”...\n",
      "ğŸ‘¤ \"ì¢…ë£Œ.\"\n",
      "ğŸ¤– ëŒ€í™”ë¥¼ ë§ˆì¹˜ê² ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“Š ì¢…í•© ë¶„ì„ ê²°ê³¼ ìƒì„± ì¤‘...\n",
      "ğŸ“ ì €ì¥ êµ¬ì¡°:\n",
      "   ë©”ì¸ í´ë”: conversation_log/images/images_conv5/\n",
      "   ëŒ€í™” íŒŒì¼: images_conv5.txt\n",
      "\n",
      "âœ… íŒŒì¼ ì €ì¥ ì™„ë£Œ!\n",
      "ğŸ“ ëŒ€í™” í´ë”: conversation_log\\images\\images_conv5\n",
      "ğŸ“„ ëŒ€í™” íŒŒì¼: conversation_log\\images\\images_conv5\\images_conv5.txt\n",
      "ğŸ“Š ë¶„ì„ íŒŒì¼: analysis\\images_conv5_analysis.txt\n",
      "ğŸ“‹ QA íŒŒì¼ë“¤: 3ê°œ\n",
      "\n",
      "============================================================\n",
      "ğŸ“‹ ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ë¶„ì„ ë¦¬í¬íŠ¸\n",
      "============================================================\n",
      "ğŸ“… ë¶„ì„ ì¼ì‹œ: 2025ë…„ 06ì›” 09ì¼ 10:40:56\n",
      "ğŸ†” ëŒ€í™” ID: images_conv5\n",
      "============================================================\n",
      "\n",
      "ğŸ¯ ì¢…í•© í‰ê°€\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ˜Š ê°ì • ìƒíƒœ:     â­â­â­â­â˜† (4/5)\n",
      "ğŸ’¬ ë‹µë³€ ì¼ê´€ì„±:   â­â­â˜†â˜†â˜† (2/5)\n",
      "ğŸ§  ì „ë°˜ì  ì¸ì§€:   â­â˜†â˜†â˜†â˜† (1/5)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“Š ëŒ€í™” ê°œìš”\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ’¬ ì´ ëŒ€í™” íšŸìˆ˜: 3íšŒ\n",
      "ğŸ˜Š ì „ë°˜ì  ê°ì •: ê¸ì •ì  (ì£¼ìš”: ë¶ˆì•ˆ)\n",
      "âš ï¸ ì–´ê¸‹ë‚œ ë‹µë³€: 3íšŒ\n",
      "âœ… ë°œí™” íŒ¨í„´: íŠ¹ì´ì‚¬í•­ ì—†ìŒ\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸš¨ ì£¼ìš” ë°œê²¬ì‚¬í•­\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ” ì–´ê¸‹ë‚œ ë‹µë³€ ë¶„ì„:\n",
      "  ğŸŸ¡ ì¡°ê¸ˆ ì–´ê¸‹ë‚¨: 1íšŒ\n",
      "  ğŸŸ  ê½¤ ì–´ê¸‹ë‚¨: 2íšŒ\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“ ì–´ê¸‹ë‚œ ë‹µë³€ ìƒì„¸\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "1. 2025-06-09 10:39:39\n",
      "   â“ ì§ˆë¬¸: \"ì–´ë¥´ì‹ , ì´ ì‚¬ì§„ ì† ì¶•í•˜ í–‰ì‚¬ ë¶„ìœ„ê¸°ê°€ ì°¸ ë”°ëœ»í•˜ë„¤ìš”. ì˜ˆì „ì— ì´ëŸ° ëª¨ì„ì— ì°¸ì„í•´ë³´ì‹  ì  ìˆìœ¼ì‹ ê°€ìš”?\"\n",
      "   ğŸ’¬ ë‹µë³€: ì— ì°¸ì„í•´ì˜¨ ì  ìˆì–´?\n",
      "   ğŸ˜Š ìƒíƒœ: ë¶ˆì•ˆ | ğŸ¯ í’ˆì§ˆ: poor\n",
      "\n",
      "2. 2025-06-09 10:40:00\n",
      "   â“ ì§ˆë¬¸: \"ì•„, ê·¸ëŸ¬ì…¨êµ°ìš”! ì¶•í•˜ ëª¨ì„ì€ ëŠ˜ íŠ¹ë³„í•˜ì£ . í˜¹ì‹œ ê¸°ì–µì— ë‚¨ëŠ” ì¶•í•˜ í–‰ì‚¬ë‚˜ ë¶„ìœ„ê¸°ê°€ ë– ì˜¤ë¥´ì‹œë‚˜ìš”?\"\n",
      "   ğŸ’¬ ë‹µë³€: ì–´ ê¸°ì–µì— ë‚¨ëŠ”ê±´ë° ìƒì¼ ìƒì¼ë‚ ë„ ìˆì–´?\n",
      "   ğŸ˜Š ìƒíƒœ: ê·¸ë¦¬ì›€ | ğŸ¯ í’ˆì§ˆ: normal\n",
      "\n",
      "3. 2025-06-09 10:40:19\n",
      "   â“ ì§ˆë¬¸: \"ìƒì¼ë‚ ì´ë¼ë‹ˆ, ì •ë§ íŠ¹ë³„í•œ ë‚ ì´ì…¨ê² ì–´ìš”! ìƒì¼ë‚ ì— ì–´ë–¤ ë¶„ìœ„ê¸°ì˜€ëŠ”ì§€ ë” ìì„¸íˆ ë“¤ë ¤ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?\"\n",
      "   ğŸ’¬ ë‹µë³€: ì„¸ë¯¸ë‚˜ë¥¼ ì¼€ì´í¬ ë¨¹ì—ˆì§€?\n",
      "   ğŸ˜Š ìƒíƒœ: í¥ë¯¸ | ğŸ¯ í’ˆì§ˆ: poor\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ’¡ ê¶Œì¥ì‚¬í•­\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ’™ ê´€ì‹¬ ê¶Œì¥ì‚¬í•­:\n",
      "   ì „ë°˜ì ìœ¼ë¡œ ì˜ ì‘ë‹µí•´ì£¼ì…¨ì§€ë§Œ, ê°„í˜¹ ì–´ê¸‹ë‚œ ë‹µë³€ì´ ë³´ì…ë‹ˆë‹¤.\n",
      "   ê°€ë³ê²Œë¼ë„ ì£¼ë³€ì˜ ê´€ì‹¬ê³¼ í™•ì¸ì´ ìˆìœ¼ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ  ê°€ì¡±ì„ ìœ„í•œ ì¡°ì–¸\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸŸ¤ ë¶ˆì•ˆê°ì„ ëŠë¼ì‹œëŠ” ê²ƒ ê°™ì•„ìš”.\n",
      "   â†’ ì–´ë¥´ì‹ ì˜ ì´ì•¼ê¸°ë¥¼ ì˜ ë“¤ì–´ì£¼ì‹œê³ , ë”°ëœ»í•œ ë§ í•œë§ˆë””ê°€ í° ìœ„ë¡œê°€ ë©ë‹ˆë‹¤.\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“ˆ í‰ê°€ ê¸°ì¤€\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ˜Š ê°ì • ìƒíƒœ: ê¸ì •ì ì´ê³  ì•ˆì •ì ì¸ ê°ì • í‘œí˜„ì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜\n",
      "ğŸ’¬ ë‹µë³€ ì¼ê´€ì„±: ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì ì ˆí•œ ë‹µë³€ì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜\n",
      "ğŸ§  ì „ë°˜ì  ì¸ì§€: ë‹µë³€ì˜ í’ˆì§ˆê³¼ ì†Œí†µ ëŠ¥ë ¥ì„ ì¢…í•©í•œ ì ìˆ˜\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "============================================================\n",
      "ğŸ“‹ ë¦¬í¬íŠ¸ ë - ì–´ë¥´ì‹ ì˜ ê±´ê°•ê³¼ í–‰ë³µì„ ìœ„í•´\n",
      "============================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "ğŸ“– ìƒì„±ëœ ì¶”ì–µ ì´ì•¼ê¸°\n",
      "==================================================\n",
      "\"ì•„, ê·¸ë ‡êµ¬ë‚˜. ì´ ì‚¬ì§„ì„ ë³´ë‹ˆ ì°¸ ë”°ëœ»í•œ ì¶•í•˜ ë¶„ìœ„ê¸°ê°€ ëŠê»´ì§€ë„¤. ë‚˜ë„ ì´ëŸ° ì¶•í•˜ í–‰ì‚¬ì— ì—¬ëŸ¬ ë²ˆ ì°¸ì„í–ˆë˜ ê¸°ì–µì´ ìˆì–´. ì •ë§ íŠ¹ë³„í•œ ìˆœê°„ë“¤ì´ì—ˆì§€. íŠ¹íˆ ê¸°ì–µì— ë‚¨ëŠ” ê±´ ë‚´ ìƒì¼ë‚ ì´ì—ˆì–´. ì˜¤ë˜ì „ ì¼ì¸ë°ë„ ìƒìƒí•˜ê²Œ ë– ì˜¤ë¥¸ë‹¤.\n",
      "\n",
      "ê·¸ë‚ ì€ ë‚´ê°€ ì¡°ê¸ˆ ë” íŠ¹ë³„í•œ ì‚¬ëŒì´ë¼ë„ ëœ ê²ƒì²˜ëŸ¼ ëª¨ë‘ê°€ ë‚˜ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ëª¨ì˜€ì§€. ì†ë‹˜ë“¤ì€ ì›ƒìŒ ê°€ë“í•œ ì–¼êµ´ë¡œ ì¶•í•˜í•´ì£¼ê³ , ì¹´í˜ì—ì„  ìƒì¼ ì¼€ì´í¬ê°€ ì¤€ë¹„ë˜ì–´ ìˆì—ˆì–´. ê·¸ ì¼€ì´í¬ëŠ” ì •ë§ë¡œ í¬ê³  ì•„ë¦„ë‹¤ì› ëŠ”ë°, ìœ„ì— ì´ˆë„ ê½‚í˜€ ìˆì—ˆì§€. ì´ˆë¥¼ ë¶ˆì—ˆì„ ë•Œ ì‚¬ëŒë“¤ì´ ë°•ìˆ˜ë¥¼ ì¹˜ë©° í™˜í˜¸í•˜ë˜ ì†Œë¦¬ê°€ ì•„ì§ë„ ê·€ì— ì„ í•˜êµ¬ë‚˜.\n",
      "\n",
      "ê°€ì¥ ê¸°ì–µì— ë‚¨ëŠ” ê±´ ì¼€ì´í¬ë¥¼ ë‚˜ëˆ  ë¨¹ë˜ ìˆœê°„ì´ì—ˆì–´. í•œ ì… ë² ì–´ ë¬¸ ì´ˆì½œë¦¿ ì¼€ì´í¬ì˜ ë‹¬ì½¤í•¨ê³¼ í¬ë¦¼ì˜ ë¶€ë“œëŸ¬ì›€ì´ ì •ë§ í™©í™€í–ˆì§€. ê·¸ë•ŒëŠ” ì§€ê¸ˆì²˜ëŸ¼ ì‚¬ì§„ ì°ëŠ” ë¬¸í™”ê°€ ì—†ì—ˆìœ¼ë‹ˆ, ë§ˆìŒìœ¼ë¡œ ê·¸ ìˆœê°„ì„ ê°„ì§í–ˆì–´. ì‚¬ëŒë“¤ì˜ ë”°ëœ»í•œ ì›ƒìŒê³¼ ë‚´ê°€ ëŠê¼ˆë˜ í–‰ë³µì€ ì •ë§ ì†Œì¤‘í•œ ì¶”ì–µì´ì•¼.\n",
      "\n",
      "ë‚´ ì¹œêµ¬ë“¤ ì¤‘ í•œ ëª…ì€ ê¸°íƒ€ë¥¼ ê°€ì ¸ì™€ì„œ ì¶•í•˜ ë…¸ë˜ë¥¼ ë¶ˆëŸ¬ì¤¬ëŠ”ë°, ì •ë§ ê°ë™ì ì´ì—ˆì–´. ê·¸ ë©œë¡œë””ê°€ ë°”ëŒì„ íƒ€ê³  í¼ì ¸ë‚˜ê°€ë©° ê·¸ ë‚ ì„ ë”ìš± íŠ¹ë³„í•˜ê²Œ ë§Œë“¤ì—ˆì§€. ëª¨ë‘ê°€ í•¨ê»˜ ë°•ìˆ˜ë¥¼ ì¹˜ë©° ë…¸ë˜ë¥¼ ë”°ë¼ ë¶€ë¥´ë˜ ê·¸ ìˆœê°„ì€ ë§ë¡œ ë‹¤ í‘œí˜„í•  ìˆ˜ ì—†ì„ ë§Œí¼ ì¦ê±°ì› ì–´.\n",
      "\n",
      "ê·¸ë¦¬ê³  ìƒì¼ ì„ ë¬¼ë„ ë¹¼ë†“ì„ ìˆ˜ ì—†ì§€. ì‘ì€ ìƒìì— ë‹´ê¸´ ì†ìˆ˜ê±´ì„ ë°›ì•˜ëŠ”ë°, ê·¸ ì†ìˆ˜ê±´ì€ ì–¼ë§ˆë‚˜ ê·€í–ˆë˜ì§€ ì§€ê¸ˆë„ ê°„ì§í•˜ê³  ìˆë‹¨ë‹¤. ì†ìœ¼ë¡œ ê¾¹ê¾¹ ëˆŒëŸ¬ì„œ ë‚´ ì´ë¦„ì„ ìˆ˜ë†“ì€ ì†ìˆ˜ê±´ì´ì—ˆì–´. ê·¸ ë§ˆìŒì´ ë„ˆë¬´ë‚˜ ê³ ë§™ê³  ì‚¬ë‘ìŠ¤ëŸ¬ì› ì§€.\n",
      "\n",
      "ê·¸ë‚ ì˜ ë”°ëœ»í•œ ê¸°ì–µì€ ë‚´ ì‚¶ì—ì„œ ë¹›ë‚˜ëŠ” ë³´ì„ ê°™ì€ ë‚ ë“¤ì´ì•¼. ì†ì£¼ì•¼, ë„ˆë„ ê·¸ëŸ° í–‰ë³µí•œ ìˆœê°„ì„ ë§ì´ ë§Œë“¤ì–´ê°€ë©´ ì¢‹ê² ì–´. ì‚¬ëŒë“¤ê³¼ í•¨ê»˜ í•˜ëŠ” ì‘ì€ ìˆœê°„ë“¤ì´ ë‚˜ì¤‘ì— ë„¤ ì‚¶ì„ ë°ê²Œ ë¹„ì¶”\n",
      "==================================================\n",
      "ğŸ“‚ ëŒ€í™”ê¸°ë¡: conversation_log\\images\\images_conv5\\images_conv5.txt\n",
      "ğŸ“Š ë¶„ì„ê²°ê³¼: analysis\\images_conv5_analysis.txt\n",
      "ğŸ“– ìŠ¤í† ë¦¬: story_telling\\images_story.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'conversation_file': 'conversation_log\\\\images\\\\images_conv5\\\\images_conv5.txt',\n",
       " 'analysis_file': 'analysis\\\\images_conv5_analysis.txt',\n",
       " 'story_file': 'story_telling\\\\images_story.txt',\n",
       " 'story_content': '\"ì•„, ê·¸ë ‡êµ¬ë‚˜. ì´ ì‚¬ì§„ì„ ë³´ë‹ˆ ì°¸ ë”°ëœ»í•œ ì¶•í•˜ ë¶„ìœ„ê¸°ê°€ ëŠê»´ì§€ë„¤. ë‚˜ë„ ì´ëŸ° ì¶•í•˜ í–‰ì‚¬ì— ì—¬ëŸ¬ ë²ˆ ì°¸ì„í–ˆë˜ ê¸°ì–µì´ ìˆì–´. ì •ë§ íŠ¹ë³„í•œ ìˆœê°„ë“¤ì´ì—ˆì§€. íŠ¹íˆ ê¸°ì–µì— ë‚¨ëŠ” ê±´ ë‚´ ìƒì¼ë‚ ì´ì—ˆì–´. ì˜¤ë˜ì „ ì¼ì¸ë°ë„ ìƒìƒí•˜ê²Œ ë– ì˜¤ë¥¸ë‹¤.\\n\\nê·¸ë‚ ì€ ë‚´ê°€ ì¡°ê¸ˆ ë” íŠ¹ë³„í•œ ì‚¬ëŒì´ë¼ë„ ëœ ê²ƒì²˜ëŸ¼ ëª¨ë‘ê°€ ë‚˜ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ëª¨ì˜€ì§€. ì†ë‹˜ë“¤ì€ ì›ƒìŒ ê°€ë“í•œ ì–¼êµ´ë¡œ ì¶•í•˜í•´ì£¼ê³ , ì¹´í˜ì—ì„  ìƒì¼ ì¼€ì´í¬ê°€ ì¤€ë¹„ë˜ì–´ ìˆì—ˆì–´. ê·¸ ì¼€ì´í¬ëŠ” ì •ë§ë¡œ í¬ê³  ì•„ë¦„ë‹¤ì› ëŠ”ë°, ìœ„ì— ì´ˆë„ ê½‚í˜€ ìˆì—ˆì§€. ì´ˆë¥¼ ë¶ˆì—ˆì„ ë•Œ ì‚¬ëŒë“¤ì´ ë°•ìˆ˜ë¥¼ ì¹˜ë©° í™˜í˜¸í•˜ë˜ ì†Œë¦¬ê°€ ì•„ì§ë„ ê·€ì— ì„ í•˜êµ¬ë‚˜.\\n\\nê°€ì¥ ê¸°ì–µì— ë‚¨ëŠ” ê±´ ì¼€ì´í¬ë¥¼ ë‚˜ëˆ  ë¨¹ë˜ ìˆœê°„ì´ì—ˆì–´. í•œ ì… ë² ì–´ ë¬¸ ì´ˆì½œë¦¿ ì¼€ì´í¬ì˜ ë‹¬ì½¤í•¨ê³¼ í¬ë¦¼ì˜ ë¶€ë“œëŸ¬ì›€ì´ ì •ë§ í™©í™€í–ˆì§€. ê·¸ë•ŒëŠ” ì§€ê¸ˆì²˜ëŸ¼ ì‚¬ì§„ ì°ëŠ” ë¬¸í™”ê°€ ì—†ì—ˆìœ¼ë‹ˆ, ë§ˆìŒìœ¼ë¡œ ê·¸ ìˆœê°„ì„ ê°„ì§í–ˆì–´. ì‚¬ëŒë“¤ì˜ ë”°ëœ»í•œ ì›ƒìŒê³¼ ë‚´ê°€ ëŠê¼ˆë˜ í–‰ë³µì€ ì •ë§ ì†Œì¤‘í•œ ì¶”ì–µì´ì•¼.\\n\\në‚´ ì¹œêµ¬ë“¤ ì¤‘ í•œ ëª…ì€ ê¸°íƒ€ë¥¼ ê°€ì ¸ì™€ì„œ ì¶•í•˜ ë…¸ë˜ë¥¼ ë¶ˆëŸ¬ì¤¬ëŠ”ë°, ì •ë§ ê°ë™ì ì´ì—ˆì–´. ê·¸ ë©œë¡œë””ê°€ ë°”ëŒì„ íƒ€ê³  í¼ì ¸ë‚˜ê°€ë©° ê·¸ ë‚ ì„ ë”ìš± íŠ¹ë³„í•˜ê²Œ ë§Œë“¤ì—ˆì§€. ëª¨ë‘ê°€ í•¨ê»˜ ë°•ìˆ˜ë¥¼ ì¹˜ë©° ë…¸ë˜ë¥¼ ë”°ë¼ ë¶€ë¥´ë˜ ê·¸ ìˆœê°„ì€ ë§ë¡œ ë‹¤ í‘œí˜„í•  ìˆ˜ ì—†ì„ ë§Œí¼ ì¦ê±°ì› ì–´.\\n\\nê·¸ë¦¬ê³  ìƒì¼ ì„ ë¬¼ë„ ë¹¼ë†“ì„ ìˆ˜ ì—†ì§€. ì‘ì€ ìƒìì— ë‹´ê¸´ ì†ìˆ˜ê±´ì„ ë°›ì•˜ëŠ”ë°, ê·¸ ì†ìˆ˜ê±´ì€ ì–¼ë§ˆë‚˜ ê·€í–ˆë˜ì§€ ì§€ê¸ˆë„ ê°„ì§í•˜ê³  ìˆë‹¨ë‹¤. ì†ìœ¼ë¡œ ê¾¹ê¾¹ ëˆŒëŸ¬ì„œ ë‚´ ì´ë¦„ì„ ìˆ˜ë†“ì€ ì†ìˆ˜ê±´ì´ì—ˆì–´. ê·¸ ë§ˆìŒì´ ë„ˆë¬´ë‚˜ ê³ ë§™ê³  ì‚¬ë‘ìŠ¤ëŸ¬ì› ì§€.\\n\\nê·¸ë‚ ì˜ ë”°ëœ»í•œ ê¸°ì–µì€ ë‚´ ì‚¶ì—ì„œ ë¹›ë‚˜ëŠ” ë³´ì„ ê°™ì€ ë‚ ë“¤ì´ì•¼. ì†ì£¼ì•¼, ë„ˆë„ ê·¸ëŸ° í–‰ë³µí•œ ìˆœê°„ì„ ë§ì´ ë§Œë“¤ì–´ê°€ë©´ ì¢‹ê² ì–´. ì‚¬ëŒë“¤ê³¼ í•¨ê»˜ í•˜ëŠ” ì‘ì€ ìˆœê°„ë“¤ì´ ë‚˜ì¤‘ì— ë„¤ ì‚¶ì„ ë°ê²Œ ë¹„ì¶”',\n",
       " 'summary': '\\n============================================================\\nğŸ“‹ ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ë¶„ì„ ë¦¬í¬íŠ¸\\n============================================================\\nğŸ“… ë¶„ì„ ì¼ì‹œ: 2025ë…„ 06ì›” 09ì¼ 10:40:56\\nğŸ†” ëŒ€í™” ID: images_conv5\\n============================================================\\n\\nğŸ¯ ì¢…í•© í‰ê°€\\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\nğŸ˜Š ê°ì • ìƒíƒœ:     â­â­â­â­â˜† (4/5)\\nğŸ’¬ ë‹µë³€ ì¼ê´€ì„±:   â­â­â˜†â˜†â˜† (2/5)\\nğŸ§  ì „ë°˜ì  ì¸ì§€:   â­â˜†â˜†â˜†â˜† (1/5)\\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\\nğŸ“Š ëŒ€í™” ê°œìš”\\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\nğŸ’¬ ì´ ëŒ€í™” íšŸìˆ˜: 3íšŒ\\nğŸ˜Š ì „ë°˜ì  ê°ì •: ê¸ì •ì  (ì£¼ìš”: ë¶ˆì•ˆ)\\nâš ï¸ ì–´ê¸‹ë‚œ ë‹µë³€: 3íšŒ\\nâœ… ë°œí™” íŒ¨í„´: íŠ¹ì´ì‚¬í•­ ì—†ìŒ\\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\\nğŸš¨ ì£¼ìš” ë°œê²¬ì‚¬í•­\\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\nğŸ” ì–´ê¸‹ë‚œ ë‹µë³€ ë¶„ì„:\\n  ğŸŸ¡ ì¡°ê¸ˆ ì–´ê¸‹ë‚¨: 1íšŒ\\n  ğŸŸ  ê½¤ ì–´ê¸‹ë‚¨: 2íšŒ\\n\\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\\nğŸ“ ì–´ê¸‹ë‚œ ë‹µë³€ ìƒì„¸\\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n1. 2025-06-09 10:39:39\\n   â“ ì§ˆë¬¸: \"ì–´ë¥´ì‹ , ì´ ì‚¬ì§„ ì† ì¶•í•˜ í–‰ì‚¬ ë¶„ìœ„ê¸°ê°€ ì°¸ ë”°ëœ»í•˜ë„¤ìš”. ì˜ˆì „ì— ì´ëŸ° ëª¨ì„ì— ì°¸ì„í•´ë³´ì‹  ì  ìˆìœ¼ì‹ ê°€ìš”?\"\\n   ğŸ’¬ ë‹µë³€: ì— ì°¸ì„í•´ì˜¨ ì  ìˆì–´?\\n   ğŸ˜Š ìƒíƒœ: ë¶ˆì•ˆ | ğŸ¯ í’ˆì§ˆ: poor\\n\\n2. 2025-06-09 10:40:00\\n   â“ ì§ˆë¬¸: \"ì•„, ê·¸ëŸ¬ì…¨êµ°ìš”! ì¶•í•˜ ëª¨ì„ì€ ëŠ˜ íŠ¹ë³„í•˜ì£ . í˜¹ì‹œ ê¸°ì–µì— ë‚¨ëŠ” ì¶•í•˜ í–‰ì‚¬ë‚˜ ë¶„ìœ„ê¸°ê°€ ë– ì˜¤ë¥´ì‹œë‚˜ìš”?\"\\n   ğŸ’¬ ë‹µë³€: ì–´ ê¸°ì–µì— ë‚¨ëŠ”ê±´ë° ìƒì¼ ìƒì¼ë‚ ë„ ìˆì–´?\\n   ğŸ˜Š ìƒíƒœ: ê·¸ë¦¬ì›€ | ğŸ¯ í’ˆì§ˆ: normal\\n\\n3. 2025-06-09 10:40:19\\n   â“ ì§ˆë¬¸: \"ìƒì¼ë‚ ì´ë¼ë‹ˆ, ì •ë§ íŠ¹ë³„í•œ ë‚ ì´ì…¨ê² ì–´ìš”! ìƒì¼ë‚ ì— ì–´ë–¤ ë¶„ìœ„ê¸°ì˜€ëŠ”ì§€ ë” ìì„¸íˆ ë“¤ë ¤ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?\"\\n   ğŸ’¬ ë‹µë³€: ì„¸ë¯¸ë‚˜ë¥¼ ì¼€ì´í¬ ë¨¹ì—ˆì§€?\\n   ğŸ˜Š ìƒíƒœ: í¥ë¯¸ | ğŸ¯ í’ˆì§ˆ: poor\\n\\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\\nğŸ’¡ ê¶Œì¥ì‚¬í•­\\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\nğŸ’™ ê´€ì‹¬ ê¶Œì¥ì‚¬í•­:\\n   ì „ë°˜ì ìœ¼ë¡œ ì˜ ì‘ë‹µí•´ì£¼ì…¨ì§€ë§Œ, ê°„í˜¹ ì–´ê¸‹ë‚œ ë‹µë³€ì´ ë³´ì…ë‹ˆë‹¤.\\n   ê°€ë³ê²Œë¼ë„ ì£¼ë³€ì˜ ê´€ì‹¬ê³¼ í™•ì¸ì´ ìˆìœ¼ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤.\\n\\nğŸ  ê°€ì¡±ì„ ìœ„í•œ ì¡°ì–¸\\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\nğŸŸ¤ ë¶ˆì•ˆê°ì„ ëŠë¼ì‹œëŠ” ê²ƒ ê°™ì•„ìš”.\\n   â†’ ì–´ë¥´ì‹ ì˜ ì´ì•¼ê¸°ë¥¼ ì˜ ë“¤ì–´ì£¼ì‹œê³ , ë”°ëœ»í•œ ë§ í•œë§ˆë””ê°€ í° ìœ„ë¡œê°€ ë©ë‹ˆë‹¤.\\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\\nğŸ“ˆ í‰ê°€ ê¸°ì¤€\\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\nğŸ˜Š ê°ì • ìƒíƒœ: ê¸ì •ì ì´ê³  ì•ˆì •ì ì¸ ê°ì • í‘œí˜„ì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜\\nğŸ’¬ ë‹µë³€ ì¼ê´€ì„±: ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì ì ˆí•œ ë‹µë³€ì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜\\nğŸ§  ì „ë°˜ì  ì¸ì§€: ë‹µë³€ì˜ í’ˆì§ˆê³¼ ì†Œí†µ ëŠ¥ë ¥ì„ ì¢…í•©í•œ ì ìˆ˜\\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\\n============================================================\\nğŸ“‹ ë¦¬í¬íŠ¸ ë - ì–´ë¥´ì‹ ì˜ ê±´ê°•ê³¼ í–‰ë³µì„ ìœ„í•´\\n============================================================\\n',\n",
       " 'conversation_id': 'images_conv5'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactive_voice_conversation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
