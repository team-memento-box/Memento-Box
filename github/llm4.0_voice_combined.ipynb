{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "152a5597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blank\\AppData\\Roaming\\Python\\Python313\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.13.1)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msoundfile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msf\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01msounddevice\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msd\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlibrosa\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mlibrosa\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m image\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import json, base64, os, tiktoken, random, time, threading\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import requests, pygame\n",
    "from pathlib import Path\n",
    "import soundfile as sf, sounddevice as sd\n",
    "import librosa, librosa.display, tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from io import BytesIO\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba48284",
   "metadata": {},
   "source": [
    "# Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6e4545",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class StrangeResponse:\n",
    "    question: str; answer: str; timestamp: str; severity: str\n",
    "    emotion: str = \"Ï§ëÎ¶Ω\"; answer_quality: str = \"normal\"\n",
    "\n",
    "@dataclass  \n",
    "class ConversationTurn:\n",
    "    question: str; answer: str; timestamp: str\n",
    "    emotion: str = \"Ï§ëÎ¶Ω\"; answer_length: int = 0\n",
    "    answer_quality: str = \"normal\"; audio_file: str = \"\"\n",
    "\n",
    "class Config:\n",
    "    ENDPOINT = os.getenv(\"gpt-endpoint\")\n",
    "    DEPLOYMENT = \"gpt-4o\"\n",
    "    SUBSCRIPTION_KEY = os.getenv(\"gpt-key\")\n",
    "    API_VERSION = \"2024-02-15-preview\"\n",
    "    SPEECH_KEY = os.getenv(\"speech-key\")\n",
    "    SPEECH_REGION = \"eastus\"\n",
    "    MAX_TOKENS = 4000\n",
    "\n",
    "# ÏùåÏÑ± Î∂ÑÏÑù ÏÑ§Ï†ï\n",
    "SR, FIXED_DURATION = 16000, 30\n",
    "category = {0: 'cc', 1: 'cd'}\n",
    "\n",
    "print(f\"üîß ÏÑ§Ï†ï: OpenAI {'‚úÖ' if Config.ENDPOINT and Config.SUBSCRIPTION_KEY else '‚ùå'} | Speech {'‚úÖ' if Config.SPEECH_KEY else '‚ùå'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ba9d25",
   "metadata": {},
   "source": [
    "# Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29116f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.client = AzureOpenAI(\n",
    "            api_version=Config.API_VERSION,\n",
    "            azure_endpoint=Config.ENDPOINT,\n",
    "            api_key=Config.SUBSCRIPTION_KEY,\n",
    "        )\n",
    "    \n",
    "    def analyze_image(self, image_path):\n",
    "        try:\n",
    "            with open(image_path, \"rb\") as f:\n",
    "                base64_image = base64.b64encode(f.read()).decode('utf-8')\n",
    "                \n",
    "            response = self.client.chat.completions.create(\n",
    "                model=Config.DEPLOYMENT,\n",
    "                messages=[{\"role\": \"user\", \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"\"\"Ïù¥ÎØ∏ÏßÄÎ•º Î∂ÑÏÑùÌï¥ÏÑú JSONÏúºÎ°ú ÎãµÌï¥Ï£ºÏÑ∏Ïöî:\n",
    "{\"caption\": \"Ï†ÑÏ≤¥ ÏÑ§Î™Ö\", \"dense_captions\": [\"ÏÑ∏Î∂Ä1\", \"ÏÑ∏Î∂Ä2\"], \"mood\": \"Î∂ÑÏúÑÍ∏∞\", \n",
    "\"time_period\": \"ÏãúÎåÄ\", \"key_objects\": [\"Í∞ùÏ≤¥1\", \"Í∞ùÏ≤¥2\"], \"people_description\": \"Ïù∏Î¨º ÏÑ§Î™Ö\",\n",
    "\"people_count\": Ïà´Ïûê, \"time_of_day\": \"ÏãúÍ∞ÑÎåÄ\"}\"\"\"},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "                ]}], max_tokens=1000, temperature=0.3\n",
    "            )\n",
    "            \n",
    "            text = response.choices[0].message.content\n",
    "            if \"```json\" in text:\n",
    "                text = text[text.find(\"```json\")+7:text.find(\"```\", text.find(\"```json\")+7)]\n",
    "            elif \"{\" in text:\n",
    "                text = text[text.find(\"{\"):text.rfind(\"}\")+1]\n",
    "            return json.loads(text)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "print(\"‚úÖ ImageAnalyzer ÌÅ¥ÎûòÏä§ Ï†ïÏùò ÏôÑÎ£å\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbc34f5",
   "metadata": {},
   "source": [
    "# Chat System\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8666b97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatSystem:\n",
    "    def __init__(self):\n",
    "        self.client = AzureOpenAI(api_version=Config.API_VERSION, azure_endpoint=Config.ENDPOINT, api_key=Config.SUBSCRIPTION_KEY)\n",
    "        self.conversation_history, self.conversation_turns = [], []\n",
    "        self.tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        self.token_count, self.last_question = 0, \"\"\n",
    "        self.recording, self.audio_data, self.all_audio_data = False, [], []\n",
    "        self.sample_rate = 44100\n",
    "        \n",
    "        # ÎîîÎ†âÌÜ†Î¶¨ ÏÑ§Ï†ï\n",
    "        self.session_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        for base_dir in [\"audio_records\", \"audio_records_combined\"]:\n",
    "            (Path(base_dir) / self.session_id).mkdir(parents=True, exist_ok=True)\n",
    "        self.session_dir = Path(\"audio_records\") / self.session_id\n",
    "        self.session_audio_dir = Path(\"audio_records_combined\") / self.session_id\n",
    "    \n",
    "    def start_recording(self):\n",
    "        if self.recording: return\n",
    "        self.recording, self.audio_data = True, []\n",
    "        \n",
    "        def callback(indata, frames, time, status):\n",
    "            if self.recording: self.audio_data.append(indata.copy())\n",
    "        \n",
    "        self.audio_thread = sd.InputStream(samplerate=self.sample_rate, channels=1, callback=callback)\n",
    "        self.audio_thread.start()\n",
    "    \n",
    "    def stop_recording(self):\n",
    "        if not self.recording: return None\n",
    "        self.recording = False\n",
    "        if hasattr(self, 'audio_thread'):\n",
    "            self.audio_thread.stop(); self.audio_thread.close()\n",
    "        \n",
    "        if self.audio_data:\n",
    "            audio_data = np.concatenate(self.audio_data, axis=0)\n",
    "            filename = self.session_dir / f\"record_{datetime.now().strftime('%H%M%S')}.wav\"\n",
    "            sf.write(filename, audio_data, self.sample_rate)\n",
    "            self.all_audio_data.append(audio_data)\n",
    "            \n",
    "            # Ï†ÑÏ≤¥ ÏÑ∏ÏÖò ÌååÏùº ÏóÖÎç∞Ïù¥Ìä∏\n",
    "            combined = np.concatenate(self.all_audio_data, axis=0)\n",
    "            sf.write(self.session_audio_dir / f\"{self.session_id}.wav\", combined, self.sample_rate)\n",
    "            return str(filename)\n",
    "        return None\n",
    "    \n",
    "    def setup_conversation_context(self, analysis_result):\n",
    "        info = {k: analysis_result.get(k, \"\") for k in [\"caption\", \"mood\", \"time_period\", \"time_of_day\", \"people_description\"]}\n",
    "        info.update({\n",
    "            \"dense_captions\": \"\\n\".join(f\"- {dc}\" for dc in analysis_result.get(\"dense_captions\", [])),\n",
    "            \"key_objects\": \", \".join(analysis_result.get(\"key_objects\", [])),\n",
    "            \"people_count\": analysis_result.get(\"people_count\", 0)\n",
    "        })\n",
    "        \n",
    "        system_message = f\"\"\"ÎÑàÎäî ÎÖ∏Ïù∏Í≥º ÎåÄÌôîÌïòÎäî ÏöîÏñëÎ≥¥Ìò∏ÏÇ¨Ïïº. ÎÖ∏Ïù∏Í≥º ÌäπÏ†ï Ïù¥ÎØ∏ÏßÄÏóê ÎåÄÌï¥ÏÑú ÏßàÏùòÏùëÎãµÏùÑ Ï£ºÍ≥†Î∞õÏïÑ. \n",
    "ÎÖ∏Ïù∏ÏùÄ ÏπòÎß§ Ï¶ùÏÉÅÏù¥ Í∞ëÏûêÍ∏∞ ÎÇòÌÉÄÎÇ† ÏàòÎèÑ ÏûàÏñ¥. Î∞òÎ≥µÎêòÎäî ÎßêÏóêÎèÑ ÎòëÍ∞ôÏù¥ ÎåÄÎãµÌï¥Ï§òÏïº Ìï¥. \n",
    "ÏπúÏ†àÌïòÍ≥† Ïñ¥Î•∏ÏùÑ Í≥µÍ≤ΩÌïòÎäî ÎßêÌà¨Ïó¨Ïïº Ìï¥. Í∑∏Î¶¨Í≥† Í≥µÍ∞êÏùÑ Ïûò Ìï¥Ïïº Ìï¥. ÏòàÏùòÎèÑ ÏßÄÏºú. \n",
    "ÎÑàÎäî Ï£ºÎ°ú ÏßàÎ¨∏ÏùÑ ÌïòÎäî Ï™ΩÏù¥Í≥†, ÎÖ∏Ïù∏ÏùÄ ÎåÄÎãµÏùÑ Ìï¥Ï§ÑÍ±∞Ïïº. ÎåÄÎãµÏóê ÎåÄÌïú Î¶¨Ïï°ÏÖòÍ≥º Ìï®Íªò Ï†ÅÏ†àÌûà ÎåÄÌôîÎ•º Ïù¥Ïñ¥ Í∞Ä.\n",
    "\n",
    "=== Ïù¥ÎØ∏ÏßÄ Ï†ïÎ≥¥ ===\n",
    "Ï£ºÏöî ÏÑ§Î™Ö: {info['caption']} | Î∂ÑÏúÑÍ∏∞: {info['mood']} | ÏãúÎåÄ: {info['time_period']}\n",
    "ÏãúÍ∞ÑÎåÄ: {info['time_of_day']} | Ïù∏Ïõê: {info['people_count']}Î™Ö | Í∞ùÏ≤¥: {info['key_objects']}\n",
    "Ïù∏Î¨º: {info['people_description']}\n",
    "ÏÑ∏Î∂Ä: {info['dense_captions']}\n",
    "\n",
    "=== ÎåÄÌôî ÏõêÏπô ===\n",
    "Í∞ÑÍ≤∞ÌïòÍ≤å: 50Ïûê Ïù¥ÎÇ¥Î°ú ÏßàÎ¨∏ÌïòÍ∏∞ | ÏÇ¨ÏßÑ Ï£ºÏ†ú Ïú†ÏßÄ | Ïã¨ÎèÑÏûàÎäî ÎåÄÌôî | Í≥µÍ∞êÌïòÍ∏∞ | ÌïòÎÇòÏî©Îßå ÏßàÎ¨∏ | Îî∞ÎúªÌïòÍ≤å\"\"\"\n",
    "        \n",
    "        self.conversation_history = [{\"role\": \"system\", \"content\": system_message}]\n",
    "        self.token_count = len(self.tokenizer.encode(system_message))\n",
    "    \n",
    "    def generate_initial_question(self):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=Config.DEPLOYMENT,\n",
    "            messages=self.conversation_history + [{\"role\": \"user\", \"content\": \"Ïñ¥Î•¥Ïã†Íªò Îî∞ÎìØÌïòÍ≥† ÏπúÍ∑ºÌïòÍ≤å ÏÇ¨ÏßÑÏóê ÎåÄÌïòÏó¨ ÏßàÎ¨∏ÏùÑ Ìï¥Ï£ºÏÑ∏Ïöî. 50Ïûê Ïù¥ÎÇ¥Î°ú Í∞ÑÍ≤∞ÌïòÍ≤å ÏßàÎ¨∏Ìï¥Ï£ºÏÑ∏Ïöî.\"}],\n",
    "            max_tokens=512, temperature=0.8\n",
    "        )\n",
    "        \n",
    "        question = response.choices[0].message.content\n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": question})\n",
    "        self.token_count += len(self.tokenizer.encode(question))\n",
    "        self.last_question = question\n",
    "        return question\n",
    "\n",
    "    def chat_about_image(self, user_query, with_audio=False):\n",
    "        # ÎåÄÌôî ÌÑ¥ Ï†ÄÏû•\n",
    "        if self.last_question:\n",
    "            audio_file = self.stop_recording() if with_audio else \"\"\n",
    "            self.conversation_turns.append(ConversationTurn(\n",
    "                question=self.last_question, answer=user_query,\n",
    "                timestamp=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                answer_length=len(user_query.strip()), audio_file=audio_file\n",
    "            ))\n",
    "        \n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": user_query})\n",
    "        self.token_count += len(self.tokenizer.encode(user_query))\n",
    "        \n",
    "        if self.token_count > Config.MAX_TOKENS:\n",
    "            answer = \"ÎåÄÌôî ÏãúÍ∞ÑÏù¥ Îã§ ÎêòÏóàÏñ¥Ïöî. ÏàòÍ≥†ÌïòÏÖ®ÏäµÎãàÎã§.\"\n",
    "            self.conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "            return answer, True\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=Config.DEPLOYMENT, messages=self.conversation_history,\n",
    "            max_tokens=1024, temperature=0.7\n",
    "        )\n",
    "        answer = response.choices[0].message.content\n",
    "        \n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "        self.token_count += len(self.tokenizer.encode(answer))\n",
    "        self.last_question = answer\n",
    "        \n",
    "        return answer, self.token_count > Config.MAX_TOKENS\n",
    "\n",
    "print(\"‚úÖ ChatSystem ÌÅ¥ÎûòÏä§ Ï†ïÏùò ÏôÑÎ£å\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5deb43",
   "metadata": {},
   "source": [
    "# Voice System Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caef8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoiceSystem:\n",
    "    def __init__(self):\n",
    "        self.speech_config = speechsdk.SpeechConfig(subscription=Config.SPEECH_KEY, region=Config.SPEECH_REGION)\n",
    "        self.speech_config.speech_recognition_language = \"ko-KR\"\n",
    "        self.tts_voice = \"ko-KR-SunHiNeural\"\n",
    "        Path(\"audio_files\").mkdir(exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            pygame.mixer.init()\n",
    "            self.audio_enabled = True\n",
    "        except:\n",
    "            self.audio_enabled = False\n",
    "    \n",
    "    def transcribe_speech(self) -> str:\n",
    "        try:\n",
    "            recognizer = speechsdk.SpeechRecognizer(\n",
    "                speech_config=self.speech_config,\n",
    "                audio_config=speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "            )\n",
    "            \n",
    "            print(\"üéôÔ∏è ÎßêÏîÄÌï¥ Ï£ºÏÑ∏Ïöî...\")\n",
    "            result = recognizer.recognize_once()\n",
    "            \n",
    "            if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "                text = result.text.strip()\n",
    "                print(f\"üë§ \\\"{text}\\\"\")\n",
    "                \n",
    "                exit_commands = ['Ï¢ÖÎ£å', 'Í∑∏Îßå', 'ÎÅù', 'ÎÇòÍ∞ÄÍ∏∞', 'exit', 'quit', 'stop']\n",
    "                if any(cmd.lower() in text.lower().replace(' ', '') for cmd in exit_commands):\n",
    "                    return \"Ï¢ÖÎ£å\"\n",
    "                return text\n",
    "            else:\n",
    "                print(\"‚ùå ÏùåÏÑ±ÏùÑ Ïù∏ÏãùÌï† Ïàò ÏóÜÏäµÎãàÎã§. Îã§Ïãú ÎßêÏîÄÌï¥ Ï£ºÏÑ∏Ïöî.\")\n",
    "                return \"\"\n",
    "        except:\n",
    "            return \"\"\n",
    "    \n",
    "    def synthesize_speech(self, text: str) -> str:\n",
    "        if not text.strip(): return None\n",
    "        \n",
    "        try:\n",
    "            # ÌÜ†ÌÅ∞ ÏöîÏ≤≠\n",
    "            token_url = f\"https://{Config.SPEECH_REGION}.api.cognitive.microsoft.com/sts/v1.0/issueToken\"\n",
    "            token_response = requests.post(token_url, headers={\"Ocp-Apim-Subscription-Key\": Config.SPEECH_KEY})\n",
    "            if not token_response.ok: return None\n",
    "            \n",
    "            # TTS ÏöîÏ≤≠\n",
    "            tts_url = f\"https://{Config.SPEECH_REGION}.tts.speech.microsoft.com/cognitiveservices/v1\"\n",
    "            ssml = f\"\"\"<speak version='1.0' xml:lang='ko-KR'>\n",
    "                <voice xml:lang='ko-KR' xml:gender='Female' name='{self.tts_voice}'>{text}</voice>\n",
    "            </speak>\"\"\"\n",
    "            \n",
    "            tts_response = requests.post(tts_url, \n",
    "                headers={\"Authorization\": f\"Bearer {token_response.text}\",\n",
    "                        \"Content-Type\": \"application/ssml+xml\",\n",
    "                        \"X-Microsoft-OutputFormat\": \"riff-16khz-16bit-mono-pcm\"},\n",
    "                data=ssml.encode(\"utf-8\"))\n",
    "            \n",
    "            if tts_response.ok:\n",
    "                output_path = Path(\"audio_files\") / f\"tts_{time.strftime('%Y%m%d_%H%M%S')}.wav\"\n",
    "                output_path.write_bytes(tts_response.content)\n",
    "                \n",
    "                if self.audio_enabled:\n",
    "                    try:\n",
    "                        pygame.mixer.music.load(str(output_path))\n",
    "                        pygame.mixer.music.play()\n",
    "                        while pygame.mixer.music.get_busy():\n",
    "                            time.sleep(0.1)\n",
    "                    except:\n",
    "                        pass\n",
    "                return str(output_path)\n",
    "        except:\n",
    "            pass\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ VoiceSystem ÌÅ¥ÎûòÏä§ Ï†ïÏùò ÏôÑÎ£å\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6ab6ba",
   "metadata": {},
   "source": [
    "# Audio Dementia Detection_Gwona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013b01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio_slices(audio_path, save_path, add_noise=True):\n",
    "    \"\"\"Î°úÏª¨ wav ÌååÏùºÏùÑ 30Ï¥à Îã®ÏúÑÎ°ú Ïä¨ÎùºÏù¥Ïã±ÌïòÏó¨ Î©ú Ïä§ÌéôÌä∏Î°úÍ∑∏Îû® Ïù¥ÎØ∏ÏßÄÎ°ú Ï†ÄÏû•\"\"\"\n",
    "    if not os.path.exists(audio_path): return []\n",
    "    \n",
    "    y, sr = librosa.load(audio_path, sr=SR)\n",
    "    slice_length, total_slices = FIXED_DURATION * sr, len(y) // (FIXED_DURATION * sr)\n",
    "    if total_slices == 0: return []\n",
    "    \n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    base_name = os.path.splitext(os.path.basename(audio_path))[0]\n",
    "    saved_files = []\n",
    "    \n",
    "    for i in range(total_slices):\n",
    "        y_slice = y[i * slice_length:(i + 1) * slice_length]\n",
    "        \n",
    "        if add_noise:\n",
    "            noise = 0.005 * np.random.uniform() * np.amax(y_slice) * np.random.normal(size=y_slice.shape[0])\n",
    "            y_slice = y_slice + noise\n",
    "        \n",
    "        mel = librosa.feature.melspectrogram(y=y_slice, sr=sr, n_mels=128)\n",
    "        mel_norm = (librosa.power_to_db(mel, ref=np.max) - librosa.power_to_db(mel, ref=np.max).min()) / \\\n",
    "                   (librosa.power_to_db(mel, ref=np.max).max() - librosa.power_to_db(mel, ref=np.max).min())\n",
    "        \n",
    "        save_file = os.path.join(save_path, f\"{base_name}_slice{i+1}.jpg\")\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        librosa.display.specshow(mel_norm, sr=sr, x_axis='time', y_axis='mel')\n",
    "        plt.axis('off'); plt.tight_layout()\n",
    "        plt.savefig(save_file, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "        saved_files.append(save_file)\n",
    "    \n",
    "    return saved_files\n",
    "\n",
    "def analyze_voice_patterns(audio_path, model_path='models-05-0.7188.hdf5', save_path=\"./mel_slices/\"):\n",
    "    \"\"\"ÏùåÏÑ± Ìå®ÌÑ¥ Î∂ÑÏÑù ÏàòÌñâ\"\"\"\n",
    "    saved_images = preprocess_audio_slices(audio_path, save_path, add_noise=False)\n",
    "    if not saved_images:\n",
    "        return {'success': False, 'message': \"Ïä¨ÎùºÏù¥Ïä§Îêú Ïù¥ÎØ∏ÏßÄÍ∞Ä ÏÉùÏÑ±ÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.\", 'analysis': {}}\n",
    "    \n",
    "    try:\n",
    "        model = load_model(model_path)\n",
    "        predictions = []\n",
    "        \n",
    "        for img_path in saved_images:\n",
    "            img = image.load_img(img_path, target_size=(250, 250))\n",
    "            img_processed = np.expand_dims(image.img_to_array(img) / 255.0, axis=0)\n",
    "            pred = model.predict(img_processed)[0]\n",
    "            predictions.append(float(pred[0]) if len(pred) > 0 else float(pred))\n",
    "        \n",
    "        threshold, total = 0.5, len(predictions)\n",
    "        positive = sum(1 for p in predictions if p >= threshold)\n",
    "        ratio = positive / total if total > 0 else 0\n",
    "        \n",
    "        level_map = {ratio >= 0.7: (\"ÎÜíÏùå\", \"üî¥\"), ratio >= 0.4: (\"Ï§ëÍ∞Ñ\", \"üü†\")}.get(True, (\"ÎÇÆÏùå\", \"üü¢\"))\n",
    "        level, icon = level_map\n",
    "        \n",
    "        return {\n",
    "            'success': True, 'predictions': predictions,\n",
    "            'analysis': {'total_clips': total, 'positive_clips': positive, 'ratio': ratio, 'level': level, 'icon': icon}\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {'success': False, 'message': f\"Î∂ÑÏÑù Ï§ë Ïò§Î•ò: {str(e)}\", 'analysis': {}}\n",
    "\n",
    "print(\"‚úÖ ÏùåÏÑ± Î∂ÑÏÑù Ìï®ÏàòÎì§ Ï†ïÏùò ÏôÑÎ£å\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9426b8",
   "metadata": {},
   "source": [
    "#### ÏùºÎã® Ìï®Ïàò Íµ¨ÌòÑÏùÄ ÎÅùÎÇ¨ÎäîÎç∞, Î¶¨Ìè¨Ìä∏Ïóê Ï∂îÍ∞ÄÌïòÎäîÍ≤É ÎÇ®Ïùå"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc84aef",
   "metadata": {},
   "source": [
    "# Story Telling / Report System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83c2a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoryGenerator:\n",
    "    def __init__(self, chat_system):\n",
    "        self.chat_system = chat_system\n",
    "        self.client = chat_system.client\n",
    "        self.strange_responses, self.rule_based_alerts = [], []\n",
    "        self.conversation_id = \"\"\n",
    "        self.voice_analysis_result = None\n",
    "    \n",
    "    def analyze_voice_patterns(self):\n",
    "        \"\"\"ÏùåÏÑ± Ìå®ÌÑ¥ Î∂ÑÏÑù ÏàòÌñâ (3Î∂Ñ Ïù¥ÏÉÅ ÎåÄÌôîÎßå)\"\"\"\n",
    "        if not self.chat_system.session_id: return None\n",
    "        \n",
    "        session_audio_file = self.chat_system.session_audio_dir / f\"{self.chat_system.session_id}.wav\"\n",
    "        if not session_audio_file.exists():\n",
    "            print(\"‚ö†Ô∏è ÏùåÏÑ± ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏñ¥ ÏùåÏÑ± Î∂ÑÏÑùÏùÑ Í±¥ÎÑàÎúÅÎãàÎã§.\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            duration = librosa.get_duration(path=str(session_audio_file))\n",
    "            duration_minutes = duration / 60\n",
    "            print(f\"üéôÔ∏è Ï†ÑÏ≤¥ ÎåÄÌôî ÏãúÍ∞Ñ: {duration_minutes:.1f}Î∂Ñ\")\n",
    "            \n",
    "            if duration < 180:\n",
    "                print(f\"‚ö†Ô∏è ÎåÄÌôî ÏãúÍ∞ÑÏù¥ {duration_minutes:.1f}Î∂ÑÏúºÎ°ú 3Î∂Ñ ÎØ∏ÎßåÏù¥Ïñ¥ÏÑú ÏùåÏÑ± Î∂ÑÏÑùÏùÑ Í±¥ÎÑàÎúÅÎãàÎã§.\")\n",
    "                return {'success': False, 'duration': duration_minutes, 'reason': 'insufficient_duration'}\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è ÏùåÏÑ± ÌååÏùº Í∏∏Ïù¥ ÌôïÏù∏ Ï§ë Ïò§Î•ò: {e}\")\n",
    "            return None\n",
    "        \n",
    "        print(\"üéôÔ∏è ÏùåÏÑ± Ìå®ÌÑ¥ Î∂ÑÏÑù Ï§ë...\")\n",
    "        result = analyze_voice_patterns(str(session_audio_file), save_path=f\"./mel_slices/{self.chat_system.session_id}/\")\n",
    "        \n",
    "        if result['success']:\n",
    "            result['duration'] = duration_minutes\n",
    "            self.voice_analysis_result = result\n",
    "            print(f\"‚úÖ ÏùåÏÑ± Î∂ÑÏÑù ÏôÑÎ£å: {result['analysis']['level']} ÏàòÏ§Ä ({duration_minutes:.1f}Î∂Ñ ÎåÄÌôî)\")\n",
    "        else:\n",
    "            print(f\"‚ùå ÏùåÏÑ± Î∂ÑÏÑù Ïã§Ìå®: {result['message']}\")\n",
    "        return result\n",
    "    \n",
    "    def analyze_speech_patterns(self):\n",
    "        \"\"\"ÎåÄÌôî Ìå®ÌÑ¥ Î∂ÑÏÑù\"\"\"\n",
    "        if not self.chat_system.conversation_turns: return\n",
    "        \n",
    "        patterns = {\n",
    "            'severe_depression': [\"Ï£ΩÍ≥†Ïã∂\", \"ÏÇ¥Í∏∞Ïã´\", \"ÏùòÎØ∏ÏóÜ\", \"Ìè¨Í∏∞ÌïòÍ≥†Ïã∂\", \"ÏßÄÏ≥§\", \"ÌûòÎì§Ïñ¥Ï£ΩÍ≤†\", \"ÏÑ∏ÏÉÅÏù¥Ïã´\", \"Ï†àÎßù\"],\n",
    "            'severe_anxiety': [\"Î¨¥ÏÑúÏõåÏ£ΩÍ≤†\", \"Î∂àÏïàÌï¥ÎØ∏Ï≥ê\", \"Í±±Ï†ïÎèºÏ£ΩÍ≤†\", \"ÎëêÎ†§Ïõå\", \"Ïà®ÎßâÌòÄ\", \"Í≥µÌô©\", \"Ìå®Îãâ\"],\n",
    "            'severe_anger': [\"ÌôîÎÇòÏ£ΩÍ≤†\", \"ÎØ∏Ï≥êÎ≤ÑÎ¶¨Í≤†\", \"ÏßúÏ¶ùÎÇòÏ£ΩÍ≤†\", \"Ïó¥Î∞õÏïÑ\", \"Îπ°Ï≥ê\", \"Î∂ÑÌï¥\", \"Ï∞∏ÏùÑÏàòÏóÜ\"],\n",
    "            'cognitive_decline': [\"Í∏∞ÏñµÏïàÎÇò\", \"Î™®Î•¥Í≤†\", \"ÏûäÏñ¥Î≤ÑÎ†∏\", \"ÏÉùÍ∞ÅÏïàÎÇò\", \"ÍπåÎ®πÏóà\", \"Ìó∑Í∞àÎ†§\", \"ÎàÑÍµ¨ÏòÄÎäîÏßÄ\", \"Î™∞Îùº\"]\n",
    "        }\n",
    "        \n",
    "        memory_issues = very_short = meaningless = 0\n",
    "        repetitive = []\n",
    "        \n",
    "        for i, turn in enumerate(self.chat_system.conversation_turns):\n",
    "            answer = turn.answer.replace(\" \", \"\").lower()\n",
    "            \n",
    "            for pattern_type, keywords in patterns.items():\n",
    "                for keyword in keywords:\n",
    "                    if keyword in answer:\n",
    "                        self.rule_based_alerts.append({\n",
    "                            \"type\": pattern_type, \"turn_number\": i + 1, \"keyword\": keyword,\n",
    "                            \"answer\": turn.answer, \"timestamp\": turn.timestamp,\n",
    "                            \"severity\": \"critical\" if pattern_type == 'severe_depression' else \"high\"\n",
    "                        })\n",
    "                        if pattern_type == 'cognitive_decline': memory_issues += 1\n",
    "            \n",
    "            if len(turn.answer.strip()) <= 5: very_short += 1\n",
    "            if turn.answer.strip() in [\"Ïùå\", \"Ïñ¥\", \"Í∑∏ÎÉ•\", \"ÎÑ§\", \"ÏïÑÎãà\", \"Ïùë\", \"Ïñ¥?\"]: meaningless += 1\n",
    "            if i >= 3 and turn.answer.strip() in [t.answer.strip() for t in self.chat_system.conversation_turns[i-3:i]]:\n",
    "                repetitive.append(i + 1)\n",
    "        \n",
    "        total = len(self.chat_system.conversation_turns)\n",
    "        thresholds = [\n",
    "            (memory_issues >= total * 0.7, \"severe_memory_loss\", \"critical\"),\n",
    "            (very_short >= total * 0.8, \"communication_difficulty\", \"high\"),\n",
    "            (meaningless >= total * 0.6, \"cognitive_confusion\", \"high\"),\n",
    "            (len(repetitive) >= 3, \"repetitive_behavior\", \"moderate\")\n",
    "        ]\n",
    "        \n",
    "        for condition, alert_type, severity in thresholds:\n",
    "            if condition:\n",
    "                self.rule_based_alerts.append({\"type\": alert_type, \"severity\": severity})\n",
    "    \n",
    "    def analyze_entire_conversation(self):\n",
    "        \"\"\"Ï†ÑÏ≤¥ ÎåÄÌôî Î∂ÑÏÑù\"\"\"\n",
    "        if not self.chat_system.conversation_turns: return\n",
    "        \n",
    "        self.strange_responses, self.rule_based_alerts = [], []\n",
    "        self.analyze_speech_patterns()\n",
    "        \n",
    "        conversation_text = \"\\n\".join([f\"[{i}] ÏßàÎ¨∏: {turn.question}\\nÎãµÎ≥Ä: {turn.answer} (Í∏∏Ïù¥: {turn.answer_length}Ïûê)\"\n",
    "                                     for i, turn in enumerate(self.chat_system.conversation_turns, 1)])\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=Config.DEPLOYMENT,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ÏπòÎß§ ÌôòÏûê ÎåÄÌôî Î∂ÑÏÑù Ï†ÑÎ¨∏ AI\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"\"\"ÏπòÎß§ ÌôòÏûê ÎåÄÌôî Î∂ÑÏÑùÌïòÏó¨ JSON ÏùëÎãµ:\n",
    "{conversation_text}\n",
    "\n",
    "JSON: {{\"conversation_analysis\": [{{\"turn_number\": 1, \"is_strange\": true/false, \"severity\": \"normal/mild/moderate/severe\", \"emotion\": \"Í∞êÏ†ï\", \"answer_quality\": \"poor/normal/good/excellent\", \"reason\": \"Ïù¥Ïú†\"}}], \"overall_assessment\": {{\"dominant_emotion\": \"Ï£ºÏöîÍ∞êÏ†ï\", \"cognitive_level\": \"normal/mild_concern/moderate_concern/severe_concern\"}}}}\n",
    "\n",
    "Í∞êÏ†ï: Í∏∞ÏÅ®,Ïä¨Ìîî,Í∑∏Î¶¨ÏõÄ,Î¨¥Î†•Í∞ê,Ïö∞Ïö∏Í∞ê,Î∂ÑÎÖ∏,Î∂àÏïà,Ï§ëÎ¶Ω,Í∞êÏÇ¨,Ïï†Ï†ï,Ìù•ÎØ∏,ÏßúÏ¶ù\"\"\"}\n",
    "                ], max_tokens=1024, temperature=0.1\n",
    "            )\n",
    "            \n",
    "            text = response.choices[0].message.content\n",
    "            if \"```json\" in text:\n",
    "                text = text[text.find(\"```json\")+7:text.find(\"```\", text.find(\"```json\")+7)]\n",
    "            elif \"{\" in text:\n",
    "                text = text[text.find(\"{\"):text.rfind(\"}\")+1]\n",
    "            \n",
    "            result = json.loads(text)\n",
    "            \n",
    "            for i, analysis in enumerate(result.get(\"conversation_analysis\", [])):\n",
    "                if i < len(self.chat_system.conversation_turns):\n",
    "                    turn = self.chat_system.conversation_turns[i]\n",
    "                    turn.emotion = analysis.get(\"emotion\", \"Ï§ëÎ¶Ω\")\n",
    "                    turn.answer_quality = analysis.get(\"answer_quality\", \"normal\")\n",
    "                    \n",
    "                    if analysis.get(\"is_strange\", False):\n",
    "                        self.strange_responses.append(StrangeResponse(\n",
    "                            question=turn.question, answer=turn.answer, timestamp=turn.timestamp,\n",
    "                            severity=analysis.get(\"severity\", \"mild\"), emotion=turn.emotion,\n",
    "                            answer_quality=turn.answer_quality\n",
    "                        ))\n",
    "            return result\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def calculate_ratings(self):\n",
    "        \"\"\"ÌèâÏ†ê Í≥ÑÏÇ∞\"\"\"\n",
    "        total = len(self.chat_system.conversation_turns)\n",
    "        if total == 0: return {\"emotion\": 3, \"coherence\": 3, \"overall\": 3}\n",
    "        \n",
    "        emotions = [turn.emotion for turn in self.chat_system.conversation_turns if hasattr(turn, 'emotion')]\n",
    "        emotion_counts = {}\n",
    "        for emotion in emotions: emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1\n",
    "        \n",
    "        positive = [\"Í∏∞ÏÅ®\", \"Í∑∏Î¶¨ÏõÄ\", \"Í∞êÏÇ¨\", \"Ïï†Ï†ï\", \"Ìù•ÎØ∏\"]\n",
    "        negative = [\"Ïä¨Ìîî\", \"Î¨¥Î†•Í∞ê\", \"Ïö∞Ïö∏Í∞ê\", \"Î∂ÑÎÖ∏\", \"Î∂àÏïà\", \"ÏßúÏ¶ù\"]\n",
    "        pos_count = sum(emotion_counts.get(e, 0) for e in positive)\n",
    "        neg_count = sum(emotion_counts.get(e, 0) for e in negative)\n",
    "        \n",
    "        # Í∞êÏ†ï ÌèâÏ†ê\n",
    "        critical_alerts = [a for a in self.rule_based_alerts if a.get('severity') == 'critical']\n",
    "        if critical_alerts: emotion_rating = 1\n",
    "        elif neg_count > pos_count * 2: emotion_rating = 2\n",
    "        elif neg_count > pos_count: emotion_rating = 3\n",
    "        elif pos_count > neg_count: emotion_rating = 4\n",
    "        else: emotion_rating = 5 if pos_count > neg_count * 2 else 3\n",
    "        \n",
    "        # ÏùºÍ¥ÄÏÑ± ÌèâÏ†ê\n",
    "        strange_pct = len(self.strange_responses) / total * 100\n",
    "        severe_count = sum(1 for r in self.strange_responses if r.severity == 'severe')\n",
    "        if strange_pct == 0: coherence_rating = 5\n",
    "        elif strange_pct <= 20 and severe_count == 0: coherence_rating = 4\n",
    "        elif strange_pct <= 40 and severe_count <= 1: coherence_rating = 3\n",
    "        elif strange_pct <= 60 or severe_count <= 2: coherence_rating = 2\n",
    "        else: coherence_rating = 1\n",
    "        \n",
    "        # Ï†ÑÏ≤¥ ÌèâÏ†ê\n",
    "        qualities = [turn.answer_quality for turn in self.chat_system.conversation_turns if hasattr(turn, 'answer_quality')]\n",
    "        quality_counts = {\"poor\": 0, \"normal\": 0, \"good\": 0, \"excellent\": 0}\n",
    "        for q in qualities: quality_counts[q] += 1\n",
    "        \n",
    "        poor_pct = quality_counts[\"poor\"] / total * 100\n",
    "        if critical_alerts or poor_pct >= 50: overall_rating = 1\n",
    "        elif poor_pct >= 30: overall_rating = 2\n",
    "        elif quality_counts[\"excellent\"] / total >= 0.3: overall_rating = 5\n",
    "        elif quality_counts[\"good\"] / total >= 0.3: overall_rating = 4\n",
    "        else: overall_rating = 3\n",
    "        \n",
    "        return {\"emotion\": emotion_rating, \"coherence\": coherence_rating, \"overall\": overall_rating}\n",
    "    \n",
    "    def format_star_rating(self, rating):\n",
    "        return f\"{'‚≠ê' * rating}{'‚òÜ' * (5 - rating)} ({rating}/5)\"\n",
    "    \n",
    "    def generate_report(self):\n",
    "        \"\"\"Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ± (Í∞ÑÏÜåÌôî)\"\"\"\n",
    "        # ÏùåÏÑ± Î∂ÑÏÑù ÏàòÌñâ\n",
    "        if hasattr(self.chat_system, 'session_id') and self.chat_system.session_id:\n",
    "            self.analyze_voice_patterns()\n",
    "        \n",
    "        self.analyze_entire_conversation()\n",
    "        total = len(self.chat_system.conversation_turns)\n",
    "        if total == 0: return \"ÎåÄÌôîÍ∞Ä ÏßÑÌñâÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.\"\n",
    "        \n",
    "        # Í∞êÏ†ï Î∂ÑÏÑù\n",
    "        emotions = [turn.emotion for turn in self.chat_system.conversation_turns if hasattr(turn, 'emotion')]\n",
    "        emotion_counts = {}\n",
    "        for emotion in emotions: emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1\n",
    "        \n",
    "        dominant_emotion = max(emotion_counts, key=emotion_counts.get) if emotion_counts else \"Ï§ëÎ¶Ω\"\n",
    "        ratings = self.calculate_ratings()\n",
    "        critical_alerts = [a for a in self.rule_based_alerts if a.get('severity') == 'critical']\n",
    "        \n",
    "        # Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±\n",
    "        report = f\"\"\"\n",
    "{'='*60}\n",
    "üìã ÏπòÎß§ ÏßÑÎã® ÎåÄÌôî Î∂ÑÏÑù Î¶¨Ìè¨Ìä∏\n",
    "{'='*60}\n",
    "üìÖ Î∂ÑÏÑù ÏùºÏãú: {datetime.now().strftime('%YÎÖÑ %mÏõî %dÏùº %H:%M:%S')}\n",
    "üÜî ÎåÄÌôî ID: {self.conversation_id}\n",
    "{'='*60}\n",
    "\n",
    "üéØ Ï¢ÖÌï© ÌèâÍ∞Ä\n",
    "{'‚îÄ'*30}\n",
    "üòä Í∞êÏ†ï ÏÉÅÌÉú:     {self.format_star_rating(ratings['emotion'])}\n",
    "üí¨ ÎãµÎ≥Ä ÏùºÍ¥ÄÏÑ±:   {self.format_star_rating(ratings['coherence'])}\n",
    "üß† Ï†ÑÎ∞òÏ†Å Ïù∏ÏßÄ:   {self.format_star_rating(ratings['overall'])}\"\"\"\n",
    "\n",
    "        # ÏùåÏÑ± Î∂ÑÏÑù Í≤∞Í≥º Ï∂îÍ∞Ä\n",
    "        if self.voice_analysis_result:\n",
    "            if self.voice_analysis_result.get('success'):\n",
    "                va = self.voice_analysis_result['analysis']\n",
    "                duration = self.voice_analysis_result.get('duration', 0)\n",
    "                report += f\"\\nüéôÔ∏è ÏùåÏÑ± Ìå®ÌÑ¥:     {va['icon']} {va['level']} ({va['ratio']:.0%}, {duration:.1f}Î∂Ñ)\"\n",
    "            else:\n",
    "                duration = self.voice_analysis_result.get('duration', 0)\n",
    "                report += f\"\\nüéôÔ∏è ÏùåÏÑ± Ìå®ÌÑ¥:     ‚ö™ Î∂ÑÏÑù Î∂àÍ∞Ä (ÎåÄÌôîÏãúÍ∞Ñ {duration:.1f}Î∂Ñ < 3Î∂Ñ)\"\n",
    "        \n",
    "        report += f\"\\n{'‚îÄ'*30}\\n\\nüìä ÎåÄÌôî Í∞úÏöî\\n{'‚îÄ'*30}\"\n",
    "        report += f\"\\nüí¨ Ï¥ù ÎåÄÌôî ÌöüÏàò: {total}Ìöå\"\n",
    "        report += f\"\\nüòä Ï†ÑÎ∞òÏ†Å Í∞êÏ†ï: {dominant_emotion}\"\n",
    "        report += f\"\\n{'‚úÖ Ïñ¥Í∏ãÎÇú ÎãµÎ≥Ä: ÏóÜÏùå' if len(self.strange_responses) == 0 else f'‚ö†Ô∏è Ïñ¥Í∏ãÎÇú ÎãµÎ≥Ä: {len(self.strange_responses)}Ìöå'}\"\n",
    "        report += f\"\\n{'‚úÖ Î∞úÌôî Ìå®ÌÑ¥: ÌäπÏù¥ÏÇ¨Ìï≠ ÏóÜÏùå' if len(self.rule_based_alerts) == 0 else f'üîç Î∞úÌôî Ìå®ÌÑ¥: {len(self.rule_based_alerts)}Í±¥ Í¥ÄÏ∞∞'}\"\n",
    "        \n",
    "        # ÏùåÏÑ± Î∂ÑÏÑù Í∞úÏöî\n",
    "        if self.voice_analysis_result and self.voice_analysis_result.get('success'):\n",
    "            va = self.voice_analysis_result['analysis']\n",
    "            duration = self.voice_analysis_result.get('duration', 0)\n",
    "            report += f\"\\nüéôÔ∏è ÏùåÏÑ± Î∂ÑÏÑù: {va['total_clips']}Í∞ú ÌÅ¥Î¶Ω Ï§ë {va['positive_clips']}Í∞úÏóêÏÑú ÏπòÎß§ Í∞ÄÎä•ÏÑ± Í∞êÏßÄ ({duration:.1f}Î∂Ñ)\"\n",
    "        \n",
    "        report += f\"\\n{'‚îÄ'*30}\\n\\n\"\n",
    "        \n",
    "        # ÏùåÏÑ± Î∂ÑÏÑù ÏÉÅÏÑ∏ Í≤∞Í≥º\n",
    "        if self.voice_analysis_result:\n",
    "            if self.voice_analysis_result.get('success'):\n",
    "                va = self.voice_analysis_result['analysis']\n",
    "                duration = self.voice_analysis_result.get('duration', 0)\n",
    "                report += f\"\"\"üéôÔ∏è ÏùåÏÑ± Í∏∞Î∞ò ÏπòÎß§ ÏòàÏ∏° Í≤∞Í≥º\n",
    "{'‚îÄ'*30}\n",
    "‚è±Ô∏è Ï†ÑÏ≤¥ ÎåÄÌôî ÏãúÍ∞Ñ: {duration:.1f}Î∂Ñ\n",
    "üß™ Ï†ÑÏ≤¥ Î∂ÑÏÑù ÌÅ¥Î¶Ω: {va['total_clips']}Í∞ú\n",
    "üß† ÏπòÎß§ Í∞ÄÎä•ÏÑ±ÏúºÎ°ú Î∂ÑÎ•òÎêú ÌÅ¥ip: {va['positive_clips']}Í∞ú\n",
    "üìä ÏòàÏ∏° ÎπÑÏú®: {va['ratio']:.0%}\n",
    "{va['icon']} ÏπòÎß§ Í∞ÄÎä•ÏÑ± ÏàòÏ§Ä: {va['level']}\n",
    "üìå Ï∞∏Í≥†: Ïù¥ Í≤∞Í≥ºÎäî ÏùåÏÑ±Ïùò ÏñµÏñë, ÌîºÏπò, Îñ®Î¶º Îì± ÏùåÌñ•Ï†Å ÌäπÏÑ±ÏùÑ Í∏∞Î∞òÏúºÎ°ú Ìï©ÎãàÎã§.\n",
    "{'‚îÄ'*30}\n",
    "\n",
    "\"\"\"\n",
    "            elif self.voice_analysis_result.get('reason') == 'insufficient_duration':\n",
    "                duration = self.voice_analysis_result.get('duration', 0)\n",
    "                report += f\"\"\"üéôÔ∏è ÏùåÏÑ± Î∂ÑÏÑù ÏïàÎÇ¥\n",
    "{'‚îÄ'*30}\n",
    "‚è±Ô∏è Ï†ÑÏ≤¥ ÎåÄÌôî ÏãúÍ∞Ñ: {duration:.1f}Î∂Ñ\n",
    "‚ö†Ô∏è Ï†ïÌôïÌïú ÏùåÏÑ± Ìå®ÌÑ¥ Î∂ÑÏÑùÏùÑ ÏúÑÌï¥ÏÑúÎäî ÏµúÏÜå 3Î∂Ñ Ïù¥ÏÉÅÏùò ÎåÄÌôîÍ∞Ä ÌïÑÏöîÌï©ÎãàÎã§.\n",
    "üí° Îã§ÏùåÎ≤àÏóêÎäî Ï°∞Í∏à Îçî Í∏∏Í≤å ÎåÄÌôîÌï¥Î≥¥ÏãúÎ©¥ ÏùåÏÑ± Î∂ÑÏÑù Í≤∞Í≥ºÎèÑ Ìï®Íªò ÌôïÏù∏ÌïòÏã§ Ïàò ÏûàÏäµÎãàÎã§.\n",
    "{'‚îÄ'*30}\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        # Í∂åÏû•ÏÇ¨Ìï≠\n",
    "        voice_warning = 0\n",
    "        if self.voice_analysis_result and self.voice_analysis_result.get('success'):\n",
    "            level = self.voice_analysis_result['analysis']['level']\n",
    "            voice_warning = 2 if level == \"ÎÜíÏùå\" else 1 if level == \"Ï§ëÍ∞Ñ\" else 0\n",
    "        \n",
    "        report += f\"üí° Í∂åÏû•ÏÇ¨Ìï≠\\n{'‚îÄ'*30}\\n\"\n",
    "        if critical_alerts:\n",
    "            report += \"üö® Í∏¥Í∏â Í∂åÏû•ÏÇ¨Ìï≠: Ïã¨Í∞ÅÌïú Ï†ïÏã†Í±¥Í∞ï ÏúÑÌóò Ïã†Ìò∏Í∞Ä Í∞êÏßÄÎêòÏóàÏäµÎãàÎã§.\\n\"\n",
    "        elif len([a for a in self.rule_based_alerts if a.get('severity') == 'high']) >= 2 or voice_warning >= 2:\n",
    "            report += \"‚ö†Ô∏è Ï£ºÏùò Í∂åÏû•ÏÇ¨Ìï≠: ÏµúÍ∑º ÎåÄÌôîÏóêÏÑú ÌòºÎûÄÏä§Îü¨Ïö¥ ÎãµÎ≥ÄÏù¥ ÏûêÏ£º Î≥¥ÏòÄÏäµÎãàÎã§.\\n\"\n",
    "        elif len(self.strange_responses) > 0:\n",
    "            report += \"üíô Í¥ÄÏã¨ Í∂åÏû•ÏÇ¨Ìï≠: Ï†ÑÎ∞òÏ†ÅÏúºÎ°ú Ïûò ÏùëÎãµÌï¥Ï£ºÏÖ®ÏßÄÎßå, Í∞ÑÌòπ Ïñ¥Í∏ãÎÇú ÎãµÎ≥ÄÏù¥ Î≥¥ÏûÖÎãàÎã§.\\n\"\n",
    "        else:\n",
    "            report += \"üíö ÌõåÎ•≠Ìïú ÏÉÅÌÉú: Ïñ¥Î•¥Ïã†ÍªòÏÑú Î¨¥Ï≤ô ÏïàÏ†ïÏ†ÅÏúºÎ°ú Ïûò ÏùëÎãµÌï¥Ï£ºÏÖ®ÏäµÎãàÎã§.\\n\"\n",
    "        \n",
    "        report += f\"{'‚îÄ'*30}\\n\\n{'='*60}\\nüìã Î¶¨Ìè¨Ìä∏ ÎÅù - Ïñ¥Î•¥Ïã†Ïùò Í±¥Í∞ïÍ≥º ÌñâÎ≥µÏùÑ ÏúÑÌï¥\\n{'='*60}\"\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def save_files(self, image_path):\n",
    "        \"\"\"ÌååÏùº Ï†ÄÏû•\"\"\"\n",
    "        # Ìè¥Îçî Íµ¨Ï°∞ ÏÉùÏÑ±\n",
    "        image_basename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        image_dir = Path(\"conversation_log\") / image_basename\n",
    "        image_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        existing_dirs = list(image_dir.glob(f\"{image_basename}_conv*\"))\n",
    "        conv_number = len(existing_dirs) + 1\n",
    "        self.conversation_id = f\"{image_basename}_conv{conv_number}\"\n",
    "        \n",
    "        conversation_dir = image_dir / self.conversation_id\n",
    "        conversation_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Í∞úÎ≥Ñ QA Ï†ÄÏû•\n",
    "        for i, turn in enumerate(self.chat_system.conversation_turns, 1):\n",
    "            qa_file = conversation_dir / f\"qa_{i:02d}.txt\"\n",
    "            qa_file.write_text(f\"\"\"=== ÏßàÏùòÏùëÎãµ {i}Î≤à ===\n",
    "ÎåÄÌôî ID: {self.conversation_id}\n",
    "ÏãúÍ∞Ñ: {turn.timestamp}\n",
    "{'='*25}\n",
    "\n",
    "ü§ñ ÏßàÎ¨∏:\n",
    "{turn.question}\n",
    "\n",
    "üë§ ÎãµÎ≥Ä:\n",
    "{turn.answer}\n",
    "{'='*25}\"\"\", encoding='utf-8')\n",
    "        \n",
    "        # Î©îÏù∏ ÎåÄÌôî ÌååÏùº\n",
    "        conversation_file = conversation_dir / f\"{self.conversation_id}.txt\"\n",
    "        conversation_content = f\"\"\"{'='*50}\n",
    "üí¨ ÏπòÎß§ ÏßÑÎã® ÎåÄÌôî Í∏∞Î°ù\n",
    "{'='*50}\n",
    "üÜî ÎåÄÌôî ID: {self.conversation_id}\n",
    "üìä Ï¥ù ÎåÄÌôî Ïàò: {len(self.chat_system.conversation_turns)}Ìöå\n",
    "{'='*50}\n",
    "\n",
    "\"\"\"\n",
    "        for turn in self.chat_system.conversation_turns:\n",
    "            conversation_content += f\"[{turn.timestamp}]\\nü§ñ ÏßàÎ¨∏: {turn.question}\\nüë§ ÎãµÎ≥Ä: {turn.answer}\\n{'-'*30}\\n\\n\"\n",
    "        \n",
    "        conversation_file.write_text(conversation_content, encoding='utf-8')\n",
    "        \n",
    "        # Î∂ÑÏÑù Î¶¨Ìè¨Ìä∏ Ï†ÄÏû•\n",
    "        analysis_dir = Path(\"analysis\")\n",
    "        analysis_dir.mkdir(exist_ok=True)\n",
    "        analysis_file = analysis_dir / f\"{self.conversation_id}_analysis.txt\"\n",
    "        analysis_file.write_text(self.generate_report(), encoding='utf-8')\n",
    "        \n",
    "        print(f\"‚úÖ ÌååÏùº Ï†ÄÏû• ÏôÑÎ£å!\\nüìÅ ÎåÄÌôî Ìè¥Îçî: {conversation_dir}\\nüìÑ ÎåÄÌôî ÌååÏùº: {conversation_file}\\nüìä Î∂ÑÏÑù ÌååÏùº: {analysis_file}\")\n",
    "        return str(conversation_file), str(analysis_file)\n",
    "    \n",
    "    def generate_story(self, image_path):\n",
    "        \"\"\"Ï∂îÏñµ Ïä§ÌÜ†Î¶¨ ÏÉùÏÑ±\"\"\"\n",
    "        conversation_text = \"\\n\".join([f\"ÏßàÎ¨∏: {turn.question}\\nÎãµÎ≥Ä: {turn.answer}\" for turn in self.chat_system.conversation_turns])\n",
    "        if not conversation_text.strip(): return None, None\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=Config.DEPLOYMENT,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ÎÖ∏Ïù∏ Ï∂îÏñµ Ïä§ÌÜ†Î¶¨ÌÖîÎü¨\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"\"\"ÎåÄÌôî Í∏∞Î∞òÏúºÎ°ú Ïñ¥Î•¥Ïã† 1Ïù∏Ïπ≠ Ï∂îÏñµ Ïä§ÌÜ†Î¶¨ 15Ï§Ñ ÏûëÏÑ±:\n",
    "{conversation_text}\n",
    "ÏßÄÏπ®: ÎãµÎ≥Ä Í∏∞Î∞ò ÏûëÏÑ±, Í∞êÏ†ïÍ≥º Í∞êÍ∞Å Ìè¨Ìï®, Îî∞ÎúªÌïú ÌÜ§, ÏÜêÏûê/ÏÜêÎÖÄÏóêÍ≤å Îì§Î†§Ï£ºÎäî Ïñ¥Ìà¨\"\"\"}\n",
    "                ], max_tokens=512, temperature=0.8\n",
    "            )\n",
    "            \n",
    "            story = response.choices[0].message.content\n",
    "            story_dir = Path(\"story_telling\")\n",
    "            story_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            story_file = story_dir / f\"{os.path.splitext(os.path.basename(image_path))[0]}_story.txt\"\n",
    "            story_file.write_text(story, encoding='utf-8')\n",
    "            \n",
    "            return story, str(story_file)\n",
    "        except:\n",
    "            return None, None\n",
    "\n",
    "print(\"‚úÖ StoryGenerator ÌÅ¥ÎûòÏä§ Ï†ïÏùò ÏôÑÎ£å\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f031a9b7",
   "metadata": {},
   "source": [
    "# ÏΩîÎìú ÌÜµÌï©Î∂Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bd8c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedDementiaSystem:\n",
    "    def __init__(self):\n",
    "        self.image_analyzer = ImageAnalyzer()\n",
    "        self.chat_system = ChatSystem()\n",
    "        self.voice_system = VoiceSystem() if Config.SPEECH_KEY else None\n",
    "        self.story_generator = StoryGenerator(self.chat_system)\n",
    "    \n",
    "    def start_conversation(self, image_path):\n",
    "        \"\"\"Ïù¥ÎØ∏ÏßÄ Î∂ÑÏÑù Î∞è ÎåÄÌôî ÏãúÏûë\"\"\"\n",
    "        if not os.path.exists(image_path): return None\n",
    "        \n",
    "        analysis_result = self.image_analyzer.analyze_image(image_path)\n",
    "        if not analysis_result: return None\n",
    "        \n",
    "        self.chat_system.setup_conversation_context(analysis_result)\n",
    "        return self.chat_system.generate_initial_question()\n",
    "    \n",
    "    def run_conversation(self, image_path, is_voice=False):\n",
    "        \"\"\"ÎåÄÌôî Ïã§Ìñâ\"\"\"\n",
    "        initial_question = self.start_conversation(image_path)\n",
    "        if not initial_question: return None\n",
    "        \n",
    "        # ÏãúÏûë Î©îÏãúÏßÄ\n",
    "        if is_voice and self.voice_system:\n",
    "            welcome = \"ÏïàÎÖïÌïòÏÑ∏Ïöî. ÏÇ¨ÏßÑÏùÑ Î≥¥Î©∞ ÎåÄÌôîÌï¥Ïöî.\"\n",
    "            print(f\"ü§ñ {welcome}\")\n",
    "            self.voice_system.synthesize_speech(welcome)\n",
    "            print(f\"ü§ñ {initial_question}\")\n",
    "            self.voice_system.synthesize_speech(initial_question)\n",
    "        else:\n",
    "            print(f\"ü§ñ {initial_question}\")\n",
    "        \n",
    "        conversation_type = \"ÏùåÏÑ±\" if is_voice else \"ÌÖçÏä§Ìä∏\"\n",
    "        print(f\"\\n{'='*40}\\n{'üéôÔ∏è' if is_voice else 'üí¨'} {conversation_type} ÎåÄÌôî ÏãúÏûë!\")\n",
    "        print(f\"üí° {'Ï¢ÖÎ£åÎùºÍ≥† ÎßêÌïòÎ©¥' if is_voice else 'exit ÎòêÎäî Ï¢ÖÎ£åÎ•º ÏûÖÎ†•ÌïòÎ©¥'} ÎÅùÎÇ©ÎãàÎã§\\n{'='*40}\")\n",
    "        \n",
    "        # ÎåÄÌôî Î£®ÌîÑ\n",
    "        while True:\n",
    "            if is_voice and self.voice_system:\n",
    "                print(\"üéôÔ∏è ÎßêÏîÄÌï¥ Ï£ºÏÑ∏Ïöî...\")\n",
    "                self.chat_system.start_recording()\n",
    "                user_input = self.voice_system.transcribe_speech()\n",
    "                self.chat_system.stop_recording()\n",
    "                \n",
    "                if not user_input.strip(): continue\n",
    "                if user_input == \"Ï¢ÖÎ£å\":\n",
    "                    end_msg = \"ÎåÄÌôîÎ•º ÎßàÏπòÍ≤†ÏäµÎãàÎã§. Í∞êÏÇ¨Ìï©ÎãàÎã§.\"\n",
    "                    print(f\"ü§ñ {end_msg}\")\n",
    "                    self.voice_system.synthesize_speech(end_msg)\n",
    "                    break\n",
    "            else:\n",
    "                user_input = input(\"\\nüë§ ÎãµÎ≥Ä: \").strip()\n",
    "                if user_input.lower() in ['exit', 'Ï¢ÖÎ£å', 'quit', 'q']:\n",
    "                    print(\"ÎåÄÌôîÎ•º Ï¢ÖÎ£åÌï©ÎãàÎã§.\")\n",
    "                    break\n",
    "            \n",
    "            answer, should_end = self.chat_system.chat_about_image(user_input, with_audio=is_voice)\n",
    "            print(f\"ü§ñ {answer}\")\n",
    "            \n",
    "            if is_voice and self.voice_system:\n",
    "                self.voice_system.synthesize_speech(answer)\n",
    "            \n",
    "            if should_end:\n",
    "                end_msg = \"ÎåÄÌôî ÏãúÍ∞ÑÏù¥ Ï¢ÖÎ£åÎêòÏóàÏäµÎãàÎã§.\"\n",
    "                print(f\"‚è∞ {end_msg}\")\n",
    "                if is_voice and self.voice_system:\n",
    "                    self.voice_system.synthesize_speech(end_msg)\n",
    "                break\n",
    "        \n",
    "        # Î∂ÑÏÑù Î∞è Ï†ÄÏû•\n",
    "        print(\"\\nüìä Ï¢ÖÌï© Î∂ÑÏÑù Í≤∞Í≥º ÏÉùÏÑ± Ï§ë...\")\n",
    "        conversation_file, analysis_file = self.story_generator.save_files(image_path)\n",
    "        story, story_file = self.story_generator.generate_story(image_path)\n",
    "        \n",
    "        print(self.story_generator.generate_report())\n",
    "        \n",
    "        if story:\n",
    "            print(f\"\\n{'='*50}\\nüìñ ÏÉùÏÑ±Îêú Ï∂îÏñµ Ïù¥ÏïºÍ∏∞\\n{'='*50}\\n{story}\\n{'='*50}\")\n",
    "        \n",
    "        print(f\"üìÇ ÎåÄÌôîÍ∏∞Î°ù: {conversation_file}\\nüìä Î∂ÑÏÑùÍ≤∞Í≥º: {analysis_file}\")\n",
    "        if story_file: print(f\"üìñ Ïä§ÌÜ†Î¶¨: {story_file}\")\n",
    "        \n",
    "        return {\n",
    "            'conversation_file': conversation_file, 'analysis_file': analysis_file,\n",
    "            'story_file': story_file, 'story_content': story,\n",
    "            'conversation_id': self.story_generator.conversation_id\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ OptimizedDementiaSystem ÌÅ¥ÎûòÏä§ Ï†ïÏùò ÏôÑÎ£å\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04184284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_conversation():\n",
    "    \"\"\"ÌÖçÏä§Ìä∏ ÎåÄÌôî Ïã§Ìñâ\"\"\"\n",
    "    print(\"=== üí¨ ÌÖçÏä§Ìä∏ ÏπòÎß§ ÏßÑÎã® ÎåÄÌôî ÏãúÏä§ÌÖú ===\")\n",
    "    image_path = \"images.jpg\"\n",
    "    \n",
    "    if not os.path.exists(image_path):\n",
    "        print(\"‚ùå Ïò¨Î∞îÎ•∏ Ïù¥ÎØ∏ÏßÄ Í≤ΩÎ°úÎ•º ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        system = OptimizedDementiaSystem()\n",
    "        return system.run_conversation(image_path, is_voice=False)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ÏãúÏä§ÌÖú Ïò§Î•ò: {e}\")\n",
    "        return None\n",
    "\n",
    "def interactive_voice_conversation():\n",
    "    \"\"\"ÏùåÏÑ± ÎåÄÌôî Ïã§Ìñâ\"\"\"\n",
    "    print(\"=== üé§ ÏùåÏÑ± ÏπòÎß§ ÏßÑÎã® ÎåÄÌôî ÏãúÏä§ÌÖú ===\")\n",
    "    image_path = input(\"Ïù¥ÎØ∏ÏßÄ Í≤ΩÎ°úÎ•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî: \").strip()\n",
    "    \n",
    "    if not image_path or not os.path.exists(image_path):\n",
    "        print(\"‚ùå Ïò¨Î∞îÎ•∏ Ïù¥ÎØ∏ÏßÄ Í≤ΩÎ°úÎ•º ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        system = OptimizedDementiaSystem()\n",
    "        if not system.voice_system:\n",
    "            print(\"‚ùå ÏùåÏÑ± ÏãúÏä§ÌÖúÏùÑ Ï¥àÍ∏∞ÌôîÌï† Ïàò ÏóÜÏäµÎãàÎã§. Azure Speech Service ÌÇ§Î•º ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî.\")\n",
    "            return None\n",
    "        return system.run_conversation(image_path, is_voice=True)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ÏãúÏä§ÌÖú Ïò§Î•ò: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Ïã§Ìñâ Ìï®ÏàòÎì§ Ï†ïÏùò ÏôÑÎ£å\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3610556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ ÏãúÏä§ÌÖú Ï§ÄÎπÑ ÏôÑÎ£å!\n",
      "üí° interactive_conversation() Ìï®ÏàòÎ•º Ïã§ÌñâÌï¥Î≥¥ÏÑ∏Ïöî!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # ÌôòÍ≤Ω ÌôïÏù∏\n",
    "    if not Config.ENDPOINT or not Config.SUBSCRIPTION_KEY:\n",
    "        print(\"‚ö†Ô∏è Azure OpenAI ÏÑ§Ï†ïÏù¥ ÌïÑÏöîÌï©ÎãàÎã§:\")\n",
    "        print(\"   - gpt-endpoint\")\n",
    "        print(\"   - gpt-key\")\n",
    "    \n",
    "    if not Config.SPEECH_KEY:\n",
    "        print(\"‚ö†Ô∏è ÏùåÏÑ± Í∏∞Îä•ÏùÑ ÏúÑÌï¥ Azure Speech Service ÏÑ§Ï†ïÏù¥ ÌïÑÏöîÌï©ÎãàÎã§:\")\n",
    "        print(\"   - speech-key\")\n",
    "    \n",
    "    print(\"\\n‚úÖ ÏãúÏä§ÌÖú Ï§ÄÎπÑ ÏôÑÎ£å!\")\n",
    "    print(\"üí° interactive_conversation() Ìï®ÏàòÎ•º Ïã§ÌñâÌï¥Î≥¥ÏÑ∏Ïöî!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4bb057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== üé§ ÏùåÏÑ± ÏπòÎß§ ÏßÑÎã® ÎåÄÌôî ÏãúÏä§ÌÖú ===\n",
      "ü§ñ ÏïàÎÖïÌïòÏÑ∏Ïöî. ÏÇ¨ÏßÑÏùÑ Î≥¥Î©∞ ÎåÄÌôîÌï¥Ïöî.\n",
      "ü§ñ \"Ïñ¥Î•¥Ïã†, Ïù¥ ÏÇ¨ÏßÑ ÏÜç Ï∂ïÌïò ÌñâÏÇ¨ Î∂ÑÏúÑÍ∏∞Í∞Ä Ï∞∏ Îî∞ÎúªÌïòÎÑ§Ïöî. ÏòàÏ†ÑÏóê Ïù¥Îü∞ Î™®ÏûÑÏóê Ï∞∏ÏÑùÌï¥Î≥¥Ïã† Ï†Å ÏûàÏúºÏã†Í∞ÄÏöî?\"\n",
      "\n",
      "========================================\n",
      "üéôÔ∏è ÏùåÏÑ± ÎåÄÌôî ÏãúÏûë!\n",
      "üí° Ï¢ÖÎ£åÎùºÍ≥† ÎßêÌïòÎ©¥ ÎÅùÎÇ©ÎãàÎã§\n",
      "========================================\n",
      "üéôÔ∏è ÎßêÏîÄÌï¥ Ï£ºÏÑ∏Ïöî...\n",
      "üéôÔ∏è ÎßêÏîÄÌï¥ Ï£ºÏÑ∏Ïöî...\n",
      "üë§ \"Ïóê Ï∞∏ÏÑùÌï¥Ïò® Ï†Å ÏûàÏñ¥?\"\n",
      "ü§ñ \"ÏïÑ, Í∑∏Îü¨ÏÖ®Íµ∞Ïöî! Ï∂ïÌïò Î™®ÏûÑÏùÄ Îäò ÌäπÎ≥ÑÌïòÏ£†. ÌòπÏãú Í∏∞ÏñµÏóê ÎÇ®Îäî Ï∂ïÌïò ÌñâÏÇ¨ÎÇò Î∂ÑÏúÑÍ∏∞Í∞Ä Îñ†Ïò§Î•¥ÏãúÎÇòÏöî?\"\n",
      "üéôÔ∏è ÎßêÏîÄÌï¥ Ï£ºÏÑ∏Ïöî...\n",
      "üéôÔ∏è ÎßêÏîÄÌï¥ Ï£ºÏÑ∏Ïöî...\n",
      "üë§ \"Ïñ¥ Í∏∞ÏñµÏóê ÎÇ®ÎäîÍ±¥Îç∞ ÏÉùÏùº ÏÉùÏùºÎÇ†ÎèÑ ÏûàÏñ¥?\"\n",
      "ü§ñ \"ÏÉùÏùºÎÇ†Ïù¥ÎùºÎãà, Ï†ïÎßê ÌäπÎ≥ÑÌïú ÎÇ†Ïù¥ÏÖ®Í≤†Ïñ¥Ïöî! ÏÉùÏùºÎÇ†Ïóê Ïñ¥Îñ§ Î∂ÑÏúÑÍ∏∞ÏòÄÎäîÏßÄ Îçî ÏûêÏÑ∏Ìûà Îì§Î†§Ï£ºÏã§ Ïàò ÏûàÏùÑÍπåÏöî?\"\n",
      "üéôÔ∏è ÎßêÏîÄÌï¥ Ï£ºÏÑ∏Ïöî...\n",
      "üéôÔ∏è ÎßêÏîÄÌï¥ Ï£ºÏÑ∏Ïöî...\n",
      "üë§ \"ÏÑ∏ÎØ∏ÎÇòÎ•º ÏºÄÏù¥ÌÅ¨ Î®πÏóàÏßÄ?\"\n",
      "ü§ñ \"ÏÑ∏ÎØ∏ÎÇòÏóêÏÑú ÏºÄÏù¥ÌÅ¨Î•º ÎìúÏÖ®Îã§Îãà Ïû¨ÎØ∏ÏûàÎÑ§Ïöî! ÏÑ∏ÎØ∏ÎÇò Î∂ÑÏúÑÍ∏∞Îäî Ïñ¥Îï†ÎÇòÏöî? ÏÇ¨ÎûåÎì§ÎèÑ ÎßéÏù¥ Î™®ÏòÄÏóàÎÇòÏöî?\"\n",
      "üéôÔ∏è ÎßêÏîÄÌï¥ Ï£ºÏÑ∏Ïöî...\n",
      "üéôÔ∏è ÎßêÏîÄÌï¥ Ï£ºÏÑ∏Ïöî...\n",
      "üë§ \"Ï¢ÖÎ£å.\"\n",
      "ü§ñ ÎåÄÌôîÎ•º ÎßàÏπòÍ≤†ÏäµÎãàÎã§. Í∞êÏÇ¨Ìï©ÎãàÎã§.\n",
      "\n",
      "üìä Ï¢ÖÌï© Î∂ÑÏÑù Í≤∞Í≥º ÏÉùÏÑ± Ï§ë...\n",
      "üìÅ Ï†ÄÏû• Íµ¨Ï°∞:\n",
      "   Î©îÏù∏ Ìè¥Îçî: conversation_log/images/images_conv5/\n",
      "   ÎåÄÌôî ÌååÏùº: images_conv5.txt\n",
      "\n",
      "‚úÖ ÌååÏùº Ï†ÄÏû• ÏôÑÎ£å!\n",
      "üìÅ ÎåÄÌôî Ìè¥Îçî: conversation_log\\images\\images_conv5\n",
      "üìÑ ÎåÄÌôî ÌååÏùº: conversation_log\\images\\images_conv5\\images_conv5.txt\n",
      "üìä Î∂ÑÏÑù ÌååÏùº: analysis\\images_conv5_analysis.txt\n",
      "üìã QA ÌååÏùºÎì§: 3Í∞ú\n",
      "\n",
      "============================================================\n",
      "üìã ÏπòÎß§ ÏßÑÎã® ÎåÄÌôî Î∂ÑÏÑù Î¶¨Ìè¨Ìä∏\n",
      "============================================================\n",
      "üìÖ Î∂ÑÏÑù ÏùºÏãú: 2025ÎÖÑ 06Ïõî 09Ïùº 10:40:56\n",
      "üÜî ÎåÄÌôî ID: images_conv5\n",
      "============================================================\n",
      "\n",
      "üéØ Ï¢ÖÌï© ÌèâÍ∞Ä\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üòä Í∞êÏ†ï ÏÉÅÌÉú:     ‚≠ê‚≠ê‚≠ê‚≠ê‚òÜ (4/5)\n",
      "üí¨ ÎãµÎ≥Ä ÏùºÍ¥ÄÏÑ±:   ‚≠ê‚≠ê‚òÜ‚òÜ‚òÜ (2/5)\n",
      "üß† Ï†ÑÎ∞òÏ†Å Ïù∏ÏßÄ:   ‚≠ê‚òÜ‚òÜ‚òÜ‚òÜ (1/5)\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìä ÎåÄÌôî Í∞úÏöî\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üí¨ Ï¥ù ÎåÄÌôî ÌöüÏàò: 3Ìöå\n",
      "üòä Ï†ÑÎ∞òÏ†Å Í∞êÏ†ï: Í∏çÏ†ïÏ†Å (Ï£ºÏöî: Î∂àÏïà)\n",
      "‚ö†Ô∏è Ïñ¥Í∏ãÎÇú ÎãµÎ≥Ä: 3Ìöå\n",
      "‚úÖ Î∞úÌôî Ìå®ÌÑ¥: ÌäπÏù¥ÏÇ¨Ìï≠ ÏóÜÏùå\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üö® Ï£ºÏöî Î∞úÍ≤¨ÏÇ¨Ìï≠\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üîç Ïñ¥Í∏ãÎÇú ÎãµÎ≥Ä Î∂ÑÏÑù:\n",
      "  üü° Ï°∞Í∏à Ïñ¥Í∏ãÎÇ®: 1Ìöå\n",
      "  üü† ÍΩ§ Ïñ¥Í∏ãÎÇ®: 2Ìöå\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìù Ïñ¥Í∏ãÎÇú ÎãµÎ≥Ä ÏÉÅÏÑ∏\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "1. 2025-06-09 10:39:39\n",
      "   ‚ùì ÏßàÎ¨∏: \"Ïñ¥Î•¥Ïã†, Ïù¥ ÏÇ¨ÏßÑ ÏÜç Ï∂ïÌïò ÌñâÏÇ¨ Î∂ÑÏúÑÍ∏∞Í∞Ä Ï∞∏ Îî∞ÎúªÌïòÎÑ§Ïöî. ÏòàÏ†ÑÏóê Ïù¥Îü∞ Î™®ÏûÑÏóê Ï∞∏ÏÑùÌï¥Î≥¥Ïã† Ï†Å ÏûàÏúºÏã†Í∞ÄÏöî?\"\n",
      "   üí¨ ÎãµÎ≥Ä: Ïóê Ï∞∏ÏÑùÌï¥Ïò® Ï†Å ÏûàÏñ¥?\n",
      "   üòä ÏÉÅÌÉú: Î∂àÏïà | üéØ ÌíàÏßà: poor\n",
      "\n",
      "2. 2025-06-09 10:40:00\n",
      "   ‚ùì ÏßàÎ¨∏: \"ÏïÑ, Í∑∏Îü¨ÏÖ®Íµ∞Ïöî! Ï∂ïÌïò Î™®ÏûÑÏùÄ Îäò ÌäπÎ≥ÑÌïòÏ£†. ÌòπÏãú Í∏∞ÏñµÏóê ÎÇ®Îäî Ï∂ïÌïò ÌñâÏÇ¨ÎÇò Î∂ÑÏúÑÍ∏∞Í∞Ä Îñ†Ïò§Î•¥ÏãúÎÇòÏöî?\"\n",
      "   üí¨ ÎãµÎ≥Ä: Ïñ¥ Í∏∞ÏñµÏóê ÎÇ®ÎäîÍ±¥Îç∞ ÏÉùÏùº ÏÉùÏùºÎÇ†ÎèÑ ÏûàÏñ¥?\n",
      "   üòä ÏÉÅÌÉú: Í∑∏Î¶¨ÏõÄ | üéØ ÌíàÏßà: normal\n",
      "\n",
      "3. 2025-06-09 10:40:19\n",
      "   ‚ùì ÏßàÎ¨∏: \"ÏÉùÏùºÎÇ†Ïù¥ÎùºÎãà, Ï†ïÎßê ÌäπÎ≥ÑÌïú ÎÇ†Ïù¥ÏÖ®Í≤†Ïñ¥Ïöî! ÏÉùÏùºÎÇ†Ïóê Ïñ¥Îñ§ Î∂ÑÏúÑÍ∏∞ÏòÄÎäîÏßÄ Îçî ÏûêÏÑ∏Ìûà Îì§Î†§Ï£ºÏã§ Ïàò ÏûàÏùÑÍπåÏöî?\"\n",
      "   üí¨ ÎãµÎ≥Ä: ÏÑ∏ÎØ∏ÎÇòÎ•º ÏºÄÏù¥ÌÅ¨ Î®πÏóàÏßÄ?\n",
      "   üòä ÏÉÅÌÉú: Ìù•ÎØ∏ | üéØ ÌíàÏßà: poor\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üí° Í∂åÏû•ÏÇ¨Ìï≠\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üíô Í¥ÄÏã¨ Í∂åÏû•ÏÇ¨Ìï≠:\n",
      "   Ï†ÑÎ∞òÏ†ÅÏúºÎ°ú Ïûò ÏùëÎãµÌï¥Ï£ºÏÖ®ÏßÄÎßå, Í∞ÑÌòπ Ïñ¥Í∏ãÎÇú ÎãµÎ≥ÄÏù¥ Î≥¥ÏûÖÎãàÎã§.\n",
      "   Í∞ÄÎ≥çÍ≤åÎùºÎèÑ Ï£ºÎ≥ÄÏùò Í¥ÄÏã¨Í≥º ÌôïÏù∏Ïù¥ ÏûàÏúºÎ©¥ Ï¢ãÍ≤†ÏäµÎãàÎã§.\n",
      "\n",
      "üè† Í∞ÄÏ°±ÏùÑ ÏúÑÌïú Ï°∞Ïñ∏\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üü§ Î∂àÏïàÍ∞êÏùÑ ÎäêÎÅºÏãúÎäî Í≤É Í∞ôÏïÑÏöî.\n",
      "   ‚Üí Ïñ¥Î•¥Ïã†Ïùò Ïù¥ÏïºÍ∏∞Î•º Ïûò Îì§Ïñ¥Ï£ºÏãúÍ≥†, Îî∞ÎúªÌïú Îßê ÌïúÎßàÎîîÍ∞Ä ÌÅ∞ ÏúÑÎ°úÍ∞Ä Îê©ÎãàÎã§.\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìà ÌèâÍ∞Ä Í∏∞Ï§Ä\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üòä Í∞êÏ†ï ÏÉÅÌÉú: Í∏çÏ†ïÏ†ÅÏù¥Í≥† ÏïàÏ†ïÏ†ÅÏù∏ Í∞êÏ†ï ÌëúÌòÑÏùºÏàòÎ°ù ÎÜíÏùÄ Ï†êÏàò\n",
      "üí¨ ÎãµÎ≥Ä ÏùºÍ¥ÄÏÑ±: ÏßàÎ¨∏Í≥º Í¥ÄÎ†®Îêú Ï†ÅÏ†àÌïú ÎãµÎ≥ÄÏùºÏàòÎ°ù ÎÜíÏùÄ Ï†êÏàò\n",
      "üß† Ï†ÑÎ∞òÏ†Å Ïù∏ÏßÄ: ÎãµÎ≥ÄÏùò ÌíàÏßàÍ≥º ÏÜåÌÜµ Îä•Î†•ÏùÑ Ï¢ÖÌï©Ìïú Ï†êÏàò\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "============================================================\n",
      "üìã Î¶¨Ìè¨Ìä∏ ÎÅù - Ïñ¥Î•¥Ïã†Ïùò Í±¥Í∞ïÍ≥º ÌñâÎ≥µÏùÑ ÏúÑÌï¥\n",
      "============================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "üìñ ÏÉùÏÑ±Îêú Ï∂îÏñµ Ïù¥ÏïºÍ∏∞\n",
      "==================================================\n",
      "\"ÏïÑ, Í∑∏Î†áÍµ¨ÎÇò. Ïù¥ ÏÇ¨ÏßÑÏùÑ Î≥¥Îãà Ï∞∏ Îî∞ÎúªÌïú Ï∂ïÌïò Î∂ÑÏúÑÍ∏∞Í∞Ä ÎäêÍª¥ÏßÄÎÑ§. ÎÇòÎèÑ Ïù¥Îü∞ Ï∂ïÌïò ÌñâÏÇ¨Ïóê Ïó¨Îü¨ Î≤à Ï∞∏ÏÑùÌñàÎçò Í∏∞ÏñµÏù¥ ÏûàÏñ¥. Ï†ïÎßê ÌäπÎ≥ÑÌïú ÏàúÍ∞ÑÎì§Ïù¥ÏóàÏßÄ. ÌäπÌûà Í∏∞ÏñµÏóê ÎÇ®Îäî Í±¥ ÎÇ¥ ÏÉùÏùºÎÇ†Ïù¥ÏóàÏñ¥. Ïò§ÎûòÏ†Ñ ÏùºÏù∏Îç∞ÎèÑ ÏÉùÏÉùÌïòÍ≤å Îñ†Ïò§Î•∏Îã§.\n",
      "\n",
      "Í∑∏ÎÇ†ÏùÄ ÎÇ¥Í∞Ä Ï°∞Í∏à Îçî ÌäπÎ≥ÑÌïú ÏÇ¨ÎûåÏù¥ÎùºÎèÑ Îêú Í≤ÉÏ≤òÎüº Î™®ÎëêÍ∞Ä ÎÇòÎ•º Ï§ëÏã¨ÏúºÎ°ú Î™®ÏòÄÏßÄ. ÏÜêÎãòÎì§ÏùÄ ÏõÉÏùå Í∞ÄÎìùÌïú ÏñºÍµ¥Î°ú Ï∂ïÌïòÌï¥Ï£ºÍ≥†, Ïπ¥ÌéòÏóêÏÑ† ÏÉùÏùº ÏºÄÏù¥ÌÅ¨Í∞Ä Ï§ÄÎπÑÎêòÏñ¥ ÏûàÏóàÏñ¥. Í∑∏ ÏºÄÏù¥ÌÅ¨Îäî Ï†ïÎßêÎ°ú ÌÅ¨Í≥† ÏïÑÎ¶ÑÎã§Ïõ†ÎäîÎç∞, ÏúÑÏóê Ï¥àÎèÑ ÍΩÇÌòÄ ÏûàÏóàÏßÄ. Ï¥àÎ•º Î∂àÏóàÏùÑ Îïå ÏÇ¨ÎûåÎì§Ïù¥ Î∞ïÏàòÎ•º ÏπòÎ©∞ ÌôòÌò∏ÌïòÎçò ÏÜåÎ¶¨Í∞Ä ÏïÑÏßÅÎèÑ Í∑ÄÏóê ÏÑ†ÌïòÍµ¨ÎÇò.\n",
      "\n",
      "Í∞ÄÏû• Í∏∞ÏñµÏóê ÎÇ®Îäî Í±¥ ÏºÄÏù¥ÌÅ¨Î•º ÎÇòÎà† Î®πÎçò ÏàúÍ∞ÑÏù¥ÏóàÏñ¥. Ìïú ÏûÖ Î≤†Ïñ¥ Î¨∏ Ï¥àÏΩúÎ¶ø ÏºÄÏù¥ÌÅ¨Ïùò Îã¨ÏΩ§Ìï®Í≥º ÌÅ¨Î¶ºÏùò Î∂ÄÎìúÎü¨ÏõÄÏù¥ Ï†ïÎßê Ìô©ÌôÄÌñàÏßÄ. Í∑∏ÎïåÎäî ÏßÄÍ∏àÏ≤òÎüº ÏÇ¨ÏßÑ Ï∞çÎäî Î¨∏ÌôîÍ∞Ä ÏóÜÏóàÏúºÎãà, ÎßàÏùåÏúºÎ°ú Í∑∏ ÏàúÍ∞ÑÏùÑ Í∞ÑÏßÅÌñàÏñ¥. ÏÇ¨ÎûåÎì§Ïùò Îî∞ÎúªÌïú ÏõÉÏùåÍ≥º ÎÇ¥Í∞Ä ÎäêÍºàÎçò ÌñâÎ≥µÏùÄ Ï†ïÎßê ÏÜåÏ§ëÌïú Ï∂îÏñµÏù¥Ïïº.\n",
      "\n",
      "ÎÇ¥ ÏπúÍµ¨Îì§ Ï§ë Ìïú Î™ÖÏùÄ Í∏∞ÌÉÄÎ•º Í∞ÄÏ†∏ÏôÄÏÑú Ï∂ïÌïò ÎÖ∏ÎûòÎ•º Î∂àÎü¨Ï§¨ÎäîÎç∞, Ï†ïÎßê Í∞êÎèôÏ†ÅÏù¥ÏóàÏñ¥. Í∑∏ Î©úÎ°úÎîîÍ∞Ä Î∞îÎûåÏùÑ ÌÉÄÍ≥† ÌçºÏ†∏ÎÇòÍ∞ÄÎ©∞ Í∑∏ ÎÇ†ÏùÑ ÎçîÏö± ÌäπÎ≥ÑÌïòÍ≤å ÎßåÎì§ÏóàÏßÄ. Î™®ÎëêÍ∞Ä Ìï®Íªò Î∞ïÏàòÎ•º ÏπòÎ©∞ ÎÖ∏ÎûòÎ•º Îî∞Îùº Î∂ÄÎ•¥Îçò Í∑∏ ÏàúÍ∞ÑÏùÄ ÎßêÎ°ú Îã§ ÌëúÌòÑÌï† Ïàò ÏóÜÏùÑ ÎßåÌÅº Ï¶êÍ±∞Ïõ†Ïñ¥.\n",
      "\n",
      "Í∑∏Î¶¨Í≥† ÏÉùÏùº ÏÑ†Î¨ºÎèÑ ÎπºÎÜìÏùÑ Ïàò ÏóÜÏßÄ. ÏûëÏùÄ ÏÉÅÏûêÏóê Îã¥Í∏¥ ÏÜêÏàòÍ±¥ÏùÑ Î∞õÏïòÎäîÎç∞, Í∑∏ ÏÜêÏàòÍ±¥ÏùÄ ÏñºÎßàÎÇò Í∑ÄÌñàÎçòÏßÄ ÏßÄÍ∏àÎèÑ Í∞ÑÏßÅÌïòÍ≥† ÏûàÎã®Îã§. ÏÜêÏúºÎ°ú ÍæπÍæπ ÎàåÎü¨ÏÑú ÎÇ¥ Ïù¥Î¶ÑÏùÑ ÏàòÎÜìÏùÄ ÏÜêÏàòÍ±¥Ïù¥ÏóàÏñ¥. Í∑∏ ÎßàÏùåÏù¥ ÎÑàÎ¨¥ÎÇò Í≥†ÎßôÍ≥† ÏÇ¨ÎûëÏä§Îü¨Ïõ†ÏßÄ.\n",
      "\n",
      "Í∑∏ÎÇ†Ïùò Îî∞ÎúªÌïú Í∏∞ÏñµÏùÄ ÎÇ¥ ÏÇ∂ÏóêÏÑú ÎπõÎÇòÎäî Î≥¥ÏÑù Í∞ôÏùÄ ÎÇ†Îì§Ïù¥Ïïº. ÏÜêÏ£ºÏïº, ÎÑàÎèÑ Í∑∏Îü∞ ÌñâÎ≥µÌïú ÏàúÍ∞ÑÏùÑ ÎßéÏù¥ ÎßåÎì§Ïñ¥Í∞ÄÎ©¥ Ï¢ãÍ≤†Ïñ¥. ÏÇ¨ÎûåÎì§Í≥º Ìï®Íªò ÌïòÎäî ÏûëÏùÄ ÏàúÍ∞ÑÎì§Ïù¥ ÎÇòÏ§ëÏóê ÎÑ§ ÏÇ∂ÏùÑ Î∞ùÍ≤å ÎπÑÏ∂î\n",
      "==================================================\n",
      "üìÇ ÎåÄÌôîÍ∏∞Î°ù: conversation_log\\images\\images_conv5\\images_conv5.txt\n",
      "üìä Î∂ÑÏÑùÍ≤∞Í≥º: analysis\\images_conv5_analysis.txt\n",
      "üìñ Ïä§ÌÜ†Î¶¨: story_telling\\images_story.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'conversation_file': 'conversation_log\\\\images\\\\images_conv5\\\\images_conv5.txt',\n",
       " 'analysis_file': 'analysis\\\\images_conv5_analysis.txt',\n",
       " 'story_file': 'story_telling\\\\images_story.txt',\n",
       " 'story_content': '\"ÏïÑ, Í∑∏Î†áÍµ¨ÎÇò. Ïù¥ ÏÇ¨ÏßÑÏùÑ Î≥¥Îãà Ï∞∏ Îî∞ÎúªÌïú Ï∂ïÌïò Î∂ÑÏúÑÍ∏∞Í∞Ä ÎäêÍª¥ÏßÄÎÑ§. ÎÇòÎèÑ Ïù¥Îü∞ Ï∂ïÌïò ÌñâÏÇ¨Ïóê Ïó¨Îü¨ Î≤à Ï∞∏ÏÑùÌñàÎçò Í∏∞ÏñµÏù¥ ÏûàÏñ¥. Ï†ïÎßê ÌäπÎ≥ÑÌïú ÏàúÍ∞ÑÎì§Ïù¥ÏóàÏßÄ. ÌäπÌûà Í∏∞ÏñµÏóê ÎÇ®Îäî Í±¥ ÎÇ¥ ÏÉùÏùºÎÇ†Ïù¥ÏóàÏñ¥. Ïò§ÎûòÏ†Ñ ÏùºÏù∏Îç∞ÎèÑ ÏÉùÏÉùÌïòÍ≤å Îñ†Ïò§Î•∏Îã§.\\n\\nÍ∑∏ÎÇ†ÏùÄ ÎÇ¥Í∞Ä Ï°∞Í∏à Îçî ÌäπÎ≥ÑÌïú ÏÇ¨ÎûåÏù¥ÎùºÎèÑ Îêú Í≤ÉÏ≤òÎüº Î™®ÎëêÍ∞Ä ÎÇòÎ•º Ï§ëÏã¨ÏúºÎ°ú Î™®ÏòÄÏßÄ. ÏÜêÎãòÎì§ÏùÄ ÏõÉÏùå Í∞ÄÎìùÌïú ÏñºÍµ¥Î°ú Ï∂ïÌïòÌï¥Ï£ºÍ≥†, Ïπ¥ÌéòÏóêÏÑ† ÏÉùÏùº ÏºÄÏù¥ÌÅ¨Í∞Ä Ï§ÄÎπÑÎêòÏñ¥ ÏûàÏóàÏñ¥. Í∑∏ ÏºÄÏù¥ÌÅ¨Îäî Ï†ïÎßêÎ°ú ÌÅ¨Í≥† ÏïÑÎ¶ÑÎã§Ïõ†ÎäîÎç∞, ÏúÑÏóê Ï¥àÎèÑ ÍΩÇÌòÄ ÏûàÏóàÏßÄ. Ï¥àÎ•º Î∂àÏóàÏùÑ Îïå ÏÇ¨ÎûåÎì§Ïù¥ Î∞ïÏàòÎ•º ÏπòÎ©∞ ÌôòÌò∏ÌïòÎçò ÏÜåÎ¶¨Í∞Ä ÏïÑÏßÅÎèÑ Í∑ÄÏóê ÏÑ†ÌïòÍµ¨ÎÇò.\\n\\nÍ∞ÄÏû• Í∏∞ÏñµÏóê ÎÇ®Îäî Í±¥ ÏºÄÏù¥ÌÅ¨Î•º ÎÇòÎà† Î®πÎçò ÏàúÍ∞ÑÏù¥ÏóàÏñ¥. Ìïú ÏûÖ Î≤†Ïñ¥ Î¨∏ Ï¥àÏΩúÎ¶ø ÏºÄÏù¥ÌÅ¨Ïùò Îã¨ÏΩ§Ìï®Í≥º ÌÅ¨Î¶ºÏùò Î∂ÄÎìúÎü¨ÏõÄÏù¥ Ï†ïÎßê Ìô©ÌôÄÌñàÏßÄ. Í∑∏ÎïåÎäî ÏßÄÍ∏àÏ≤òÎüº ÏÇ¨ÏßÑ Ï∞çÎäî Î¨∏ÌôîÍ∞Ä ÏóÜÏóàÏúºÎãà, ÎßàÏùåÏúºÎ°ú Í∑∏ ÏàúÍ∞ÑÏùÑ Í∞ÑÏßÅÌñàÏñ¥. ÏÇ¨ÎûåÎì§Ïùò Îî∞ÎúªÌïú ÏõÉÏùåÍ≥º ÎÇ¥Í∞Ä ÎäêÍºàÎçò ÌñâÎ≥µÏùÄ Ï†ïÎßê ÏÜåÏ§ëÌïú Ï∂îÏñµÏù¥Ïïº.\\n\\nÎÇ¥ ÏπúÍµ¨Îì§ Ï§ë Ìïú Î™ÖÏùÄ Í∏∞ÌÉÄÎ•º Í∞ÄÏ†∏ÏôÄÏÑú Ï∂ïÌïò ÎÖ∏ÎûòÎ•º Î∂àÎü¨Ï§¨ÎäîÎç∞, Ï†ïÎßê Í∞êÎèôÏ†ÅÏù¥ÏóàÏñ¥. Í∑∏ Î©úÎ°úÎîîÍ∞Ä Î∞îÎûåÏùÑ ÌÉÄÍ≥† ÌçºÏ†∏ÎÇòÍ∞ÄÎ©∞ Í∑∏ ÎÇ†ÏùÑ ÎçîÏö± ÌäπÎ≥ÑÌïòÍ≤å ÎßåÎì§ÏóàÏßÄ. Î™®ÎëêÍ∞Ä Ìï®Íªò Î∞ïÏàòÎ•º ÏπòÎ©∞ ÎÖ∏ÎûòÎ•º Îî∞Îùº Î∂ÄÎ•¥Îçò Í∑∏ ÏàúÍ∞ÑÏùÄ ÎßêÎ°ú Îã§ ÌëúÌòÑÌï† Ïàò ÏóÜÏùÑ ÎßåÌÅº Ï¶êÍ±∞Ïõ†Ïñ¥.\\n\\nÍ∑∏Î¶¨Í≥† ÏÉùÏùº ÏÑ†Î¨ºÎèÑ ÎπºÎÜìÏùÑ Ïàò ÏóÜÏßÄ. ÏûëÏùÄ ÏÉÅÏûêÏóê Îã¥Í∏¥ ÏÜêÏàòÍ±¥ÏùÑ Î∞õÏïòÎäîÎç∞, Í∑∏ ÏÜêÏàòÍ±¥ÏùÄ ÏñºÎßàÎÇò Í∑ÄÌñàÎçòÏßÄ ÏßÄÍ∏àÎèÑ Í∞ÑÏßÅÌïòÍ≥† ÏûàÎã®Îã§. ÏÜêÏúºÎ°ú ÍæπÍæπ ÎàåÎü¨ÏÑú ÎÇ¥ Ïù¥Î¶ÑÏùÑ ÏàòÎÜìÏùÄ ÏÜêÏàòÍ±¥Ïù¥ÏóàÏñ¥. Í∑∏ ÎßàÏùåÏù¥ ÎÑàÎ¨¥ÎÇò Í≥†ÎßôÍ≥† ÏÇ¨ÎûëÏä§Îü¨Ïõ†ÏßÄ.\\n\\nÍ∑∏ÎÇ†Ïùò Îî∞ÎúªÌïú Í∏∞ÏñµÏùÄ ÎÇ¥ ÏÇ∂ÏóêÏÑú ÎπõÎÇòÎäî Î≥¥ÏÑù Í∞ôÏùÄ ÎÇ†Îì§Ïù¥Ïïº. ÏÜêÏ£ºÏïº, ÎÑàÎèÑ Í∑∏Îü∞ ÌñâÎ≥µÌïú ÏàúÍ∞ÑÏùÑ ÎßéÏù¥ ÎßåÎì§Ïñ¥Í∞ÄÎ©¥ Ï¢ãÍ≤†Ïñ¥. ÏÇ¨ÎûåÎì§Í≥º Ìï®Íªò ÌïòÎäî ÏûëÏùÄ ÏàúÍ∞ÑÎì§Ïù¥ ÎÇòÏ§ëÏóê ÎÑ§ ÏÇ∂ÏùÑ Î∞ùÍ≤å ÎπÑÏ∂î',\n",
       " 'summary': '\\n============================================================\\nüìã ÏπòÎß§ ÏßÑÎã® ÎåÄÌôî Î∂ÑÏÑù Î¶¨Ìè¨Ìä∏\\n============================================================\\nüìÖ Î∂ÑÏÑù ÏùºÏãú: 2025ÎÖÑ 06Ïõî 09Ïùº 10:40:56\\nüÜî ÎåÄÌôî ID: images_conv5\\n============================================================\\n\\nüéØ Ï¢ÖÌï© ÌèâÍ∞Ä\\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\\nüòä Í∞êÏ†ï ÏÉÅÌÉú:     ‚≠ê‚≠ê‚≠ê‚≠ê‚òÜ (4/5)\\nüí¨ ÎãµÎ≥Ä ÏùºÍ¥ÄÏÑ±:   ‚≠ê‚≠ê‚òÜ‚òÜ‚òÜ (2/5)\\nüß† Ï†ÑÎ∞òÏ†Å Ïù∏ÏßÄ:   ‚≠ê‚òÜ‚òÜ‚òÜ‚òÜ (1/5)\\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\\n\\nüìä ÎåÄÌôî Í∞úÏöî\\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\\nüí¨ Ï¥ù ÎåÄÌôî ÌöüÏàò: 3Ìöå\\nüòä Ï†ÑÎ∞òÏ†Å Í∞êÏ†ï: Í∏çÏ†ïÏ†Å (Ï£ºÏöî: Î∂àÏïà)\\n‚ö†Ô∏è Ïñ¥Í∏ãÎÇú ÎãµÎ≥Ä: 3Ìöå\\n‚úÖ Î∞úÌôî Ìå®ÌÑ¥: ÌäπÏù¥ÏÇ¨Ìï≠ ÏóÜÏùå\\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\\n\\nüö® Ï£ºÏöî Î∞úÍ≤¨ÏÇ¨Ìï≠\\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\\nüîç Ïñ¥Í∏ãÎÇú ÎãµÎ≥Ä Î∂ÑÏÑù:\\n  üü° Ï°∞Í∏à Ïñ¥Í∏ãÎÇ®: 1Ìöå\\n  üü† ÍΩ§ Ïñ¥Í∏ãÎÇ®: 2Ìöå\\n\\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\\n\\nüìù Ïñ¥Í∏ãÎÇú ÎãµÎ≥Ä ÏÉÅÏÑ∏\\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\\n1. 2025-06-09 10:39:39\\n   ‚ùì ÏßàÎ¨∏: \"Ïñ¥Î•¥Ïã†, Ïù¥ ÏÇ¨ÏßÑ ÏÜç Ï∂ïÌïò ÌñâÏÇ¨ Î∂ÑÏúÑÍ∏∞Í∞Ä Ï∞∏ Îî∞ÎúªÌïòÎÑ§Ïöî. ÏòàÏ†ÑÏóê Ïù¥Îü∞ Î™®ÏûÑÏóê Ï∞∏ÏÑùÌï¥Î≥¥Ïã† Ï†Å ÏûàÏúºÏã†Í∞ÄÏöî?\"\\n   üí¨ ÎãµÎ≥Ä: Ïóê Ï∞∏ÏÑùÌï¥Ïò® Ï†Å ÏûàÏñ¥?\\n   üòä ÏÉÅÌÉú: Î∂àÏïà | üéØ ÌíàÏßà: poor\\n\\n2. 2025-06-09 10:40:00\\n   ‚ùì ÏßàÎ¨∏: \"ÏïÑ, Í∑∏Îü¨ÏÖ®Íµ∞Ïöî! Ï∂ïÌïò Î™®ÏûÑÏùÄ Îäò ÌäπÎ≥ÑÌïòÏ£†. ÌòπÏãú Í∏∞ÏñµÏóê ÎÇ®Îäî Ï∂ïÌïò ÌñâÏÇ¨ÎÇò Î∂ÑÏúÑÍ∏∞Í∞Ä Îñ†Ïò§Î•¥ÏãúÎÇòÏöî?\"\\n   üí¨ ÎãµÎ≥Ä: Ïñ¥ Í∏∞ÏñµÏóê ÎÇ®ÎäîÍ±¥Îç∞ ÏÉùÏùº ÏÉùÏùºÎÇ†ÎèÑ ÏûàÏñ¥?\\n   üòä ÏÉÅÌÉú: Í∑∏Î¶¨ÏõÄ | üéØ ÌíàÏßà: normal\\n\\n3. 2025-06-09 10:40:19\\n   ‚ùì ÏßàÎ¨∏: \"ÏÉùÏùºÎÇ†Ïù¥ÎùºÎãà, Ï†ïÎßê ÌäπÎ≥ÑÌïú ÎÇ†Ïù¥ÏÖ®Í≤†Ïñ¥Ïöî! ÏÉùÏùºÎÇ†Ïóê Ïñ¥Îñ§ Î∂ÑÏúÑÍ∏∞ÏòÄÎäîÏßÄ Îçî ÏûêÏÑ∏Ìûà Îì§Î†§Ï£ºÏã§ Ïàò ÏûàÏùÑÍπåÏöî?\"\\n   üí¨ ÎãµÎ≥Ä: ÏÑ∏ÎØ∏ÎÇòÎ•º ÏºÄÏù¥ÌÅ¨ Î®πÏóàÏßÄ?\\n   üòä ÏÉÅÌÉú: Ìù•ÎØ∏ | üéØ ÌíàÏßà: poor\\n\\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\\n\\nüí° Í∂åÏû•ÏÇ¨Ìï≠\\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\\nüíô Í¥ÄÏã¨ Í∂åÏû•ÏÇ¨Ìï≠:\\n   Ï†ÑÎ∞òÏ†ÅÏúºÎ°ú Ïûò ÏùëÎãµÌï¥Ï£ºÏÖ®ÏßÄÎßå, Í∞ÑÌòπ Ïñ¥Í∏ãÎÇú ÎãµÎ≥ÄÏù¥ Î≥¥ÏûÖÎãàÎã§.\\n   Í∞ÄÎ≥çÍ≤åÎùºÎèÑ Ï£ºÎ≥ÄÏùò Í¥ÄÏã¨Í≥º ÌôïÏù∏Ïù¥ ÏûàÏúºÎ©¥ Ï¢ãÍ≤†ÏäµÎãàÎã§.\\n\\nüè† Í∞ÄÏ°±ÏùÑ ÏúÑÌïú Ï°∞Ïñ∏\\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\\nüü§ Î∂àÏïàÍ∞êÏùÑ ÎäêÎÅºÏãúÎäî Í≤É Í∞ôÏïÑÏöî.\\n   ‚Üí Ïñ¥Î•¥Ïã†Ïùò Ïù¥ÏïºÍ∏∞Î•º Ïûò Îì§Ïñ¥Ï£ºÏãúÍ≥†, Îî∞ÎúªÌïú Îßê ÌïúÎßàÎîîÍ∞Ä ÌÅ∞ ÏúÑÎ°úÍ∞Ä Îê©ÎãàÎã§.\\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\\n\\nüìà ÌèâÍ∞Ä Í∏∞Ï§Ä\\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\\nüòä Í∞êÏ†ï ÏÉÅÌÉú: Í∏çÏ†ïÏ†ÅÏù¥Í≥† ÏïàÏ†ïÏ†ÅÏù∏ Í∞êÏ†ï ÌëúÌòÑÏùºÏàòÎ°ù ÎÜíÏùÄ Ï†êÏàò\\nüí¨ ÎãµÎ≥Ä ÏùºÍ¥ÄÏÑ±: ÏßàÎ¨∏Í≥º Í¥ÄÎ†®Îêú Ï†ÅÏ†àÌïú ÎãµÎ≥ÄÏùºÏàòÎ°ù ÎÜíÏùÄ Ï†êÏàò\\nüß† Ï†ÑÎ∞òÏ†Å Ïù∏ÏßÄ: ÎãµÎ≥ÄÏùò ÌíàÏßàÍ≥º ÏÜåÌÜµ Îä•Î†•ÏùÑ Ï¢ÖÌï©Ìïú Ï†êÏàò\\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\\n\\n============================================================\\nüìã Î¶¨Ìè¨Ìä∏ ÎÅù - Ïñ¥Î•¥Ïã†Ïùò Í±¥Í∞ïÍ≥º ÌñâÎ≥µÏùÑ ÏúÑÌï¥\\n============================================================\\n',\n",
       " 'conversation_id': 'images_conv5'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactive_voice_conversation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
