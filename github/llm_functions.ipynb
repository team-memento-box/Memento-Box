{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f5bbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (1.72.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (0.9.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (1.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai tiktoken python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a6eb31",
   "metadata": {},
   "source": [
    "\n",
    "# ì‹¤í–‰ ê³¼ì •\n",
    "\n",
    "ì´ ì‹œìŠ¤í…œì€ ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. **ImageAnalysisGPT í´ë˜ìŠ¤**\n",
    "   - GPT-4oë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë¶„ì„\n",
    "   - ì´ë¯¸ì§€ì˜ caption, mood, objects ë“± ì¶”ì¶œ\n",
    "\n",
    "2. **LLMDescription í´ë˜ìŠ¤**\n",
    "   - ì–´ë¥´ì‹ ê³¼ì˜ ëŒ€í™” ê´€ë¦¬\n",
    "   - ì´ìƒ ë‹µë³€ ê°ì§€ ë° í‰ê°€\n",
    "   - ëŒ€í™” ë‚´ìš© ì €ì¥\n",
    "\n",
    "3. **ìƒì„±ë˜ëŠ” íŒŒì¼ êµ¬ì¡°**\n",
    "   ```\n",
    "   í”„ë¡œì íŠ¸ í´ë”/\n",
    "   â”œâ”€â”€ conversation_log/     # ì§ˆì˜ì‘ë‹µ ëŒ€í™” ê¸°ë¡\n",
    "   â”‚   â””â”€â”€ images_20250124_143022.txt\n",
    "   â”œâ”€â”€ analysis/            # ì´ìƒ ë‹µë³€ ë¶„ì„\n",
    "   â”‚   â””â”€â”€ images_20250124_143022_analysis.txt\n",
    "   â””â”€â”€ story_telling/       # ì¶”ì–µ ìŠ¤í† ë¦¬\n",
    "       â””â”€â”€ images.txt\n",
    "   ```\n",
    "\n",
    "4. **ì‚¬ìš© ë°©ë²•**\n",
    "   ```python\n",
    "   # ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì •\n",
    "   image_path = \"your_image.jpg\"\n",
    "   \n",
    "   # ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° ì‹¤í–‰\n",
    "   result, llm_chat, img_path = analyze_and_describe_image(image_path)\n",
    "   ```\n",
    "\n",
    "5. **ì´ìƒ ë‹µë³€ ì‹¬ê°ë„ ë¶„ë¥˜**\n",
    "   - mild: ì•½ê°„ ë²—ì–´ë‚¬ì§€ë§Œ ì´í•´ ê°€ëŠ¥\n",
    "   - moderate: ìƒë‹¹íˆ ì—‰ëš±í•˜ì§€ë§Œ ì™„ì „íˆ ë¬´ê´€í•˜ì§€ëŠ” ì•ŠìŒ\n",
    "   - severe: ì™„ì „íˆ ë¬´ê´€í•˜ê±°ë‚˜ ë¹„ë…¼ë¦¬ì ì¸ ë‹µë³€\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2e7d60",
   "metadata": {},
   "source": [
    "# 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36de4620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 1: í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° í™˜ê²½ ì„¤ì •\n",
    "\n",
    "import json\n",
    "import base64\n",
    "import os\n",
    "import tiktoken\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from datetime import datetime\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd65a71",
   "metadata": {},
   "source": [
    "# 2. ë°ì´í„° êµ¬ì¡° ì •ì˜\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198a1560",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class StrangeResponse:\n",
    "    \"\"\"ì´ìƒí•œ ë‹µë³€ì„ ì €ì¥í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤\"\"\"\n",
    "    question: str\n",
    "    answer: str\n",
    "    timestamp: str\n",
    "    severity: str  # \"mild\", \"moderate\", \"severe\"\n",
    "\n",
    "@dataclass\n",
    "class ConversationTurn:\n",
    "    \"\"\"ëŒ€í™” í„´ì„ ì €ì¥í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤\"\"\"\n",
    "    question: str\n",
    "    answer: str\n",
    "    timestamp: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b31d02",
   "metadata": {},
   "source": [
    "# 3. GPT-4oë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë¶„ì„ í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be770fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageAnalysisGPT:\n",
    "    \"\"\"GPT-4oë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë¶„ì„ í´ë˜ìŠ¤\"\"\"\n",
    "    def __init__(self):\n",
    "        # Azure OpenAI ê´€ë ¨ ì„¤ì •\n",
    "        self.endpoint = os.getenv(\"gpt-endpoint\")\n",
    "        self.deployment = \"gpt-4o\"\n",
    "        self.subscription_key = os.getenv(\"gpt-key\")\n",
    "        self.api_version = \"2024-12-01-preview\"\n",
    "        \n",
    "        if not self.endpoint or not self.subscription_key:\n",
    "            raise ValueError(\"Please set the gpt-endpoint and gpt-key in the environment variables.\")\n",
    "        \n",
    "        # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "        self.client = AzureOpenAI(\n",
    "            api_version=self.api_version,\n",
    "            azure_endpoint=self.endpoint,\n",
    "            api_key=self.subscription_key,\n",
    "        )\n",
    "    \n",
    "    def encode_image_to_base64(self, image_path):\n",
    "        \"\"\"ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©\"\"\"\n",
    "        try:\n",
    "            with open(image_path, \"rb\") as image_file:\n",
    "                return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"ì´ë¯¸ì§€ ì¸ì½”ë”© ì˜¤ë¥˜: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def analyze_image_with_gpt(self, image_path):\n",
    "        \"\"\"GPT-4oë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë¶„ì„\"\"\"\n",
    "        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©\n",
    "        base64_image = self.encode_image_to_base64(image_path)\n",
    "        if not base64_image:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.deployment,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": \"\"\"ì´ ì´ë¯¸ì§€ë¥¼ ìì„¸íˆ ë¶„ì„í•´ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:\n",
    "\n",
    "1. caption: ì´ë¯¸ì§€ì˜ ì „ì²´ì ì¸ ì„¤ëª… (êµ¬ì²´ì ìœ¼ë¡œ ê·¸ë¦¬ê³  í•œí¸ì˜ ì´ì•¼ê¸°ì²˜ëŸ¼)\n",
    "2. dense_captions: ì´ë¯¸ì§€ì˜ ì„¸ë¶€ì ì¸ ìš”ì†Œë“¤ì„ ì—¬ëŸ¬ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª… (ë°°ì—´ í˜•íƒœ)\n",
    "3. mood: ì´ë¯¸ì§€ì—ì„œ ëŠê»´ì§€ëŠ” ë¶„ìœ„ê¸°ë‚˜ ê°ì •\n",
    "4. time_period: ì¶”ì •ë˜ëŠ” ì‹œëŒ€ë‚˜ ì‹œê¸°\n",
    "5. key_objects: ì£¼ìš” ê°ì²´ë“¤ (ë°°ì—´ í˜•íƒœ)\n",
    "6. people_description: ì‚¬ëŒì´ ìˆë‹¤ë©´ ê·¸ë“¤ì— ëŒ€í•œ ì„¤ëª…\n",
    "\n",
    "ë‹¤ìŒê³¼ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œ ë‹µí•´ì£¼ì„¸ìš”:\n",
    "{\n",
    "    \"caption\": \"ì „ì²´ ì´ë¯¸ì§€ ì„¤ëª…\",\n",
    "    \"dense_captions\": [\"ì„¸ë¶€ì‚¬í•­1\", \"ì„¸ë¶€ì‚¬í•­2\", \"ì„¸ë¶€ì‚¬í•­3\"],\n",
    "    \"mood\": \"ë¶„ìœ„ê¸° ì„¤ëª…\",\n",
    "    \"time_period\": \"ì¶”ì • ì‹œëŒ€\",\n",
    "    \"key_objects\": [\"ê°ì²´1\", \"ê°ì²´2\", \"ê°ì²´3\"],\n",
    "    \"people_description\": \"ì‚¬ëŒë“¤ì— ëŒ€í•œ ì„¤ëª…\"\n",
    "}\"\"\"\n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"image_url\",\n",
    "                                \"image_url\": {\n",
    "                                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                                }\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "                max_tokens=1000,\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            # ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ\n",
    "            response_text = response.choices[0].message.content\n",
    "            \n",
    "            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (```jsonìœ¼ë¡œ ê°ì‹¸ì ¸ ìˆì„ ìˆ˜ ìˆìŒ)\n",
    "            if \"```json\" in response_text:\n",
    "                json_start = response_text.find(\"```json\") + 7\n",
    "                json_end = response_text.find(\"```\", json_start)\n",
    "                response_text = response_text[json_start:json_end].strip()\n",
    "            elif \"{\" in response_text:\n",
    "                json_start = response_text.find(\"{\")\n",
    "                json_end = response_text.rfind(\"}\") + 1\n",
    "                response_text = response_text[json_start:json_end]\n",
    "            \n",
    "            analysis_result = json.loads(response_text)\n",
    "            \n",
    "            # ê²°ê³¼ ì¶œë ¥\n",
    "            print(f\"\\nCaption: {analysis_result.get('caption', 'N/A')}\")\n",
    "            print(f\"Mood: {analysis_result.get('mood', 'N/A')}\")\n",
    "            print(f\"Time Period: {analysis_result.get('time_period', 'N/A')}\")\n",
    "            print(\"\\nDense Captions:\")\n",
    "            for caption in analysis_result.get('dense_captions', []):\n",
    "                print(f\"- {caption}\")\n",
    "            \n",
    "            return analysis_result\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON íŒŒì‹± ì˜¤ë¥˜: {e}\")\n",
    "            print(f\"ì›ë³¸ ì‘ë‹µ: {response_text}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9823bb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac6a5d32",
   "metadata": {},
   "source": [
    "# 4 / 5. LLM ëŒ€í™” ì‹œìŠ¤í…œ - ì´ˆê¸°í™” ë° ê¸°ë³¸ ì„¤ì • / í† í° ê´€ë¦¬ ë° ë‹µë³€ í‰ê°€ ê¸°ëŠ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb504fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMDescription:\n",
    "    def __init__(self):\n",
    "        # Azure OpenAI ê´€ë ¨ ì„¤ì •\n",
    "        self.endpoint = os.getenv(\"gpt-endpoint\")\n",
    "        self.deployment = \"gpt-4o\"\n",
    "        self.subscription_key = os.getenv(\"gpt-key\")\n",
    "        self.api_version = \"2024-12-01-preview\"\n",
    "        \n",
    "        if not self.endpoint or not self.subscription_key:\n",
    "            raise ValueError(\"Please set the gpt-endpoint and gpt-key in the environment variables.\")\n",
    "        \n",
    "        # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "        self.client = AzureOpenAI(\n",
    "            api_version=self.api_version,\n",
    "            azure_endpoint=self.endpoint,\n",
    "            api_key=self.subscription_key,\n",
    "        )\n",
    "        \n",
    "        # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”\n",
    "        self.conversation_history = []\n",
    "        \n",
    "        # í† í° ì¹´ìš´í„° ì´ˆê¸°í™”\n",
    "        self.tokenizer = tiktoken.get_encoding(\"cl100k_base\")  # GPT-4oìš© í† í¬ë‚˜ì´ì €\n",
    "        self.token_count = 0\n",
    "        self.MAX_TOKENS = 4000  # ìµœëŒ€ í† í° ì œí•œ\n",
    "        \n",
    "        # ì´ìƒí•œ ë‹µë³€ ì¶”ì \n",
    "        self.strange_responses = []\n",
    "        self.strange_response_count = 0\n",
    "        self.last_question = \"\"  # ë§ˆì§€ë§‰ ì§ˆë¬¸ ì €ì¥\n",
    "        \n",
    "        # ëŒ€í™” ê¸°ë¡ ì¶”ì  (íŒŒì¼ ì €ì¥ìš©)\n",
    "        self.conversation_turns = []\n",
    "    def _count_tokens(self, text: str) -> int:\n",
    "        \"\"\"ë¬¸ìì—´ì˜ í† í° ìˆ˜ ê³„ì‚°\"\"\"\n",
    "        return len(self.tokenizer.encode(text))\n",
    "    \n",
    "    def _count_message_tokens(self, messages: List[Dict[str, Any]]) -> int:\n",
    "        \"\"\"ëŒ€í™” ë©”ì‹œì§€ ëª©ë¡ì˜ ì´ í† í° ìˆ˜ ê³„ì‚°\"\"\"\n",
    "        total = 0\n",
    "        for message in messages:\n",
    "            total += self._count_tokens(message.get(\"content\", \"\"))\n",
    "        return total\n",
    "    \n",
    "    def _evaluate_response_relevance(self, question: str, answer: str) -> Dict[str, Any]:\n",
    "        \"\"\"ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ì„±ì´ ìˆëŠ”ì§€ LLMìœ¼ë¡œ í‰ê°€\"\"\"\n",
    "        evaluation_prompt = f\"\"\"\n",
    "ë‹¤ìŒ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë¶„ì„í•´ì„œ ë‹µë³€ì´ ì–¼ë§ˆë‚˜ ì ì ˆí•œì§€ í‰ê°€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "ë‹µë³€: {answer}\n",
    "\n",
    "í‰ê°€ ê¸°ì¤€:\n",
    "1. ì§ˆë¬¸ê³¼ ë‹µë³€ì˜ ê´€ë ¨ì„±\n",
    "2. ë‹µë³€ì˜ ì¼ê´€ì„±\n",
    "3. ë§¥ë½ì  ì ì ˆì„±\n",
    "\n",
    "ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•´ì£¼ì„¸ìš”:\n",
    "{{\n",
    "    \"is_strange\": true/false,\n",
    "    \"severity\": \"normal/mild/moderate/severe\",\n",
    "    \"reason\": \"í‰ê°€ ì´ìœ ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…\"\n",
    "}}\n",
    "\n",
    "severity ê¸°ì¤€:\n",
    "- normal: ì™„ì „íˆ ì ì ˆí•œ ë‹µë³€\n",
    "- mild: ì•½ê°„ ë²—ì–´ë‚¬ì§€ë§Œ ì´í•´ ê°€ëŠ¥\n",
    "- moderate: ìƒë‹¹íˆ ì—‰ëš±í•˜ì§€ë§Œ ì™„ì „íˆ ë¬´ê´€í•˜ì§€ëŠ” ì•ŠìŒ\n",
    "- severe: ì™„ì „íˆ ë¬´ê´€í•˜ê±°ë‚˜ ë¹„ë…¼ë¦¬ì ì¸ ë‹µë³€\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.deployment,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ ì¹˜ë§¤ í™˜ìì˜ ë‹µë³€ì„ í‰ê°€í•˜ëŠ” ì˜ë£Œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê°ê´€ì ì´ê³  ì •í™•í•˜ê²Œ í‰ê°€í•´ì£¼ì„¸ìš”.\"},\n",
    "                    {\"role\": \"user\", \"content\": evaluation_prompt}\n",
    "                ],\n",
    "                max_tokens=256,\n",
    "                temperature=0.1,  # ì¼ê´€ëœ í‰ê°€ë¥¼ ìœ„í•´ ë‚®ì€ temperature\n",
    "                top_p=1.0,\n",
    "            )\n",
    "            \n",
    "            evaluation_text = response.choices[0].message.content\n",
    "            \n",
    "            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ\n",
    "            if \"```json\" in evaluation_text:\n",
    "                json_start = evaluation_text.find(\"```json\") + 7\n",
    "                json_end = evaluation_text.find(\"```\", json_start)\n",
    "                evaluation_text = evaluation_text[json_start:json_end].strip()\n",
    "            elif \"{\" in evaluation_text:\n",
    "                json_start = evaluation_text.find(\"{\")\n",
    "                json_end = evaluation_text.rfind(\"}\") + 1\n",
    "                evaluation_text = evaluation_text[json_start:json_end]\n",
    "            \n",
    "            evaluation_json = json.loads(evaluation_text)\n",
    "            return evaluation_json\n",
    "            \n",
    "        except (json.JSONDecodeError, Exception) as e:\n",
    "            print(f\"ë‹µë³€ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            # ê¸°ë³¸ê°’ ë°˜í™˜\n",
    "            return {\n",
    "                \"is_strange\": False,\n",
    "                \"severity\": \"normal\",\n",
    "                \"reason\": \"í‰ê°€ ì‹¤íŒ¨\"\n",
    "            }\n",
    "    \n",
    "    def _store_strange_response(self, question: str, answer: str, severity: str, reason: str):\n",
    "        \"\"\"ì´ìƒí•œ ë‹µë³€ì„ ì €ì¥ (ì½˜ì†” ì¶œë ¥ ì œê±°)\"\"\"\n",
    "        strange_response = StrangeResponse(\n",
    "            question=question,\n",
    "            answer=answer,\n",
    "            timestamp=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            severity=severity\n",
    "        )\n",
    "        \n",
    "        self.strange_responses.append(strange_response)\n",
    "        self.strange_response_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ebcd7c",
   "metadata": {},
   "source": [
    "# 6. ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì„¤ì • ë° ì´ˆê¸° ì§ˆë¬¸ ìƒì„±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cab0f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def setup_conversation_context(self, analysis_result, user_description=\"\", user_description_date=\"\"):\n",
    "        \"\"\"ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì„¤ì •\"\"\"\n",
    "        caption = analysis_result.get(\"caption\", \"\")\n",
    "        dense_captions = analysis_result.get(\"dense_captions\", [])\n",
    "        mood = analysis_result.get(\"mood\", \"\")\n",
    "        time_period = analysis_result.get(\"time_period\", \"\")\n",
    "        key_objects = analysis_result.get(\"key_objects\", [])\n",
    "        people_description = analysis_result.get(\"people_description\", \"\")\n",
    "        \n",
    "        # ìƒì„¸ ìº¡ì…˜ í…ìŠ¤íŠ¸ í¬ë§·íŒ…\n",
    "        dense_captions_text = \"\\n\".join([f\"- {dc}\" for dc in dense_captions])\n",
    "        key_objects_text = \", \".join(key_objects)\n",
    "        \n",
    "        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„¤ì •\n",
    "        system_message = f\"\"\"ë‹¹ì‹ ì€ ì´ë¯¸ì§€ì— ëŒ€í•´ í• ë¨¸ë‹ˆ í• ì•„ë²„ì§€ì™€ ê°™ì´ ì–´ë¥´ì‹ ë“¤ê³¼ ëŒ€í™”í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. \n",
    "ë‹¤ìŒ ì´ë¯¸ì§€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”:\n",
    "\n",
    "=== ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ===\n",
    "ì£¼ìš” ì„¤ëª…(Caption): {caption}\n",
    "ë¶„ìœ„ê¸°/ê°ì •: {mood}\n",
    "ì¶”ì • ì‹œëŒ€: {time_period}\n",
    "ì£¼ìš” ê°ì²´ë“¤: {key_objects_text}\n",
    "ì¸ë¬¼ ì„¤ëª…: {people_description}\n",
    "\n",
    "ì„¸ë¶€ ìš”ì†Œë“¤:\n",
    "{dense_captions_text}\n",
    "\n",
    "=== ëŒ€í™” ê°€ì´ë“œë¼ì¸ ===\n",
    "1. ì–´ë¥´ì‹ ë“¤(íŠ¹íˆ ì¹˜ë§¤ í™˜ì)ê³¼ ëŒ€í™”í•œë‹¤ê³  ê°€ì •í•˜ê³  ì¹œê·¼í•˜ê³  ë”°ëœ»í•˜ê²Œ ëŒ€í™”í•˜ì„¸ìš”.\n",
    "2. ì´ë¯¸ì§€ì— ëŒ€í•œ í¥ë¯¸ë¡œìš´ ì§ˆë¬¸ì„ ë¨¼ì € ë˜ì ¸ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”.\n",
    "3. ì‚¬ìš©ìê°€ ì—‰ëš±í•œ ë‹µë³€ì„ í•´ë„ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°€ë©° ì¹œì ˆí•˜ê²Œ ì´ëŒì–´ì£¼ì„¸ìš”.\n",
    "4. ê·¸ë•Œ ë‹¹ì‹œì˜ ê°ì •ì´ë‚˜ ê²½í—˜ì— ëŒ€í•´ ë¬¼ì–´ë³´ë©° ì¶”ì–µì„ ë˜ì‚´ë ¤ì£¼ì„¸ìš”.\n",
    "\n",
    "=== ëŒ€í™” ì „ëµ ===\n",
    "ë¬¸ì œ ìƒí™©ë³„ í•´ê²° ë°©ë²•:\n",
    "\n",
    "â–ª ì§ˆë¬¸ì„ ì´í•´í•˜ì§€ ëª»í•  ê²½ìš°:\n",
    "  - ì§ˆë¬¸ì„ ë‹¨ìˆœí™”í•˜ì—¬ ì¬êµ¬ì„±\n",
    "  - ì„ íƒì§€ë¥¼ ì œê³µí•˜ì—¬ ë‹µí•˜ê¸° ì‰½ê²Œ ë§Œë“¤ê¸°\n",
    "  - ì˜ˆì‹œë‚˜ ë§¥ë½ì„ í•¨ê»˜ ì œê³µ\n",
    "\n",
    "â–ª ì—‰ëš±í•œ ëŒ€ë‹µì„ í•  ê²½ìš°:\n",
    "  - ëŒ€ë‹µì„ ìˆ˜ìš©í•˜ë©´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ì£¼ì œë¡œ ìœ ë„\n",
    "  - ëŒ€ë‹µì˜ ì¼ë¶€ë¶„ì´ë¼ë„ ì—°ê²°ì ì„ ì°¾ì•„ ì´ì–´ê°€ê¸°\n",
    "\n",
    "â–ª ëŒ€ë‹µì„ ëª»í•  ê²½ìš°:\n",
    "  - ì‹¬ë¦¬ì  ë¶€ë‹´ ì—†ì´ ë„˜ì–´ê°€ê¸°\n",
    "  - \"ê¸°ì–µì´ ì•ˆ ë‚˜ì…”ë„ ê´œì°®ë‹¤\"ê³  ì•ˆì‹¬ì‹œí‚¤ê¸°\n",
    "\n",
    "ì´ë¯¸ì§€ì˜ ì‹œê°ì  ìš”ì†Œë“¤ì„ ìƒìƒí•˜ê²Œ ë¬˜ì‚¬í•˜ë©°, ê·¸ë•Œì˜ ê°ì •ê³¼ ìƒí™©ì— ëŒ€í•´ ê¶ê¸ˆí•´í•˜ëŠ” ì†ì/ì†ë…€ì˜ ë§ˆìŒìœ¼ë¡œ ëŒ€í™”í•˜ì„¸ìš”.\"\"\"\n",
    "        \n",
    "        # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ë° í† í° ìˆ˜ ê³„ì‚°\n",
    "        self.conversation_history = [{\"role\": \"system\", \"content\": system_message}]\n",
    "        self.token_count = self._count_tokens(system_message)\n",
    "        \n",
    "        return system_message\n",
    "    \n",
    "    def generate_initial_question(self):\n",
    "        \"\"\"ì²« ì§ˆë¬¸ ìƒì„± í•¨ìˆ˜\"\"\"\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.deployment,\n",
    "            messages=self.conversation_history + [\n",
    "                {\"role\": \"user\", \"content\": \"ì´ ì˜›ë‚  ì‚¬ì§„ì— ëŒ€í•´ ì–´ë¥´ì‹ ì—ê²Œ ë¬¼ì–´ë³¼ ì²« ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”. ê°„ë‹¨í•˜ê³  ê¸°ì–µí•˜ê¸° ì‰¬ìš°ë©°, ê°ì •ì ìœ¼ë¡œ ì—°ê²°ë  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\"}\n",
    "            ],\n",
    "            max_tokens=512,\n",
    "            temperature=0.8,\n",
    "            top_p=1.0,\n",
    "        )\n",
    "        \n",
    "        initial_question = response.choices[0].message.content\n",
    "        \n",
    "        # ì§ˆë¬¸ ì¶”ê°€ ë° í† í° ìˆ˜ ì—…ë°ì´íŠ¸\n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": initial_question})\n",
    "        self.token_count += self._count_tokens(initial_question)\n",
    "        \n",
    "        # ë§ˆì§€ë§‰ ì§ˆë¬¸ ì €ì¥\n",
    "        self.last_question = initial_question\n",
    "        \n",
    "        return initial_question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880396f6",
   "metadata": {},
   "source": [
    "# 7. ëŒ€í™” ì²˜ë¦¬ ë° ì‘ë‹µ ìƒì„±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e55843",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def chat_about_image(self, user_query):\n",
    "        \"\"\"ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±\"\"\"\n",
    "        # í† í° ì œí•œ í™•ì¸\n",
    "        user_tokens = self._count_tokens(user_query)\n",
    "        \n",
    "        # ì‚¬ìš©ì ë‹µë³€ì˜ ì ì ˆì„± í‰ê°€ (ì´ì „ ì§ˆë¬¸ì´ ìˆëŠ” ê²½ìš°)\n",
    "        if self.last_question:\n",
    "            evaluation = self._evaluate_response_relevance(self.last_question, user_query)\n",
    "            \n",
    "            if evaluation.get(\"is_strange\", False):\n",
    "                severity = evaluation.get(\"severity\", \"mild\")\n",
    "                reason = evaluation.get(\"reason\", \"ê´€ë ¨ì„± ë¶€ì¡±\")\n",
    "                \n",
    "                # ì´ìƒí•œ ë‹µë³€ ì €ì¥\n",
    "                self._store_strange_response(\n",
    "                    question=self.last_question,\n",
    "                    answer=user_query,\n",
    "                    severity=severity,\n",
    "                    reason=reason\n",
    "                )\n",
    "        \n",
    "        # ëŒ€í™” í„´ ì €ì¥ (ì§ˆë¬¸-ë‹µë³€ ìŒ)\n",
    "        if self.last_question:\n",
    "            conversation_turn = ConversationTurn(\n",
    "                question=self.last_question,\n",
    "                answer=user_query,\n",
    "                timestamp=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            )\n",
    "            self.conversation_turns.append(conversation_turn)\n",
    "        \n",
    "        # ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": user_query})\n",
    "        self.token_count += user_tokens\n",
    "        \n",
    "        # í† í° ì œí•œ ì´ˆê³¼ í™•ì¸\n",
    "        if self.token_count > self.MAX_TOKENS:\n",
    "            answer = \"ì£„ì†¡í•©ë‹ˆë‹¤, ë‚˜ì¤‘ì— ë‹¤ì‹œ ì–˜ê¸°í•´ìš”. ì§€ê¸ˆì€ ì ì‹œ ì‰¬ì–´ì•¼ í•  ê²ƒ ê°™ì•„ìš”. ë§Œì•½ ë” ë§ì€ ëŒ€í™”ë¥¼ ì›í•œë‹¤ë©´ MEMENTO BOX Premiumì„ ì‚¬ìš©í•´ë³´ì„¸ìš”.\"\n",
    "            self.conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "            return answer, True  # TrueëŠ” ëŒ€í™” ì¢…ë£Œ ì‹ í˜¸\n",
    "        \n",
    "        # LLM ì‘ë‹µ ìƒì„±\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.deployment,\n",
    "            messages=self.conversation_history,\n",
    "            max_tokens=1024,\n",
    "            temperature=0.7,\n",
    "            top_p=1.0,\n",
    "        )\n",
    "        \n",
    "        # ì‘ë‹µ ì¶”ì¶œ\n",
    "        answer = response.choices[0].message.content\n",
    "        \n",
    "        # ì‘ë‹µ ì¶”ê°€ ë° í† í° ìˆ˜ ì—…ë°ì´íŠ¸\n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "        self.token_count += self._count_tokens(answer)\n",
    "        \n",
    "        # ë‹¤ìŒ í‰ê°€ë¥¼ ìœ„í•´ í˜„ì¬ AI ì‘ë‹µì„ ì§ˆë¬¸ìœ¼ë¡œ ì €ì¥ (ì§ˆë¬¸ì´ í¬í•¨ëœ ê²½ìš°)\n",
    "        if \"?\" in answer or \"ê¹Œìš”\" in answer or \"ë‚˜ìš”\" in answer:\n",
    "            self.last_question = answer\n",
    "        \n",
    "        # í† í° ì œí•œ ì´ˆê³¼ í™•ì¸ (ì‘ë‹µ í›„)\n",
    "        if self.token_count > self.MAX_TOKENS:\n",
    "            return answer, True  # ëŒ€í™” ì¢…ë£Œ ì‹ í˜¸\n",
    "        \n",
    "        return answer, False  # ëŒ€í™” ê³„ì†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db00d2f",
   "metadata": {},
   "source": [
    "# 8. ëŒ€í™” ê²°ê³¼ ë¶„ì„ ë° ìš”ì•½\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf080438",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def get_conversation_summary(self):\n",
    "        \"\"\"ëŒ€í™” ì¢…ë£Œ í›„ ì´ìƒí•œ ë‹µë³€ ìš”ì•½ ì œê³µ\"\"\"\n",
    "        if self.strange_response_count == 0:\n",
    "            return \"ğŸ‰ ëŒ€í™” ì¤‘ íŠ¹ë³„íˆ ì´ìƒí•œ ë‹µë³€ì€ ì—†ì—ˆìŠµë‹ˆë‹¤. ì¢‹ì€ ëŒ€í™”ì˜€ì–´ìš”!\"\n",
    "        \n",
    "        summary = f\"\\n{'='*50}\\n\"\n",
    "        summary += f\"ğŸ“Š ëŒ€í™” ì¢…ë£Œ - ë¶„ì„ ê²°ê³¼\\n\"\n",
    "        summary += f\"{'='*50}\\n\"\n",
    "        summary += f\"ğŸ” ì´ ì´ìƒí•œ ë‹µë³€ íšŸìˆ˜: {self.strange_response_count}íšŒ\\n\\n\"\n",
    "        \n",
    "        # ì‹¬ê°ë„ë³„ ë¶„ë¥˜\n",
    "        severity_counts = {\"mild\": 0, \"moderate\": 0, \"severe\": 0}\n",
    "        for response in self.strange_responses:\n",
    "            severity_counts[response.severity] += 1\n",
    "        \n",
    "        summary += f\"ğŸ“ˆ ì‹¬ê°ë„ë³„ ë¶„ë¥˜:\\n\"\n",
    "        summary += f\"  â€¢ ê²½ë¯¸ (Mild): {severity_counts['mild']}íšŒ\\n\"\n",
    "        summary += f\"  â€¢ ë³´í†µ (Moderate): {severity_counts['moderate']}íšŒ\\n\"\n",
    "        summary += f\"  â€¢ ì‹¬ê° (Severe): {severity_counts['severe']}íšŒ\\n\\n\"\n",
    "        \n",
    "        summary += f\"ğŸ“ ìƒì„¸ ê¸°ë¡:\\n\"\n",
    "        for i, response in enumerate(self.strange_responses, 1):\n",
    "            summary += f\"\\n{i}. [{response.severity.upper()}] {response.timestamp}\\n\"\n",
    "            summary += f\"   ì§ˆë¬¸: {response.question[:100]}{'...' if len(response.question) > 100 else ''}\\n\"\n",
    "            summary += f\"   ë‹µë³€: {response.answer[:100]}{'...' if len(response.answer) > 100 else ''}\\n\"\n",
    "        \n",
    "        # ê¶Œì¥ì‚¬í•­ ì¶”ê°€\n",
    "        if severity_counts['severe'] > 3:\n",
    "            summary += f\"\\nâš ï¸  ê¶Œì¥ì‚¬í•­: ì‹¬ê°í•œ ìˆ˜ì¤€ì˜ ì´ìƒ ë‹µë³€ì´ ë‹¤ìˆ˜ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤. ì „ë¬¸ì˜ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤.\\n\"\n",
    "        elif severity_counts['moderate'] > 5:\n",
    "            summary += f\"\\nğŸ’¡ ê¶Œì¥ì‚¬í•­: ì¤‘ê°„ ìˆ˜ì¤€ì˜ ì´ìƒ ë‹µë³€ì´ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤. ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ì´ í•„ìš”í•©ë‹ˆë‹¤.\\n\"\n",
    "        else:\n",
    "            summary += f\"\\nâœ… ëŒ€ë¶€ë¶„ ê²½ë¯¸í•œ ìˆ˜ì¤€ì˜ ë‹µë³€ìœ¼ë¡œ, ì •ìƒ ë²”ìœ„ ë‚´ë¡œ ë³´ì…ë‹ˆë‹¤.\\n\"\n",
    "        \n",
    "        summary += f\"{'='*50}\\n\"\n",
    "        \n",
    "        return summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe912917",
   "metadata": {},
   "source": [
    "9. ì¶”ì–µ ìŠ¤í† ë¦¬ ìƒì„±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b311fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def generate_story_from_conversation(self, image_path):\n",
    "        \"\"\"ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë…¸ì¸ë¶„ì˜ ê´€ì ì—ì„œ ìŠ¤í† ë¦¬ ìƒì„±\"\"\"\n",
    "        # ëŒ€í™” ë‚´ìš© ì •ë¦¬\n",
    "        conversation_text = \"\"\n",
    "        for turn in self.conversation_turns:\n",
    "            conversation_text += f\"ì§ˆë¬¸: {turn.question}\\në‹µë³€: {turn.answer}\\n\\n\"\n",
    "        \n",
    "        # ìŠ¤í† ë¦¬ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸\n",
    "        story_prompt = f\"\"\"\n",
    "ë‹¤ìŒì€ í•œ ì–´ë¥´ì‹ ì´ ì˜›ë‚  ì‚¬ì§„ì„ ë³´ë©° ë‚˜ëˆˆ ëŒ€í™”ì…ë‹ˆë‹¤:\n",
    "\n",
    "{conversation_text}\n",
    "\n",
    "ì´ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ì§„ ì† ìˆœê°„ì— ëŒ€í•œ ì–´ë¥´ì‹ ì˜ ì¶”ì–µì„ 1ì¸ì¹­ ì‹œì ìœ¼ë¡œ 10ì¤„ ì •ë„ì˜ ì§§ì€ ì´ì•¼ê¸°ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì‘ì„± ì§€ì¹¨:\n",
    "1. ì–´ë¥´ì‹ ì˜ ê°ì •ê³¼ ë‹¹ì‹œì˜ ëŠë‚Œì„ ìƒìƒí•˜ê²Œ í‘œí˜„\n",
    "2. êµ¬ì²´ì ì¸ ê°ê°ì  ë¬˜ì‚¬ í¬í•¨ (ì†Œë¦¬, ëƒ„ìƒˆ, ì´‰ê° ë“±)\n",
    "3. ë”°ëœ»í•˜ê³  í–¥ìˆ˜ë¥¼ ë¶ˆëŸ¬ì¼ìœ¼í‚¤ëŠ” í†¤\n",
    "4. ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ ë‚´ìš©ì„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨\n",
    "5. ë§ˆì¹˜ ì†ì/ì†ë…€ì—ê²Œ ë“¤ë ¤ì£¼ëŠ” ê²ƒì²˜ëŸ¼ ì¹œê·¼í•œ ì–´íˆ¬\n",
    "\n",
    "ìŠ¤í† ë¦¬ë§Œ ì‘ì„±í•˜ê³  ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.deployment,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ ë…¸ì¸ì˜ ì¶”ì–µì„ ì•„ë¦„ë‹µê²Œ ì¬êµ¬ì„±í•˜ëŠ” ìŠ¤í† ë¦¬í…”ëŸ¬ì…ë‹ˆë‹¤.\"},\n",
    "                    {\"role\": \"user\", \"content\": story_prompt}\n",
    "                ],\n",
    "                max_tokens=1024,\n",
    "                temperature=0.8,\n",
    "                top_p=1.0,\n",
    "            )\n",
    "            \n",
    "            story = response.choices[0].message.content\n",
    "            \n",
    "            # story_telling í´ë” ìƒì„±\n",
    "            story_dir = \"story_telling\"\n",
    "            os.makedirs(story_dir, exist_ok=True)\n",
    "            \n",
    "            # ì´ë¯¸ì§€ íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°í•˜ì—¬ ìŠ¤í† ë¦¬ íŒŒì¼ëª… ìƒì„±\n",
    "            image_basename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "            story_filename = os.path.join(story_dir, f\"{image_basename}.txt\")\n",
    "            \n",
    "            # ìŠ¤í† ë¦¬ íŒŒì¼ ì €ì¥\n",
    "            with open(story_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(story)\n",
    "            \n",
    "            print(f\"ì¶”ì–µ ì´ì•¼ê¸°ê°€ '{story_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "            \n",
    "            return story, story_filename\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"ìŠ¤í† ë¦¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            return None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35d5e5a",
   "metadata": {},
   "source": [
    "# 9. ì¶”ì–µ ìŠ¤í† ë¦¬ ìƒì„±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2661290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "10. ëŒ€í™” ë‚´ìš© ë° ë¶„ì„ ê²°ê³¼ íŒŒì¼ ì €ì¥\n",
    "\"\"\"\n",
    "    def save_conversation_to_file(self, filename_prefix=\"conversation\", image_path=None):\n",
    "        \"\"\"ëŒ€í™” ë‚´ìš©ì„ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # ì´ë¯¸ì§€ íŒŒì¼ëª… ì¶”ì¶œ (í™•ì¥ì ì œì™¸)\n",
    "        if image_path:\n",
    "            image_basename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "            base_filename = f\"{image_basename}_{timestamp}\"\n",
    "        else:\n",
    "            base_filename = f\"{filename_prefix}_{timestamp}\"\n",
    "        \n",
    "        # í´ë” ìƒì„± (ì—†ëŠ” ê²½ìš°)\n",
    "        conversation_dir = \"conversation_log\"\n",
    "        analysis_dir = \"analysis\"\n",
    "        os.makedirs(conversation_dir, exist_ok=True)\n",
    "        os.makedirs(analysis_dir, exist_ok=True)\n",
    "        \n",
    "        # ëŒ€í™” ê¸°ë¡ íŒŒì¼ ì €ì¥\n",
    "        conversation_filename = os.path.join(conversation_dir, f\"{base_filename}.txt\")\n",
    "        with open(conversation_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"=== ëŒ€í™” ê¸°ë¡ ===\\n\")\n",
    "            f.write(f\"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}\\n\")\n",
    "            f.write(f\"{'='*50}\\n\\n\")\n",
    "            \n",
    "            for i, turn in enumerate(self.conversation_turns, 1):\n",
    "                f.write(f\"[ëŒ€í™” {i}] {turn.timestamp}\\n\")\n",
    "                f.write(f\"ì§ˆë¬¸: {turn.question}\\n\")\n",
    "                f.write(f\"ë‹µë³€: {turn.answer}\\n\")\n",
    "                f.write(f\"{'-'*30}\\n\\n\")\n",
    "        \n",
    "        print(f\"ëŒ€í™” ê¸°ë¡ì´ '{conversation_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        # ì´ìƒ ë‹µë³€ ë¶„ì„ íŒŒì¼ ì €ì¥\n",
    "        analysis_filename = None\n",
    "        if self.strange_response_count > 0:\n",
    "            analysis_filename = os.path.join(analysis_dir, f\"{base_filename}_analysis.txt\")\n",
    "            with open(analysis_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(self.get_conversation_summary())\n",
    "            \n",
    "            print(f\"ì´ìƒ ë‹µë³€ ë¶„ì„ì´ '{analysis_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        return conversation_filename, analysis_filename\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44e0d93",
   "metadata": {},
   "source": [
    "# 11. í†µí•© ì‹¤í–‰ í•¨ìˆ˜\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2986de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_and_describe_image(image_path, user_description=\"\", user_description_date=\"\"):\n",
    "    \"\"\"ì´ë¯¸ì§€ ë¶„ì„ ë° ì„¤ëª… í†µí•© í•¨ìˆ˜\"\"\"\n",
    "    # 1. GPT-4o ì´ë¯¸ì§€ ë¶„ì„ ê°ì²´ ìƒì„±\n",
    "    analyzer = ImageAnalysisGPT()\n",
    "    \n",
    "    # 2. ì´ë¯¸ì§€ ë¶„ì„ ìˆ˜í–‰\n",
    "    print(f\"GPT-4oë¡œ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘: {image_path}\")\n",
    "    analysis_result = analyzer.analyze_image_with_gpt(image_path)\n",
    "    \n",
    "    if not analysis_result:\n",
    "        return \"ì´ë¯¸ì§€ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\", None, None\n",
    "    \n",
    "    # 3. LLM ëŒ€í™” ê°ì²´ ìƒì„±\n",
    "    llm_chat = LLMDescription()\n",
    "    \n",
    "    # 4. ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì„¤ì •\n",
    "    print(\"\\nëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì„¤ì • ì¤‘...\")\n",
    "    llm_chat.setup_conversation_context(\n",
    "        analysis_result, \n",
    "        user_description, \n",
    "        user_description_date\n",
    "    )\n",
    "    \n",
    "    # 5. ê²°ê³¼ ì¶œë ¥\n",
    "    print(\"\\n===== GPT-4o ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ =====\")\n",
    "    print(\"ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "    \n",
    "    return \"ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ\", llm_chat, image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41d1d6e",
   "metadata": {},
   "source": [
    "# 12. ë©”ì¸ ì‹¤í–‰ ì½”ë“œ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2de455",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'analyze_and_describe_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      8\u001b[39m     exit(\u001b[32m1\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# user_description_date = input(\"ì‚¬ì§„ì˜ ë‚ ì§œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (ì˜ˆ: 1980ë…„ëŒ€, 2000ë…„ ì—¬ë¦„): \")\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# user_description = input(\"ì‚¬ì§„ì— ëŒ€í•œ ì„¤ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”: \")  --> ë‘ë¶€ë¶„ë„ DBì—ì„œ ê°€ì ¸ì™€ì•¼í•¨\u001b[39;00m\n\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# ì´ë¯¸ì§€ ë¶„ì„ ë° ëŒ€í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m result, llm_chat, img_path = \u001b[43manalyze_and_describe_image\u001b[49m(\n\u001b[32m     15\u001b[39m     image_path\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# user_description, \u001b[39;00m\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# user_description_date\u001b[39;00m\n\u001b[32m     18\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m llm_chat:\n\u001b[32m     21\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m===== ì´ë¯¸ì§€ì— ê´€í•œ ëŒ€í™” ì‹œì‘ =====\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'analyze_and_describe_image' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ë¶„ì„í•  ì´ë¯¸ì§€ ê²½ë¡œ ì…ë ¥\n",
    "    image_path = \"images.jpg\"  # DBì—ì„œ ê°€ì ¸ì˜¨ ì´ë¯¸ì§€ ê²½ë¡œë¡œ ë³€ê²½ í•„ìš”\n",
    "    \n",
    "    # ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"ì˜¤ë¥˜: íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ - {image_path}\")\n",
    "        exit(1)\n",
    "    \n",
    "    # user_description_date = input(\"ì‚¬ì§„ì˜ ë‚ ì§œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (ì˜ˆ: 1980ë…„ëŒ€, 2000ë…„ ì—¬ë¦„): \")\n",
    "    # user_description = input(\"ì‚¬ì§„ì— ëŒ€í•œ ì„¤ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”: \")  --> ë‘ë¶€ë¶„ë„ DBì—ì„œ ê°€ì ¸ì™€ì•¼í•¨\n",
    "    \n",
    "    # ì´ë¯¸ì§€ ë¶„ì„ ë° ëŒ€í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "    result, llm_chat, img_path = analyze_and_describe_image(\n",
    "        image_path\n",
    "        # user_description, \n",
    "        # user_description_date\n",
    "    )\n",
    "    \n",
    "    if llm_chat:\n",
    "        print(\"\\n===== ì´ë¯¸ì§€ì— ê´€í•œ ëŒ€í™” ì‹œì‘ =====\")\n",
    "        \n",
    "        # GPTê°€ ë¨¼ì € ì§ˆë¬¸ ë˜ì§€ê¸°\n",
    "        initial_question = llm_chat.generate_initial_question()\n",
    "        print(f\"\\nAI: {initial_question}\")\n",
    "        \n",
    "        print(\"\\nğŸ’¡ ëŒ€í™”ë¥¼ ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'ì¢…ë£Œ'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\")\n",
    "        \n",
    "        while True:\n",
    "            user_query = input(\"\\në‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”: \")\n",
    "            \n",
    "            # ìˆ˜ë™ ì¢…ë£Œ ì¡°ê±´ í™•ì¸\n",
    "            if user_query.lower() in ['exit', 'ì¢…ë£Œ', 'quit', 'q']:\n",
    "                print(\"ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "                break\n",
    "            \n",
    "            # GPTì—ê²Œ ì‚¬ìš©ì ë‹µë³€ ì „ë‹¬ ë° í† í° ì œí•œ í™•ì¸\n",
    "            answer, should_end = llm_chat.chat_about_image(user_query)\n",
    "            print(f\"\\nAI: {answer}\")\n",
    "            \n",
    "            # í† í° ì œí•œìœ¼ë¡œ ì¸í•œ ì¢…ë£Œ í™•ì¸\n",
    "            if should_end:\n",
    "                print(\"\\nëŒ€í™” í† í° ì œí•œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "                break\n",
    "        \n",
    "        # ëŒ€í™” ì¢…ë£Œ í›„ íŒŒì¼ë¡œ ì €ì¥\n",
    "        llm_chat.save_conversation_to_file(image_path=img_path)\n",
    "        \n",
    "        # ì¶”ì–µ ìŠ¤í† ë¦¬ ìƒì„±\n",
    "        print(\"\\nì¶”ì–µ ì´ì•¼ê¸°ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘...\")\n",
    "        story, story_file = llm_chat.generate_story_from_conversation(img_path)\n",
    "        \n",
    "        if story:\n",
    "            print(f\"\\n=== ìƒì„±ëœ ì¶”ì–µ ì´ì•¼ê¸° ===\\n{story}\\n\")\n",
    "        \n",
    "        # ì½˜ì†”ì—ë„ ìš”ì•½ ì¶œë ¥\n",
    "        print(llm_chat.get_conversation_summary())\n",
    "        \n",
    "    else:\n",
    "        print(\"ì´ë¯¸ì§€ ë¶„ì„ì— ì‹¤íŒ¨í•˜ì—¬ ëŒ€í™”ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7525436d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
