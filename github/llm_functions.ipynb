{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f5bbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (1.72.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (0.9.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (1.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\blank\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai tiktoken python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a6eb31",
   "metadata": {},
   "source": [
    "\n",
    "# 실행 과정\n",
    "\n",
    "이 시스템은 다음과 같이 구성되어 있습니다:\n",
    "\n",
    "1. **ImageAnalysisGPT 클래스**\n",
    "   - GPT-4o를 사용하여 이미지 분석\n",
    "   - 이미지의 caption, mood, objects 등 추출\n",
    "\n",
    "2. **LLMDescription 클래스**\n",
    "   - 어르신과의 대화 관리\n",
    "   - 이상 답변 감지 및 평가\n",
    "   - 대화 내용 저장\n",
    "\n",
    "3. **생성되는 파일 구조**\n",
    "   ```\n",
    "   프로젝트 폴더/\n",
    "   ├── conversation_log/     # 질의응답 대화 기록\n",
    "   │   └── images_20250124_143022.txt\n",
    "   ├── analysis/            # 이상 답변 분석\n",
    "   │   └── images_20250124_143022_analysis.txt\n",
    "   └── story_telling/       # 추억 스토리\n",
    "       └── images.txt\n",
    "   ```\n",
    "\n",
    "4. **사용 방법**\n",
    "   ```python\n",
    "   # 이미지 경로 설정\n",
    "   image_path = \"your_image.jpg\"\n",
    "   \n",
    "   # 시스템 초기화 및 실행\n",
    "   result, llm_chat, img_path = analyze_and_describe_image(image_path)\n",
    "   ```\n",
    "\n",
    "5. **이상 답변 심각도 분류**\n",
    "   - mild: 약간 벗어났지만 이해 가능\n",
    "   - moderate: 상당히 엉뚱하지만 완전히 무관하지는 않음\n",
    "   - severe: 완전히 무관하거나 비논리적인 답변\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2e7d60",
   "metadata": {},
   "source": [
    "# 1. 환경 설정 및 라이브러리 임포트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36de4620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 1: 필요한 라이브러리 임포트 및 환경 설정\n",
    "\n",
    "import json\n",
    "import base64\n",
    "import os\n",
    "import tiktoken\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from datetime import datetime\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd65a71",
   "metadata": {},
   "source": [
    "# 2. 데이터 구조 정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198a1560",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class StrangeResponse:\n",
    "    \"\"\"이상한 답변을 저장하는 데이터 클래스\"\"\"\n",
    "    question: str\n",
    "    answer: str\n",
    "    timestamp: str\n",
    "    severity: str  # \"mild\", \"moderate\", \"severe\"\n",
    "\n",
    "@dataclass\n",
    "class ConversationTurn:\n",
    "    \"\"\"대화 턴을 저장하는 데이터 클래스\"\"\"\n",
    "    question: str\n",
    "    answer: str\n",
    "    timestamp: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b31d02",
   "metadata": {},
   "source": [
    "# 3. GPT-4o를 사용한 이미지 분석 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be770fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageAnalysisGPT:\n",
    "    \"\"\"GPT-4o를 사용한 이미지 분석 클래스\"\"\"\n",
    "    def __init__(self):\n",
    "        # Azure OpenAI 관련 설정\n",
    "        self.endpoint = os.getenv(\"gpt-endpoint\")\n",
    "        self.deployment = \"gpt-4o\"\n",
    "        self.subscription_key = os.getenv(\"gpt-key\")\n",
    "        self.api_version = \"2024-12-01-preview\"\n",
    "        \n",
    "        if not self.endpoint or not self.subscription_key:\n",
    "            raise ValueError(\"Please set the gpt-endpoint and gpt-key in the environment variables.\")\n",
    "        \n",
    "        # LLM 클라이언트 초기화\n",
    "        self.client = AzureOpenAI(\n",
    "            api_version=self.api_version,\n",
    "            azure_endpoint=self.endpoint,\n",
    "            api_key=self.subscription_key,\n",
    "        )\n",
    "    \n",
    "    def encode_image_to_base64(self, image_path):\n",
    "        \"\"\"이미지를 base64로 인코딩\"\"\"\n",
    "        try:\n",
    "            with open(image_path, \"rb\") as image_file:\n",
    "                return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: 이미지 파일을 찾을 수 없습니다: {image_path}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"이미지 인코딩 오류: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def analyze_image_with_gpt(self, image_path):\n",
    "        \"\"\"GPT-4o를 사용하여 이미지 분석\"\"\"\n",
    "        # 이미지를 base64로 인코딩\n",
    "        base64_image = self.encode_image_to_base64(image_path)\n",
    "        if not base64_image:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.deployment,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": \"\"\"이 이미지를 자세히 분석해서 다음 정보를 JSON 형식으로 제공해주세요:\n",
    "\n",
    "1. caption: 이미지의 전체적인 설명 (구체적으로 그리고 한편의 이야기처럼)\n",
    "2. dense_captions: 이미지의 세부적인 요소들을 여러 문장으로 설명 (배열 형태)\n",
    "3. mood: 이미지에서 느껴지는 분위기나 감정\n",
    "4. time_period: 추정되는 시대나 시기\n",
    "5. key_objects: 주요 객체들 (배열 형태)\n",
    "6. people_description: 사람이 있다면 그들에 대한 설명\n",
    "\n",
    "다음과 같은 JSON 형식으로 답해주세요:\n",
    "{\n",
    "    \"caption\": \"전체 이미지 설명\",\n",
    "    \"dense_captions\": [\"세부사항1\", \"세부사항2\", \"세부사항3\"],\n",
    "    \"mood\": \"분위기 설명\",\n",
    "    \"time_period\": \"추정 시대\",\n",
    "    \"key_objects\": [\"객체1\", \"객체2\", \"객체3\"],\n",
    "    \"people_description\": \"사람들에 대한 설명\"\n",
    "}\"\"\"\n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"image_url\",\n",
    "                                \"image_url\": {\n",
    "                                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                                }\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "                max_tokens=1000,\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            # 응답에서 JSON 추출\n",
    "            response_text = response.choices[0].message.content\n",
    "            \n",
    "            # JSON 부분만 추출 (```json으로 감싸져 있을 수 있음)\n",
    "            if \"```json\" in response_text:\n",
    "                json_start = response_text.find(\"```json\") + 7\n",
    "                json_end = response_text.find(\"```\", json_start)\n",
    "                response_text = response_text[json_start:json_end].strip()\n",
    "            elif \"{\" in response_text:\n",
    "                json_start = response_text.find(\"{\")\n",
    "                json_end = response_text.rfind(\"}\") + 1\n",
    "                response_text = response_text[json_start:json_end]\n",
    "            \n",
    "            analysis_result = json.loads(response_text)\n",
    "            \n",
    "            # 결과 출력\n",
    "            print(f\"\\nCaption: {analysis_result.get('caption', 'N/A')}\")\n",
    "            print(f\"Mood: {analysis_result.get('mood', 'N/A')}\")\n",
    "            print(f\"Time Period: {analysis_result.get('time_period', 'N/A')}\")\n",
    "            print(\"\\nDense Captions:\")\n",
    "            for caption in analysis_result.get('dense_captions', []):\n",
    "                print(f\"- {caption}\")\n",
    "            \n",
    "            return analysis_result\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON 파싱 오류: {e}\")\n",
    "            print(f\"원본 응답: {response_text}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"이미지 분석 오류: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9823bb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac6a5d32",
   "metadata": {},
   "source": [
    "# 4 / 5. LLM 대화 시스템 - 초기화 및 기본 설정 / 토큰 관리 및 답변 평가 기능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb504fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMDescription:\n",
    "    def __init__(self):\n",
    "        # Azure OpenAI 관련 설정\n",
    "        self.endpoint = os.getenv(\"gpt-endpoint\")\n",
    "        self.deployment = \"gpt-4o\"\n",
    "        self.subscription_key = os.getenv(\"gpt-key\")\n",
    "        self.api_version = \"2024-12-01-preview\"\n",
    "        \n",
    "        if not self.endpoint or not self.subscription_key:\n",
    "            raise ValueError(\"Please set the gpt-endpoint and gpt-key in the environment variables.\")\n",
    "        \n",
    "        # LLM 클라이언트 초기화\n",
    "        self.client = AzureOpenAI(\n",
    "            api_version=self.api_version,\n",
    "            azure_endpoint=self.endpoint,\n",
    "            api_key=self.subscription_key,\n",
    "        )\n",
    "        \n",
    "        # 대화 기록 초기화\n",
    "        self.conversation_history = []\n",
    "        \n",
    "        # 토큰 카운터 초기화\n",
    "        self.tokenizer = tiktoken.get_encoding(\"cl100k_base\")  # GPT-4o용 토크나이저\n",
    "        self.token_count = 0\n",
    "        self.MAX_TOKENS = 4000  # 최대 토큰 제한\n",
    "        \n",
    "        # 이상한 답변 추적\n",
    "        self.strange_responses = []\n",
    "        self.strange_response_count = 0\n",
    "        self.last_question = \"\"  # 마지막 질문 저장\n",
    "        \n",
    "        # 대화 기록 추적 (파일 저장용)\n",
    "        self.conversation_turns = []\n",
    "    def _count_tokens(self, text: str) -> int:\n",
    "        \"\"\"문자열의 토큰 수 계산\"\"\"\n",
    "        return len(self.tokenizer.encode(text))\n",
    "    \n",
    "    def _count_message_tokens(self, messages: List[Dict[str, Any]]) -> int:\n",
    "        \"\"\"대화 메시지 목록의 총 토큰 수 계산\"\"\"\n",
    "        total = 0\n",
    "        for message in messages:\n",
    "            total += self._count_tokens(message.get(\"content\", \"\"))\n",
    "        return total\n",
    "    \n",
    "    def _evaluate_response_relevance(self, question: str, answer: str) -> Dict[str, Any]:\n",
    "        \"\"\"답변이 질문과 얼마나 관련성이 있는지 LLM으로 평가\"\"\"\n",
    "        evaluation_prompt = f\"\"\"\n",
    "다음 질문과 답변을 분석해서 답변이 얼마나 적절한지 평가해주세요.\n",
    "\n",
    "질문: {question}\n",
    "답변: {answer}\n",
    "\n",
    "평가 기준:\n",
    "1. 질문과 답변의 관련성\n",
    "2. 답변의 일관성\n",
    "3. 맥락적 적절성\n",
    "\n",
    "다음 JSON 형식으로만 답해주세요:\n",
    "{{\n",
    "    \"is_strange\": true/false,\n",
    "    \"severity\": \"normal/mild/moderate/severe\",\n",
    "    \"reason\": \"평가 이유를 간단히 설명\"\n",
    "}}\n",
    "\n",
    "severity 기준:\n",
    "- normal: 완전히 적절한 답변\n",
    "- mild: 약간 벗어났지만 이해 가능\n",
    "- moderate: 상당히 엉뚱하지만 완전히 무관하지는 않음\n",
    "- severe: 완전히 무관하거나 비논리적인 답변\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.deployment,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"당신은 치매 환자의 답변을 평가하는 의료 전문가입니다. 객관적이고 정확하게 평가해주세요.\"},\n",
    "                    {\"role\": \"user\", \"content\": evaluation_prompt}\n",
    "                ],\n",
    "                max_tokens=256,\n",
    "                temperature=0.1,  # 일관된 평가를 위해 낮은 temperature\n",
    "                top_p=1.0,\n",
    "            )\n",
    "            \n",
    "            evaluation_text = response.choices[0].message.content\n",
    "            \n",
    "            # JSON 부분만 추출\n",
    "            if \"```json\" in evaluation_text:\n",
    "                json_start = evaluation_text.find(\"```json\") + 7\n",
    "                json_end = evaluation_text.find(\"```\", json_start)\n",
    "                evaluation_text = evaluation_text[json_start:json_end].strip()\n",
    "            elif \"{\" in evaluation_text:\n",
    "                json_start = evaluation_text.find(\"{\")\n",
    "                json_end = evaluation_text.rfind(\"}\") + 1\n",
    "                evaluation_text = evaluation_text[json_start:json_end]\n",
    "            \n",
    "            evaluation_json = json.loads(evaluation_text)\n",
    "            return evaluation_json\n",
    "            \n",
    "        except (json.JSONDecodeError, Exception) as e:\n",
    "            print(f\"답변 평가 중 오류 발생: {e}\")\n",
    "            # 기본값 반환\n",
    "            return {\n",
    "                \"is_strange\": False,\n",
    "                \"severity\": \"normal\",\n",
    "                \"reason\": \"평가 실패\"\n",
    "            }\n",
    "    \n",
    "    def _store_strange_response(self, question: str, answer: str, severity: str, reason: str):\n",
    "        \"\"\"이상한 답변을 저장 (콘솔 출력 제거)\"\"\"\n",
    "        strange_response = StrangeResponse(\n",
    "            question=question,\n",
    "            answer=answer,\n",
    "            timestamp=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            severity=severity\n",
    "        )\n",
    "        \n",
    "        self.strange_responses.append(strange_response)\n",
    "        self.strange_response_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ebcd7c",
   "metadata": {},
   "source": [
    "# 6. 대화 컨텍스트 설정 및 초기 질문 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cab0f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def setup_conversation_context(self, analysis_result, user_description=\"\", user_description_date=\"\"):\n",
    "        \"\"\"대화 컨텍스트 설정\"\"\"\n",
    "        caption = analysis_result.get(\"caption\", \"\")\n",
    "        dense_captions = analysis_result.get(\"dense_captions\", [])\n",
    "        mood = analysis_result.get(\"mood\", \"\")\n",
    "        time_period = analysis_result.get(\"time_period\", \"\")\n",
    "        key_objects = analysis_result.get(\"key_objects\", [])\n",
    "        people_description = analysis_result.get(\"people_description\", \"\")\n",
    "        \n",
    "        # 상세 캡션 텍스트 포맷팅\n",
    "        dense_captions_text = \"\\n\".join([f\"- {dc}\" for dc in dense_captions])\n",
    "        key_objects_text = \", \".join(key_objects)\n",
    "        \n",
    "        # 시스템 메시지 설정\n",
    "        system_message = f\"\"\"당신은 이미지에 대해 할머니 할아버지와 같이 어르신들과 대화하는 어시스턴트입니다. \n",
    "다음 이미지 정보를 바탕으로 사용자의 질문에 답변하세요:\n",
    "\n",
    "=== 이미지 분석 결과 ===\n",
    "주요 설명(Caption): {caption}\n",
    "분위기/감정: {mood}\n",
    "추정 시대: {time_period}\n",
    "주요 객체들: {key_objects_text}\n",
    "인물 설명: {people_description}\n",
    "\n",
    "세부 요소들:\n",
    "{dense_captions_text}\n",
    "\n",
    "=== 대화 가이드라인 ===\n",
    "1. 어르신들(특히 치매 환자)과 대화한다고 가정하고 친근하고 따뜻하게 대화하세요.\n",
    "2. 이미지에 대한 흥미로운 질문을 먼저 던져 대화를 시작하세요.\n",
    "3. 사용자가 엉뚱한 답변을 해도 자연스럽게 이어가며 친절하게 이끌어주세요.\n",
    "4. 그때 당시의 감정이나 경험에 대해 물어보며 추억을 되살려주세요.\n",
    "\n",
    "=== 대화 전략 ===\n",
    "문제 상황별 해결 방법:\n",
    "\n",
    "▪ 질문을 이해하지 못할 경우:\n",
    "  - 질문을 단순화하여 재구성\n",
    "  - 선택지를 제공하여 답하기 쉽게 만들기\n",
    "  - 예시나 맥락을 함께 제공\n",
    "\n",
    "▪ 엉뚱한 대답을 할 경우:\n",
    "  - 대답을 수용하면서 자연스럽게 주제로 유도\n",
    "  - 대답의 일부분이라도 연결점을 찾아 이어가기\n",
    "\n",
    "▪ 대답을 못할 경우:\n",
    "  - 심리적 부담 없이 넘어가기\n",
    "  - \"기억이 안 나셔도 괜찮다\"고 안심시키기\n",
    "\n",
    "이미지의 시각적 요소들을 생생하게 묘사하며, 그때의 감정과 상황에 대해 궁금해하는 손자/손녀의 마음으로 대화하세요.\"\"\"\n",
    "        \n",
    "        # 대화 기록 초기화 및 토큰 수 계산\n",
    "        self.conversation_history = [{\"role\": \"system\", \"content\": system_message}]\n",
    "        self.token_count = self._count_tokens(system_message)\n",
    "        \n",
    "        return system_message\n",
    "    \n",
    "    def generate_initial_question(self):\n",
    "        \"\"\"첫 질문 생성 함수\"\"\"\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.deployment,\n",
    "            messages=self.conversation_history + [\n",
    "                {\"role\": \"user\", \"content\": \"이 옛날 사진에 대해 어르신에게 물어볼 첫 질문을 만들어주세요. 간단하고 기억하기 쉬우며, 감정적으로 연결될 수 있는 질문이어야 합니다.\"}\n",
    "            ],\n",
    "            max_tokens=512,\n",
    "            temperature=0.8,\n",
    "            top_p=1.0,\n",
    "        )\n",
    "        \n",
    "        initial_question = response.choices[0].message.content\n",
    "        \n",
    "        # 질문 추가 및 토큰 수 업데이트\n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": initial_question})\n",
    "        self.token_count += self._count_tokens(initial_question)\n",
    "        \n",
    "        # 마지막 질문 저장\n",
    "        self.last_question = initial_question\n",
    "        \n",
    "        return initial_question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880396f6",
   "metadata": {},
   "source": [
    "# 7. 대화 처리 및 응답 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e55843",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def chat_about_image(self, user_query):\n",
    "        \"\"\"사용자 질문에 대한 응답 생성\"\"\"\n",
    "        # 토큰 제한 확인\n",
    "        user_tokens = self._count_tokens(user_query)\n",
    "        \n",
    "        # 사용자 답변의 적절성 평가 (이전 질문이 있는 경우)\n",
    "        if self.last_question:\n",
    "            evaluation = self._evaluate_response_relevance(self.last_question, user_query)\n",
    "            \n",
    "            if evaluation.get(\"is_strange\", False):\n",
    "                severity = evaluation.get(\"severity\", \"mild\")\n",
    "                reason = evaluation.get(\"reason\", \"관련성 부족\")\n",
    "                \n",
    "                # 이상한 답변 저장\n",
    "                self._store_strange_response(\n",
    "                    question=self.last_question,\n",
    "                    answer=user_query,\n",
    "                    severity=severity,\n",
    "                    reason=reason\n",
    "                )\n",
    "        \n",
    "        # 대화 턴 저장 (질문-답변 쌍)\n",
    "        if self.last_question:\n",
    "            conversation_turn = ConversationTurn(\n",
    "                question=self.last_question,\n",
    "                answer=user_query,\n",
    "                timestamp=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            )\n",
    "            self.conversation_turns.append(conversation_turn)\n",
    "        \n",
    "        # 사용자 입력 추가\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": user_query})\n",
    "        self.token_count += user_tokens\n",
    "        \n",
    "        # 토큰 제한 초과 확인\n",
    "        if self.token_count > self.MAX_TOKENS:\n",
    "            answer = \"죄송합니다, 나중에 다시 얘기해요. 지금은 잠시 쉬어야 할 것 같아요. 만약 더 많은 대화를 원한다면 MEMENTO BOX Premium을 사용해보세요.\"\n",
    "            self.conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "            return answer, True  # True는 대화 종료 신호\n",
    "        \n",
    "        # LLM 응답 생성\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.deployment,\n",
    "            messages=self.conversation_history,\n",
    "            max_tokens=1024,\n",
    "            temperature=0.7,\n",
    "            top_p=1.0,\n",
    "        )\n",
    "        \n",
    "        # 응답 추출\n",
    "        answer = response.choices[0].message.content\n",
    "        \n",
    "        # 응답 추가 및 토큰 수 업데이트\n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "        self.token_count += self._count_tokens(answer)\n",
    "        \n",
    "        # 다음 평가를 위해 현재 AI 응답을 질문으로 저장 (질문이 포함된 경우)\n",
    "        if \"?\" in answer or \"까요\" in answer or \"나요\" in answer:\n",
    "            self.last_question = answer\n",
    "        \n",
    "        # 토큰 제한 초과 확인 (응답 후)\n",
    "        if self.token_count > self.MAX_TOKENS:\n",
    "            return answer, True  # 대화 종료 신호\n",
    "        \n",
    "        return answer, False  # 대화 계속"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db00d2f",
   "metadata": {},
   "source": [
    "# 8. 대화 결과 분석 및 요약\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf080438",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def get_conversation_summary(self):\n",
    "        \"\"\"대화 종료 후 이상한 답변 요약 제공\"\"\"\n",
    "        if self.strange_response_count == 0:\n",
    "            return \"🎉 대화 중 특별히 이상한 답변은 없었습니다. 좋은 대화였어요!\"\n",
    "        \n",
    "        summary = f\"\\n{'='*50}\\n\"\n",
    "        summary += f\"📊 대화 종료 - 분석 결과\\n\"\n",
    "        summary += f\"{'='*50}\\n\"\n",
    "        summary += f\"🔍 총 이상한 답변 횟수: {self.strange_response_count}회\\n\\n\"\n",
    "        \n",
    "        # 심각도별 분류\n",
    "        severity_counts = {\"mild\": 0, \"moderate\": 0, \"severe\": 0}\n",
    "        for response in self.strange_responses:\n",
    "            severity_counts[response.severity] += 1\n",
    "        \n",
    "        summary += f\"📈 심각도별 분류:\\n\"\n",
    "        summary += f\"  • 경미 (Mild): {severity_counts['mild']}회\\n\"\n",
    "        summary += f\"  • 보통 (Moderate): {severity_counts['moderate']}회\\n\"\n",
    "        summary += f\"  • 심각 (Severe): {severity_counts['severe']}회\\n\\n\"\n",
    "        \n",
    "        summary += f\"📝 상세 기록:\\n\"\n",
    "        for i, response in enumerate(self.strange_responses, 1):\n",
    "            summary += f\"\\n{i}. [{response.severity.upper()}] {response.timestamp}\\n\"\n",
    "            summary += f\"   질문: {response.question[:100]}{'...' if len(response.question) > 100 else ''}\\n\"\n",
    "            summary += f\"   답변: {response.answer[:100]}{'...' if len(response.answer) > 100 else ''}\\n\"\n",
    "        \n",
    "        # 권장사항 추가\n",
    "        if severity_counts['severe'] > 3:\n",
    "            summary += f\"\\n⚠️  권장사항: 심각한 수준의 이상 답변이 다수 관찰되었습니다. 전문의 상담을 권장합니다.\\n\"\n",
    "        elif severity_counts['moderate'] > 5:\n",
    "            summary += f\"\\n💡 권장사항: 중간 수준의 이상 답변이 관찰되었습니다. 지속적인 모니터링이 필요합니다.\\n\"\n",
    "        else:\n",
    "            summary += f\"\\n✅ 대부분 경미한 수준의 답변으로, 정상 범위 내로 보입니다.\\n\"\n",
    "        \n",
    "        summary += f\"{'='*50}\\n\"\n",
    "        \n",
    "        return summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe912917",
   "metadata": {},
   "source": [
    "9. 추억 스토리 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b311fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def generate_story_from_conversation(self, image_path):\n",
    "        \"\"\"대화 내용을 바탕으로 노인분의 관점에서 스토리 생성\"\"\"\n",
    "        # 대화 내용 정리\n",
    "        conversation_text = \"\"\n",
    "        for turn in self.conversation_turns:\n",
    "            conversation_text += f\"질문: {turn.question}\\n답변: {turn.answer}\\n\\n\"\n",
    "        \n",
    "        # 스토리 생성을 위한 프롬프트\n",
    "        story_prompt = f\"\"\"\n",
    "다음은 한 어르신이 옛날 사진을 보며 나눈 대화입니다:\n",
    "\n",
    "{conversation_text}\n",
    "\n",
    "이 대화 내용을 바탕으로, 사진 속 순간에 대한 어르신의 추억을 1인칭 시점으로 10줄 정도의 짧은 이야기로 작성해주세요.\n",
    "\n",
    "작성 지침:\n",
    "1. 어르신의 감정과 당시의 느낌을 생생하게 표현\n",
    "2. 구체적인 감각적 묘사 포함 (소리, 냄새, 촉감 등)\n",
    "3. 따뜻하고 향수를 불러일으키는 톤\n",
    "4. 대화에서 언급된 내용을 자연스럽게 포함\n",
    "5. 마치 손자/손녀에게 들려주는 것처럼 친근한 어투\n",
    "\n",
    "스토리만 작성하고 다른 설명은 하지 마세요.\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.deployment,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"당신은 노인의 추억을 아름답게 재구성하는 스토리텔러입니다.\"},\n",
    "                    {\"role\": \"user\", \"content\": story_prompt}\n",
    "                ],\n",
    "                max_tokens=1024,\n",
    "                temperature=0.8,\n",
    "                top_p=1.0,\n",
    "            )\n",
    "            \n",
    "            story = response.choices[0].message.content\n",
    "            \n",
    "            # story_telling 폴더 생성\n",
    "            story_dir = \"story_telling\"\n",
    "            os.makedirs(story_dir, exist_ok=True)\n",
    "            \n",
    "            # 이미지 파일명에서 확장자 제거하여 스토리 파일명 생성\n",
    "            image_basename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "            story_filename = os.path.join(story_dir, f\"{image_basename}.txt\")\n",
    "            \n",
    "            # 스토리 파일 저장\n",
    "            with open(story_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(story)\n",
    "            \n",
    "            print(f\"추억 이야기가 '{story_filename}' 파일로 저장되었습니다.\")\n",
    "            \n",
    "            return story, story_filename\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"스토리 생성 중 오류 발생: {e}\")\n",
    "            return None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35d5e5a",
   "metadata": {},
   "source": [
    "# 9. 추억 스토리 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2661290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "10. 대화 내용 및 분석 결과 파일 저장\n",
    "\"\"\"\n",
    "    def save_conversation_to_file(self, filename_prefix=\"conversation\", image_path=None):\n",
    "        \"\"\"대화 내용을 텍스트 파일로 저장\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # 이미지 파일명 추출 (확장자 제외)\n",
    "        if image_path:\n",
    "            image_basename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "            base_filename = f\"{image_basename}_{timestamp}\"\n",
    "        else:\n",
    "            base_filename = f\"{filename_prefix}_{timestamp}\"\n",
    "        \n",
    "        # 폴더 생성 (없는 경우)\n",
    "        conversation_dir = \"conversation_log\"\n",
    "        analysis_dir = \"analysis\"\n",
    "        os.makedirs(conversation_dir, exist_ok=True)\n",
    "        os.makedirs(analysis_dir, exist_ok=True)\n",
    "        \n",
    "        # 대화 기록 파일 저장\n",
    "        conversation_filename = os.path.join(conversation_dir, f\"{base_filename}.txt\")\n",
    "        with open(conversation_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"=== 대화 기록 ===\\n\")\n",
    "            f.write(f\"생성 시간: {datetime.now().strftime('%Y년 %m월 %d일 %H:%M:%S')}\\n\")\n",
    "            f.write(f\"{'='*50}\\n\\n\")\n",
    "            \n",
    "            for i, turn in enumerate(self.conversation_turns, 1):\n",
    "                f.write(f\"[대화 {i}] {turn.timestamp}\\n\")\n",
    "                f.write(f\"질문: {turn.question}\\n\")\n",
    "                f.write(f\"답변: {turn.answer}\\n\")\n",
    "                f.write(f\"{'-'*30}\\n\\n\")\n",
    "        \n",
    "        print(f\"대화 기록이 '{conversation_filename}' 파일로 저장되었습니다.\")\n",
    "        \n",
    "        # 이상 답변 분석 파일 저장\n",
    "        analysis_filename = None\n",
    "        if self.strange_response_count > 0:\n",
    "            analysis_filename = os.path.join(analysis_dir, f\"{base_filename}_analysis.txt\")\n",
    "            with open(analysis_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(self.get_conversation_summary())\n",
    "            \n",
    "            print(f\"이상 답변 분석이 '{analysis_filename}' 파일로 저장되었습니다.\")\n",
    "        \n",
    "        return conversation_filename, analysis_filename\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44e0d93",
   "metadata": {},
   "source": [
    "# 11. 통합 실행 함수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2986de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_and_describe_image(image_path, user_description=\"\", user_description_date=\"\"):\n",
    "    \"\"\"이미지 분석 및 설명 통합 함수\"\"\"\n",
    "    # 1. GPT-4o 이미지 분석 객체 생성\n",
    "    analyzer = ImageAnalysisGPT()\n",
    "    \n",
    "    # 2. 이미지 분석 수행\n",
    "    print(f\"GPT-4o로 이미지 분석 중: {image_path}\")\n",
    "    analysis_result = analyzer.analyze_image_with_gpt(image_path)\n",
    "    \n",
    "    if not analysis_result:\n",
    "        return \"이미지 분석에 실패했습니다.\", None, None\n",
    "    \n",
    "    # 3. LLM 대화 객체 생성\n",
    "    llm_chat = LLMDescription()\n",
    "    \n",
    "    # 4. 대화 컨텍스트 설정\n",
    "    print(\"\\n대화 컨텍스트 설정 중...\")\n",
    "    llm_chat.setup_conversation_context(\n",
    "        analysis_result, \n",
    "        user_description, \n",
    "        user_description_date\n",
    "    )\n",
    "    \n",
    "    # 5. 결과 출력\n",
    "    print(\"\\n===== GPT-4o 이미지 분석 완료 =====\")\n",
    "    print(\"시스템이 준비되었습니다. 대화를 시작합니다.\")\n",
    "    \n",
    "    return \"시스템 준비 완료\", llm_chat, image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41d1d6e",
   "metadata": {},
   "source": [
    "# 12. 메인 실행 코드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2de455",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'analyze_and_describe_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      8\u001b[39m     exit(\u001b[32m1\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# user_description_date = input(\"사진의 날짜를 입력해주세요 (예: 1980년대, 2000년 여름): \")\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# user_description = input(\"사진에 대한 설명을 입력해주세요: \")  --> 두부분도 DB에서 가져와야함\u001b[39;00m\n\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# 이미지 분석 및 대화 시스템 초기화\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m result, llm_chat, img_path = \u001b[43manalyze_and_describe_image\u001b[49m(\n\u001b[32m     15\u001b[39m     image_path\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# user_description, \u001b[39;00m\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# user_description_date\u001b[39;00m\n\u001b[32m     18\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m llm_chat:\n\u001b[32m     21\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m===== 이미지에 관한 대화 시작 =====\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'analyze_and_describe_image' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 분석할 이미지 경로 입력\n",
    "    image_path = \"images.jpg\"  # DB에서 가져온 이미지 경로로 변경 필요\n",
    "    \n",
    "    # 이미지 파일 존재 확인\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"오류: 파일이 존재하지 않습니다 - {image_path}\")\n",
    "        exit(1)\n",
    "    \n",
    "    # user_description_date = input(\"사진의 날짜를 입력해주세요 (예: 1980년대, 2000년 여름): \")\n",
    "    # user_description = input(\"사진에 대한 설명을 입력해주세요: \")  --> 두부분도 DB에서 가져와야함\n",
    "    \n",
    "    # 이미지 분석 및 대화 시스템 초기화\n",
    "    result, llm_chat, img_path = analyze_and_describe_image(\n",
    "        image_path\n",
    "        # user_description, \n",
    "        # user_description_date\n",
    "    )\n",
    "    \n",
    "    if llm_chat:\n",
    "        print(\"\\n===== 이미지에 관한 대화 시작 =====\")\n",
    "        \n",
    "        # GPT가 먼저 질문 던지기\n",
    "        initial_question = llm_chat.generate_initial_question()\n",
    "        print(f\"\\nAI: {initial_question}\")\n",
    "        \n",
    "        print(\"\\n💡 대화를 종료하려면 'exit' 또는 '종료'를 입력하세요.\")\n",
    "        \n",
    "        while True:\n",
    "            user_query = input(\"\\n답변을 입력하세요: \")\n",
    "            \n",
    "            # 수동 종료 조건 확인\n",
    "            if user_query.lower() in ['exit', '종료', 'quit', 'q']:\n",
    "                print(\"대화를 종료합니다.\")\n",
    "                break\n",
    "            \n",
    "            # GPT에게 사용자 답변 전달 및 토큰 제한 확인\n",
    "            answer, should_end = llm_chat.chat_about_image(user_query)\n",
    "            print(f\"\\nAI: {answer}\")\n",
    "            \n",
    "            # 토큰 제한으로 인한 종료 확인\n",
    "            if should_end:\n",
    "                print(\"\\n대화 토큰 제한에 도달했습니다. 대화를 종료합니다.\")\n",
    "                break\n",
    "        \n",
    "        # 대화 종료 후 파일로 저장\n",
    "        llm_chat.save_conversation_to_file(image_path=img_path)\n",
    "        \n",
    "        # 추억 스토리 생성\n",
    "        print(\"\\n추억 이야기를 생성하는 중...\")\n",
    "        story, story_file = llm_chat.generate_story_from_conversation(img_path)\n",
    "        \n",
    "        if story:\n",
    "            print(f\"\\n=== 생성된 추억 이야기 ===\\n{story}\\n\")\n",
    "        \n",
    "        # 콘솔에도 요약 출력\n",
    "        print(llm_chat.get_conversation_summary())\n",
    "        \n",
    "    else:\n",
    "        print(\"이미지 분석에 실패하여 대화를 시작할 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7525436d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
