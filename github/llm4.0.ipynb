{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "152a5597",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pygame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcognitiveservices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspeech\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspeechsdk\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpygame\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pygame'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import base64\n",
    "import os\n",
    "import tiktoken\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import requests\n",
    "import pygame\n",
    "import time\n",
    "from pathlib import Path\n",
    "import threading\n",
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba48284",
   "metadata": {},
   "source": [
    "# Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab6e4545",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class StrangeResponse:\n",
    "    \"\"\"ì´ìƒí•œ ë‹µë³€ì„ ì €ì¥í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤\"\"\"\n",
    "    question: str\n",
    "    answer: str\n",
    "    timestamp: str\n",
    "    severity: str  # \"mild\", \"moderate\", \"severe\"\n",
    "    emotion: str = \"ì¤‘ë¦½\"\n",
    "    answer_quality: str = \"normal\"\n",
    "\n",
    "@dataclass\n",
    "class ConversationTurn:\n",
    "    \"\"\"ëŒ€í™” í„´ì„ ì €ì¥í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤\"\"\"\n",
    "    question: str\n",
    "    answer: str\n",
    "    timestamp: str\n",
    "    emotion: str = \"ì¤‘ë¦½\"\n",
    "    answer_length: int = 0\n",
    "    answer_quality: str = \"normal\"\n",
    "    audio_file: str = \"\"  # ìŒì„± íŒŒì¼ ê²½ë¡œ ì¶”ê°€\n",
    "\n",
    "class Config:\n",
    "    \"\"\"ì‹œìŠ¤í…œ ì„¤ì •\"\"\"\n",
    "    # Azure OpenAI ì„¤ì •\n",
    "    ENDPOINT = os.getenv(\"gpt-endpoint\")\n",
    "    DEPLOYMENT = \"gpt-4o\"\n",
    "    SUBSCRIPTION_KEY = os.getenv(\"gpt-key\")\n",
    "    API_VERSION = \"2024-02-15-preview\"\n",
    "    \n",
    "    # Azure Speech ì„¤ì •\n",
    "    SPEECH_KEY = os.getenv(\"speech-key\")\n",
    "    SPEECH_REGION = \"eastus\"\n",
    "    \n",
    "    # í† í° ì œí•œ\n",
    "    MAX_TOKENS = 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ba9d25",
   "metadata": {},
   "source": [
    "# Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f29116f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAnalyzer:\n",
    "    \"\"\"GPT-4oë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë¶„ì„\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = AzureOpenAI(\n",
    "            api_version=Config.API_VERSION,\n",
    "            azure_endpoint=Config.ENDPOINT,\n",
    "            api_key=Config.SUBSCRIPTION_KEY,\n",
    "        )\n",
    "    \n",
    "    def analyze_image(self, image_path):\n",
    "        \"\"\"ì´ë¯¸ì§€ ë¶„ì„\"\"\"\n",
    "        try:\n",
    "            with open(image_path, \"rb\") as image_file:\n",
    "                base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        except Exception:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=Config.DEPLOYMENT,\n",
    "                messages=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [{\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"\"\"ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì„œ JSONìœ¼ë¡œ ë‹µí•´ì£¼ì„¸ìš”:\n",
    "{\n",
    "    \"caption\": \"ì „ì²´ ì„¤ëª…\",\n",
    "    \"dense_captions\": [\"ì„¸ë¶€ ì„¤ëª…1\", \"ì„¸ë¶€ ì„¤ëª…2\"],\n",
    "    \"mood\": \"ë¶„ìœ„ê¸°\",\n",
    "    \"time_period\": \"ì‹œëŒ€\",\n",
    "    \"key_objects\": [\"ê°ì²´1\", \"ê°ì²´2\"],\n",
    "    \"people_description\": \"ì¸ë¬¼ ì„¤ëª…\",\n",
    "    \"people_count\": ìˆ«ì,\n",
    "    \"time_of_day\": \"ì‹œê°„ëŒ€\"\n",
    "}\"\"\"\n",
    "                    }, {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "                    }]\n",
    "                }],\n",
    "                max_tokens=1000,\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            response_text = response.choices[0].message.content\n",
    "            \n",
    "            # JSON ì¶”ì¶œ\n",
    "            if \"```json\" in response_text:\n",
    "                json_start = response_text.find(\"```json\") + 7\n",
    "                json_end = response_text.find(\"```\", json_start)\n",
    "                response_text = response_text[json_start:json_end].strip()\n",
    "            elif \"{\" in response_text:\n",
    "                json_start = response_text.find(\"{\")\n",
    "                json_end = response_text.rfind(\"}\") + 1\n",
    "                response_text = response_text[json_start:json_end]\n",
    "            \n",
    "            return json.loads(response_text)\n",
    "            \n",
    "        except Exception:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbc34f5",
   "metadata": {},
   "source": [
    "# Chat System\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8666b97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatSystem:\n",
    "    \"\"\"ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ í†µí•© ì±„íŒ… ì‹œìŠ¤í…œ - í† í° íš¨ìœ¨ ê°œì„ \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = AzureOpenAI(\n",
    "            api_version=Config.API_VERSION,\n",
    "            azure_endpoint=Config.ENDPOINT,\n",
    "            api_key=Config.SUBSCRIPTION_KEY,\n",
    "        )\n",
    "        \n",
    "        self.conversation_history = []\n",
    "        self.tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        self.token_count = 0\n",
    "        self.MAX_TOKENS = Config.MAX_TOKENS\n",
    "        self.conversation_turns = []\n",
    "        self.last_question = \"\"\n",
    "        \n",
    "        # ìŒì„± ë…¹ìŒ ê´€ë ¨ ì„¤ì •\n",
    "        self.recording = False\n",
    "        self.audio_thread = None\n",
    "        self.audio_data = []\n",
    "        self.sample_rate = 44100\n",
    "        \n",
    "        # ìŒì„± íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "        self.audio_dir = Path(\"audio_records\")\n",
    "        self.audio_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    def start_recording(self):\n",
    "        \"\"\"ìŒì„± ë…¹ìŒ ì‹œì‘\"\"\"\n",
    "        if self.recording:\n",
    "            return\n",
    "        \n",
    "        self.recording = True\n",
    "        self.audio_data = []\n",
    "        \n",
    "        def audio_callback(indata, frames, time, status):\n",
    "            if status:\n",
    "                print(f\"Status: {status}\")\n",
    "            if self.recording:\n",
    "                self.audio_data.append(indata.copy())\n",
    "        \n",
    "        self.audio_thread = sd.InputStream(\n",
    "            samplerate=self.sample_rate,\n",
    "            channels=1,\n",
    "            callback=audio_callback\n",
    "        )\n",
    "        self.audio_thread.start()\n",
    "    \n",
    "    def stop_recording(self):\n",
    "        \"\"\"ìŒì„± ë…¹ìŒ ì¤‘ì§€ ë° íŒŒì¼ ì €ì¥\"\"\"\n",
    "        if not self.recording:\n",
    "            return None\n",
    "        \n",
    "        self.recording = False\n",
    "        if self.audio_thread:\n",
    "            self.audio_thread.stop()\n",
    "            self.audio_thread.close()\n",
    "            self.audio_thread = None\n",
    "        \n",
    "        if not self.audio_data:\n",
    "            return None\n",
    "        \n",
    "        # ë…¹ìŒëœ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ ë°°ì—´ë¡œ í•©ì¹˜ê¸°\n",
    "        audio_data = np.concatenate(self.audio_data, axis=0)\n",
    "        \n",
    "        # íŒŒì¼ëª… ìƒì„± (timestamp ì‚¬ìš©)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = self.audio_dir / f\"record_{timestamp}.wav\"\n",
    "        \n",
    "        # WAV íŒŒì¼ë¡œ ì €ì¥\n",
    "        sf.write(filename, audio_data, self.sample_rate)\n",
    "        \n",
    "        return str(filename)\n",
    "        \n",
    "    def setup_conversation_context(self, analysis_result):\n",
    "        \"\"\"ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì„¤ì •\"\"\"\n",
    "        caption = analysis_result.get(\"caption\", \"\")\n",
    "        dense_captions = analysis_result.get(\"dense_captions\", [])\n",
    "        mood = analysis_result.get(\"mood\", \"\")\n",
    "        time_period = analysis_result.get(\"time_period\", \"\")\n",
    "        key_objects = analysis_result.get(\"key_objects\", [])\n",
    "        people_description = analysis_result.get(\"people_description\", \"\")\n",
    "        people_count = analysis_result.get(\"people_count\", 0)\n",
    "        time_of_day = analysis_result.get(\"time_of_day\", \"\")\n",
    "        \n",
    "        dense_captions_text = \"\\n\".join([f\"- {dc}\" for dc in dense_captions])\n",
    "        key_objects_text = \", \".join(key_objects)\n",
    "        \n",
    "        system_message = f\"\"\"ë„ˆëŠ” ë…¸ì¸ê³¼ ëŒ€í™”í•˜ëŠ” ìš”ì–‘ë³´í˜¸ì‚¬ì•¼. ë…¸ì¸ê³¼ íŠ¹ì • ì´ë¯¸ì§€ì— ëŒ€í•´ì„œ ì§ˆì˜ì‘ë‹µì„ ì£¼ê³ ë°›ì•„. \n",
    "ë…¸ì¸ì€ ì¹˜ë§¤ ì¦ìƒì´ ê°‘ìê¸° ë‚˜íƒ€ë‚  ìˆ˜ë„ ìˆì–´. ë°˜ë³µë˜ëŠ” ë§ì—ë„ ë˜‘ê°™ì´ ëŒ€ë‹µí•´ì¤˜ì•¼ í•´. \n",
    "ì¹œì ˆí•˜ê³  ì–´ë¥¸ì„ ê³µê²½í•˜ëŠ” ë§íˆ¬ì—¬ì•¼ í•´. ê·¸ë¦¬ê³  ê³µê°ì„ ì˜ í•´ì•¼ í•´. ì˜ˆì˜ë„ ì§€ì¼œ. \n",
    "ë„ˆëŠ” ì£¼ë¡œ ì§ˆë¬¸ì„ í•˜ëŠ” ìª½ì´ê³ , ë…¸ì¸ì€ ëŒ€ë‹µì„ í•´ì¤„ê±°ì•¼. ëŒ€ë‹µì— ëŒ€í•œ ë¦¬ì•¡ì…˜ê³¼ í•¨ê»˜ ì ì ˆíˆ ëŒ€í™”ë¥¼ ì´ì–´ ê°€.\n",
    "ë…¸ì¸ì˜ ë°œì–¸ì´ ëë‚˜ë©´ ê·¸ì™€ ê´€ë ¨ëœ ê³µê° ë¬¸ì¥ì„ ë¨¼ì € ë§í•œ í›„, ìì—°ìŠ¤ëŸ½ê²Œ ê·¸ ê¸°ì–µì— ëŒ€í•´ ë” ë¬¼ì–´ë³´ëŠ” ê¼¬ë¦¬ ì§ˆë¬¸ì„ ë§ë¶™ì—¬. í•˜ì§€ë§Œ ë©”ì¸ ì£¼ì œëŠ” ì£¼ì–´ì§„ ì´ë¯¸ì§€ ì •ë³´ì— ëŒ€í•´ ì–´ë¥´ì‹ ê»˜ ëŒ€í™” ë¬¸ë§¥ì— ë§ì¶° ìì—°ìŠ¤ëŸ½ê²Œ ì§ˆë¬¸í•˜ëŠ” ê±°ì•¼.\n",
    "\n",
    "=== ì´ë¯¸ì§€ ì •ë³´ ===\n",
    "ì£¼ìš” ì„¤ëª…: {caption}\n",
    "ë¶„ìœ„ê¸°/ê°ì •: {mood}\n",
    "ì¶”ì • ì‹œëŒ€: {time_period}\n",
    "ì‹œê°„ëŒ€: {time_of_day}\n",
    "ì¸ì› ìˆ˜: {people_count}ëª…\n",
    "ì£¼ìš” ê°ì²´ë“¤: {key_objects_text}\n",
    "ì¸ë¬¼ ì„¤ëª…: {people_description}\n",
    "\n",
    "ì„¸ë¶€ ìš”ì†Œë“¤:\n",
    "{dense_captions_text}\n",
    "\n",
    "=== ëŒ€í™” ì›ì¹™ ===\n",
    "ê°„ê²°í•˜ê²Œ: 50ì ì´ë‚´ë¡œ ì§ˆë¬¸í•˜ê¸°\n",
    "ì‚¬ì§„: ëŒ€í™”ë„ ëŒ€í™”ì§€ë§Œ ì‚¬ì§„ì— ëŒ€í•œ ì£¼ì œì—ì„œ ë²—ì•„ë‚˜ì§„ ë§ì•„ì¤˜\n",
    "ì‹¬ë„ìˆëŠ”: ì‚¬ëŒê³¼ ê¹Šê³  ì˜ë¯¸ìˆê²Œ ëŒ€í™”í•˜ê¸° \n",
    "í¥ë¯¸ë¡­ê²Œ: ì´ë¯¸ì§€ì— ëŒ€í•œ í¥ë¯¸ë¡œìš´ ì§ˆë¬¸ì„ ë¨¼ì € ë˜ì ¸ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”\n",
    "ê³µê°í•˜ê¸°: ì‚¬ì§„ì— ëŒ€í•˜ì—¬ ê³µê°ì„ í•˜ê³  ì¹œê·¼í•˜ê²Œ ëŒ€í™”\n",
    "í•˜ë‚˜ì”©ë§Œ: í•œ ë²ˆì— ì§ˆë¬¸ í•˜ë‚˜ë§Œ\n",
    "ìì—°ìŠ¤ëŸ½ê²Œ: ë‹µë³€ì— ë”°ë¼ ì—°ê´€ ì§ˆë¬¸\n",
    "ë”°ëœ»í•˜ê²Œ: ê³µê° í›„ ì§ˆë¬¸, ì‚¬ëŒì˜ ë§ˆìŒì„ ë”°ë“¯í•˜ê²Œ í•´ì£¼ëŠ” ëŒ€í™”ë“¤\"\"\"\n",
    "        \n",
    "        self.conversation_history = [{\"role\": \"system\", \"content\": system_message}]\n",
    "        self.token_count = len(self.tokenizer.encode(system_message))\n",
    "    \n",
    "    def generate_initial_question(self):\n",
    "        \"\"\"ì²« ì§ˆë¬¸ ìƒì„±\"\"\"\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=Config.DEPLOYMENT,\n",
    "            messages=self.conversation_history + [\n",
    "                {\"role\": \"user\", \"content\": \"ì–´ë¥´ì‹ ê»˜ ë”°ë“¯í•˜ê³  ì¹œê·¼í•˜ê²Œ ì‚¬ì§„ì— ëŒ€í•˜ì—¬ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”. 50ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.\"}\n",
    "            ],\n",
    "            max_tokens=512,\n",
    "            temperature=0.8\n",
    "        )\n",
    "        \n",
    "        initial_question = response.choices[0].message.content\n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": initial_question})\n",
    "        self.token_count += len(self.tokenizer.encode(initial_question))\n",
    "        self.last_question = initial_question\n",
    "        \n",
    "        return initial_question\n",
    "\n",
    "    def chat_about_image(self, user_query, with_audio=False):\n",
    "        \"\"\"ëŒ€í™” ì²˜ë¦¬\"\"\"\n",
    "        user_tokens = len(self.tokenizer.encode(user_query))\n",
    "        \n",
    "        # ìŒì„± ë…¹ìŒ ì‹œì‘ (if requested)\n",
    "        audio_file = None\n",
    "        if with_audio:\n",
    "            self.start_recording()\n",
    "        \n",
    "        # ëŒ€í™” í„´ ì €ì¥\n",
    "        if self.last_question:\n",
    "            # ìŒì„± ë…¹ìŒ ì¤‘ì§€ ë° íŒŒì¼ ì €ì¥ (if recording)\n",
    "            if with_audio:\n",
    "                audio_file = self.stop_recording()\n",
    "            \n",
    "            conversation_turn = ConversationTurn(\n",
    "                question=self.last_question,\n",
    "                answer=user_query,\n",
    "                timestamp=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                answer_length=len(user_query.strip()),\n",
    "                audio_file=audio_file if audio_file else \"\"\n",
    "            )\n",
    "            self.conversation_turns.append(conversation_turn)\n",
    "        \n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": user_query})\n",
    "        self.token_count += user_tokens\n",
    "        \n",
    "        # í† í° ì œí•œ í™•ì¸\n",
    "        if self.token_count > self.MAX_TOKENS:\n",
    "            answer = \"ëŒ€í™” ì‹œê°„ì´ ë‹¤ ë˜ì—ˆì–´ìš”. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.\"\n",
    "            self.conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "            return answer, True\n",
    "        \n",
    "        # AI ì‘ë‹µ ìƒì„±\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=Config.DEPLOYMENT,\n",
    "            messages=self.conversation_history,\n",
    "            max_tokens=1024,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        answer = response.choices[0].message.content\n",
    "        \n",
    "        self.conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "        self.token_count += len(self.tokenizer.encode(answer))\n",
    "        self.last_question = answer\n",
    "        \n",
    "        if self.token_count > self.MAX_TOKENS:\n",
    "            return answer, True\n",
    "        \n",
    "        return answer, False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5deb43",
   "metadata": {},
   "source": [
    "# Voice System Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caef8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoiceSystem:\n",
    "    \"\"\"ìŒì„± ì…ì¶œë ¥ ì‹œìŠ¤í…œ\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.speech_key = Config.SPEECH_KEY\n",
    "        self.region = Config.SPEECH_REGION\n",
    "        \n",
    "        # STT ì„¤ì •\n",
    "        self.speech_config = speechsdk.SpeechConfig(subscription=self.speech_key, region=self.region)\n",
    "        self.speech_config.speech_recognition_language = \"ko-KR\"\n",
    "        \n",
    "        # TTS ì„¤ì •\n",
    "        self.tts_voice = \"ko-KR-SunHiNeural\"\n",
    "        \n",
    "        # ì˜¤ë””ì˜¤ í´ë”\n",
    "        self.audio_dir = Path(\"audio_files\")\n",
    "        self.audio_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # pygame ì´ˆê¸°í™”\n",
    "        try:\n",
    "            pygame.mixer.init()\n",
    "            self.audio_enabled = True\n",
    "        except:\n",
    "            self.audio_enabled = False\n",
    "    \n",
    "    def transcribe_speech(self) -> str:\n",
    "        \"\"\"STT: ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜\"\"\"\n",
    "        try:\n",
    "            audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "            speech_recognizer = speechsdk.SpeechRecognizer(\n",
    "                speech_config=self.speech_config, \n",
    "                audio_config=audio_config\n",
    "            )\n",
    "            \n",
    "            print(\"ğŸ™ï¸ ë§ì”€í•´ ì£¼ì„¸ìš”...\")\n",
    "            result = speech_recognizer.recognize_once()\n",
    "            \n",
    "            if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "                recognized_text = result.text.strip()\n",
    "                print(f\"ğŸ‘¤ \\\"{recognized_text}\\\"\")\n",
    "                \n",
    "                # ì¢…ë£Œ ëª…ë ¹ì–´ ê°ì§€\n",
    "                exit_commands = ['ì¢…ë£Œ', 'ê·¸ë§Œ', 'ë', 'ë‚˜ê°€ê¸°', 'exit', 'quit', 'stop']\n",
    "                cleaned_text = recognized_text.lower().replace(' ', '').replace('.', '')\n",
    "                \n",
    "                for exit_cmd in exit_commands:\n",
    "                    if exit_cmd.lower() in cleaned_text:\n",
    "                        return \"ì¢…ë£Œ\"\n",
    "                \n",
    "                return recognized_text\n",
    "            else:\n",
    "                print(\"âŒ ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”.\")\n",
    "                return \"\"\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "    \n",
    "    def get_access_token(self):\n",
    "        \"\"\"Azure Speech Service ì•¡ì„¸ìŠ¤ í† í° ìš”ì²­\"\"\"\n",
    "        url = f\"https://{self.region}.api.cognitive.microsoft.com/sts/v1.0/issueToken\"\n",
    "        headers = {\"Ocp-Apim-Subscription-Key\": self.speech_key}\n",
    "        try:\n",
    "            res = requests.post(url, headers=headers)\n",
    "            res.raise_for_status()\n",
    "            return res.text\n",
    "        except Exception:\n",
    "            return None\n",
    "    \n",
    "    def synthesize_speech(self, text: str) -> str:\n",
    "        \"\"\"TTS: í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì¬ìƒ\"\"\"\n",
    "        if not text.strip():\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            token = self.get_access_token()\n",
    "            if not token:\n",
    "                return None\n",
    "                \n",
    "            tts_url = f\"https://{self.region}.tts.speech.microsoft.com/cognitiveservices/v1\"\n",
    "            \n",
    "            headers = {\n",
    "                \"Authorization\": f\"Bearer {token}\",\n",
    "                \"Content-Type\": \"application/ssml+xml\",\n",
    "                \"X-Microsoft-OutputFormat\": \"riff-16khz-16bit-mono-pcm\",\n",
    "                \"User-Agent\": \"DementiaAnalysisSystem\"\n",
    "            }\n",
    "            \n",
    "            ssml = f\"\"\"\n",
    "            <speak version='1.0' xml:lang='ko-KR'>\n",
    "                <voice xml:lang='ko-KR' xml:gender='Female' name='{self.tts_voice}'>\n",
    "                    {text}\n",
    "                </voice>\n",
    "            </speak>\n",
    "            \"\"\"\n",
    "            \n",
    "            res = requests.post(tts_url, headers=headers, data=ssml.encode(\"utf-8\"))\n",
    "            res.raise_for_status()\n",
    "            \n",
    "            # ìŒì„± íŒŒì¼ ì €ì¥\n",
    "            timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_path = self.audio_dir / f\"tts_{timestamp}.wav\"\n",
    "            \n",
    "            with open(output_path, \"wb\") as f:\n",
    "                f.write(res.content)\n",
    "            \n",
    "            # ìŒì„± ì¬ìƒ\n",
    "            if self.audio_enabled:\n",
    "                try:\n",
    "                    pygame.mixer.music.load(str(output_path))\n",
    "                    pygame.mixer.music.play()\n",
    "                    while pygame.mixer.music.get_busy():\n",
    "                        time.sleep(0.1)\n",
    "                except Exception:\n",
    "                    pass\n",
    "            \n",
    "            return str(output_path)\n",
    "            \n",
    "        except Exception:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc84aef",
   "metadata": {},
   "source": [
    "# Story Telling / Report System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c83c2a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoryGenerator:\n",
    "    def __init__(self, chat_system):\n",
    "        self.chat_system = chat_system\n",
    "        self.client = chat_system.client\n",
    "        self.strange_responses = []\n",
    "        self.rule_based_alerts = []\n",
    "        self.conversation_id = \"\"\n",
    "    \n",
    "    def _create_conversation_folders(self, image_path):\n",
    "        image_basename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        \n",
    "        # conversation_log/{ì´ë¯¸ì§€ëª…}/ í´ë” ìƒì„±\n",
    "        image_dir = Path(\"conversation_log\") / image_basename\n",
    "        image_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # ê¸°ì¡´ ëŒ€í™” í´ë”ë“¤ í™•ì¸í•˜ì—¬ ë‹¤ìŒ ë²ˆí˜¸ ê²°ì •\n",
    "        existing_dirs = list(image_dir.glob(f\"{image_basename}_conv*\"))\n",
    "        conv_number = len(existing_dirs) + 1\n",
    "        \n",
    "        # ëŒ€í™” ID: {ì´ë¯¸ì§€ëª…}_conv{ë²ˆí˜¸}\n",
    "        self.conversation_id = f\"{image_basename}_conv{conv_number}\"\n",
    "        \n",
    "        # ëŒ€í™”ë³„ í´ë”: {ì´ë¯¸ì§€ëª…}_conv{ë²ˆí˜¸}/\n",
    "        conversation_dir = image_dir / self.conversation_id\n",
    "        conversation_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        print(f\"ğŸ“ ì €ì¥ êµ¬ì¡°:\")\n",
    "        print(f\"   ë©”ì¸ í´ë”: conversation_log/{image_basename}/{self.conversation_id}/\")\n",
    "        print(f\"   ëŒ€í™” íŒŒì¼: {self.conversation_id}.txt\")\n",
    "        return conversation_dir\n",
    "    \n",
    "    def _save_individual_qa_pairs(self, conversation_dir):\n",
    "        \"\"\"ê°œë³„ ì§ˆì˜ì‘ë‹µ ìŒ ì €ì¥ - ê°„ì†Œí™”ëœ í˜•ì‹\"\"\"\n",
    "        for i, turn in enumerate(self.chat_system.conversation_turns, 1):\n",
    "            qa_filename = conversation_dir / f\"qa_{i:02d}.txt\"\n",
    "            \n",
    "            with open(qa_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(f\"=== ì§ˆì˜ì‘ë‹µ {i}ë²ˆ ===\\n\")\n",
    "                f.write(f\"ëŒ€í™” ID: {self.conversation_id}\\n\")\n",
    "                f.write(f\"ì‹œê°„: {turn.timestamp}\\n\")\n",
    "                f.write(f\"{'='*25}\\n\\n\")\n",
    "                f.write(f\"ğŸ¤– ì§ˆë¬¸:\\n{turn.question}\\n\\n\")\n",
    "                f.write(f\"ğŸ‘¤ ë‹µë³€:\\n{turn.answer}\\n\")\n",
    "                f.write(f\"{'='*25}\\n\")\n",
    "    \n",
    "    def _load_qa_pairs_for_report(self, pairs_dir):\n",
    "        qa_files = sorted([f for f in pairs_dir.glob(\"qa_*.txt\")])\n",
    "        qa_data = []\n",
    "        for qa_file in qa_files:\n",
    "            try:\n",
    "                with open(qa_file, 'r', encoding='utf-8') as f:\n",
    "                    qa_data.append({'file': qa_file.name, 'content': f.read()})\n",
    "            except Exception:\n",
    "                continue\n",
    "        return qa_data\n",
    "    \n",
    "    def analyze_speech_patterns(self):\n",
    "        if not self.chat_system.conversation_turns:\n",
    "            return\n",
    "        \n",
    "        patterns = {\n",
    "            'severe_depression': [\"ì£½ê³ ì‹¶\", \"ì‚´ê¸°ì‹«\", \"ì˜ë¯¸ì—†\", \"í¬ê¸°í•˜ê³ ì‹¶\", \"ì§€ì³¤\", \"í˜ë“¤ì–´ì£½ê² \", \"ì„¸ìƒì´ì‹«\", \"ì ˆë§\"],\n",
    "            'severe_anxiety': [\"ë¬´ì„œì›Œì£½ê² \", \"ë¶ˆì•ˆí•´ë¯¸ì³\", \"ê±±ì •ë¼ì£½ê² \", \"ë‘ë ¤ì›Œ\", \"ìˆ¨ë§‰í˜€\", \"ê³µí™©\", \"íŒ¨ë‹‰\"],\n",
    "            'severe_anger': [\"í™”ë‚˜ì£½ê² \", \"ë¯¸ì³ë²„ë¦¬ê² \", \"ì§œì¦ë‚˜ì£½ê² \", \"ì—´ë°›ì•„\", \"ë¹¡ì³\", \"ë¶„í•´\", \"ì°¸ì„ìˆ˜ì—†\"],\n",
    "            'cognitive_decline': [\"ê¸°ì–µì•ˆë‚˜\", \"ëª¨ë¥´ê² \", \"ìŠì–´ë²„ë ¸\", \"ìƒê°ì•ˆë‚˜\", \"ê¹Œë¨¹ì—ˆ\", \"í—·ê°ˆë ¤\", \"ëˆ„êµ¬ì˜€ëŠ”ì§€\", \"ëª°ë¼\"]\n",
    "        }\n",
    "        \n",
    "        memory_issues = very_short_answers = meaningless_answers = 0\n",
    "        repetitive_patterns = []\n",
    "        \n",
    "        for i, turn in enumerate(self.chat_system.conversation_turns):\n",
    "            answer = turn.answer.replace(\" \", \"\").lower()\n",
    "            \n",
    "            for pattern_type, keywords in patterns.items():\n",
    "                for keyword in keywords:\n",
    "                    if keyword in answer:\n",
    "                        severity = \"critical\" if pattern_type == 'severe_depression' else \"high\"\n",
    "                        self.rule_based_alerts.append({\n",
    "                            \"type\": pattern_type,\n",
    "                            \"turn_number\": i + 1,\n",
    "                            \"keyword\": keyword,\n",
    "                            \"answer\": turn.answer,\n",
    "                            \"timestamp\": turn.timestamp,\n",
    "                            \"severity\": severity\n",
    "                        })\n",
    "                        if pattern_type == 'cognitive_decline':\n",
    "                            memory_issues += 1\n",
    "            \n",
    "            if len(turn.answer.strip()) <= 5:\n",
    "                very_short_answers += 1\n",
    "            \n",
    "            if turn.answer.strip() in [\"ìŒ\", \"ì–´\", \"ê·¸ëƒ¥\", \"ë„¤\", \"ì•„ë‹ˆ\", \"ì‘\", \"ì–´?\"]:\n",
    "                meaningless_answers += 1\n",
    "            \n",
    "            if i >= 3:\n",
    "                recent_answers = [t.answer.strip() for t in self.chat_system.conversation_turns[i-3:i]]\n",
    "                if turn.answer.strip() in recent_answers:\n",
    "                    repetitive_patterns.append(i + 1)\n",
    "        \n",
    "        total_turns = len(self.chat_system.conversation_turns)\n",
    "        \n",
    "        thresholds = [\n",
    "            (memory_issues >= total_turns * 0.7, \"severe_memory_loss\", \"critical\", f\"ì „ì²´ {total_turns}íšŒ ì¤‘ {memory_issues}íšŒ ê¸°ì–µ ë¬¸ì œ\"),\n",
    "            (very_short_answers >= total_turns * 0.8, \"communication_difficulty\", \"high\", f\"ì „ì²´ {total_turns}íšŒ ì¤‘ {very_short_answers}íšŒ ì§§ì€ ë‹µë³€\"),\n",
    "            (meaningless_answers >= total_turns * 0.6, \"cognitive_confusion\", \"high\", f\"ì „ì²´ {total_turns}íšŒ ì¤‘ {meaningless_answers}íšŒ ë¬´ì˜ë¯¸í•œ ë‹µë³€\"),\n",
    "            (len(repetitive_patterns) >= 3, \"repetitive_behavior\", \"moderate\", f\"ë‹µë³€ ë°˜ë³µ {len(repetitive_patterns)}íšŒ\")\n",
    "        ]\n",
    "        \n",
    "        for condition, alert_type, severity, description in thresholds:\n",
    "            if condition:\n",
    "                self.rule_based_alerts.append({\"type\": alert_type, \"description\": description, \"severity\": severity})\n",
    "\n",
    "    def calculate_ratings(self):\n",
    "        total_responses = len(self.chat_system.conversation_turns)\n",
    "        strange_count = len(self.strange_responses)\n",
    "        \n",
    "        if total_responses == 0:\n",
    "            return {\"emotion\": 3, \"coherence\": 3, \"overall\": 3}\n",
    "        \n",
    "        emotions = [turn.emotion for turn in self.chat_system.conversation_turns if hasattr(turn, 'emotion')]\n",
    "        emotion_counts = {}\n",
    "        for emotion in emotions:\n",
    "            emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1\n",
    "        \n",
    "        positive_emotions = [\"ê¸°ì¨\", \"ê·¸ë¦¬ì›€\", \"ê°ì‚¬\", \"ì• ì •\", \"í¥ë¯¸\"]\n",
    "        negative_emotions = [\"ìŠ¬í””\", \"ë¬´ë ¥ê°\", \"ìš°ìš¸ê°\", \"ë¶„ë…¸\", \"ë¶ˆì•ˆ\", \"ì§œì¦\"]\n",
    "        \n",
    "        positive_count = sum(emotion_counts.get(e, 0) for e in positive_emotions)\n",
    "        negative_count = sum(emotion_counts.get(e, 0) for e in negative_emotions)\n",
    "        \n",
    "        critical_emotion_alerts = [alert for alert in self.rule_based_alerts \n",
    "                                 if alert.get('severity') == 'critical' and \n",
    "                                 alert.get('type') in ['severe_depression', 'severe_anxiety', 'severe_anger']]\n",
    "        \n",
    "        if len(critical_emotion_alerts) > 0:\n",
    "            emotion_rating = 1\n",
    "        elif negative_count > positive_count * 2:\n",
    "            emotion_rating = 2\n",
    "        elif negative_count > positive_count:\n",
    "            emotion_rating = 3\n",
    "        elif positive_count > negative_count:\n",
    "            emotion_rating = 4\n",
    "        else:\n",
    "            emotion_rating = 5 if positive_count > negative_count * 2 else 3\n",
    "        \n",
    "        strange_percentage = (strange_count / total_responses * 100) if total_responses > 0 else 0\n",
    "        severe_count = sum(1 for resp in self.strange_responses if resp.severity == 'severe')\n",
    "        \n",
    "        if strange_percentage == 0:\n",
    "            coherence_rating = 5\n",
    "        elif strange_percentage <= 20 and severe_count == 0:\n",
    "            coherence_rating = 4\n",
    "        elif strange_percentage <= 40 and severe_count <= 1:\n",
    "            coherence_rating = 3\n",
    "        elif strange_percentage <= 60 or severe_count <= 2:\n",
    "            coherence_rating = 2\n",
    "        else:\n",
    "            coherence_rating = 1\n",
    "        \n",
    "        answer_qualities = [turn.answer_quality for turn in self.chat_system.conversation_turns if hasattr(turn, 'answer_quality')]\n",
    "        quality_counts = {\"poor\": 0, \"normal\": 0, \"good\": 0, \"excellent\": 0}\n",
    "        for quality in answer_qualities:\n",
    "            quality_counts[quality] += 1\n",
    "        \n",
    "        excellent_percentage = (quality_counts[\"excellent\"] / total_responses * 100) if total_responses > 0 else 0\n",
    "        good_percentage = (quality_counts[\"good\"] / total_responses * 100) if total_responses > 0 else 0\n",
    "        poor_percentage = (quality_counts[\"poor\"] / total_responses * 100) if total_responses > 0 else 0\n",
    "        \n",
    "        critical_cognitive_alerts = [alert for alert in self.rule_based_alerts \n",
    "                                   if alert.get('severity') == 'critical' and \n",
    "                                   alert.get('type') in ['severe_memory_loss', 'communication_difficulty']]\n",
    "        \n",
    "        if len(critical_cognitive_alerts) > 0 or poor_percentage >= 50:\n",
    "            overall_rating = 1\n",
    "        elif poor_percentage >= 30 or (strange_percentage > 50 and severe_count >= 2):\n",
    "            overall_rating = 2\n",
    "        elif excellent_percentage >= 30 or (good_percentage >= 50 and strange_percentage <= 20):\n",
    "            overall_rating = 5\n",
    "        elif good_percentage >= 30 or strange_percentage <= 30:\n",
    "            overall_rating = 4\n",
    "        else:\n",
    "            overall_rating = 3\n",
    "        \n",
    "        return {\"emotion\": emotion_rating, \"coherence\": coherence_rating, \"overall\": overall_rating}\n",
    "    \n",
    "    def format_star_rating(self, rating):\n",
    "        stars = \"â­\" * rating + \"â˜†\" * (5 - rating)\n",
    "        return f\"{stars} ({rating}/5)\"\n",
    "\n",
    "    def analyze_entire_conversation(self):\n",
    "        if not self.chat_system.conversation_turns:\n",
    "            return\n",
    "        \n",
    "        self.strange_responses = []\n",
    "        self.rule_based_alerts = []\n",
    "        self.analyze_speech_patterns()\n",
    "        \n",
    "        conversation_text = \"\"\n",
    "        for i, turn in enumerate(self.chat_system.conversation_turns, 1):\n",
    "            conversation_text += f\"[{i}] ì§ˆë¬¸: {turn.question}\\në‹µë³€: {turn.answer} (ê¸¸ì´: {turn.answer_length}ì)\\n\\n\"\n",
    "        \n",
    "        analysis_prompt = f\"\"\"ì¹˜ë§¤ í™˜ì ëŒ€í™” ë¶„ì„í•˜ì—¬ JSON ì‘ë‹µ:\n",
    "{conversation_text}\n",
    "\n",
    "JSON: {{\"conversation_analysis\": [{{\"turn_number\": 1, \"is_strange\": true/false, \"severity\": \"normal/mild/moderate/severe\", \"emotion\": \"ê°ì •\", \"answer_quality\": \"poor/normal/good/excellent\", \"reason\": \"ì´ìœ \"}}], \"overall_assessment\": {{\"dominant_emotion\": \"ì£¼ìš”ê°ì •\", \"cognitive_level\": \"normal/mild_concern/moderate_concern/severe_concern\"}}}}\n",
    "\n",
    "ê°ì •: ê¸°ì¨,ìŠ¬í””,ê·¸ë¦¬ì›€,ë¬´ë ¥ê°,ìš°ìš¸ê°,ë¶„ë…¸,ë¶ˆì•ˆ,ì¤‘ë¦½,ê°ì‚¬,ì• ì •,í¥ë¯¸,ì§œì¦\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=Config.DEPLOYMENT,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ì¹˜ë§¤ í™˜ì ëŒ€í™” ë¶„ì„ ì „ë¬¸ AI\"},\n",
    "                    {\"role\": \"user\", \"content\": analysis_prompt}\n",
    "                ],\n",
    "                max_tokens=1024,\n",
    "                temperature=0.1\n",
    "            )\n",
    "            \n",
    "            analysis_text = response.choices[0].message.content\n",
    "            \n",
    "            if \"```json\" in analysis_text:\n",
    "                json_start = analysis_text.find(\"```json\") + 7\n",
    "                json_end = analysis_text.find(\"```\", json_start)\n",
    "                analysis_text = analysis_text[json_start:json_end].strip()\n",
    "            elif \"{\" in analysis_text:\n",
    "                json_start = analysis_text.find(\"{\")\n",
    "                json_end = analysis_text.rfind(\"}\") + 1\n",
    "                analysis_text = analysis_text[json_start:json_end]\n",
    "            \n",
    "            analysis_result = json.loads(analysis_text)\n",
    "            \n",
    "            conversation_analyses = analysis_result.get(\"conversation_analysis\", [])\n",
    "            for i, analysis in enumerate(conversation_analyses):\n",
    "                if i < len(self.chat_system.conversation_turns):\n",
    "                    turn = self.chat_system.conversation_turns[i]\n",
    "                    turn.emotion = analysis.get(\"emotion\", \"ì¤‘ë¦½\")\n",
    "                    turn.answer_quality = analysis.get(\"answer_quality\", \"normal\")\n",
    "                    \n",
    "                    if analysis.get(\"is_strange\", False):\n",
    "                        strange_response = StrangeResponse(\n",
    "                            question=turn.question,\n",
    "                            answer=turn.answer,\n",
    "                            timestamp=turn.timestamp,\n",
    "                            severity=analysis.get(\"severity\", \"mild\"),\n",
    "                            emotion=turn.emotion,\n",
    "                            answer_quality=turn.answer_quality\n",
    "                        )\n",
    "                        self.strange_responses.append(strange_response)\n",
    "            \n",
    "            return analysis_result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return None\n",
    "        \n",
    "    def generate_story_from_conversation(self, image_path):\n",
    "        conversation_text = \"\"\n",
    "        for turn in self.chat_system.conversation_turns:\n",
    "            conversation_text += f\"ì§ˆë¬¸: {turn.question}\\në‹µë³€: {turn.answer}\\n\\n\"\n",
    "        \n",
    "        if not conversation_text.strip():\n",
    "            return None, None\n",
    "        \n",
    "        story_prompt = f\"\"\"ëŒ€í™” ê¸°ë°˜ìœ¼ë¡œ ì–´ë¥´ì‹  1ì¸ì¹­ ì¶”ì–µ ìŠ¤í† ë¦¬ 15ì¤„ ì‘ì„±:\n",
    "{conversation_text}\n",
    "ì§€ì¹¨: ë‹µë³€ ê¸°ë°˜ ì‘ì„±, ê°ì •ê³¼ ê°ê° í¬í•¨, ë”°ëœ»í•œ í†¤, ì†ì/ì†ë…€ì—ê²Œ ë“¤ë ¤ì£¼ëŠ” ì–´íˆ¬\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=Config.DEPLOYMENT,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ë…¸ì¸ ì¶”ì–µ ìŠ¤í† ë¦¬í…”ëŸ¬\"},\n",
    "                    {\"role\": \"user\", \"content\": story_prompt}\n",
    "                ],\n",
    "                max_tokens=512,\n",
    "                temperature=0.8\n",
    "            )\n",
    "            \n",
    "            story = response.choices[0].message.content\n",
    "            story_dir = \"story_telling\"\n",
    "            os.makedirs(story_dir, exist_ok=True)\n",
    "            \n",
    "            image_basename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "            story_filename = os.path.join(story_dir, f\"{image_basename}_story.txt\")\n",
    "            \n",
    "            with open(story_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(story)\n",
    "            \n",
    "            return story, story_filename\n",
    "            \n",
    "        except Exception:\n",
    "            return None, None\n",
    "    \n",
    "    def save_conversation_summary(self, conversation_dir=None):\n",
    "        if conversation_dir:\n",
    "            qa_data = self._load_qa_pairs_for_report(conversation_dir)\n",
    "        \n",
    "        analysis_result = self.analyze_entire_conversation()\n",
    "        total_responses = len(self.chat_system.conversation_turns)\n",
    "        strange_count = len(self.strange_responses)\n",
    "        \n",
    "        if total_responses == 0:\n",
    "            return \"ëŒ€í™”ê°€ ì§„í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        emotions = [turn.emotion for turn in self.chat_system.conversation_turns if hasattr(turn, 'emotion')]\n",
    "        emotion_counts = {}\n",
    "        for emotion in emotions:\n",
    "            emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1\n",
    "        \n",
    "        if emotion_counts:\n",
    "            dominant_emotion = max(emotion_counts, key=emotion_counts.get)\n",
    "            positive_emotions = [\"ê¸°ì¨\", \"ê·¸ë¦¬ì›€\", \"ê°ì‚¬\", \"ì• ì •\", \"í¥ë¯¸\"]\n",
    "            negative_emotions = [\"ìŠ¬í””\", \"ë¬´ë ¥ê°\", \"ìš°ìš¸ê°\", \"ë¶„ë…¸\", \"ë¶ˆì•ˆ\", \"ì§œì¦\"]\n",
    "            \n",
    "            positive_count = sum(emotion_counts.get(e, 0) for e in positive_emotions)\n",
    "            negative_count = sum(emotion_counts.get(e, 0) for e in negative_emotions)\n",
    "            \n",
    "            if positive_count > negative_count:\n",
    "                overall_mood = \"ê¸ì •ì \"\n",
    "                mood_icon = \"ğŸ˜Š\"\n",
    "            elif negative_count > positive_count:\n",
    "                overall_mood = \"ë¶€ì •ì \" \n",
    "                mood_icon = \"ğŸ˜”\"\n",
    "            else:\n",
    "                overall_mood = \"ì¤‘ë¦½ì \"\n",
    "                mood_icon = \"ğŸ˜\"\n",
    "        else:\n",
    "            dominant_emotion = \"ì¤‘ë¦½\"\n",
    "            overall_mood = \"ì¤‘ë¦½ì \"\n",
    "            mood_icon = \"ğŸ˜\"\n",
    "        \n",
    "        critical_alerts = [alert for alert in self.rule_based_alerts if alert.get('severity') == 'critical']\n",
    "        high_alerts = [alert for alert in self.rule_based_alerts if alert.get('severity') == 'high']\n",
    "        ratings = self.calculate_ratings()\n",
    "        \n",
    "        summary = f\"\\n{'='*60}\\nğŸ“‹ ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ë¶„ì„ ë¦¬í¬íŠ¸\\n{'='*60}\\n\"\n",
    "        summary += f\"ğŸ“… ë¶„ì„ ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}\\n\"\n",
    "        summary += f\"ğŸ†” ëŒ€í™” ID: {self.conversation_id}\\n{'='*60}\\n\\n\"\n",
    "        \n",
    "        summary += f\"ğŸ¯ ì¢…í•© í‰ê°€\\n{'â”€'*30}\\n\"\n",
    "        summary += f\"ğŸ˜Š ê°ì • ìƒíƒœ:     {self.format_star_rating(ratings['emotion'])}\\n\"\n",
    "        summary += f\"ğŸ’¬ ë‹µë³€ ì¼ê´€ì„±:   {self.format_star_rating(ratings['coherence'])}\\n\"\n",
    "        summary += f\"ğŸ§  ì „ë°˜ì  ì¸ì§€:   {self.format_star_rating(ratings['overall'])}\\n{'â”€'*30}\\n\\n\"\n",
    "        \n",
    "        summary += f\"ğŸ“Š ëŒ€í™” ê°œìš”\\n{'â”€'*30}\\n\"\n",
    "        summary += f\"ğŸ’¬ ì´ ëŒ€í™” íšŸìˆ˜: {total_responses}íšŒ\\n\"\n",
    "        summary += f\"{mood_icon} ì „ë°˜ì  ê°ì •: {overall_mood} (ì£¼ìš”: {dominant_emotion})\\n\"\n",
    "        summary += f\"{'âœ… ì–´ê¸‹ë‚œ ë‹µë³€: ì—†ìŒ' if strange_count == 0 else f'âš ï¸ ì–´ê¸‹ë‚œ ë‹µë³€: {strange_count}íšŒ'}\\n\"\n",
    "        summary += f\"{'âœ… ë°œí™” íŒ¨í„´: íŠ¹ì´ì‚¬í•­ ì—†ìŒ' if len(self.rule_based_alerts) == 0 else f'ğŸ” ë°œí™” íŒ¨í„´: {len(self.rule_based_alerts)}ê±´ ê´€ì°°'}\"\n",
    "        if len(critical_alerts) > 0:\n",
    "            summary += f\" (âš ï¸ ì£¼ì˜: {len(critical_alerts)}ê±´)\"\n",
    "        summary += f\"\\n{'â”€'*30}\\n\\n\"\n",
    "        \n",
    "        if strange_count == 0 and len(critical_alerts) == 0:\n",
    "            summary += f\"ğŸ‰ ëŒ€í™” ê²°ê³¼\\n{'â”€'*30}\\n\"\n",
    "            summary += f\"âœ… ëŒ€í™” ì¤‘ íŠ¹ë³„íˆ ê±±ì •ë˜ëŠ” ë‹µë³€ì€ ì—†ì—ˆìŠµë‹ˆë‹¤.\\n\"\n",
    "            summary += f\"ğŸ’š ì–´ë¥´ì‹ ê»˜ì„œ ì•ˆì •ì ìœ¼ë¡œ ì˜ ì‘ë‹µí•´ì£¼ì…¨ì–´ìš”.\\n\"\n",
    "            if len(high_alerts) > 0:\n",
    "                summary += f\"ğŸ’¡ ì°¸ê³ : {len(high_alerts)}ë²ˆì˜ ë°œí™” íŒ¨í„´ì´ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤.\\n\"\n",
    "            summary += f\"ğŸŒŸ ì§€ê¸ˆì²˜ëŸ¼ ë”°ëœ»í•œ í™˜ê²½ê³¼ ê¾¸ì¤€í•œ ê´€ì‹¬ ì†ì— ê³„ì‹œë©´ ì¢‹ê² ìŠµë‹ˆë‹¤.\\n\"\n",
    "            summary += f\"{'='*60}\\n\"\n",
    "            return summary\n",
    "        \n",
    "        if len(self.rule_based_alerts) > 0 or strange_count > 0:\n",
    "            summary += f\"ğŸš¨ ì£¼ìš” ë°œê²¬ì‚¬í•­\\n{'â”€'*30}\\n\"\n",
    "            \n",
    "            if len(self.rule_based_alerts) > 0:\n",
    "                alert_types = {\n",
    "                    'severe_depression': 'ğŸ˜” ìš°ìš¸í•œ í‘œí˜„',\n",
    "                    'severe_anxiety': 'ğŸ˜° ë¶ˆì•ˆí•œ í‘œí˜„', \n",
    "                    'severe_anger': 'ğŸ˜¡ í™”ê°€ ë‚œ í‘œí˜„',\n",
    "                    'severe_memory_loss': 'ğŸ§  ê¸°ì–µ ê´€ë ¨ ì–´ë ¤ì›€',\n",
    "                    'communication_difficulty': 'ğŸ’¬ ëŒ€í™” ì–´ë ¤ì›€',\n",
    "                    'cognitive_confusion': 'â“ í˜¼ë€ìŠ¤ëŸ¬ìš´ ë‹µë³€',\n",
    "                    'repetitive_behavior': 'ğŸ”„ ë°˜ë³µë˜ëŠ” ë‹µë³€'\n",
    "                }\n",
    "                \n",
    "                alert_summary = {}\n",
    "                for alert in self.rule_based_alerts:\n",
    "                    alert_name = alert_types.get(alert['type'], f\"âš ï¸ {alert['type']}\")\n",
    "                    alert_summary[alert_name] = alert_summary.get(alert_name, 0) + 1\n",
    "                \n",
    "                for alert_name, count in alert_summary.items():\n",
    "                    summary += f\"{alert_name}: {count}ë²ˆ\\n\"\n",
    "                summary += f\"\\n\"\n",
    "            \n",
    "            if strange_count > 0:\n",
    "                severity_counts = {\"mild\": 0, \"moderate\": 0, \"severe\": 0}\n",
    "                for response in self.strange_responses:\n",
    "                    severity_counts[response.severity] += 1\n",
    "                \n",
    "                summary += f\"ğŸ” ì–´ê¸‹ë‚œ ë‹µë³€ ë¶„ì„:\\n\"\n",
    "                if severity_counts['mild'] > 0:\n",
    "                    summary += f\"  ğŸŸ¡ ì¡°ê¸ˆ ì–´ê¸‹ë‚¨: {severity_counts['mild']}íšŒ\\n\"\n",
    "                if severity_counts['moderate'] > 0:\n",
    "                    summary += f\"  ğŸŸ  ê½¤ ì–´ê¸‹ë‚¨: {severity_counts['moderate']}íšŒ\\n\"\n",
    "                if severity_counts['severe'] > 0:\n",
    "                    summary += f\"  ğŸ”´ ë§ì´ ì–´ê¸‹ë‚¨: {severity_counts['severe']}íšŒ\\n\"\n",
    "                summary += f\"\\n\"\n",
    "            \n",
    "            summary += f\"{'â”€'*30}\\n\\n\"\n",
    "        \n",
    "        if strange_count > 0 and strange_count <= 5:\n",
    "            summary += f\"ğŸ“ ì–´ê¸‹ë‚œ ë‹µë³€ ìƒì„¸\\n{'â”€'*30}\\n\"\n",
    "            for i, response in enumerate(self.strange_responses, 1):\n",
    "                summary += f\"{i}. {response.timestamp}\\n\"\n",
    "                summary += f\"   â“ ì§ˆë¬¸: {response.question}\\n\"\n",
    "                summary += f\"   ğŸ’¬ ë‹µë³€: {response.answer}\\n\"\n",
    "                summary += f\"   ğŸ˜Š ìƒíƒœ: {response.emotion} | ğŸ¯ í’ˆì§ˆ: {response.answer_quality}\\n\\n\"\n",
    "            summary += f\"{'â”€'*30}\\n\\n\"\n",
    "        \n",
    "        summary += f\"ğŸ’¡ ê¶Œì¥ì‚¬í•­\\n{'â”€'*30}\\n\"\n",
    "        \n",
    "        if len(critical_alerts) > 0:\n",
    "            summary += f\"ğŸš¨ ê¸´ê¸‰ ê¶Œì¥ì‚¬í•­:\\n   ì‹¬ê°í•œ ì •ì‹ ê±´ê°• ìœ„í—˜ ì‹ í˜¸ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\\n   ë¹ ë¥¸ ì‹œì¼ ë‚´ë¡œ ì—°ë½ì„ ë“œë¦¬ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.\\n\\n\"\n",
    "            for alert in critical_alerts:\n",
    "                if alert['type'] == 'severe_depression':\n",
    "                    summary += f\"   âš ï¸ ê·¹ì‹¬í•œ ìš°ìš¸ê° í‘œí˜„ ê°ì§€\\n      â†’ ì—°ë½ë“œë ¤ ê¸°ë¶„ì „í™˜ì„ ë„ì™€ë“œë¦¬ì„¸ìš”.\\n\\n\"\n",
    "                elif alert['type'] == 'severe_memory_loss':\n",
    "                    summary += f\"   âš ï¸ ì‹¬ê°í•œ ê¸°ì–µë ¥ ì €í•˜ ê°ì§€\\n      â†’ ê°€ì¡±ê³¼ í•¨ê»˜ ì¶”ì–µì„ ë˜ìƒˆê²¨ë³´ì„¸ìš”.\\n\\n\"\n",
    "        elif len(high_alerts) >= 2:\n",
    "            summary += f\"âš ï¸ ì£¼ì˜ ê¶Œì¥ì‚¬í•­:\\n   ìµœê·¼ ëŒ€í™”ì—ì„œ í˜¼ë€ìŠ¤ëŸ¬ìš´ ë‹µë³€ì´ ìì£¼ ë³´ì˜€ìŠµë‹ˆë‹¤.\\n   ê°€ì¡±ê³¼ í•¨ê»˜ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ ë³´ì‹œê¸¸ ê¶Œì¥í•©ë‹ˆë‹¤.\\n\\n\"\n",
    "        elif len(high_alerts) >= 1:\n",
    "            summary += f\"ğŸ”¶ ì¼ë°˜ ê¶Œì¥ì‚¬í•­:\\n   ì•½ê°„ ê±±ì •ë˜ëŠ” ë‹µë³€ì´ ìˆì—ˆìŠµë‹ˆë‹¤.\\n   ì‹œê°„ì„ ë‚´ì–´ ì•ˆë¶€ ì „í™”ë¥¼ ë“œë ¤ë³´ì„¸ìš”.\\n\\n\"\n",
    "        elif strange_count > 0:\n",
    "            summary += f\"ğŸ’™ ê´€ì‹¬ ê¶Œì¥ì‚¬í•­:\\n   ì „ë°˜ì ìœ¼ë¡œ ì˜ ì‘ë‹µí•´ì£¼ì…¨ì§€ë§Œ, ê°„í˜¹ ì–´ê¸‹ë‚œ ë‹µë³€ì´ ë³´ì…ë‹ˆë‹¤.\\n   ê°€ë³ê²Œë¼ë„ ì£¼ë³€ì˜ ê´€ì‹¬ê³¼ í™•ì¸ì´ ìˆìœ¼ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤.\\n\\n\"\n",
    "        else:\n",
    "            summary += f\"ğŸ’š í›Œë¥­í•œ ìƒíƒœ:\\n   ì–´ë¥´ì‹ ê»˜ì„œ ë¬´ì²™ ì•ˆì •ì ìœ¼ë¡œ ì˜ ì‘ë‹µí•´ì£¼ì…¨ìŠµë‹ˆë‹¤.\\n   ì§€ê¸ˆì²˜ëŸ¼ ë”°ëœ»í•œ í™˜ê²½ê³¼ ê¾¸ì¤€í•œ ê´€ì‹¬ì„ ìœ ì§€í•´ì£¼ì„¸ìš”.\\n\\n\"\n",
    "        \n",
    "        summary += f\"ğŸ  ê°€ì¡±ì„ ìœ„í•œ ì¡°ì–¸\\n{'â”€'*30}\\n\"\n",
    "        \n",
    "        emotion_advice = {\n",
    "            \"ì§œì¦\": \"ğŸ”´ ìµœê·¼ ì§œì¦ìŠ¤ëŸ¬ìš´ ê°ì •ì„ í‘œí˜„í•˜ì…¨ì–´ìš”.\\n   â†’ ê°ì •ì„ ìì—°ìŠ¤ëŸ½ê²Œ í‘œí˜„í•˜ë„ë¡ ë”°ëœ»í•˜ê²Œ ê³µê°í•´ì£¼ì„¸ìš”.\\n   â†’ ìš”ì¦˜ ì–´ë– ì‹ ì§€ ìì£¼ ì•ˆë¶€ë¥¼ ì—¬ì­¤ë³´ì‹œë©´ í° í˜ì´ ë©ë‹ˆë‹¤.\",\n",
    "            \"ìš°ìš¸ê°\": \"ğŸŸ  ìŠ¬í””ì´ë‚˜ ìš°ìš¸ê°ì„ í‘œí˜„í•˜ì…¨ì–´ìš”.\\n   â†’ í•¨ê»˜ ì˜› ì¶”ì–µì„ ë‚˜ëˆ„ê±°ë‚˜ ì¢‹ì•„í•˜ì‹œë˜ ì´ì•¼ê¸°ë¥¼ êº¼ë‚´ë³´ì„¸ìš”.\\n   â†’ ê°ì •ì„ ì•ˆì •ì‹œí‚¤ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\",\n",
    "            \"ìŠ¬í””\": \"ğŸŸ  ìŠ¬í””ì´ë‚˜ ìš°ìš¸ê°ì„ í‘œí˜„í•˜ì…¨ì–´ìš”.\\n   â†’ í•¨ê»˜ ì˜› ì¶”ì–µì„ ë‚˜ëˆ„ê±°ë‚˜ ì¢‹ì•„í•˜ì‹œë˜ ì´ì•¼ê¸°ë¥¼ êº¼ë‚´ë³´ì„¸ìš”.\\n   â†’ ê°ì •ì„ ì•ˆì •ì‹œí‚¤ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\",\n",
    "            \"ë¬´ë ¥ê°\": \"ğŸ˜ ë¬´ê¸°ë ¥í•˜ê±°ë‚˜ ì†Œì™¸ê°ì„ í‘œí˜„í•˜ì…¨ì–´ìš”.\\n   â†’ 'ì–´ë¥´ì‹  ë•ë¶„ì´ì—ìš”'ì²˜ëŸ¼ ì¸ì •í•´ë“œë¦¬ë©´ ìì¡´ê° íšŒë³µì— ë„ì›€ë©ë‹ˆë‹¤.\\n   â†’ í•¨ê»˜ ì˜ë¯¸ ìˆëŠ” í™œë™ì„ í•˜ë©° í˜ì´ ë˜ì–´ ì£¼ì„¸ìš”.\",\n",
    "            \"ë¶„ë…¸\": \"ğŸ˜¡ ê°‘ì‘ìŠ¤ëŸ½ê²Œ í™”ë¥¼ ë‚´ì‹œê±°ë‚˜ ê°•í•œ ì–´ì¡°ë¥¼ ë³´ì´ì…¨ì–´ìš”.\\n   â†’ ê°ì • ë’¤ì— ë¶ˆì•ˆì´ë‚˜ í˜¼ë€ê°ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ ì¡°ìš©íˆ ê³µê°í•´ì£¼ì„¸ìš”.\\n   â†’ í™˜ê²½ì„ ì ê²€í•˜ê³  ë°˜ë³µ ìê·¹ì„ ì¤„ì´ë©´ ì•ˆì •ì— ë„ì›€ë©ë‹ˆë‹¤.\",\n",
    "            \"ë¶ˆì•ˆ\": \"ğŸŸ¤ ë¶ˆì•ˆê°ì„ ëŠë¼ì‹œëŠ” ê²ƒ ê°™ì•„ìš”.\\n   â†’ ì–´ë¥´ì‹ ì˜ ì´ì•¼ê¸°ë¥¼ ì˜ ë“¤ì–´ì£¼ì‹œê³ , ë”°ëœ»í•œ ë§ í•œë§ˆë””ê°€ í° ìœ„ë¡œê°€ ë©ë‹ˆë‹¤.\",\n",
    "            \"ê·¸ë¦¬ì›€\": \"ğŸ’™ ê³¼ê±°ë¥¼ ê·¸ë¦¬ì›Œí•˜ì‹œëŠ” ë§ˆìŒì„ í‘œí˜„í•˜ì…¨ì–´ìš”.\\n   â†’ í•¨ê»˜ ì˜›ë‚  ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ„ê±°ë‚˜ ì¶”ì–µ ì† ì¥ì†Œë‚˜ ì‚¬ëŒë“¤ì— ëŒ€í•´ ëŒ€í™”í•´ë³´ì„¸ìš”.\\n   â†’ ë§ˆìŒì˜ í‰ì•ˆì„ ì°¾ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
    "        }\n",
    "        \n",
    "        if dominant_emotion in emotion_advice:\n",
    "            summary += emotion_advice[dominant_emotion]\n",
    "        elif dominant_emotion in [\"ê¸°ì¨\", \"ê°ì‚¬\", \"ì• ì •\", \"í¥ë¯¸\"]:\n",
    "            summary += \"ğŸ˜Š ê¸ì •ì ì¸ ê°ì •ì„ í‘œí˜„í•˜ì…¨ì–´ìš”. ì •ë§ ì¢‹ë„¤ìš”!\\n   â†’ ì´ëŸ° ë°ì€ ëª¨ìŠµì„ ê³„ì† ìœ ì§€í•˜ì‹¤ ìˆ˜ ìˆë„ë¡ ì¦ê±°ìš´ ëŒ€í™”ì™€ í™œë™ì„ í•¨ê»˜ í•´ë³´ì„¸ìš”.\"\n",
    "        elif dominant_emotion == \"ì¤‘ë¦½\":\n",
    "            summary += \"ğŸ’¬ ëŒ€ë¶€ë¶„ì˜ ëŒ€í™”ì—ì„œ í° ê°ì • ë³€í™” ì—†ì´ ì°¨ë¶„íˆ ì‘ë‹µí•˜ì…¨ì–´ìš”.\\n   â†’ ë¬´ë˜í•´ ë³´ì´ì§€ë§Œ ë‚´ë©´ì˜ ê°ì •ì„ ì˜ í‘œí˜„í•˜ì§€ ëª»í•˜ì‹¤ ìˆ˜ë„ ìˆìœ¼ë‹ˆ\\n   â†’ ë”°ëœ»í•œ ë§ í•œë§ˆë””ê°€ í° ìœ„ë¡œê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
    "        else:\n",
    "            summary += \"ğŸŒˆ ë‹¤ì–‘í•œ ê°ì •ì´ ì„ì—¬ ìˆì—ˆì§€ë§Œ, ì „ë°˜ì ìœ¼ë¡œ ì•ˆì •ì ì¸ í¸ì…ë‹ˆë‹¤.\\n   â†’ ì§€ê¸ˆì²˜ëŸ¼ ê´€ì‹¬ê³¼ ì• ì •ì„ ê¾¸ì¤€íˆ í‘œí˜„í•´ ì£¼ì‹œë©´ ì¢‹ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        summary += f\"\\n{'â”€'*30}\\n\\n\"\n",
    "        summary += f\"ğŸ“ˆ í‰ê°€ ê¸°ì¤€\\n{'â”€'*30}\\n\"\n",
    "        summary += f\"ğŸ˜Š ê°ì • ìƒíƒœ: ê¸ì •ì ì´ê³  ì•ˆì •ì ì¸ ê°ì • í‘œí˜„ì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜\\n\"\n",
    "        summary += f\"ğŸ’¬ ë‹µë³€ ì¼ê´€ì„±: ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì ì ˆí•œ ë‹µë³€ì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜\\n\"\n",
    "        summary += f\"ğŸ§  ì „ë°˜ì  ì¸ì§€: ë‹µë³€ì˜ í’ˆì§ˆê³¼ ì†Œí†µ ëŠ¥ë ¥ì„ ì¢…í•©í•œ ì ìˆ˜\\n\"\n",
    "        summary += f\"{'â”€'*30}\\n\\n\"\n",
    "        summary += f\"{'='*60}\\nğŸ“‹ ë¦¬í¬íŠ¸ ë - ì–´ë¥´ì‹ ì˜ ê±´ê°•ê³¼ í–‰ë³µì„ ìœ„í•´\\n{'='*60}\\n\"\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def save_conversation_to_file(self, image_path=None):\n",
    "        if len(self.strange_responses) == 0 and len(self.rule_based_alerts) == 0:\n",
    "            self.analyze_entire_conversation()\n",
    "        \n",
    "        # í´ë” êµ¬ì¡° ìƒì„±\n",
    "        conversation_dir = self._create_conversation_folders(image_path)\n",
    "        \n",
    "        # ê°œë³„ ì§ˆì˜ì‘ë‹µ ìŒ ì €ì¥ (ê°™ì€ í´ë” ì•ˆì—)\n",
    "        self._save_individual_qa_pairs(conversation_dir)\n",
    "        \n",
    "        # ë©”ì¸ ëŒ€í™” íŒŒì¼ ì €ì¥: {ì´ë¯¸ì§€ëª…}_conv{ë²ˆí˜¸}/{ì´ë¯¸ì§€ëª…}_conv{ë²ˆí˜¸}.txt\n",
    "        conversation_filename = conversation_dir / f\"{self.conversation_id}.txt\"\n",
    "        with open(conversation_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"{'='*50}\\n\")\n",
    "            f.write(f\"ğŸ’¬ ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ê¸°ë¡\\n\")\n",
    "            f.write(f\"{'='*50}\\n\")\n",
    "            f.write(f\"ğŸ†” ëŒ€í™” ID: {self.conversation_id}\\n\")\n",
    "            f.write(f\"ğŸ“Š ì´ ëŒ€í™” ìˆ˜: {len(self.chat_system.conversation_turns)}íšŒ\\n\")\n",
    "            f.write(f\"{'='*50}\\n\\n\")\n",
    "            \n",
    "            # ëŒ€í™” ë‚´ìš©ë§Œ ê°„ë‹¨íˆ ì¶œë ¥ (íƒ€ì„ìŠ¤íƒ¬í”„ + ëŒ€í™”)\n",
    "            for i, turn in enumerate(self.chat_system.conversation_turns, 1):\n",
    "                f.write(f\"[{turn.timestamp}]\\n\")\n",
    "                f.write(f\"ğŸ¤– ì§ˆë¬¸: {turn.question}\\n\")\n",
    "                f.write(f\"ğŸ‘¤ ë‹µë³€: {turn.answer}\\n\")\n",
    "                f.write(f\"{'-'*30}\\n\\n\")\n",
    "        \n",
    "        # analysis í´ë”ì— ë¶„ì„ ë¦¬í¬íŠ¸ ì €ì¥\n",
    "        analysis_dir = Path(\"analysis\")\n",
    "        analysis_dir.mkdir(exist_ok=True)\n",
    "        analysis_filename = analysis_dir / f\"{self.conversation_id}_analysis.txt\"\n",
    "        \n",
    "        with open(analysis_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(self.save_conversation_summary(conversation_dir))\n",
    "        \n",
    "        # ì €ì¥ ì™„ë£Œ ë©”ì‹œì§€\n",
    "        print(f\"\\nâœ… íŒŒì¼ ì €ì¥ ì™„ë£Œ!\")\n",
    "        print(f\"ğŸ“ ëŒ€í™” í´ë”: {conversation_dir}\")\n",
    "        print(f\"ğŸ“„ ëŒ€í™” íŒŒì¼: {conversation_filename}\")\n",
    "        print(f\"ğŸ“Š ë¶„ì„ íŒŒì¼: {analysis_filename}\")\n",
    "        print(f\"ğŸ“‹ QA íŒŒì¼ë“¤: {len(self.chat_system.conversation_turns)}ê°œ\")\n",
    "        \n",
    "        return str(conversation_filename), str(analysis_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f031a9b7",
   "metadata": {},
   "source": [
    "# ì½”ë“œ í†µí•©ë¶€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25bd8c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedDementiaSystem:\n",
    "    \"\"\"ìµœì í™”ëœ ì¹˜ë§¤ ì§„ë‹¨ ì‹œìŠ¤í…œ\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.image_analyzer = ImageAnalyzer()\n",
    "        self.chat_system = ChatSystem()\n",
    "        self.voice_system = VoiceSystem() if Config.SPEECH_KEY else None\n",
    "        self.story_generator = StoryGenerator(self.chat_system)\n",
    "    \n",
    "    def analyze_and_start_conversation(self, image_path):\n",
    "        \"\"\"ì´ë¯¸ì§€ ë¶„ì„ ë° ëŒ€í™” ì‹œì‘\"\"\"\n",
    "        if not os.path.exists(image_path):\n",
    "            return None\n",
    "        \n",
    "        # ì´ë¯¸ì§€ ë¶„ì„\n",
    "        analysis_result = self.image_analyzer.analyze_image(image_path)\n",
    "        if not analysis_result:\n",
    "            return None\n",
    "        \n",
    "        # ëŒ€í™” ì„¤ì •\n",
    "        self.chat_system.setup_conversation_context(analysis_result)\n",
    "        \n",
    "        # ì²« ì§ˆë¬¸ ìƒì„±\n",
    "        initial_question = self.chat_system.generate_initial_question()\n",
    "        \n",
    "        return initial_question\n",
    "    \n",
    "    def generate_complete_analysis(self, image_path):\n",
    "        \"\"\"ì™„ì „í•œ ë¶„ì„ ìƒì„±\"\"\"\n",
    "        print(\"\\nğŸ“Š ì¢…í•© ë¶„ì„ ê²°ê³¼ ìƒì„± ì¤‘...\")\n",
    "        \n",
    "        # 1. ëŒ€í™” ê¸°ë¡ ì €ì¥ (ìƒˆë¡œìš´ í´ë” êµ¬ì¡°)\n",
    "        conversation_file, analysis_file = self.story_generator.save_conversation_to_file(image_path)\n",
    "        \n",
    "        # 2. ì¶”ì–µ ìŠ¤í† ë¦¬ ìƒì„±\n",
    "        story, story_file = self.story_generator.generate_story_from_conversation(image_path)\n",
    "        \n",
    "        # 3. ì½˜ì†”ì— ìš”ì•½ ì¶œë ¥\n",
    "        summary = self.story_generator.save_conversation_summary()\n",
    "        print(summary)\n",
    "        \n",
    "        # 4. ìŠ¤í† ë¦¬ ì¶œë ¥\n",
    "        if story:\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(\"ğŸ“– ìƒì„±ëœ ì¶”ì–µ ì´ì•¼ê¸°\")\n",
    "            print(f\"{'='*50}\")\n",
    "            print(story)\n",
    "            print(f\"{'='*50}\")\n",
    "        \n",
    "        return {\n",
    "            'conversation_file': conversation_file,\n",
    "            'analysis_file': analysis_file,\n",
    "            'story_file': story_file,\n",
    "            'story_content': story,\n",
    "            'summary': summary,\n",
    "            'conversation_id': self.story_generator.conversation_id\n",
    "        }\n",
    "    \n",
    "    def _run_conversation_loop(self, image_path, is_voice=False):\n",
    "        \"\"\"ëŒ€í™” ë£¨í”„ ì‹¤í–‰ (ìŒì„±/í…ìŠ¤íŠ¸ ê³µí†µ)\"\"\"\n",
    "        initial_question = self.analyze_and_start_conversation(image_path)\n",
    "        if not initial_question:\n",
    "            return None\n",
    "        \n",
    "        if is_voice and self.voice_system:\n",
    "            welcome_msg = \"ì•ˆë…•í•˜ì„¸ìš”. ì‚¬ì§„ì„ ë³´ë©° ëŒ€í™”í•´ìš”.\"\n",
    "            print(f\"ğŸ¤– {welcome_msg}\")\n",
    "            self.voice_system.synthesize_speech(welcome_msg)\n",
    "            \n",
    "            print(f\"ğŸ¤– {initial_question}\")\n",
    "            self.voice_system.synthesize_speech(initial_question)\n",
    "        else:\n",
    "            print(f\"ğŸ¤– {initial_question}\")\n",
    "        \n",
    "        conversation_type = \"ìŒì„±\" if is_voice else \"í…ìŠ¤íŠ¸\"\n",
    "        print(f\"\\n\" + \"=\"*40)\n",
    "        print(f\"{'ğŸ™ï¸' if is_voice else 'ğŸ’¬'} {conversation_type} ëŒ€í™” ì‹œì‘!\")\n",
    "        print(f\"ğŸ’¡ {'ì¢…ë£Œë¼ê³  ë§í•˜ë©´' if is_voice else 'exit ë˜ëŠ” ì¢…ë£Œë¥¼ ì…ë ¥í•˜ë©´'} ëë‚©ë‹ˆë‹¤\")\n",
    "        print(\"=\"*40)\n",
    "        \n",
    "        # ëŒ€í™” ë£¨í”„\n",
    "        while True:\n",
    "            if is_voice and self.voice_system:\n",
    "                print(\"ğŸ™ï¸ ë§ì”€í•´ ì£¼ì„¸ìš”...\")\n",
    "                # ìŒì„± ë…¹ìŒ ì‹œì‘\n",
    "                self.chat_system.start_recording()\n",
    "                user_input = self.voice_system.transcribe_speech()\n",
    "                # ìŒì„± ë…¹ìŒ ì¤‘ì§€\n",
    "                audio_file = self.chat_system.stop_recording()\n",
    "                \n",
    "                if not user_input.strip():\n",
    "                    continue\n",
    "                if user_input == \"ì¢…ë£Œ\":\n",
    "                    end_msg = \"ëŒ€í™”ë¥¼ ë§ˆì¹˜ê² ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.\"\n",
    "                    print(f\"ğŸ¤– {end_msg}\")\n",
    "                    self.voice_system.synthesize_speech(end_msg)\n",
    "                    break\n",
    "            else:\n",
    "                user_input = input(\"\\nğŸ‘¤ ë‹µë³€: \").strip()\n",
    "                if user_input.lower() in ['exit', 'ì¢…ë£Œ', 'quit', 'q']:\n",
    "                    print(\"ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "                    break\n",
    "            \n",
    "            # AI ì‘ë‹µ (ìŒì„± ëª¨ë“œì¼ ë•ŒëŠ” ë…¹ìŒëœ ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë³´ ì „ë‹¬)\n",
    "            answer, should_end = self.chat_system.chat_about_image(user_input, with_audio=is_voice)\n",
    "            print(f\"ğŸ¤– {answer}\")\n",
    "            \n",
    "            if is_voice and self.voice_system:\n",
    "                self.voice_system.synthesize_speech(answer)\n",
    "            \n",
    "            if should_end:\n",
    "                end_msg = \"ëŒ€í™” ì‹œê°„ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\"\n",
    "                print(f\"â° {end_msg}\")\n",
    "                if is_voice and self.voice_system:\n",
    "                    self.voice_system.synthesize_speech(end_msg)\n",
    "                break\n",
    "        \n",
    "        # ì¢…í•© ë¶„ì„ ìƒì„±\n",
    "        analysis_results = self.generate_complete_analysis(image_path)\n",
    "        \n",
    "        if analysis_results['conversation_file']:\n",
    "            print(f\"ğŸ“‚ ëŒ€í™”ê¸°ë¡: {analysis_results['conversation_file']}\")\n",
    "            print(f\"ğŸ“Š ë¶„ì„ê²°ê³¼: {analysis_results['analysis_file']}\")\n",
    "            if analysis_results['story_file']:\n",
    "                print(f\"ğŸ“– ìŠ¤í† ë¦¬: {analysis_results['story_file']}\")\n",
    "        return analysis_results\n",
    "    \n",
    "    def voice_conversation(self, image_path):\n",
    "        \"\"\"ìŒì„± ëŒ€í™” ì‹¤í–‰\"\"\"\n",
    "        if not self.voice_system:\n",
    "            return None\n",
    "        return self._run_conversation_loop(image_path, is_voice=True)\n",
    "    \n",
    "    def text_conversation(self, image_path):\n",
    "        \"\"\"í…ìŠ¤íŠ¸ ëŒ€í™” ì‹¤í–‰\"\"\"\n",
    "        return self._run_conversation_loop(image_path, is_voice=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04184284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_voice_conversation():\n",
    "    \"\"\"ìŒì„± ëŒ€í™” ì‹¤í–‰ í•¨ìˆ˜\"\"\"\n",
    "    print(\"=== ğŸ¤ ìŒì„± ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ì‹œìŠ¤í…œ ===\")\n",
    "    \n",
    "    image_path = input(\"ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: \").strip()\n",
    "    \n",
    "    if not image_path or not os.path.exists(image_path):\n",
    "        print(\"âŒ ì˜¬ë°”ë¥¸ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        system = OptimizedDementiaSystem()\n",
    "        \n",
    "        if not system.voice_system:\n",
    "            print(\"âŒ ìŒì„± ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Azure Speech Service í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "            return None\n",
    "        \n",
    "        return system.voice_conversation(image_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}\")\n",
    "        return None\n",
    "\n",
    "def interactive_conversation():\n",
    "    \"\"\"í…ìŠ¤íŠ¸ ëŒ€í™” ì‹¤í–‰ í•¨ìˆ˜\"\"\"\n",
    "    print(\"=== ğŸ’¬ í…ìŠ¤íŠ¸ ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ì‹œìŠ¤í…œ ===\")\n",
    "    \n",
    "    image_path = \"images.jpg\"\n",
    "    \n",
    "    if not image_path or not os.path.exists(image_path):\n",
    "        print(\"âŒ ì˜¬ë°”ë¥¸ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        system = OptimizedDementiaSystem()\n",
    "        return system.text_conversation(image_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3610556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!\n",
      "ğŸ’¡ interactive_conversation() í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•´ë³´ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # í™˜ê²½ í™•ì¸\n",
    "    if not Config.ENDPOINT or not Config.SUBSCRIPTION_KEY:\n",
    "        print(\"âš ï¸ Azure OpenAI ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤:\")\n",
    "        print(\"   - gpt-endpoint\")\n",
    "        print(\"   - gpt-key\")\n",
    "    \n",
    "    if not Config.SPEECH_KEY:\n",
    "        print(\"âš ï¸ ìŒì„± ê¸°ëŠ¥ì„ ìœ„í•´ Azure Speech Service ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤:\")\n",
    "        print(\"   - speech-key\")\n",
    "    \n",
    "    print(\"\\nâœ… ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "    print(\"ğŸ’¡ interactive_conversation() í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•´ë³´ì„¸ìš”!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a4bb057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ğŸ¤ ìŒì„± ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ì‹œìŠ¤í…œ ===\n",
      "ğŸ¤– ì•ˆë…•í•˜ì„¸ìš”. ì‚¬ì§„ì„ ë³´ë©° ëŒ€í™”í•´ìš”.\n",
      "ğŸ¤– \"ì–´ë¥´ì‹ , ì´ëŸ° ì¶•í•˜ ìë¦¬ì— í•¨ê»˜í•˜ì…¨ë˜ ê¸°ì–µì´ ìˆìœ¼ì‹ ê°€ìš”?\"\n",
      "\n",
      "========================================\n",
      "ğŸ™ï¸ ìŒì„± ëŒ€í™” ì‹œì‘!\n",
      "ğŸ’¡ ì¢…ë£Œë¼ê³  ë§í•˜ë©´ ëë‚©ë‹ˆë‹¤\n",
      "========================================\n",
      "ğŸ™ï¸ ë§ì”€í•´ ì£¼ì„¸ìš”...\n",
      "ğŸ‘¤ \"ì•„ë‹ˆ ë‚˜ëŠ” ì´ëŸ° ê¸°ì–µ ì—†ëŠ”ë°?\"\n",
      "ğŸ¤– \"ì•„, ê·¸ëŸ¬ì…¨êµ°ìš”. ê·¸ë˜ë„ ì´ëŸ° í™”ê¸°ì• ì• í•œ ë¶„ìœ„ê¸°ëŠ” ì°¸ ì¢‹ì•„ ë³´ì´ì§€ ì•Šë‚˜ìš”? í˜¹ì‹œ ì¶•í•˜ í–‰ì‚¬ë¼ë©´ ì–´ë–¤ ì¢…ë¥˜ë¥¼ ë– ì˜¬ë¦¬ê²Œ ë˜ì„¸ìš”?\"\n",
      "ğŸ™ï¸ ë§ì”€í•´ ì£¼ì„¸ìš”...\n",
      "ğŸ‘¤ \"ì¶•í•˜ ìë¦¬ë¼ë©´ ë‚˜ëŠ” ë³´í†µ ìƒì¼ì„ ë– ì˜¬ë¥´ì§€?\"\n",
      "ğŸ¤– \"ìƒì¼ì´ë¼ë‹ˆ, ì •ë§ ë”°ëœ»í•˜ê³  íŠ¹ë³„í•œ ë‚ ì´ì£ . ì–´ë¥´ì‹ ê»˜ì„œëŠ” ê¸°ì–µì— ë‚¨ëŠ” ìƒì¼ íŒŒí‹°ê°€ ìˆìœ¼ì…¨ë‚˜ìš”?\"\n",
      "ğŸ™ï¸ ë§ì”€í•´ ì£¼ì„¸ìš”...\n",
      "ğŸ‘¤ \"ì¢…ë£Œ.\"\n",
      "ğŸ¤– ëŒ€í™”ë¥¼ ë§ˆì¹˜ê² ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“Š ì¢…í•© ë¶„ì„ ê²°ê³¼ ìƒì„± ì¤‘...\n",
      "ğŸ“ ì €ì¥ êµ¬ì¡°:\n",
      "   ë©”ì¸ í´ë”: conversation_log/images/images_conv2/\n",
      "   ëŒ€í™” íŒŒì¼: images_conv2.txt\n",
      "\n",
      "âœ… íŒŒì¼ ì €ì¥ ì™„ë£Œ!\n",
      "ğŸ“ ëŒ€í™” í´ë”: conversation_log\\images\\images_conv2\n",
      "ğŸ“„ ëŒ€í™” íŒŒì¼: conversation_log\\images\\images_conv2\\images_conv2.txt\n",
      "ğŸ“Š ë¶„ì„ íŒŒì¼: analysis\\images_conv2_analysis.txt\n",
      "ğŸ“‹ QA íŒŒì¼ë“¤: 2ê°œ\n",
      "\n",
      "============================================================\n",
      "ğŸ“‹ ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ë¶„ì„ ë¦¬í¬íŠ¸\n",
      "============================================================\n",
      "ğŸ“… ë¶„ì„ ì¼ì‹œ: 2025ë…„ 06ì›” 08ì¼ 00:25:36\n",
      "ğŸ†” ëŒ€í™” ID: images_conv2\n",
      "============================================================\n",
      "\n",
      "ğŸ¯ ì¢…í•© í‰ê°€\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ˜Š ê°ì • ìƒíƒœ:     â­â­â­â­â˜† (4/5)\n",
      "ğŸ’¬ ë‹µë³€ ì¼ê´€ì„±:   â­â­â­â­â­ (5/5)\n",
      "ğŸ§  ì „ë°˜ì  ì¸ì§€:   â­â­â­â­â­ (5/5)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“Š ëŒ€í™” ê°œìš”\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ’¬ ì´ ëŒ€í™” íšŸìˆ˜: 2íšŒ\n",
      "ğŸ˜Š ì „ë°˜ì  ê°ì •: ê¸ì •ì  (ì£¼ìš”: ì¤‘ë¦½)\n",
      "âœ… ì–´ê¸‹ë‚œ ë‹µë³€: ì—†ìŒ\n",
      "âœ… ë°œí™” íŒ¨í„´: íŠ¹ì´ì‚¬í•­ ì—†ìŒ\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ‰ ëŒ€í™” ê²°ê³¼\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "âœ… ëŒ€í™” ì¤‘ íŠ¹ë³„íˆ ê±±ì •ë˜ëŠ” ë‹µë³€ì€ ì—†ì—ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ’š ì–´ë¥´ì‹ ê»˜ì„œ ì•ˆì •ì ìœ¼ë¡œ ì˜ ì‘ë‹µí•´ì£¼ì…¨ì–´ìš”.\n",
      "ğŸŒŸ ì§€ê¸ˆì²˜ëŸ¼ ë”°ëœ»í•œ í™˜ê²½ê³¼ ê¾¸ì¤€í•œ ê´€ì‹¬ ì†ì— ê³„ì‹œë©´ ì¢‹ê² ìŠµë‹ˆë‹¤.\n",
      "============================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "ğŸ“– ìƒì„±ëœ ì¶”ì–µ ì´ì•¼ê¸°\n",
      "==================================================\n",
      "\"ì‘, ì¶•í•˜ ìë¦¬ë¼ë©´ ì—­ì‹œ ìƒì¼ì´ ê°€ì¥ ë¨¼ì € ë– ì˜¤ë¥´ì§€. ë‚´ê°€ ì–´ë¦° ì‹œì ˆì—” ì§€ê¸ˆì²˜ëŸ¼ ëŒ€ë‹¨í•œ ìƒì¼ íŒŒí‹°ëŠ” ì—†ì—ˆì–´. ê·¸ë˜ë„ ê·¸ë•ŒëŠ” ë­ë„ê¹Œ, ì°¸ ì†Œë°•í•˜ê³  ë” ë”°ëœ»í–ˆë˜ ê¸°ì–µì´ì•¼. ë‚´ê°€ ì—´ ì‚´ ë˜ë˜ í•´, ì–´ë¨¸ë‹ˆê°€ ì§ì ‘ ë§Œë“  ì†ë‘ë¶€ë¥¼ ë‚´ ìƒì¼ìƒì— ì˜¬ë ¤ì£¼ì‹œë˜ ë‚ ì´ ìˆì—ˆì§€. ê·¸ ë‘ë¶€ ìœ„ì— ê°„ì¥ì„ ì‚´ì§ ë¿Œë¦¬ê³ , ê³ ì†Œí•œ ì°¸ê¸°ë¦„ ëƒ„ìƒˆê¹Œì§€ ë”í•´ì§€ë‹ˆ ê·¸ ë§›ì€ ì§€ê¸ˆë„ ìŠíˆì§ˆ ì•Šì•„. ë‹¤ ê°™ì´ ì‹íƒì— ì•‰ì•„ì„œ ì‹êµ¬ë“¤ì´ ì›ƒê³  ë– ë“¤ë©° ë°¥ ë¨¹ë˜ ê·¸ ìˆœê°„ì´ ì •ë§ í–‰ë³µí–ˆê±°ë“ .\"\n",
      "\n",
      "\"ê·¸ë‚ ì€ ë¹„ê°€ ì¡°ê¸ˆì”© ë‚´ë ¸ì—ˆëŠ”ë°, ìš°ë¦¬ ì§‘ ë§ˆë‹¹ì— ìˆëŠ” ëŒ€ì¶”ë‚˜ë¬´ ìì‚¬ê·€ë§ˆë‹¤ ë¹—ë¬¼ì´ ë§ºí˜€ ë°˜ì§ê±°ë¦¬ë˜ ê²Œ ì•„ì§ë„ ëˆˆì— ì„ í•´. ì•„ë²„ì§€ê°€ ê·¸ëŸ¬ì…¨ì–´. 'ì˜¬í•´ëŠ” ëŒ€ì¶”ê°€ ì˜ ì—´ë¦´ ê±°ì•¼,' í•˜ì‹œë©´ì„œ í™˜íˆ ì›ƒìœ¼ì…¨ëŠ”ë°, ê·¸ í‘œì •ì´ ì°¸ ì¢‹ì•˜ì–´. ê°€ì¡±ë“¤ê³¼ í•¨ê»˜ ë¨¹ëŠ” ë”°ëœ»í•œ ë°¥ í•œ ë¼, ê·¸ê²ƒë§Œìœ¼ë¡œë„ ì¶©ë¶„íˆ ì¶•í•˜ë°›ëŠ” ê¸°ë¶„ì´ì—ˆì–´.\"\n",
      "\n",
      "\"ê·¸ë¦¬ê³  ìš°ë¦¬ ë§ˆì„ì—ì„œëŠ” ìƒì¼ë‚  ì¹œêµ¬ë“¤ì´ ì§‘ì— ì™€ì„œ ë‚˜ë¬´ í•œ ê·¸ë£¨ë¥¼ ì‹¬ì–´ì£¼ëŠ” í’ìŠµë„ ìˆì—ˆëŠ”ë°, ë‚´ ìƒì¼ì—ëŠ” ë³µìˆ­ì•„ë‚˜ë¬´ë¥¼ í•˜ë‚˜ ì‹¬ì—ˆì–´. ì†ìœ¼ë¡œ í™ ë§Œì§€ë©´ì„œ í•¨ê»˜ ë•…ì„ ë‹¤ì¡Œë˜ ê·¸ ëŠë‚Œì´ ì•„ì§ë„ ê¸°ì–µë‚˜ë„¤. ê·¸ ë‚˜ë¬´ê°€ ì˜ ìë¼ì„œ ëª‡ ë…„ ë’¤ì— í° ë³µìˆ­ì•„ë¥¼ ì£¼ë ì£¼ë  ì—´ì—ˆì§€! ê·¸ê±¸ ì•„ë²„ì§€ê°€ ë”°ì„œ í•œì… ë² ì–´ë¬¼ë˜ ë‚ , 'ìš°ë¦¬ ì•„ë“¤ì€ ë³µìˆ­ì•„ì²˜ëŸ¼ ë‹¬ì½¤í•œ ì¸ìƒì„ ì‚´ê²Œ ë  ê±°ì•¼' í•˜ì‹œë˜ ë§ì”€ë„ ë§ˆìŒ ê¹Šì´ ìƒˆê²¨ì ¸ ìˆì–´.\"\n",
      "\n",
      "\"ê·¸ë˜ì„œì¸ì§€ ë‚˜ëŠ” ìƒì¼ í•˜ë©´ ëˆ„êµ°ê°€ë¥¼ ì¶•í•˜í•œë‹¤ëŠ” ê²ƒë¿ ì•„ë‹ˆë¼, ê°€ì¡±ì´ í•¨ê»˜í•œë‹¤ëŠ” ê·¸ ë¶„ìœ„ê¸°ê°€ ë– ì˜¬ë¼. ë„ˆí¬ë„ ë‚˜ì¤‘ì— ìƒì¼ì„ ë§ì´í•  ë•Œ, ë­˜ ë¨¹ê³  ì–´ë–»ê²Œ ì¶•í•˜ë°›ë“  ê°€ì¡±ë“¤ì´ í•¨ê»˜ ìˆë‹¤ëŠ” ì‚¬ì‹¤ì´ ì–¼ë§ˆë‚˜ ì†Œì¤‘í•œì§€ ê¼­ ê¸°ì–µí–ˆìœ¼ë©´ ì¢‹ê² êµ¬ë‚˜. ìš”ì¦˜ì€ ìƒì¼ë„ ë” í™”ë ¤í•˜ê²Œ ì¦ê¸°ì§€ë§Œ, ê·¸ ì†\n",
      "==================================================\n",
      "âœ… ëª¨ë“  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ“‚ ëŒ€í™”ê¸°ë¡: conversation_log\\images\\images_conv2\\images_conv2.txt\n",
      "ğŸ“Š ë¶„ì„ê²°ê³¼: analysis\\images_conv2_analysis.txt\n",
      "ğŸ“– ìŠ¤í† ë¦¬: story_telling\\images_story.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'conversation_file': 'conversation_log\\\\images\\\\images_conv2\\\\images_conv2.txt',\n",
       " 'analysis_file': 'analysis\\\\images_conv2_analysis.txt',\n",
       " 'story_file': 'story_telling\\\\images_story.txt',\n",
       " 'story_content': '\"ì‘, ì¶•í•˜ ìë¦¬ë¼ë©´ ì—­ì‹œ ìƒì¼ì´ ê°€ì¥ ë¨¼ì € ë– ì˜¤ë¥´ì§€. ë‚´ê°€ ì–´ë¦° ì‹œì ˆì—” ì§€ê¸ˆì²˜ëŸ¼ ëŒ€ë‹¨í•œ ìƒì¼ íŒŒí‹°ëŠ” ì—†ì—ˆì–´. ê·¸ë˜ë„ ê·¸ë•ŒëŠ” ë­ë„ê¹Œ, ì°¸ ì†Œë°•í•˜ê³  ë” ë”°ëœ»í–ˆë˜ ê¸°ì–µì´ì•¼. ë‚´ê°€ ì—´ ì‚´ ë˜ë˜ í•´, ì–´ë¨¸ë‹ˆê°€ ì§ì ‘ ë§Œë“  ì†ë‘ë¶€ë¥¼ ë‚´ ìƒì¼ìƒì— ì˜¬ë ¤ì£¼ì‹œë˜ ë‚ ì´ ìˆì—ˆì§€. ê·¸ ë‘ë¶€ ìœ„ì— ê°„ì¥ì„ ì‚´ì§ ë¿Œë¦¬ê³ , ê³ ì†Œí•œ ì°¸ê¸°ë¦„ ëƒ„ìƒˆê¹Œì§€ ë”í•´ì§€ë‹ˆ ê·¸ ë§›ì€ ì§€ê¸ˆë„ ìŠíˆì§ˆ ì•Šì•„. ë‹¤ ê°™ì´ ì‹íƒì— ì•‰ì•„ì„œ ì‹êµ¬ë“¤ì´ ì›ƒê³  ë– ë“¤ë©° ë°¥ ë¨¹ë˜ ê·¸ ìˆœê°„ì´ ì •ë§ í–‰ë³µí–ˆê±°ë“ .\"\\n\\n\"ê·¸ë‚ ì€ ë¹„ê°€ ì¡°ê¸ˆì”© ë‚´ë ¸ì—ˆëŠ”ë°, ìš°ë¦¬ ì§‘ ë§ˆë‹¹ì— ìˆëŠ” ëŒ€ì¶”ë‚˜ë¬´ ìì‚¬ê·€ë§ˆë‹¤ ë¹—ë¬¼ì´ ë§ºí˜€ ë°˜ì§ê±°ë¦¬ë˜ ê²Œ ì•„ì§ë„ ëˆˆì— ì„ í•´. ì•„ë²„ì§€ê°€ ê·¸ëŸ¬ì…¨ì–´. \\'ì˜¬í•´ëŠ” ëŒ€ì¶”ê°€ ì˜ ì—´ë¦´ ê±°ì•¼,\\' í•˜ì‹œë©´ì„œ í™˜íˆ ì›ƒìœ¼ì…¨ëŠ”ë°, ê·¸ í‘œì •ì´ ì°¸ ì¢‹ì•˜ì–´. ê°€ì¡±ë“¤ê³¼ í•¨ê»˜ ë¨¹ëŠ” ë”°ëœ»í•œ ë°¥ í•œ ë¼, ê·¸ê²ƒë§Œìœ¼ë¡œë„ ì¶©ë¶„íˆ ì¶•í•˜ë°›ëŠ” ê¸°ë¶„ì´ì—ˆì–´.\"\\n\\n\"ê·¸ë¦¬ê³  ìš°ë¦¬ ë§ˆì„ì—ì„œëŠ” ìƒì¼ë‚  ì¹œêµ¬ë“¤ì´ ì§‘ì— ì™€ì„œ ë‚˜ë¬´ í•œ ê·¸ë£¨ë¥¼ ì‹¬ì–´ì£¼ëŠ” í’ìŠµë„ ìˆì—ˆëŠ”ë°, ë‚´ ìƒì¼ì—ëŠ” ë³µìˆ­ì•„ë‚˜ë¬´ë¥¼ í•˜ë‚˜ ì‹¬ì—ˆì–´. ì†ìœ¼ë¡œ í™ ë§Œì§€ë©´ì„œ í•¨ê»˜ ë•…ì„ ë‹¤ì¡Œë˜ ê·¸ ëŠë‚Œì´ ì•„ì§ë„ ê¸°ì–µë‚˜ë„¤. ê·¸ ë‚˜ë¬´ê°€ ì˜ ìë¼ì„œ ëª‡ ë…„ ë’¤ì— í° ë³µìˆ­ì•„ë¥¼ ì£¼ë ì£¼ë  ì—´ì—ˆì§€! ê·¸ê±¸ ì•„ë²„ì§€ê°€ ë”°ì„œ í•œì… ë² ì–´ë¬¼ë˜ ë‚ , \\'ìš°ë¦¬ ì•„ë“¤ì€ ë³µìˆ­ì•„ì²˜ëŸ¼ ë‹¬ì½¤í•œ ì¸ìƒì„ ì‚´ê²Œ ë  ê±°ì•¼\\' í•˜ì‹œë˜ ë§ì”€ë„ ë§ˆìŒ ê¹Šì´ ìƒˆê²¨ì ¸ ìˆì–´.\"\\n\\n\"ê·¸ë˜ì„œì¸ì§€ ë‚˜ëŠ” ìƒì¼ í•˜ë©´ ëˆ„êµ°ê°€ë¥¼ ì¶•í•˜í•œë‹¤ëŠ” ê²ƒë¿ ì•„ë‹ˆë¼, ê°€ì¡±ì´ í•¨ê»˜í•œë‹¤ëŠ” ê·¸ ë¶„ìœ„ê¸°ê°€ ë– ì˜¬ë¼. ë„ˆí¬ë„ ë‚˜ì¤‘ì— ìƒì¼ì„ ë§ì´í•  ë•Œ, ë­˜ ë¨¹ê³  ì–´ë–»ê²Œ ì¶•í•˜ë°›ë“  ê°€ì¡±ë“¤ì´ í•¨ê»˜ ìˆë‹¤ëŠ” ì‚¬ì‹¤ì´ ì–¼ë§ˆë‚˜ ì†Œì¤‘í•œì§€ ê¼­ ê¸°ì–µí–ˆìœ¼ë©´ ì¢‹ê² êµ¬ë‚˜. ìš”ì¦˜ì€ ìƒì¼ë„ ë” í™”ë ¤í•˜ê²Œ ì¦ê¸°ì§€ë§Œ, ê·¸ ì†',\n",
       " 'summary': '\\n============================================================\\nğŸ“‹ ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ë¶„ì„ ë¦¬í¬íŠ¸\\n============================================================\\nğŸ“… ë¶„ì„ ì¼ì‹œ: 2025ë…„ 06ì›” 08ì¼ 00:25:36\\nğŸ†” ëŒ€í™” ID: images_conv2\\n============================================================\\n\\nğŸ¯ ì¢…í•© í‰ê°€\\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\nğŸ˜Š ê°ì • ìƒíƒœ:     â­â­â­â­â˜† (4/5)\\nğŸ’¬ ë‹µë³€ ì¼ê´€ì„±:   â­â­â­â­â­ (5/5)\\nğŸ§  ì „ë°˜ì  ì¸ì§€:   â­â­â­â­â­ (5/5)\\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\\nğŸ“Š ëŒ€í™” ê°œìš”\\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\nğŸ’¬ ì´ ëŒ€í™” íšŸìˆ˜: 2íšŒ\\nğŸ˜Š ì „ë°˜ì  ê°ì •: ê¸ì •ì  (ì£¼ìš”: ì¤‘ë¦½)\\nâœ… ì–´ê¸‹ë‚œ ë‹µë³€: ì—†ìŒ\\nâœ… ë°œí™” íŒ¨í„´: íŠ¹ì´ì‚¬í•­ ì—†ìŒ\\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\n\\nğŸ‰ ëŒ€í™” ê²°ê³¼\\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\\nâœ… ëŒ€í™” ì¤‘ íŠ¹ë³„íˆ ê±±ì •ë˜ëŠ” ë‹µë³€ì€ ì—†ì—ˆìŠµë‹ˆë‹¤.\\nğŸ’š ì–´ë¥´ì‹ ê»˜ì„œ ì•ˆì •ì ìœ¼ë¡œ ì˜ ì‘ë‹µí•´ì£¼ì…¨ì–´ìš”.\\nğŸŒŸ ì§€ê¸ˆì²˜ëŸ¼ ë”°ëœ»í•œ í™˜ê²½ê³¼ ê¾¸ì¤€í•œ ê´€ì‹¬ ì†ì— ê³„ì‹œë©´ ì¢‹ê² ìŠµë‹ˆë‹¤.\\n============================================================\\n',\n",
       " 'conversation_id': 'images_conv2'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactive_voice_conversation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
